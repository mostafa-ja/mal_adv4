{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv4/blob/main/study_adverserial_examples_RBF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RBF_models\n",
        "\n",
        "download_links = [\n",
        "                  'https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f',\n",
        "                  'https://drive.google.com/uc?id=1-OHACrNCt0yKBbdqQPVfNZcjKt5_jxKD',\n",
        "                  'https://drive.google.com/uc?id=1-KeXJXtU1_6m9JOhormeVwigy0myX3HL',\n",
        "                  'https://drive.google.com/uc?id=1-13RDdZqnrNkdHg3D8PC5KI0CZREwlsz',\n",
        "                  'https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP',\n",
        "\n",
        "]\n",
        "\n",
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM_3KjraHnkn",
        "outputId": "eaf498c6-d0c3-4c1c-c74b-e172ed9fccdb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f\n",
            "From (redirected): https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f&confirm=t&uuid=4e315a3c-a2a3-490b-9a73-d884804d3740\n",
            "To: /content/best_model_gaussian_400.pth\n",
            "100%|██████████| 32.0M/32.0M [00:00<00:00, 32.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-OHACrNCt0yKBbdqQPVfNZcjKt5_jxKD\n",
            "To: /content/best_model_gaussian_600_nonremoval.pth\n",
            "100%|██████████| 5.50M/5.50M [00:00<00:00, 75.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-KeXJXtU1_6m9JOhormeVwigy0myX3HL\n",
            "To: /content/best_model_gaussian_600.pth\n",
            "100%|██████████| 24.0M/24.0M [00:00<00:00, 200MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-13RDdZqnrNkdHg3D8PC5KI0CZREwlsz\n",
            "To: /content/best_model_gaussian_1000_nonremoval.pth\n",
            "100%|██████████| 9.16M/9.16M [00:00<00:00, 44.3MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP\n",
            "From (redirected): https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP&confirm=t&uuid=9d7091a5-10aa-4a86-a798-f970d5f7850b\n",
            "To: /content/best_model_gaussian_1000.pth\n",
            "100%|██████████| 40.0M/40.0M [00:00<00:00, 57.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "download_links = ['https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py'\n",
        "]"
      ],
      "metadata": {
        "id": "1IW4pHac9VLq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kzSbjaXGVeG",
        "outputId": "e26f1c42-7b25-4838-e583-f1821cdc3c97"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz\n",
            "To: /content/sparse_matrix_0.npz\n",
            "100%|██████████| 461k/461k [00:00<00:00, 4.24MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz\n",
            "To: /content/sparse_matrix_1.npz\n",
            "100%|██████████| 148k/148k [00:00<00:00, 2.13MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz\n",
            "To: /content/sparse_matrix_2.npz\n",
            "100%|██████████| 150k/150k [00:00<00:00, 2.51MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz\n",
            "To: /content/sparse_matrix_y0.npz\n",
            "100%|██████████| 5.79k/5.79k [00:00<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz\n",
            "To: /content/sparse_matrix_y1.npz\n",
            "100%|██████████| 2.64k/2.64k [00:00<00:00, 4.47MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz\n",
            "To: /content/sparse_matrix_y2.npz\n",
            "100%|██████████| 2.71k/2.71k [00:00<00:00, 493kB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth\n",
            "To: /content/model_DNN_drebin_best.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 16.4MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth\n",
            "To: /content/model_AT_rFGSM_weightedLoss.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 19.1MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth\n",
            "To: /content/model_AT_rFGSM.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 16.5MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl\n",
            "To: /content/insertion_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 2.14MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl\n",
            "To: /content/removal_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 1.46MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py\n",
            "To: /content/adverserial_attacks_functions.py\n",
            "67.1kB [00:00, 43.3MB/s]                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,balanced_accuracy_score\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "from adverserial_attacks_functions import *\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494f2768-0873-4a7c-c893-015219fe90d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a8e417e1e30>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    #os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX4ncRLLFDnN",
        "outputId": "41fe3822-dbf5-4eda-edcc-2a2607420aea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the .pkl file\n",
        "with open('/content/insertion_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    insertion_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "insertion_array = torch.tensor(insertion_array).to(device)\n",
        "print(len(insertion_array))\n",
        "\n",
        "# Open the .pkl file\n",
        "with open('/content/removal_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    removal_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "removal_array = torch.tensor(removal_array).to(device)\n",
        "print(len(removal_array))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXV0WIjsJG_F",
        "outputId": "e3ed5b4b-21bb-4cb8-9829-d0029734c228"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load dataset\n",
        "X_train = sparse.load_npz(\"/content/sparse_matrix_0.npz\").toarray()\n",
        "X_val = sparse.load_npz(\"/content/sparse_matrix_1.npz\").toarray()\n",
        "X_test = sparse.load_npz(\"/content/sparse_matrix_2.npz\").toarray()\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.int8)\n",
        "X_val = torch.tensor(X_val, dtype=torch.int8)\n",
        "X_test = torch.tensor(X_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "y_train = sparse.load_npz(\"/content/sparse_matrix_y0.npz\").toarray().reshape((-1, 1))\n",
        "y_val = sparse.load_npz(\"/content/sparse_matrix_y1.npz\").toarray().reshape((-1, 1))\n",
        "y_test = sparse.load_npz(\"/content/sparse_matrix_y2.npz\").toarray().reshape((-1, 1))\n",
        "\n",
        "y_train = torch.tensor(y_train, dtype=torch.int8)\n",
        "y_val = torch.tensor(y_val, dtype=torch.int8)\n",
        "y_test = torch.tensor(y_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"x_train:\", X_train.shape)\n",
        "print(\"x_val:\", X_val.shape)\n",
        "print(\"x_test:\", X_test.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"y_val:\", y_val.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5blmEg4h-GKy",
        "outputId": "6910fd22-d96b-4084-aee6-b5850fb34214"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:\n",
            "x_train: torch.Size([28683, 10000])\n",
            "x_val: torch.Size([9562, 10000])\n",
            "x_test: torch.Size([9562, 10000])\n",
            "y_train: torch.Size([28683, 1])\n",
            "y_val: torch.Size([9562, 1])\n",
            "y_test: torch.Size([9562, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of benigns and malicious sample in training dataset\n",
        "n_ben = (y_train.squeeze()== 0).sum().item()\n",
        "n_mal = (y_train.squeeze()== 1).sum().item()\n",
        "print('the proportion of malwares : ', n_mal/(n_mal+n_ben))\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del train_dataset, val_dataset, test_dataset, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81AZSXOV-HoW",
        "outputId": "391d1051-dabf-4dba-b154-3ef64b4216ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the proportion of malwares :  0.11386535578565701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM.load_state_dict(torch.load('model_AT_rFGSM.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE8WMAUgSCms",
        "outputId": "cc57afc8-a69d-4312-9ca4-12586b996516"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RBFModel(nn.Module):\n",
        "    def __init__(self, hidden_dim, output_dim, init_centers, init_sigmas, kernel):\n",
        "        super(RBFModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.centers = nn.Parameter(torch.Tensor(init_centers))\n",
        "        self.sigmas = nn.Parameter(torch.Tensor(init_sigmas))\n",
        "        self.kernel = kernel\n",
        "        # Linear layer for output\n",
        "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def gaussian(self, x, c, sigma):\n",
        "        return torch.exp(-torch.sum((x[:, None, :] - c) ** 2, dim=-1) / (2 * sigma ** 2))\n",
        "\n",
        "    def laplacian(self, x, c, sigma):\n",
        "        return torch.exp(-torch.sum(torch.abs(x[:, None, :] - c) , dim=-1) / sigma)\n",
        "\n",
        "    def forward(self, x):\n",
        "      if self.kernel == 'gaussian':\n",
        "        radial_out = self.gaussian(x, self.centers, self.sigmas)\n",
        "      elif self.kernel == 'laplacian':\n",
        "        radial_out = self.laplacian(x, self.centers, self.sigmas)\n",
        "      else:\n",
        "        raise ValueError(\"Invalid kernel type. Choose 'gaussian' or 'laplacian'.\")\n",
        "\n",
        "      output = self.linear(radial_out.to(torch.float32))\n",
        "      return output\n"
      ],
      "metadata": {
        "id": "WHAI-VGJSGa2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_removal_features = False\n",
        "non_removal_mask = torch.logical_not(removal_array).to('cpu')\n",
        "sigma = 4.15\n",
        "kernel = 'gaussian'\n",
        "all_centers = torch.rand((1000, 10000))\n",
        "model_gaussian_1000 = RBFModel(1000, 2, all_centers, [sigma], kernel)\n",
        "model_gaussian_1000 = model_gaussian_1000.to(device)\n",
        "\n",
        "# Load the model state dictionary\n",
        "model_gaussian_1000.load_state_dict(torch.load('/content/best_model_gaussian_1000.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "id": "W9qJYeK0bbnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab14fbc-eb5b-4710-a614-9c3a7eef345f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_removal_features = True\n",
        "non_removal_mask = torch.logical_not(removal_array).to('cpu')\n",
        "sigma = 4.15\n",
        "kernel = 'gaussian'\n",
        "all_centers = torch.rand((1000, 1144))\n",
        "model_gaussian_1000_nonremoval = RBFModel(1000, 2, all_centers, [sigma], kernel)\n",
        "model_gaussian_1000_nonremoval = model_gaussian_1000_nonremoval.to(device)\n",
        "\n",
        "# Load the model state dictionary\n",
        "model_gaussian_1000_nonremoval.load_state_dict(torch.load('/content/best_model_gaussian_1000_nonremoval.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMA7rzpTPhv7",
        "outputId": "dde0f888-d895-48ec-e4d9-42277f06d6fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in test_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break\n",
        "\n",
        "mals = x[:40][y[:40].squeeze()==1]\n",
        "mals_y = y[:40][y[:40].squeeze()==1]\n",
        "mals.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StL135L1JUiE",
        "outputId": "b319adab-7f3e-4b99-b284-3f4a965a8a8d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 10000])\n",
            "torch.Size([128, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_gaussian_1000(mals)\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "id": "N9WjCVDF5DFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0a4ba9-2905-4b4c-9edd-b2ce2efb016f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0256e-02, 9.8974e-01],\n",
              "        [6.4868e-04, 9.9935e-01],\n",
              "        [6.6529e-04, 9.9933e-01],\n",
              "        [2.0942e-02, 9.7906e-01]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_gaussian_1000_nonremoval(mals[:, non_removal_mask])\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa98a66-2c25-4113-dffe-c2ba04a31e17",
        "id": "dRMeJ6lXP187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0171, 0.9829],\n",
              "        [0.0048, 0.9952],\n",
              "        [0.0023, 0.9977],\n",
              "        [0.0156, 0.9844]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_AT_rFGSM(mals.to(torch.float32))\n",
        "torch.softmax(outputs, dim=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snm7-klbKI0k",
        "outputId": "3ea8820d-7610-45ab-c726-db179b21731d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5196e-18, 1.0000e+00],\n",
              "        [2.3834e-38, 1.0000e+00],\n",
              "        [5.5222e-26, 1.0000e+00],\n",
              "        [0.0000e+00, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_AT_rFGSM, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuzcco7SL2wA",
        "outputId": "0b4ae1de-ea25-4fe5-ce32-08000b63a80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 75.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgcmZjnlNucd",
        "outputId": "1e4b982c-8574-4eb6-85e3-cef2069e5236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_gaussian_1000(adv)\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmynJJVkNwI5",
        "outputId": "d0bd452e-6786-44ce-aa2a-6b219d30b29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0273, 0.9727],\n",
              "        [0.0608, 0.9392],\n",
              "        [0.0017, 0.9983],\n",
              "        [0.0209, 0.9791]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_gaussian_1000_nonremoval(adv[:, non_removal_mask])\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCQP_gWpQGpX",
        "outputId": "3f534972-ebb9-4c61-be68-1fdf561af51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4113, 0.5887],\n",
              "        [0.7621, 0.2379],\n",
              "        [0.3029, 0.6971],\n",
              "        [0.2166, 0.7834]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_AT_rFGSM(adv.to(torch.float32))\n",
        "torch.softmax(outputs, dim=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g336ciLVN6wp",
        "outputId": "766a84fc-f2b6-4152-c53d-e3d935219159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9997e-01, 3.3653e-05],\n",
              "        [9.7767e-01, 2.2329e-02],\n",
              "        [8.8007e-01, 1.1993e-01],\n",
              "        [0.0000e+00, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EK0_fBVRxCb",
        "outputId": "ba70a804-e2e5-4880-b05f-293d5eef921d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.8403,  -5.4591],\n",
              "        [  1.5538,  -2.2255],\n",
              "        [  0.8769,  -1.1162],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gkde(x, y, model, penalty_factor, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural, _ = get_loss_kde(x,y,model, penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        #y_model = model(x_var)\n",
        "        if t > 0:\n",
        "          decayed_penalty_factor = decayed_penalty_factor/2.\n",
        "          print('t : ',t)\n",
        "          print('decayed_penalty_factor : ',decayed_penalty_factor)\n",
        "        else:\n",
        "          decayed_penalty_factor = penalty_factor\n",
        "\n",
        "        # Compute loss\n",
        "        loss, _ = get_loss_kde(x_var,y,model, decayed_penalty_factor)\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            _, done = get_loss_kde(x_next,y,model, penalty_factor)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv, done = get_loss_kde(x_next,y,model, penalty_factor)\n",
        "    loss_adv = loss_adv.data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "rBy2t9Kc5DA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_AT_rFGSM(adv.to(torch.float32))\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeNH2OZiWusD",
        "outputId": "3982e4fb-b2dc-413a-94f6-5d0bcd8481fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9997e-01, 3.3653e-05],\n",
              "        [9.7767e-01, 2.2329e-02],\n",
              "        [8.8007e-01, 1.1993e-01],\n",
              "        [0.0000e+00, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "outputs = model_AT_rFGSM(adv.to(torch.float32))\n",
        "print(outputs)\n",
        "ce = criterion(outputs, mals_y.view(-1).long())\n",
        "print(ce)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlbNKoAoVHSp",
        "outputId": "a394e4aa-c750-4147-fd11-8c5929cd8970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  4.8403,  -5.4591],\n",
            "        [  1.5538,  -2.2255],\n",
            "        [  0.8769,  -1.1162],\n",
            "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)\n",
            "tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "outputs = model_gaussian_1000(adv.to(torch.float32))\n",
        "print(outputs)\n",
        "ce = criterion(outputs, mals_y.view(-1).long())\n",
        "print(ce)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VulPv7cMVec2",
        "outputId": "da71ca45-fd98-453d-e358-134528fac298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.6591,  1.9131],\n",
            "        [-1.2412,  1.4970],\n",
            "        [-3.0718,  3.3226],\n",
            "        [-1.9212,  1.9236]], grad_fn=<AddmmBackward0>)\n",
            "tensor([0.0277, 0.0627, 0.0017, 0.0212], grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_loss_kde(adv.to(torch.float32),mals_y,model_AT_rFGSM, 1.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFLQRmSNUgKJ",
        "outputId": "2d64c7a6-49af-461c-ccf2-af44f49d9767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  4.8403,  -5.4591],\n",
            "        [  1.5538,  -2.2255],\n",
            "        [  0.8769,  -1.1162],\n",
            "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)\n",
            "ce:  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0277, 0.0627, 0.0017, 0.0212], grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10.3271,  3.8646,  2.1225,  0.0212], grad_fn=<AddBackward0>),\n",
              " tensor([ True,  True,  True, False]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model, penalty_factor):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y.view(-1).long())\n",
        "    print('ce: ', ce)\n",
        "    outputs_rbf = model_gaussian_1000(adv_x)\n",
        "    kde = criterion(outputs_rbf, y.view(-1).long())\n",
        "    #kde=0.\n",
        "    print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "gAWNQW7u5LKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_gaussian_1000, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "id": "ntOql6cfTZBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 0.001, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpJNQCSkTQxy",
        "outputId": "297001bb-458f-4d2b-9083-9dbdad42b382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0103, 0.0006, 0.0007, 0.0212], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0103, 0.0006, 0.0007, 0.0212], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([0.0040, 0.0002, 0.0002, 0.0008])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0103, 0.0006, 0.0007, 0.0212], grad_fn=<NllLossBackward0>)\n",
            "t :  1\n",
            "decayed_penalty_factor :  0.0005\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2840, 0.0139, 0.0113, 0.0289], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([0.0473, 0.0023, 0.0018, 0.0005])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2840, 0.0139, 0.0113, 0.0289], grad_fn=<NllLossBackward0>)\n",
            "t :  2\n",
            "decayed_penalty_factor :  0.00025\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1649, 0.2077, 0.1473, 0.0387], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([0.0828, 0.0152, 0.0105, 0.0003])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1649, 0.2077, 0.1473, 0.0387], grad_fn=<NllLossBackward0>)\n",
            "t :  3\n",
            "decayed_penalty_factor :  0.000125\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.8952, 1.3642, 1.0102, 0.0510], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([0.0453, 0.0294, 0.0238, 0.0002])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.8952, 1.3642, 1.0102, 0.0510], grad_fn=<NllLossBackward0>)\n",
            "t :  4\n",
            "decayed_penalty_factor :  6.25e-05\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.2471, 3.2237, 2.7530, 0.0668], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([0.0222, 0.0185, 0.0178, 0.0002])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.2471, 3.2237, 2.7530, 0.0668], grad_fn=<NllLossBackward0>)\n",
            "t :  5\n",
            "decayed_penalty_factor :  3.125e-05\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.3487, 5.0775, 4.6796, 0.0847], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.0829e-02, 9.3228e-03, 9.1865e-03, 9.2622e-05])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.3487, 5.0775, 4.6796, 0.0847], grad_fn=<NllLossBackward0>)\n",
            "t :  6\n",
            "decayed_penalty_factor :  1.5625e-05\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([11.1857,  6.7189,  6.4336,  0.1043], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.3136e-03, 4.5976e-03, 4.5158e-03, 5.5363e-05])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([11.1857,  6.7189,  6.4336,  0.1043], grad_fn=<NllLossBackward0>)\n",
            "t :  7\n",
            "decayed_penalty_factor :  7.8125e-06\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([12.8181,  8.1919,  7.9327,  0.1276], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.5946e-03, 2.2475e-03, 2.2202e-03, 3.4520e-05])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([12.8181,  8.1919,  7.9327,  0.1276], grad_fn=<NllLossBackward0>)\n",
            "t :  8\n",
            "decayed_penalty_factor :  3.90625e-06\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([14.3279,  9.6636,  9.3169,  0.1523], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.2640e-03, 1.1464e-03, 1.0852e-03, 1.9981e-05])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([14.3279,  9.6636,  9.3169,  0.1523], grad_fn=<NllLossBackward0>)\n",
            "t :  9\n",
            "decayed_penalty_factor :  1.953125e-06\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([15.7883, 11.0292, 10.5902,  0.1781], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.4318e-04, 5.5861e-04, 5.2907e-04, 1.1353e-05])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([15.7883, 11.0292, 10.5902,  0.1781], grad_fn=<NllLossBackward0>)\n",
            "t :  10\n",
            "decayed_penalty_factor :  9.765625e-07\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([17.1759, 12.4387, 11.7611,  0.2057], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.1356e-04, 2.8536e-04, 2.5810e-04, 6.3418e-06])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([17.1759, 12.4387, 11.7611,  0.2057], grad_fn=<NllLossBackward0>)\n",
            "t :  11\n",
            "decayed_penalty_factor :  4.8828125e-07\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([18.6486, 13.6986, 12.8367,  0.2342], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.6107e-04, 1.3914e-04, 1.2580e-04, 3.4905e-06])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([18.6486, 13.6986, 12.8367,  0.2342], grad_fn=<NllLossBackward0>)\n",
            "t :  12\n",
            "decayed_penalty_factor :  2.44140625e-07\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([19.9301, 14.9896, 13.8545,  0.2663], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8458e-05, 7.1473e-05, 6.1659e-05, 1.9814e-06])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([19.9301, 14.9896, 13.8545,  0.2663], grad_fn=<NllLossBackward0>)\n",
            "t :  13\n",
            "decayed_penalty_factor :  1.220703125e-07\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([21.1310, 16.1552, 14.8188,  0.3036], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.8428e-05, 3.4820e-05, 3.1182e-05, 1.1432e-06])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([21.1310, 16.1552, 14.8188,  0.3036], grad_fn=<NllLossBackward0>)\n",
            "t :  14\n",
            "decayed_penalty_factor :  6.103515625e-08\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([22.3491, 17.2454, 15.7377,  0.3461], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.9439e-05, 1.7058e-05, 1.5221e-05, 6.5439e-07])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([22.3491, 17.2454, 15.7377,  0.3461], grad_fn=<NllLossBackward0>)\n",
            "t :  15\n",
            "decayed_penalty_factor :  3.0517578125e-08\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([23.5282, 18.3016, 16.5782,  0.3927], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.0687e-05, 8.6304e-06, 7.4469e-06, 3.6809e-07])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([23.5282, 18.3016, 16.5782,  0.3927], grad_fn=<NllLossBackward0>)\n",
            "t :  16\n",
            "decayed_penalty_factor :  1.52587890625e-08\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 19.3880, 17.3629,  0.4427], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 4.4313e-06, 3.6312e-06, 2.0530e-07])\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 19.3880, 17.3629,  0.4427], grad_fn=<NllLossBackward0>)\n",
            "t :  17\n",
            "decayed_penalty_factor :  7.62939453125e-09\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 20.5049, 18.1144,  0.4989], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 2.2752e-06, 1.8038e-06, 1.1547e-07])\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 20.5049, 18.1144,  0.4989], grad_fn=<NllLossBackward0>)\n",
            "t :  18\n",
            "decayed_penalty_factor :  3.814697265625e-09\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 21.6178, 18.8310,  0.5572], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 1.2156e-06, 8.9894e-07, 6.4370e-08])\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 21.6178, 18.8310,  0.5572], grad_fn=<NllLossBackward0>)\n",
            "t :  19\n",
            "decayed_penalty_factor :  1.9073486328125e-09\n",
            "ce:  tensor([2.2319e+00, 3.5763e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.7441, 19.4446,  0.6210], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 3.5608e-03, 4.3983e-07, 3.5543e-08])\n",
            "ce:  tensor([2.2319e+00, 3.5763e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.7441, 19.4446,  0.6210], grad_fn=<NllLossBackward0>)\n",
            "t :  20\n",
            "decayed_penalty_factor :  9.5367431640625e-10\n",
            "ce:  tensor([2.2319, 0.0099, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 21.6747, 23.5219,  0.6851], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 9.1592e+01, 2.6040e-07, 1.8740e-08])\n",
            "ce:  tensor([2.2319, 0.0099, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 21.6747, 23.5219,  0.6851], grad_fn=<NllLossBackward0>)\n",
            "t :  21\n",
            "decayed_penalty_factor :  4.76837158203125e-10\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.1910,  0.7478], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 1.2767e-07, 9.7522e-09])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.1910,  0.7478], grad_fn=<NllLossBackward0>)\n",
            "t :  22\n",
            "decayed_penalty_factor :  2.384185791015625e-10\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.8489,  0.8140], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 6.7697e-08, 5.1992e-09])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.8489,  0.8140], grad_fn=<NllLossBackward0>)\n",
            "t :  23\n",
            "decayed_penalty_factor :  1.1920928955078125e-10\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.4476,  0.8851], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 3.3371e-08, 2.8167e-09])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.4476,  0.8851], grad_fn=<NllLossBackward0>)\n",
            "t :  24\n",
            "decayed_penalty_factor :  5.960464477539063e-11\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.9464,  1.1311], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 3.0244e-08, 1.7617e-09])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.9464,  1.1311], grad_fn=<NllLossBackward0>)\n",
            "t :  25\n",
            "decayed_penalty_factor :  2.980232238769531e-11\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 26.4169,  1.3205], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 3.9103e-08, 1.0039e-09])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 26.4169,  1.3205], grad_fn=<NllLossBackward0>)\n",
            "t :  26\n",
            "decayed_penalty_factor :  1.4901161193847657e-11\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 26.8470,  1.4240], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 5.3413e-08, 5.2946e-10])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 26.8470,  1.4240], grad_fn=<NllLossBackward0>)\n",
            "t :  27\n",
            "decayed_penalty_factor :  7.450580596923828e-12\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 7.1526e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.7683,  1.5345], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 6.6710e-03, 2.8092e-10])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 7.1526e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.7683,  1.5345], grad_fn=<NllLossBackward0>)\n",
            "t :  28\n",
            "decayed_penalty_factor :  3.725290298461914e-12\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 23.2601,  1.6515], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 7.5758e-03, 1.4862e-10])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 23.2601,  1.6515], grad_fn=<NllLossBackward0>)\n",
            "t :  29\n",
            "decayed_penalty_factor :  1.862645149230957e-12\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  1.7732], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 7.7849e-11])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  1.7732], grad_fn=<NllLossBackward0>)\n",
            "t :  30\n",
            "decayed_penalty_factor :  9.313225746154785e-13\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  1.8868], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 4.0661e-11])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  1.8868], grad_fn=<NllLossBackward0>)\n",
            "t :  31\n",
            "decayed_penalty_factor :  4.656612873077393e-13\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  2.0043], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 2.1280e-11])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  2.0043], grad_fn=<NllLossBackward0>)\n",
            "t :  32\n",
            "decayed_penalty_factor :  2.3283064365386963e-13\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  2.1212], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 1.0619e-11])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  2.1212], grad_fn=<NllLossBackward0>)\n",
            "t :  33\n",
            "decayed_penalty_factor :  1.1641532182693482e-13\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  2.2483], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 5.5380e-12])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  2.2483], grad_fn=<NllLossBackward0>)\n",
            "t :  34\n",
            "decayed_penalty_factor :  5.820766091346741e-14\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  8.2252], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 6.4126e-12])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  8.2252], grad_fn=<NllLossBackward0>)\n",
            "t :  35\n",
            "decayed_penalty_factor :  2.9103830456733704e-14\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  8.5204], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 3.2810e-12])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  8.5204], grad_fn=<NllLossBackward0>)\n",
            "t :  36\n",
            "decayed_penalty_factor :  1.4551915228366852e-14\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  8.8227], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 1.6831e-12])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  8.8227], grad_fn=<NllLossBackward0>)\n",
            "t :  37\n",
            "decayed_penalty_factor :  7.275957614183426e-15\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  9.1211], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 8.6351e-13])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  9.1211], grad_fn=<NllLossBackward0>)\n",
            "t :  38\n",
            "decayed_penalty_factor :  3.637978807091713e-15\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  9.4085], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 4.2252e-13])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  9.4085], grad_fn=<NllLossBackward0>)\n",
            "t :  39\n",
            "decayed_penalty_factor :  1.8189894035458565e-15\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  9.6875], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 2.1577e-13])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  9.6875], grad_fn=<NllLossBackward0>)\n",
            "t :  40\n",
            "decayed_penalty_factor :  9.094947017729283e-16\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  9.9516], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 1.0592e-13])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  9.9516], grad_fn=<NllLossBackward0>)\n",
            "t :  41\n",
            "decayed_penalty_factor :  4.547473508864641e-16\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 10.2339], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 5.3943e-14])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 10.2339], grad_fn=<NllLossBackward0>)\n",
            "t :  42\n",
            "decayed_penalty_factor :  2.2737367544323206e-16\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 10.4943], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 2.7639e-14])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 10.4943], grad_fn=<NllLossBackward0>)\n",
            "t :  43\n",
            "decayed_penalty_factor :  1.1368683772161603e-16\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 10.7537], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 1.4145e-14])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 10.7537], grad_fn=<NllLossBackward0>)\n",
            "t :  44\n",
            "decayed_penalty_factor :  5.684341886080802e-17\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 11.0182], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 7.1362e-15])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 11.0182], grad_fn=<NllLossBackward0>)\n",
            "t :  45\n",
            "decayed_penalty_factor :  2.842170943040401e-17\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 11.2812], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 3.6562e-15])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 11.2812], grad_fn=<NllLossBackward0>)\n",
            "t :  46\n",
            "decayed_penalty_factor :  1.4210854715202004e-17\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 11.8195], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 1.9198e-15])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 11.8195], grad_fn=<NllLossBackward0>)\n",
            "t :  47\n",
            "decayed_penalty_factor :  7.105427357601002e-18\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 12.0901], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 9.4005e-16])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 12.0901], grad_fn=<NllLossBackward0>)\n",
            "t :  48\n",
            "decayed_penalty_factor :  3.552713678800501e-18\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 12.3681], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 4.8164e-16])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 12.3681], grad_fn=<NllLossBackward0>)\n",
            "t :  49\n",
            "decayed_penalty_factor :  1.7763568394002505e-18\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 12.6247], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 2.3593e-16])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 12.6247], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 12.8910], grad_fn=<NllLossBackward0>)\n",
            "PGD l1: Attack effectiveness 50.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_gaussian_1000(adv2.to(torch.float32))\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq4PoC1Sdo_e",
        "outputId": "8b406a09-3f11-49c3-8fd5-38c76ba3a6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 12.4715, -12.1819],\n",
            "        [ 11.4356, -11.1617],\n",
            "        [ 12.3292, -12.0853],\n",
            "        [  6.4998,  -6.3911]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_AT_rFGSM(adv2.to(torch.float32))\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS5zPGfId5AL",
        "outputId": "bdfde24b-9070-4e1b-e242-44a28fe294c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0.8798,  -1.2386],\n",
            "        [  1.5130,  -1.9541],\n",
            "        [ -6.5551,   7.1809],\n",
            "        [-29.9500,  31.9684]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_AT_rFGSM(mals.to(torch.float32))\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "id": "Mj5rIgXvgY2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(mals_y.view(-1).long())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzEOZOp9li_p",
        "outputId": "aaedc836-d106-4a10-dad0-3b46910a55da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2, -2, -2, -2])"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "inputs = mals.to(torch.float32).clone().detach().requires_grad_(True)\n",
        "outputs = model_AT_rFGSM(inputs)\n",
        "loss = criterion(outputs, mals_y.view(-1).long())\n",
        "print(loss)\n",
        "\n",
        "\n",
        "grad_vars = torch.autograd.grad(loss.mean(), inputs)\n",
        "gradients = grad_vars[0].data\n",
        "print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH7t193OjDJD",
        "outputId": "9edd7891-8b6d-4bb1-f7a0-3ea36f33e684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.4870e-15, 1.1302e-34, 2.6278e-22, 0.0000e+00])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "inputs = mals.to(torch.float32).clone().detach().requires_grad_(True)\n",
        "outputs = model_AT_rFGSM(inputs)\n",
        "labels = (mals_y.view(-1).long() - 1)\n",
        "loss = criterion(outputs, labels)\n",
        "print(loss)\n",
        "\n",
        "\n",
        "grad_vars = torch.autograd.grad(loss.mean(), inputs)\n",
        "gradients = grad_vars[0].data\n",
        "print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yPLTp_YmKkh",
        "outputId": "20828f44-ea47-42ab-bd51-30ddfe9a1d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vj7PBARTodzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model, penalty_factor):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    print('ce: ', ce)\n",
        "    outputs_rbf = model_gaussian_1000(adv_x)\n",
        "    kde = criterion(outputs_rbf, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    #kde=0.\n",
        "    print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "i8wDOTsZnfFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWBOUPflotzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1UAKciYp9Qj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, torch.zeros_like(mals_y.view(-1).long()))\n",
        "        print('loss : ',loss)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            outputs = model(x_next)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            done = (predicted != y).squeeze()\n",
        "            print(done)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "XdQ-5RbP6oDu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_AT_rFGSM, insertion_array, removal_array, k=500, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlsAkPMhpc7S",
        "outputId": "600fa957-9145-4118-adec-d652bdc78e41"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n",
            "tensor([False, False, False, False])\n",
            "loss :  tensor([ 17.2574,  71.0176,  53.6272, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10475.5771,  8753.7480,  9374.5732,  9018.6055])\n",
            "tensor([False, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 5.5429e+01, 4.4622e+01, 1.5478e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1265e+03, 1.0463e+04, 9.0235e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 4.2018e+01, 3.5233e+01, 1.4863e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.5316e+03, 1.0955e+04, 8.8765e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 3.0319e+01, 2.5832e+01, 1.4469e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.3921e+03, 1.0962e+04, 8.4613e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 1.9540e+01, 1.7143e+01, 1.3839e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1422e+03, 1.1507e+04, 8.3465e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 1.2214e+01, 8.8525e+00, 1.3348e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 8.7310e+03, 1.1474e+04, 8.3465e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 4.0993e+00, 1.3330e+00, 1.2865e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 7.7917e+03, 9.0294e+03, 8.3465e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.2417e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3465e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1939e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1495e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1068e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0643e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0237e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.8351e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.4362e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.0639e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3357e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.7156e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.3935e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3143e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.0755e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.7752e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8621e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.4700e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.1965e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.9337e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3132e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.7578e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8157e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.4789e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8228e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2163e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2845e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2409e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7232e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.9668e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8201e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.7031e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7293e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.4995e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2633e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.2756e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5679e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.0393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.8147e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.7072e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0702e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.4889e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.2713e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.0543e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.8393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9781e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.6430e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.4583e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2908e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3707e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2531e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.4075e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2872e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.4608e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2053e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.8152e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "PGD l1: Attack effectiveness 75.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "        print('loss : ',loss)\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            outputs = model(x_next)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            done = (predicted != y).squeeze()\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "DQicJeD3wLxA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_AT_rFGSM, insertion_array, removal_array, k=500, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a652596-a011-4a8a-f953-fb4a0f4e355b",
        "id": "BCWXhAJ8W46H"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.4870e-15, 1.1302e-34, 2.6278e-22, 0.0000e+00])\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5985e-04, 6.1378e-28, 2.3369e-20, 0.0000e+00])\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 3.7722e-21, 2.1269e-16, 0.0000e+00])\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 2.6399e-15, 2.6725e-12, 0.0000e+00])\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 3.1136e-10, 3.1988e-08, 0.0000e+00])\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 1.4353e-05, 1.9638e-04, 0.0000e+00])\n",
            "loss :  tensor([1.0299e+01, 5.0068e-06, 1.4304e-04, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 4.3532e-02, 1.6415e+00, 0.0000e+00])\n",
            "loss :  tensor([10.2994,  0.0167,  0.3061, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8880.3486,  131.3973, 3233.3621,    0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "PGD l1: Attack effectiveness 75.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gkde(x, y, model,bens, bandwidth, penalty_factor, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural, _ = get_loss_kde(x,y,model,bens, bandwidth, penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        #y_model = model(x_var)\n",
        "        if t > 20:\n",
        "          decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "        else:\n",
        "          decayed_penalty_factor = penalty_factor\n",
        "\n",
        "        # Compute loss\n",
        "        loss, _ = get_loss_kde(x_var,y,model,bens, bandwidth, decayed_penalty_factor)\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            _, done = get_loss_kde(x_next,y,model,bens, bandwidth, penalty_factor)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv, done = get_loss_kde(x_next,y,model,bens, bandwidth, penalty_factor)\n",
        "    loss_adv = loss_adv.data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "2GiSV8FEoleR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Create a range of values for logits\n",
        "logit_range = np.linspace(-10, 10, 100)\n",
        "logits = torch.tensor(logit_range, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Compute sigmoid probabilities\n",
        "probabilities = torch.sigmoid(logits).numpy()\n",
        "\n",
        "# Assume the true label is 1 (malware) for simplicity\n",
        "true_labels = torch.ones_like(logits)\n",
        "\n",
        "# Compute binary cross-entropy loss\n",
        "binary_cross_entropy_loss = F.binary_cross_entropy_with_logits(logits, true_labels, reduction='none').numpy()\n",
        "\n",
        "# Plot the binary cross-entropy loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(logit_range, binary_cross_entropy_loss, label='Binary Cross-Entropy Loss')\n",
        "plt.xlabel('Logit')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Binary Cross-Entropy Loss for Different Logits')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "2PrmiKsMz7ca",
        "outputId": "59fc00d1-1487-4202-ad9a-8fdfd651d31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RHYlmKaAXuDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-TwoMjmQXt_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gkde(x, y, model, penalty_factor, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        #y_model = model(x_var)\n",
        "        if t > 40:\n",
        "          decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "          print('t : ',t)\n",
        "          print('decayed_penalty_factor : ',decayed_penalty_factor)\n",
        "        else:\n",
        "          decayed_penalty_factor = penalty_factor\n",
        "\n",
        "        # Compute loss\n",
        "        loss, _ = get_loss_kde(x_var,y,model, decayed_penalty_factor)\n",
        "        print('loss : ',loss)\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            print('l2norm ; ',l2norm)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            print('un_mod',un_mod.sum(dim=-1))\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            print('max_grad', val)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            _, done = get_loss_kde(x_next,y,model, penalty_factor)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, y.view(-1).long()).data\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    print('loss_natural : ',loss_natural)\n",
        "    print('loss_adv : ',loss_adv)\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "PP1EIy_6XqWC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model, penalty_factor):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    print('ce: ', ce)\n",
        "    outputs_rbf = model_gaussian_1000(adv_x)\n",
        "    kde = criterion(outputs_rbf, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    #kde=0.\n",
        "    print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "Y1BJFkXPXr9a"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8V-HBitZxvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 50, insertion_array, removal_array, k=200, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ec2b1d3-c4bb-4554-ef03-4404ed1a6dc1",
        "id": "_KO-eZiwZyEz"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([270.0239, 453.6583, 423.9228, 380.1457], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([27473.8125, 24902.7988, 24146.7676, 10260.3184])\n",
            "un_mod tensor([10000, 10000, 10000, 10000])\n",
            "max_grad tensor([[43.0186],\n",
            "        [37.5190],\n",
            "        [34.5575],\n",
            "        [ 8.7332]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([ 41.4521,  87.1468,  58.7566, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3975, 4.2835, 4.4865, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([111.3284, 301.3212, 283.0825, 343.9585], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([22641.8633, 24454.8613, 23824.1016, 10288.9590])\n",
            "un_mod tensor([9999, 9999, 9999, 9999])\n",
            "max_grad tensor([[31.0305],\n",
            "        [35.1407],\n",
            "        [33.1568],\n",
            "        [ 4.3887]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.4521,  87.1468,  58.7566, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3975, 4.2835, 4.4865, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([ 41.0207,  86.5490,  57.6814, 162.1008], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1219, 1.6738, 1.9881, 3.2830], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 47.1157, 170.2408, 157.0856, 326.2496], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([11464.3242, 20178.1094, 21578.3535, 10243.5723])\n",
            "un_mod tensor([9998, 9998, 9998, 9998])\n",
            "max_grad tensor([[ 7.0760],\n",
            "        [26.4701],\n",
            "        [26.3823],\n",
            "        [ 3.6644]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.0207,  86.5490,  57.6814, 162.1008], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1219, 1.6738, 1.9881, 3.2830], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([ 17.6691,  88.2370,  59.8087, 152.3671], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0622, 0.2952, 0.4528, 3.1783], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.7810, 102.9947,  82.4475, 311.2840], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([11207.5186, 12543.9766, 14275.4102, 10283.7197])\n",
            "un_mod tensor([9997, 9997, 9997, 9997])\n",
            "max_grad tensor([[6.7577],\n",
            "        [6.8699],\n",
            "        [9.8279],\n",
            "        [3.7309]], dtype=torch.float64)\n",
            "ce:  tensor([ 17.6691,  88.2370,  59.8087, 152.3671], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0622, 0.2952, 0.4528, 3.1783], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 9.0022e+01, 6.0618e+01, 1.4773e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0406, 0.0659, 2.9807], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  92.0529,  63.9109, 296.7697], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129, 10076.5664, 10651.4541, 10199.9395])\n",
            "un_mod tensor([9996, 9996, 9996, 9996])\n",
            "max_grad tensor([[1.3526],\n",
            "        [4.9291],\n",
            "        [2.5060],\n",
            "        [3.3921]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 9.0022e+01, 6.0618e+01, 1.4773e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0406, 0.0659, 2.9807], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 7.3856e+01, 5.1751e+01, 1.4841e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0212, 0.0556, 2.6996], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  74.9180,  54.5334, 283.3917], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  8698.0186, 10243.8311, 10186.6553])\n",
            "un_mod tensor([9996, 9995, 9995, 9995])\n",
            "max_grad tensor([[1.3526],\n",
            "        [3.6905],\n",
            "        [2.4005],\n",
            "        [3.3169]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 7.3856e+01, 5.1751e+01, 1.4841e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0212, 0.0556, 2.6996], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.9019e+01, 4.2614e+01, 1.5007e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0100, 0.0468, 2.4235], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  59.5218,  44.9515, 271.2455], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  8749.8428, 10771.7529, 10139.8213])\n",
            "un_mod tensor([9996, 9994, 9994, 9994])\n",
            "max_grad tensor([[1.3526],\n",
            "        [3.0322],\n",
            "        [2.3544],\n",
            "        [3.0680]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.9019e+01, 4.2614e+01, 1.5007e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0100, 0.0468, 2.4235], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 4.5852e+01, 3.4015e+01, 1.4864e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0208, 0.0391, 2.2296], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  46.8924,  35.9686, 260.1192], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  9895.3486, 10728.3408, 10076.2744])\n",
            "un_mod tensor([9996, 9993, 9993, 9993])\n",
            "max_grad tensor([[1.3526],\n",
            "        [3.1433],\n",
            "        [2.1360],\n",
            "        [2.5996]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 4.5852e+01, 3.4015e+01, 1.4864e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0208, 0.0391, 2.2296], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 3.4178e+01, 2.6019e+01, 1.4795e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0108, 0.0325, 2.0660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  34.7172,  27.6423, 251.2510], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  9272.0625, 11518.7363, 10020.2051])\n",
            "un_mod tensor([9996, 9992, 9992, 9992])\n",
            "max_grad tensor([[1.3526],\n",
            "        [2.7762],\n",
            "        [2.1603],\n",
            "        [2.4595]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 3.4178e+01, 2.6019e+01, 1.4795e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0108, 0.0325, 2.0660], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 2.3364e+01, 1.8244e+01, 1.4765e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0050, 0.0268, 1.9082], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  23.6129,  19.5851, 243.0597], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  8682.0938, 10834.2998,  9946.8027])\n",
            "un_mod tensor([9996, 9991, 9991, 9991])\n",
            "max_grad tensor([[1.3526],\n",
            "        [2.3819],\n",
            "        [1.9677],\n",
            "        [2.4791]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 2.3364e+01, 1.8244e+01, 1.4765e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0050, 0.0268, 1.9082], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 1.4976e+01, 1.1861e+01, 1.4537e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 9.8907e-04, 2.2040e-02, 1.7862e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  15.0258,  12.9626, 234.6768], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 8452.8936, 9542.7852, 9948.5527])\n",
            "un_mod tensor([9996, 9990, 9990, 9990])\n",
            "max_grad tensor([[1.3526],\n",
            "        [2.0726],\n",
            "        [1.6772],\n",
            "        [2.4560]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 1.4976e+01, 1.1861e+01, 1.4537e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 9.8907e-04, 2.2040e-02, 1.7862e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 6.8049e+00, 5.4601e+00, 1.4339e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 5.7359e-04, 5.1326e-02, 1.6648e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   6.8336,   8.0264, 226.6242], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  8224.9141, 12004.9111,  9931.3633])\n",
            "un_mod tensor([9996, 9989, 9989, 9989])\n",
            "max_grad tensor([[1.3526],\n",
            "        [1.9644],\n",
            "        [1.9553],\n",
            "        [2.4457]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 6.8049e+00, 5.4601e+00, 1.4339e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 5.7359e-04, 5.1326e-02, 1.6648e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 2.6747e+00, 1.3862e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 7.6197e-03, 1.6004e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   3.0557, 218.6424], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557, 11454.2559,  9945.8008])\n",
            "un_mod tensor([9996, 9988, 9988, 9988])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.7466],\n",
            "        [2.4387]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 2.6747e+00, 1.3862e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 7.6197e-03, 1.6004e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 1.6629e+00, 1.3269e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 3.2911e-03, 1.5615e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   1.8275, 210.7626], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  9520.9414, 10009.8223])\n",
            "un_mod tensor([9996, 9988, 9987, 9987])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.5928],\n",
            "        [2.3008]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 1.6629e+00, 1.3269e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 3.2911e-03, 1.5615e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.3047e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.4600e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 203.4710], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10004.5342])\n",
            "un_mod tensor([9996, 9988, 9986, 9986])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3216]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.3047e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.4600e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.2524e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.4188e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 196.1797], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10022.0625])\n",
            "un_mod tensor([9996, 9988, 9986, 9985])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3152]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.2524e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.4188e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.2099e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.3590e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 188.9390], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10031.0859])\n",
            "un_mod tensor([9996, 9988, 9986, 9984])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3346]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.2099e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.3590e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.1945e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.2455e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 181.7310], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10007.4678])\n",
            "un_mod tensor([9996, 9988, 9986, 9983])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3148]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.1945e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.2455e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.1453e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.2017e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 174.6136], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10014.1357])\n",
            "un_mod tensor([9996, 9988, 9986, 9982])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3248]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.1453e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.2017e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0960e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.1575e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 167.4736], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10022.9961])\n",
            "un_mod tensor([9996, 9988, 9986, 9981])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3376]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0960e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.1575e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0928e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.0223e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 160.3994], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10098.9688])\n",
            "un_mod tensor([9996, 9988, 9986, 9980])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.2300]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0928e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.0223e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0483e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 9.7730e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 153.6976], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10099.2432])\n",
            "un_mod tensor([9996, 9988, 9986, 9979])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.2149]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0483e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 9.7730e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0064e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 9.3223e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 147.2490], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9551.9482])\n",
            "un_mod tensor([9996, 9988, 9986, 9978])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.5102]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0064e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 9.3223e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0021e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 8.1230e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 140.8286], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10016.7324])\n",
            "un_mod tensor([9996, 9988, 9986, 9977])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.0417]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0021e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 8.1230e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 9.7503e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 7.4768e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 134.8872], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9986.7695])\n",
            "un_mod tensor([9996, 9988, 9986, 9976])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.0099]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 9.7503e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 7.4768e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 9.2468e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 7.3054e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 128.9951], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9851.0068])\n",
            "un_mod tensor([9996, 9988, 9986, 9975])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.9568]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 9.2468e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 7.3054e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.9963e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 6.6738e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 123.3323], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9959.9229])\n",
            "un_mod tensor([9996, 9988, 9986, 9974])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.9009]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.9963e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 6.6738e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.7584e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 6.0606e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 117.8871], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9913.5791])\n",
            "un_mod tensor([9996, 9988, 9986, 9973])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.8469]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.7584e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 6.0606e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.4324e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 5.6511e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 112.5797], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9896.8877])\n",
            "un_mod tensor([9996, 9988, 9986, 9972])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.8243]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.4324e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 5.6511e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.1053e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 5.2519e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 107.3126], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9865.8389])\n",
            "un_mod tensor([9996, 9988, 9986, 9971])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.7821]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.1053e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 5.2519e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.7883e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 4.8643e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 102.2047], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9289.5322])\n",
            "un_mod tensor([9996, 9988, 9986, 9970])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.9366]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.7883e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 4.8643e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.5592e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 4.3494e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 97.3389], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9778.2109])\n",
            "un_mod tensor([9996, 9988, 9986, 9969])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.6709]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.5592e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 4.3494e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.3225e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.8947e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 92.6987], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9116.6719])\n",
            "un_mod tensor([9996, 9988, 9986, 9968])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.5165]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.3225e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.8947e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.0579e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.5589e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 88.3732], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9082.0840])\n",
            "un_mod tensor([9996, 9988, 9986, 9967])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.4859]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.0579e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.5589e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.6893e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.4185e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 83.9854], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8934.3125])\n",
            "un_mod tensor([9996, 9988, 9986, 9966])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.4456]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.6893e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.4185e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.4816e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.3010], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 79.8673], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8880.5293])\n",
            "un_mod tensor([9996, 9988, 9986, 9965])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.3980]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.4816e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.3010], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.1276e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2898], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 75.7670], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8875.3467])\n",
            "un_mod tensor([9996, 9988, 9986, 9964])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.2806]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.1276e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2898], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.7290e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2969], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 72.1329], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8898.9033])\n",
            "un_mod tensor([9996, 9988, 9986, 9963])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.2918]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.7290e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2969], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.6723e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2414], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 68.7945], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8679.2461])\n",
            "un_mod tensor([9996, 9988, 9986, 9962])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.1641]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.6723e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2414], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.5325e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2079], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 65.7201], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8467.1582])\n",
            "un_mod tensor([9996, 9988, 9986, 9961])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.6766]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.5325e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2079], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.0726e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2431], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 62.8791], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8669.4102])\n",
            "un_mod tensor([9996, 9988, 9986, 9960])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.1642]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.0726e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2431], grad_fn=<NllLossBackward0>)\n",
            "t :  41\n",
            "decayed_penalty_factor :  39.75\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.8682e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2177], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3528,  0.5234,  0.4685, 57.3358], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 527.3314, 3066.9644, 3396.8303, 8535.8613])\n",
            "un_mod tensor([9996, 9988, 9986, 9959])\n",
            "max_grad tensor([[1.0753],\n",
            "        [0.6951],\n",
            "        [0.1387],\n",
            "        [1.0046]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.8682e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2177], grad_fn=<NllLossBackward0>)\n",
            "t :  42\n",
            "decayed_penalty_factor :  39.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.4966e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2375], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3443,  0.5233,  0.4681, 54.3462], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 524.0295, 3066.9500, 3396.7578, 8614.0801])\n",
            "un_mod tensor([9996, 9988, 9986, 9958])\n",
            "max_grad tensor([[1.0685],\n",
            "        [0.6951],\n",
            "        [0.1388],\n",
            "        [0.9965]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.4966e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2375], grad_fn=<NllLossBackward0>)\n",
            "t :  43\n",
            "decayed_penalty_factor :  39.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.3404e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2125], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3358,  0.5232,  0.4676, 51.7453], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 520.7275, 3066.9355, 3396.6853, 7897.1206])\n",
            "un_mod tensor([9996, 9988, 9986, 9957])\n",
            "max_grad tensor([[1.0618],\n",
            "        [0.6950],\n",
            "        [0.1389],\n",
            "        [0.8296]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.3404e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2125], grad_fn=<NllLossBackward0>)\n",
            "t :  44\n",
            "decayed_penalty_factor :  39.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.1768e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1965], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3273,  0.5231,  0.4672, 49.4326], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 517.4257, 3066.9211, 3396.6130, 7653.0098])\n",
            "un_mod tensor([9996, 9988, 9986, 9956])\n",
            "max_grad tensor([[1.0550],\n",
            "        [0.6950],\n",
            "        [0.1390],\n",
            "        [0.7928]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.1768e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1965], grad_fn=<NllLossBackward0>)\n",
            "t :  45\n",
            "decayed_penalty_factor :  38.75\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.9929e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1853], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3188,  0.5230,  0.4667, 47.1091], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 514.1237, 3066.9067, 3396.5405, 7641.3755])\n",
            "un_mod tensor([9996, 9988, 9986, 9955])\n",
            "max_grad tensor([[1.0482],\n",
            "        [0.6950],\n",
            "        [0.1391],\n",
            "        [0.7616]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.9929e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1853], grad_fn=<NllLossBackward0>)\n",
            "t :  46\n",
            "decayed_penalty_factor :  38.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.8578e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1642], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3103,  0.5230,  0.4663, 44.8999], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 510.8217, 3066.8921, 3396.4683, 7613.5889])\n",
            "un_mod tensor([9996, 9988, 9986, 9954])\n",
            "max_grad tensor([[1.0415],\n",
            "        [0.6949],\n",
            "        [0.1392],\n",
            "        [0.7117]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.8578e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1642], grad_fn=<NllLossBackward0>)\n",
            "t :  47\n",
            "decayed_penalty_factor :  38.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.7307e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1444], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3018,  0.5229,  0.4658, 42.8288], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 507.5199, 3066.8779, 3396.3960, 7471.3442])\n",
            "un_mod tensor([9996, 9988, 9986, 9953])\n",
            "max_grad tensor([[1.0347],\n",
            "        [0.6949],\n",
            "        [0.1394],\n",
            "        [0.6751]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.7307e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1444], grad_fn=<NllLossBackward0>)\n",
            "t :  48\n",
            "decayed_penalty_factor :  38.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.5617e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1365], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2933,  0.5228,  0.4654, 40.8025], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 504.2180, 3066.8635, 3396.3232, 7462.6655])\n",
            "un_mod tensor([9996, 9988, 9986, 9952])\n",
            "max_grad tensor([[1.0279],\n",
            "        [0.6948],\n",
            "        [0.1395],\n",
            "        [0.6281]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.5617e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1365], grad_fn=<NllLossBackward0>)\n",
            "t :  49\n",
            "decayed_penalty_factor :  37.75\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.3738e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1423], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2848,  0.5227,  0.4649, 39.1098], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 500.9161, 3066.8491, 3396.2507, 7476.2236])\n",
            "un_mod tensor([9996, 9988, 9986, 9951])\n",
            "max_grad tensor([[1.0212],\n",
            "        [0.6948],\n",
            "        [0.1396],\n",
            "        [0.6352]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.3738e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1423], grad_fn=<NllLossBackward0>)\n",
            "t :  50\n",
            "decayed_penalty_factor :  37.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.2579e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1247], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2763,  0.5226,  0.4645, 37.2543], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 497.6142, 3066.8347, 3396.1787, 7451.8208])\n",
            "un_mod tensor([9996, 9988, 9986, 9950])\n",
            "max_grad tensor([[1.0144],\n",
            "        [0.6948],\n",
            "        [0.1397],\n",
            "        [0.5819]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.2579e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1247], grad_fn=<NllLossBackward0>)\n",
            "t :  51\n",
            "decayed_penalty_factor :  37.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.1297e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1165], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2678,  0.5226,  0.4640, 35.6355], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 494.3123, 3066.8198, 3396.1064, 7263.6318])\n",
            "un_mod tensor([9996, 9988, 9986, 9949])\n",
            "max_grad tensor([[1.0076],\n",
            "        [0.6947],\n",
            "        [0.1398],\n",
            "        [0.5607]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.1297e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1165], grad_fn=<NllLossBackward0>)\n",
            "t :  52\n",
            "decayed_penalty_factor :  37.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.0226e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1015], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2592,  0.5225,  0.4636, 33.9799], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 491.0104, 3066.8057, 3396.0342, 7241.5757])\n",
            "un_mod tensor([9996, 9988, 9986, 9948])\n",
            "max_grad tensor([[1.0009],\n",
            "        [0.6947],\n",
            "        [0.1399],\n",
            "        [0.5594]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.0226e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1015], grad_fn=<NllLossBackward0>)\n",
            "t :  53\n",
            "decayed_penalty_factor :  36.75\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.7966e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1198], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2507,  0.5224,  0.4631, 32.3684], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 487.7086, 3066.7915, 3395.9614, 7189.1138])\n",
            "un_mod tensor([9996, 9988, 9986, 9947])\n",
            "max_grad tensor([[0.9941],\n",
            "        [0.6946],\n",
            "        [0.1400],\n",
            "        [0.5351]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.7966e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1198], grad_fn=<NllLossBackward0>)\n",
            "t :  54\n",
            "decayed_penalty_factor :  36.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.7006e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1045], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2422,  0.5223,  0.4627, 30.8188], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 484.4067, 3066.7769, 3395.8889, 7165.6396])\n",
            "un_mod tensor([9996, 9988, 9986, 9946])\n",
            "max_grad tensor([[0.9874],\n",
            "        [0.6946],\n",
            "        [0.1402],\n",
            "        [0.5155]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.7006e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1045], grad_fn=<NllLossBackward0>)\n",
            "t :  55\n",
            "decayed_penalty_factor :  36.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.4920e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1293], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2337,  0.5222,  0.4623, 29.6067], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 481.1049, 3066.7625, 3395.8167, 6956.0889])\n",
            "un_mod tensor([9996, 9988, 9986, 9945])\n",
            "max_grad tensor([[0.9806],\n",
            "        [0.6946],\n",
            "        [0.1403],\n",
            "        [0.5438]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.4920e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1293], grad_fn=<NllLossBackward0>)\n",
            "t :  56\n",
            "decayed_penalty_factor :  36.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.3979e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1131], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2252,  0.5221,  0.4618, 28.0489], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 477.8030, 3066.7480, 3395.7441, 6765.8354])\n",
            "un_mod tensor([9996, 9988, 9986, 9944])\n",
            "max_grad tensor([[0.9738],\n",
            "        [0.6945],\n",
            "        [0.1404],\n",
            "        [0.5204]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.3979e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1131], grad_fn=<NllLossBackward0>)\n",
            "t :  57\n",
            "decayed_penalty_factor :  35.75000000000001\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.2465e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1146], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2167,  0.5221,  0.4614, 26.5623], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 474.5012, 3066.7336, 3395.6719, 7302.1660])\n",
            "un_mod tensor([9996, 9988, 9986, 9943])\n",
            "max_grad tensor([[0.9671],\n",
            "        [0.6945],\n",
            "        [0.1405],\n",
            "        [0.5132]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.2465e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1146], grad_fn=<NllLossBackward0>)\n",
            "t :  58\n",
            "decayed_penalty_factor :  35.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.2011e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0904], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2082,  0.5220,  0.4609, 25.2216], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 471.1993, 3066.7192, 3395.5994, 7139.5796])\n",
            "un_mod tensor([9996, 9988, 9986, 9942])\n",
            "max_grad tensor([[0.9603],\n",
            "        [0.6944],\n",
            "        [0.1406],\n",
            "        [0.4599]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.2011e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0904], grad_fn=<NllLossBackward0>)\n",
            "t :  59\n",
            "decayed_penalty_factor :  35.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.1113e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0781], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.1997,  0.5219,  0.4605, 23.8658], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 467.8976, 3066.7046, 3395.5269, 6704.0073])\n",
            "un_mod tensor([9996, 9988, 9986, 9941])\n",
            "max_grad tensor([[0.9535],\n",
            "        [0.6944],\n",
            "        [0.1407],\n",
            "        [0.4140]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.1113e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0781], grad_fn=<NllLossBackward0>)\n",
            "t :  60\n",
            "decayed_penalty_factor :  35.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.0279e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0671], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.1912,  0.5218,  0.4600, 22.6283], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 464.5958, 3066.6904, 3395.4543, 6623.7344])\n",
            "un_mod tensor([9996, 9988, 9986, 9940])\n",
            "max_grad tensor([[0.9468],\n",
            "        [0.6944],\n",
            "        [0.1408],\n",
            "        [0.3690]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.0279e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0671], grad_fn=<NllLossBackward0>)\n",
            "t :  61\n",
            "decayed_penalty_factor :  34.75\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.1524e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0773], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.1827,  0.5217,  0.4596, 24.2097], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 461.2940, 3066.6758, 3395.3821, 5229.0879])\n",
            "un_mod tensor([9996, 9988, 9986, 9939])\n",
            "max_grad tensor([[0.9400],\n",
            "        [0.6943],\n",
            "        [0.1410],\n",
            "        [0.9860]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.1524e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0773], grad_fn=<NllLossBackward0>)\n",
            "t :  62\n",
            "decayed_penalty_factor :  34.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.9415e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0565], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.1742,  0.5217,  0.4591, 21.3645], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 457.9922, 3066.6616, 3395.3098, 6725.0146])\n",
            "un_mod tensor([9996, 9988, 9986, 9938])\n",
            "max_grad tensor([[0.9333],\n",
            "        [0.6943],\n",
            "        [0.1411],\n",
            "        [0.3293]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.9415e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0565], grad_fn=<NllLossBackward0>)\n",
            "t :  63\n",
            "decayed_penalty_factor :  34.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.8417e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0571], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.1657,  0.5216,  0.4587, 20.3717], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 454.6905, 3066.6470, 3395.2373, 5702.9175])\n",
            "un_mod tensor([9996, 9988, 9986, 9937])\n",
            "max_grad tensor([[0.9265],\n",
            "        [0.6943],\n",
            "        [0.1412],\n",
            "        [0.3155]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.8417e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0571], grad_fn=<NllLossBackward0>)\n",
            "t :  64\n",
            "decayed_penalty_factor :  34.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.9438e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-baac1bb428c9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmals_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_AT_rFGSM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsertion_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoval_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_rounding_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_report_loss_diff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-36e820d98cd0>\u001b[0m in \u001b[0;36mgkde\u001b[0;34m(x, y, model, penalty_factor, insertion_array, removal_array, k, step_length, norm, initial_rounding_threshold, round_threshold, random, is_report_loss_diff, is_sample)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecayed_penalty_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-33344a7622d3>\u001b[0m in \u001b[0;36mget_loss_kde\u001b[0;34m(adv_x, y, model, penalty_factor)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmals_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ce: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutputs_rbf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_gaussian_1000\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_rbf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmals_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#kde=0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-a6e13bf31657>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mradial_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'laplacian'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mradial_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaplacian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-a6e13bf31657>\u001b[0m in \u001b[0;36mgaussian\u001b[0;34m(self, x, c, sigma)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlaplacian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# See https://github.com/pytorch/pytorch/issues/75462\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 150, insertion_array, removal_array, k=150, step_length=0.1, norm='l2', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGqpNQTZgM_N",
        "outputId": "935e61fb-4ba7-49a0-c563-6bdd9226d7ad"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 728.0156, 1187.7156, 1155.4517,  766.7467], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([65625.9688, 58235.7500, 55779.8438, 13472.1680])\n",
            "l2norm ;  tensor([[682.7472],\n",
            "        [596.8692],\n",
            "        [560.4139],\n",
            "        [ 57.0439]], dtype=torch.float64)\n",
            "ce:  tensor([ 46.0083,  90.9380,  62.7585, 188.0305], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.7538, 5.7141, 5.7855, 3.7050], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([459.0752, 948.0568, 930.5891, 743.7858], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([62477.9766, 58402.9805, 55649.1953, 13476.3564])\n",
            "l2norm ;  tensor([[650.8463],\n",
            "        [600.9231],\n",
            "        [563.4948],\n",
            "        [ 57.7570]], dtype=torch.float64)\n",
            "ce:  tensor([ 50.9619,  95.0748,  67.3104, 189.1739], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1665, 4.0847, 4.2546, 3.5425], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([225.9418, 707.7725, 705.4983, 720.5509], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([48905.2656, 57829.3008, 55270.8359, 13480.7910])\n",
            "l2norm ;  tensor([[478.5675],\n",
            "        [598.0340],\n",
            "        [560.3563],\n",
            "        [ 58.4165]], dtype=torch.float64)\n",
            "ce:  tensor([ 55.6005,  99.0350,  71.8393, 190.2644], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2847, 2.4976, 2.7559, 3.3787], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 98.3048, 473.6791, 485.2194, 697.0621], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([23344.3984, 54450.2617, 53022.3906, 13486.2656])\n",
            "l2norm ;  tensor([[166.9071],\n",
            "        [562.4973],\n",
            "        [534.2544],\n",
            "        [ 59.0307]], dtype=torch.float64)\n",
            "ce:  tensor([ 58.9488, 102.8552,  76.3616, 191.2925], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0483, 1.1332, 1.4130, 3.2136], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 66.2010, 272.8354, 288.3165, 673.3350], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12194.1484, 42634.5117, 44573.0625, 13495.0391])\n",
            "l2norm ;  tensor([[ 29.5001],\n",
            "        [415.7833],\n",
            "        [430.9827],\n",
            "        [ 59.6136]], dtype=torch.float64)\n",
            "ce:  tensor([ 58.7504, 106.4169,  80.7105, 192.2183], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0094, 0.3323, 0.5028, 3.0475], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 60.1658, 156.2594, 156.1273, 649.3464], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10445.8477, 22623.1113, 27206.6152, 13363.2383])\n",
            "l2norm ;  tensor([[ 11.1979],\n",
            "        [170.1166],\n",
            "        [221.2186],\n",
            "        [ 60.3349]], dtype=torch.float64)\n",
            "ce:  tensor([ 55.1947, 108.9750,  84.3588, 193.0621], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0049, 0.0715, 0.1291, 2.8801], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 55.9265, 119.7070, 103.7191, 625.0810], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10261.3008, 12300.3271, 14304.4688, 13332.7080])\n",
            "l2norm ;  tensor([[10.3284],\n",
            "        [40.0602],\n",
            "        [63.4671],\n",
            "        [61.0015]], dtype=torch.float64)\n",
            "ce:  tensor([ 51.3652, 108.7732,  86.2083, 193.8207], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0033, 0.0158, 0.0302, 2.7117], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 51.8573, 111.1480,  90.7355, 600.5699], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 9112.4219, 10112.1982, 10418.0459, 13344.4961])\n",
            "l2norm ;  tensor([[ 9.5118],\n",
            "        [13.9123],\n",
            "        [15.4624],\n",
            "        [61.5670]], dtype=torch.float64)\n",
            "ce:  tensor([ 47.7041, 105.2175,  85.1783, 194.4948], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.4137e-03, 6.7249e-03, 9.5486e-03, 2.5423e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 48.0662, 106.2262,  86.6106, 575.8392], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 9089.5352,  9816.3135,  9717.9775, 13350.8770])\n",
            "l2norm ;  tensor([[ 9.4402],\n",
            "        [11.6389],\n",
            "        [ 8.6915],\n",
            "        [62.0941]], dtype=torch.float64)\n",
            "ce:  tensor([ 44.6479, 101.0328,  82.4411, 195.0831], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8771e-03, 4.0244e-03, 5.5802e-03, 2.3722e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 44.9295, 101.6365,  83.2781, 550.9117], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8631.8867,  9532.1152,  9485.7559, 13347.9062])\n",
            "l2norm ;  tensor([[ 8.1954],\n",
            "        [11.4106],\n",
            "        [ 8.2168],\n",
            "        [62.5416]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.4498,  96.7106,  79.3930, 195.5844], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4058e-03, 2.6943e-03, 4.0017e-03, 2.2016e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 41.6607,  97.1148,  79.9932, 525.8292], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8614.5566,  9472.8369,  9373.2852, 13332.6875])\n",
            "l2norm ;  tensor([[ 8.1494],\n",
            "        [11.2418],\n",
            "        [ 8.2000],\n",
            "        [62.8590]], dtype=torch.float64)\n",
            "ce:  tensor([ 38.2483,  92.3544,  76.2724, 195.9964], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0860e-03, 1.8929e-03, 3.0907e-03, 2.0311e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 38.4112,  92.6383,  76.7360, 500.6553], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8595.5547,  9442.8984,  9347.3145, 13301.9209])\n",
            "l2norm ;  tensor([[ 8.1046],\n",
            "        [11.1487],\n",
            "        [ 8.1414],\n",
            "        [62.9891]], dtype=torch.float64)\n",
            "ce:  tensor([ 35.0196,  88.3072,  73.7623, 196.3145], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.5794e-04, 1.3695e-03, 2.4998e-03, 1.8611e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 35.1483,  88.5126,  74.1373, 475.4769], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8739.9229,  8349.5557,  8882.9922, 13250.8086])\n",
            "l2norm ;  tensor([[ 8.1916],\n",
            "        [10.4168],\n",
            "        [ 6.8713],\n",
            "        [62.8694]], dtype=torch.float64)\n",
            "ce:  tensor([ 31.7721,  84.1969,  71.1171, 196.5343], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.8498e-04, 1.0222e-03, 1.8984e-03, 1.6925e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 31.8749,  84.3503,  71.4019, 450.4080], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8734.5361,  8327.4414,  8866.6738, 13174.8281])\n",
            "l2norm ;  tensor([[ 3.7600],\n",
            "        [10.4247],\n",
            "        [ 6.8117],\n",
            "        [62.4296]], dtype=torch.float64)\n",
            "ce:  tensor([ 30.3214,  80.0662,  68.5226, 196.6524], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.3999e-04, 7.8028e-04, 1.4856e-03, 1.5263e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 30.4024,  80.1833,  68.7455, 425.5930], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8643.1699,  8193.4365,  8828.9297, 13067.5322])\n",
            "l2norm ;  tensor([[ 3.6424],\n",
            "        [10.5124],\n",
            "        [ 6.5590],\n",
            "        [61.5482]], dtype=torch.float64)\n",
            "ce:  tensor([ 28.9139,  75.9526,  65.9732, 196.6693], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.3562e-04, 6.0147e-04, 1.1820e-03, 1.3637e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.9793,  76.0428,  66.1505, 401.2185], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8301.5117,  8168.5454,  8833.0332, 12926.8115])\n",
            "l2norm ;  tensor([[ 3.4827],\n",
            "        [10.3114],\n",
            "        [ 6.3538],\n",
            "        [60.2539]], dtype=torch.float64)\n",
            "ce:  tensor([ 27.5188,  71.8421,  63.4900, 196.5640], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5899e-04, 4.7053e-04, 9.5334e-04, 1.2060e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 27.5726,  71.9127,  63.6330, 377.4649], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8323.8857,  8152.8975,  8848.0459, 12747.3730])\n",
            "l2norm ;  tensor([[ 3.5258],\n",
            "        [10.3429],\n",
            "        [ 6.2771],\n",
            "        [58.4354]], dtype=torch.float64)\n",
            "ce:  tensor([ 26.2214,  67.7638,  61.0109, 196.3399], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.0251e-04, 3.7127e-04, 7.8004e-04, 1.0548e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.2668,  67.8195,  61.1279, 354.5670], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 9258.2852,  8159.5859,  8848.8359, 12915.6787])\n",
            "l2norm ;  tensor([[ 2.7456],\n",
            "        [10.1608],\n",
            "        [ 6.2637],\n",
            "        [56.0085]], dtype=torch.float64)\n",
            "ce:  tensor([ 25.4354,  63.7123,  58.5315, 195.8435], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3291e-04, 2.9560e-04, 6.4519e-04, 9.1276e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.4703,  63.7566,  58.6283, 332.7579], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8149.9707,  8157.3311,  8883.2666, 12270.4160])\n",
            "l2norm ;  tensor([[ 2.7019],\n",
            "        [10.1539],\n",
            "        [ 6.2394],\n",
            "        [53.1299]], dtype=torch.float64)\n",
            "ce:  tensor([ 24.6088,  59.6535,  56.0566, 195.3448], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1598e-04, 2.3720e-04, 5.3809e-04, 7.7924e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.6412,  59.6891,  56.1373, 312.2312], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 7525.3779,  8146.0156,  8878.6475, 12371.7480])\n",
            "l2norm ;  tensor([[ 2.1460],\n",
            "        [10.1746],\n",
            "        [ 6.2409],\n",
            "        [47.4480]], dtype=torch.float64)\n",
            "ce:  tensor([ 23.8909,  55.5894,  53.5749, 195.1350], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8321e-04, 1.9191e-04, 4.5313e-04, 6.5905e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.9184,  55.6182,  53.6428, 293.9920], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8529.1387,  8149.1367,  8867.3232, 11666.8516])\n",
            "l2norm ;  tensor([[ 2.4754],\n",
            "        [ 9.4710],\n",
            "        [ 6.2385],\n",
            "        [43.7501]], dtype=torch.float64)\n",
            "ce:  tensor([ 23.2159,  51.8368,  51.1315, 194.9447], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2612e-04, 1.5961e-04, 3.8473e-04, 5.4964e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.2349,  51.8607,  51.1892, 277.3908], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 7475.5923,  8173.4580,  8720.0762, 11735.1455])\n",
            "l2norm ;  tensor([[ 2.1733],\n",
            "        [ 8.3759],\n",
            "        [ 6.0681],\n",
            "        [39.6708]], dtype=torch.float64)\n",
            "ce:  tensor([ 22.4058,  49.0460,  48.7134, 194.3187], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1086e-04, 1.3577e-04, 3.2396e-04, 4.5359e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.4224,  49.0663,  48.7620, 262.3572], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 6734.4419,  7734.5308,  8714.3887, 11005.6787])\n",
            "l2norm ;  tensor([[ 1.7305],\n",
            "        [ 5.7788],\n",
            "        [ 6.0707],\n",
            "        [35.4576]], dtype=torch.float64)\n",
            "ce:  tensor([ 21.8547,  46.8161,  46.5244, 193.6927], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0442e-04, 1.0800e-04, 2.7498e-04, 3.6925e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.8704,  46.8323,  46.5657, 249.0797], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 7615.6758,  8709.6279,  8162.8911, 11081.3691])\n",
            "l2norm ;  tensor([[ 2.1113],\n",
            "        [ 6.0332],\n",
            "        [ 5.3797],\n",
            "        [31.3737]], dtype=torch.float64)\n",
            "ce:  tensor([ 21.4402,  44.7965,  44.3856, 192.6543], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.0225e-05, 8.3443e-05, 2.1646e-04, 2.9836e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.4522,  44.8090,  44.4180, 237.4089], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 6439.3281,  7674.0054,  8153.8057, 10375.4502])\n",
            "l2norm ;  tensor([[ 1.4056],\n",
            "        [ 5.6124],\n",
            "        [ 4.7394],\n",
            "        [27.3015]], dtype=torch.float64)\n",
            "ce:  tensor([ 20.8750,  42.5543,  42.5106, 191.4973], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.3192e-05, 6.6993e-05, 1.7045e-04, 2.3827e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.8860,  42.5644,  42.5362, 227.2375], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 6408.6104,  7673.4902,  8136.5400, 10096.6504])\n",
            "l2norm ;  tensor([[ 1.4258],\n",
            "        [ 5.6109],\n",
            "        [ 4.3840],\n",
            "        [23.6442]], dtype=torch.float64)\n",
            "ce:  tensor([ 20.3234,  40.3139,  41.0209, 190.0878], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.7828e-05, 5.4239e-05, 1.3470e-04, 1.8903e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.3335,  40.3220,  41.0411, 218.4419], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7336.5786, 7665.9160, 7064.8311, 9853.9258])\n",
            "l2norm ;  tensor([[ 1.8827],\n",
            "        [ 4.9939],\n",
            "        [ 3.1338],\n",
            "        [20.4325]], dtype=torch.float64)\n",
            "ce:  tensor([ 20.1007,  38.3708,  39.7648, 188.4376], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.1378e-05, 4.7802e-05, 1.1467e-04, 1.4931e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.1084,  38.3779,  39.7820, 210.8344], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6364.3755, 7093.6533, 7001.0117, 9648.4854])\n",
            "l2norm ;  tensor([[ 1.3429],\n",
            "        [ 2.9919],\n",
            "        [ 2.5366],\n",
            "        [17.7054]], dtype=torch.float64)\n",
            "ce:  tensor([ 19.5391,  37.2718,  38.7528, 186.5664], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7206e-05, 4.1961e-05, 9.8581e-05, 1.1770e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.5462,  37.2781,  38.7676, 204.2213], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6328.9702, 8113.1587, 7000.5503, 9479.5195])\n",
            "l2norm ;  tensor([[ 1.4167],\n",
            "        [ 3.5886],\n",
            "        [ 2.5354],\n",
            "        [15.4511]], dtype=torch.float64)\n",
            "ce:  tensor([ 18.9887,  36.3458,  37.7268, 184.5074], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.3510e-05, 3.3855e-05, 8.5589e-05, 9.2752e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.9953,  36.3509,  37.7396, 198.4201], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6336.6138, 7001.3281, 6961.8125, 9343.6807])\n",
            "l2norm ;  tensor([[ 1.3792],\n",
            "        [ 2.7386],\n",
            "        [ 2.6646],\n",
            "        [13.6372]], dtype=torch.float64)\n",
            "ce:  tensor([ 18.4346,  35.3684,  36.6783, 182.2861], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.0292e-05, 2.8967e-05, 7.4622e-05, 7.3217e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.4407,  35.3727,  36.6895, 193.2686], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6278.8330, 6865.3228, 6916.9131, 9233.1777])\n",
            "l2norm ;  tensor([[ 1.4138],\n",
            "        [ 2.5134],\n",
            "        [ 2.5917],\n",
            "        [11.8436]], dtype=torch.float64)\n",
            "ce:  tensor([ 17.8695,  34.4290,  35.6431, 179.9812], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.7312e-05, 2.4318e-05, 6.5682e-05, 5.8479e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.8751,  34.4327,  35.6529, 188.7531], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6278.7417, 6220.5420, 6916.6528, 9149.2021])\n",
            "l2norm ;  tensor([[ 1.4136],\n",
            "        [ 2.2265],\n",
            "        [ 2.5911],\n",
            "        [10.7453]], dtype=torch.float64)\n",
            "ce:  tensor([ 17.3299,  33.5389,  34.6609, 177.5503], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4928e-05, 2.1338e-05, 5.8292e-05, 4.7145e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.3351,  33.5421,  34.6696, 184.6220], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5880.3994, 6220.4487, 7780.8398, 9084.1279])\n",
            "l2norm ;  tensor([[1.3833],\n",
            "        [2.2263],\n",
            "        [3.2862],\n",
            "        [9.4780]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.8412,  32.6636,  34.0572, 175.2263], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.3378e-05, 1.8835e-05, 4.8755e-05, 3.8229e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.8462,  32.6665,  34.0645, 180.9608], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7170.6968, 6160.9185, 6678.1362, 9031.7412])\n",
            "l2norm ;  tensor([[2.1489],\n",
            "        [2.1791],\n",
            "        [2.3401],\n",
            "        [8.8583]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.6130,  31.7923,  33.1431, 172.8400], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.7656e-05, 1.6689e-05, 4.4583e-05, 3.1192e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.6171,  31.7948,  33.1498, 177.5187], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4243.6382, 6160.8535, 6628.2749, 8989.5303])\n",
            "l2norm ;  tensor([[0.7687],\n",
            "        [2.1789],\n",
            "        [2.2783],\n",
            "        [8.3754]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.6936,  30.9386,  32.2805, 170.4041], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3484e-05, 1.5020e-05, 4.1126e-05, 2.5622e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.6971,  30.9409,  32.2867, 174.2474], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5671.5430, 6092.0142, 6166.3623, 8955.5947])\n",
            "l2norm ;  tensor([[1.5131],\n",
            "        [2.0810],\n",
            "        [1.9949],\n",
            "        [7.9991]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.5433,  30.1404,  31.4828, 168.1270], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.4438e-05, 1.3471e-05, 3.9934e-05, 2.1188e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.5469,  30.1424,  31.4888, 171.3052], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4095.6650, 5830.0698, 6166.3252, 8374.9512])\n",
            "l2norm ;  tensor([[0.6831],\n",
            "        [1.8692],\n",
            "        [1.9352],\n",
            "        [7.2096]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.3299,  29.3950,  30.7091, 165.8633], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1100e-05, 1.1802e-05, 3.7669e-05, 1.7416e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.3331,  29.3968,  30.7147, 168.4757], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5671.4673, 5796.8003, 6166.2598, 8351.2266])\n",
            "l2norm ;  tensor([[1.4853],\n",
            "        [1.8422],\n",
            "        [1.9350],\n",
            "        [6.9498]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.5442,  28.6647,  29.9355, 163.5787], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1934e-05, 1.0490e-05, 3.5762e-05, 1.4399e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.5475,  28.6662,  29.9409, 165.7386], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5458.5708, 5770.4233, 6127.0669, 8332.1064])\n",
            "l2norm ;  tensor([[1.8880],\n",
            "        [1.8181],\n",
            "        [1.9011],\n",
            "        [6.7446]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.6186,  27.9376,  29.3004, 161.3160], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7643e-05, 9.2983e-06, 3.4332e-05, 1.1966e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.6212,  27.9390,  29.3055, 163.1109], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4095.4492, 5770.3887, 5527.6768, 8175.7246])\n",
            "l2norm ;  tensor([[0.5945],\n",
            "        [1.7437],\n",
            "        [2.5681],\n",
            "        [6.4522]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.7937,  27.3259,  29.6349, 159.0679], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7047e-05, 8.8214e-06, 2.7656e-05, 9.9468e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.7962,  27.3272,  29.6390, 160.5599], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5671.3418, 6727.1670, 6072.5059, 8156.3774])\n",
            "l2norm ;  tensor([[1.4210],\n",
            "        [2.4363],\n",
            "        [1.8578],\n",
            "        [6.2948]], dtype=torch.float64)\n",
            "t :  41\n",
            "decayed_penalty_factor :  109.0\n",
            "ce:  tensor([ 16.6799,  26.9034,  29.0633, 156.8197], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9073e-05, 7.7486e-06, 2.6822e-05, 8.3020e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.6819,  26.9043,  29.0662, 157.7246], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4495.2588, 5368.6777, 3894.6514, 8128.3652])\n",
            "l2norm ;  tensor([[1.0273],\n",
            "        [1.6753],\n",
            "        [0.9625],\n",
            "        [6.0371]], dtype=torch.float64)\n",
            "t :  42\n",
            "decayed_penalty_factor :  108.0\n",
            "ce:  tensor([ 16.5967,  26.3762,  29.0159, 154.5583], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4305e-05, 7.8678e-06, 2.0981e-05, 7.0098e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.5982,  26.3770,  29.0181, 155.3154], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5671.1333, 3788.8467, 5475.5293, 8121.6846])\n",
            "l2norm ;  tensor([[1.3774],\n",
            "        [0.9327],\n",
            "        [1.6523],\n",
            "        [5.9734]], dtype=torch.float64)\n",
            "t :  43\n",
            "decayed_penalty_factor :  107.0\n",
            "ce:  tensor([ 16.5895,  26.3344,  28.7622, 152.2948], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6212e-05, 6.6757e-06, 1.9908e-05, 5.9412e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.5913,  26.3351,  28.7643, 152.9305], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4495.1836, 5368.6519, 3894.5081, 8114.6592])\n",
            "l2norm ;  tensor([[0.7997],\n",
            "        [1.7376],\n",
            "        [0.9304],\n",
            "        [5.6716]], dtype=torch.float64)\n",
            "t :  44\n",
            "decayed_penalty_factor :  106.0\n",
            "ce:  tensor([ 16.4194,  26.1756,  28.5120, 150.1265], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4186e-05, 6.3181e-06, 1.6212e-05, 5.0776e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.4209,  26.1763,  28.5137, 150.6647], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6132.3779, 3788.8101, 5475.4346, 8110.1743])\n",
            "l2norm ;  tensor([[2.2604],\n",
            "        [0.9327],\n",
            "        [1.5872],\n",
            "        [5.5020]], dtype=torch.float64)\n",
            "t :  45\n",
            "decayed_penalty_factor :  105.0\n",
            "ce:  tensor([ 16.8341,  25.8027,  28.5039, 148.0054], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7762e-05, 5.4836e-06, 1.5616e-05, 4.3826e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.8360,  25.8032,  28.5055, 148.4656], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4495.2109, 3788.7910, 3894.4194, 8106.5469])\n",
            "l2norm ;  tensor([[1.0271],\n",
            "        [0.8175],\n",
            "        [0.9279],\n",
            "        [5.3329]], dtype=torch.float64)\n",
            "t :  46\n",
            "decayed_penalty_factor :  104.0\n",
            "ce:  tensor([ 16.5312,  25.7765,  28.1331, 145.9379], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3471e-05, 4.5299e-06, 1.2994e-05, 3.8044e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.5326,  25.7769,  28.1344, 146.3336], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4087.3296, 6325.1167, 3894.3677, 8103.5059])\n",
            "l2norm ;  tensor([[0.5824],\n",
            "        [2.3405],\n",
            "        [0.8990],\n",
            "        [4.9452]], dtype=torch.float64)\n",
            "t :  47\n",
            "decayed_penalty_factor :  103.0\n",
            "ce:  tensor([ 16.6639,  25.8267,  28.2706, 144.0120], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3232e-05, 3.8147e-06, 1.0610e-05, 3.3390e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.6652,  25.8271,  28.2717, 144.3559], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6132.3472, 3788.7534, 5219.2178, 8101.0278])\n",
            "l2norm ;  tensor([[2.2480],\n",
            "        [0.9745],\n",
            "        [1.2956],\n",
            "        [4.8199]], dtype=torch.float64)\n",
            "t :  48\n",
            "decayed_penalty_factor :  101.99999999999999\n",
            "ce:  tensor([ 16.9803,  25.4369,  28.0210, 142.1271], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6332e-05, 3.2186e-06, 1.0490e-05, 2.9505e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.9819,  25.4373,  28.0220, 142.4281], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5592.1177, 3788.7412, 3641.0273, 8098.9429])\n",
            "l2norm ;  tensor([[2.2347],\n",
            "        [0.7765],\n",
            "        [0.8187],\n",
            "        [4.5447]], dtype=torch.float64)\n",
            "t :  49\n",
            "decayed_penalty_factor :  101.0\n",
            "ce:  tensor([ 16.9877,  25.3529,  28.2585, 140.3449], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1086e-05, 2.7418e-06, 9.0599e-06, 2.6254e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.9888,  25.3531,  28.2594, 140.6101], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5806.7671, 5317.7939, 5698.2539, 8097.1855])\n",
            "l2norm ;  tensor([[1.3756],\n",
            "        [1.5675],\n",
            "        [2.1066],\n",
            "        [4.5319]], dtype=torch.float64)\n",
            "t :  50\n",
            "decayed_penalty_factor :  100.00000000000001\n",
            "ce:  tensor([ 17.0390,  25.5225,  28.2433, 138.5623], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3113e-05, 2.7418e-06, 9.6559e-06, 2.3472e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.0403,  25.5228,  28.2443, 138.7970], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4087.3091, 4709.6294, 3641.0078, 8095.6758])\n",
            "l2norm ;  tensor([[0.8213],\n",
            "        [2.0459],\n",
            "        [0.8923],\n",
            "        [4.4413]], dtype=torch.float64)\n",
            "t :  51\n",
            "decayed_penalty_factor :  98.99999999999999\n",
            "ce:  tensor([ 16.8791,  25.5500,  28.3688, 136.8105], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0729e-05, 2.3842e-06, 8.3446e-06, 2.1168e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.8802,  25.5503,  28.3696, 137.0201], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6132.2852, 3788.7222, 5219.1714, 8094.4131])\n",
            "l2norm ;  tensor([[2.2412],\n",
            "        [0.7699],\n",
            "        [1.2508],\n",
            "        [4.3321]], dtype=torch.float64)\n",
            "t :  52\n",
            "decayed_penalty_factor :  98.0\n",
            "ce:  tensor([ 17.2593,  25.6295,  28.1371, 135.0985], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3709e-05, 2.2650e-06, 8.2254e-06, 1.9204e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.2607,  25.6297,  28.1379, 135.2867], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4632.5107, 5317.7817, 3640.9800, 8093.3276])\n",
            "l2norm ;  tensor([[1.0124],\n",
            "        [1.5675],\n",
            "        [0.8922],\n",
            "        [4.2481]], dtype=torch.float64)\n",
            "t :  53\n",
            "decayed_penalty_factor :  97.00000000000001\n",
            "ce:  tensor([ 16.9353,  25.5194,  28.3339, 133.4454], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.7751e-06, 2.1458e-06, 7.2717e-06, 1.7566e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.9362,  25.5196,  28.3346, 133.6158], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3981.1533, 4140.1411, 5219.1499, 8006.0068])\n",
            "l2norm ;  tensor([[0.6526],\n",
            "        [1.0955],\n",
            "        [1.3315],\n",
            "        [3.8436]], dtype=torch.float64)\n",
            "t :  54\n",
            "decayed_penalty_factor :  96.0\n",
            "ce:  tensor([ 17.1185,  25.3256,  28.2122, 131.9222], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0133e-05, 1.7881e-06, 7.8678e-06, 1.6197e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.1195,  25.3257,  28.2130, 132.0777], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5427.8135, 5317.7720, 5014.1792, 8005.2358])\n",
            "l2norm ;  tensor([[1.3618],\n",
            "        [1.5373],\n",
            "        [2.4130],\n",
            "        [3.4647]], dtype=torch.float64)\n",
            "t :  55\n",
            "decayed_penalty_factor :  95.0\n",
            "ce:  tensor([ 17.1632,  25.4944,  28.6199, 130.5493], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1325e-05, 1.6689e-06, 6.4373e-06, 1.4934e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.1643,  25.4946,  28.6205, 130.6911], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5307.6943, 3737.7517, 5219.1338, 8004.5220])\n",
            "l2norm ;  tensor([[1.9738],\n",
            "        [0.8853],\n",
            "        [1.2986],\n",
            "        [3.4120]], dtype=torch.float64)\n",
            "t :  56\n",
            "decayed_penalty_factor :  94.0\n",
            "ce:  tensor([ 17.5465,  25.1412,  28.4445, 129.1949], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.1791e-06, 1.5497e-06, 7.2717e-06, 1.3906e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.5473,  25.1413,  28.4452, 129.3256], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6136.5176, 3729.2654, 3640.9570, 8003.9297])\n",
            "l2norm ;  tensor([[2.2008],\n",
            "        [0.6596],\n",
            "        [0.8282],\n",
            "        [3.3245]], dtype=torch.float64)\n",
            "t :  57\n",
            "decayed_penalty_factor :  93.0\n",
            "ce:  tensor([ 17.7601,  25.2149,  28.5748, 127.8727], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1325e-05, 1.3113e-06, 7.0333e-06, 1.3154e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.7612,  25.2150,  28.5755, 127.9950], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4399.3369, 5158.2080, 5875.6357, 8003.4814])\n",
            "l2norm ;  tensor([[1.1046],\n",
            "        [1.4163],\n",
            "        [1.3183],\n",
            "        [3.2637]], dtype=torch.float64)\n",
            "t :  58\n",
            "decayed_penalty_factor :  92.0\n",
            "ce:  tensor([ 17.5377,  25.3984,  28.5668, 126.5726], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.5102e-06, 1.3113e-06, 8.1062e-06, 1.2622e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.5384,  25.3985,  28.5676, 126.6887], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5574.9883, 4954.1548, 3640.9663, 8003.1426])\n",
            "l2norm ;  tensor([[1.3580],\n",
            "        [2.1626],\n",
            "        [0.8779],\n",
            "        [3.1497]], dtype=torch.float64)\n",
            "t :  59\n",
            "decayed_penalty_factor :  91.0\n",
            "ce:  tensor([ 17.6797,  25.4910,  28.6760, 125.3186], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-06, 1.1921e-06, 7.2717e-06, 1.2141e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.6804,  25.4911,  28.6766, 125.4291], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4399.2739, 5158.2051, 5219.1406, 7973.1152])\n",
            "l2norm ;  tensor([[1.1000],\n",
            "        [1.4470],\n",
            "        [1.1857],\n",
            "        [3.0654]], dtype=torch.float64)\n",
            "t :  60\n",
            "decayed_penalty_factor :  90.0\n",
            "ce:  tensor([ 17.4107,  25.6278,  28.5636, 124.0962], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.6028e-06, 1.3113e-06, 8.5830e-06, 1.1771e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.4112,  25.6279,  28.5643, 124.2021], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5902.1113, 3583.1428, 4042.0750, 7972.8560])\n",
            "l2norm ;  tensor([[2.2029],\n",
            "        [0.7609],\n",
            "        [1.0637],\n",
            "        [3.0289]], dtype=torch.float64)\n",
            "t :  61\n",
            "decayed_penalty_factor :  88.99999999999999\n",
            "ce:  tensor([ 17.9282,  25.3641,  28.7933, 122.8871], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.0333e-06, 1.3113e-06, 6.9141e-06, 1.1529e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.9288,  25.3642,  28.7939, 122.9897], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4399.2441, 4129.9473, 5698.1953, 7972.6597])\n",
            "l2norm ;  tensor([[1.0555],\n",
            "        [0.7997],\n",
            "        [2.2360],\n",
            "        [2.9316]], dtype=torch.float64)\n",
            "t :  62\n",
            "decayed_penalty_factor :  88.0\n",
            "ce:  tensor([ 17.6804,  25.6241,  28.9220, 121.7152], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.4107e-06, 1.1921e-06, 8.7022e-06, 1.1488e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.6808,  25.6242,  28.9228, 121.8163], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3853.2986, 5413.2734, 4614.8223, 7972.5537])\n",
            "l2norm ;  tensor([[0.4310],\n",
            "        [1.4693],\n",
            "        [2.2724],\n",
            "        [2.8916]], dtype=torch.float64)\n",
            "t :  63\n",
            "decayed_penalty_factor :  87.00000000000001\n",
            "ce:  tensor([ 17.7933,  25.6830,  29.3206, 120.5636], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4571e-06, 1.1921e-06, 7.5102e-06, 1.1532e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.7936,  25.6831,  29.3213, 120.6639], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5574.9097, 4556.3008, 5475.2490, 7922.8687])\n",
            "l2norm ;  tensor([[1.3554],\n",
            "        [2.1152],\n",
            "        [1.1681],\n",
            "        [2.7425]], dtype=torch.float64)\n",
            "t :  64\n",
            "decayed_penalty_factor :  85.99999999999999\n",
            "ce:  tensor([ 17.8951,  26.0210,  29.1909, 119.4647], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.0531e-06, 1.1921e-06, 8.8214e-06, 1.1700e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.8954,  26.0211,  29.1917, 119.5654], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4820.0469, 5862.9316, 4042.0710, 7937.8452])\n",
            "l2norm ;  tensor([[2.0052],\n",
            "        [1.6365],\n",
            "        [1.3058],\n",
            "        [2.7596]], dtype=torch.float64)\n",
            "t :  65\n",
            "decayed_penalty_factor :  85.0\n",
            "ce:  tensor([ 18.2827,  26.0599,  29.3843, 118.3591], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5763e-06, 1.3113e-06, 7.0333e-06, 1.1944e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.2830,  26.0600,  29.3849, 118.4606], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5973.0723, 3634.1526, 5953.6567, 7937.8604])\n",
            "l2norm ;  tensor([[1.2103],\n",
            "        [0.8836],\n",
            "        [2.3065],\n",
            "        [2.6868]], dtype=torch.float64)\n",
            "t :  66\n",
            "decayed_penalty_factor :  84.00000000000001\n",
            "ce:  tensor([ 18.3434,  25.9821,  29.3942, 117.2818], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.1723e-06, 1.1921e-06, 9.1791e-06, 1.2279e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.3438,  25.9822,  29.3950, 117.3850], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4000.0298, 5413.2725, 3640.9673, 7937.9111])\n",
            "l2norm ;  tensor([[0.5512],\n",
            "        [1.3885],\n",
            "        [0.8931],\n",
            "        [2.6386]], dtype=torch.float64)\n",
            "t :  67\n",
            "decayed_penalty_factor :  83.0\n",
            "ce:  tensor([ 18.1551,  26.1163,  29.5280, 116.2237], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.2186e-06, 1.3113e-06, 8.3446e-06, 1.2637e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.1554,  26.1164,  29.5287, 116.3286], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4252.2559, 3583.1406, 5219.1426, 7937.9648])\n",
            "l2norm ;  tensor([[0.5573],\n",
            "        [0.7480],\n",
            "        [1.1728],\n",
            "        [2.5155]], dtype=torch.float64)\n",
            "t :  68\n",
            "decayed_penalty_factor :  82.0\n",
            "ce:  tensor([ 18.5312,  25.9330,  29.4921, 115.2567], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-06, 1.3113e-06, 9.8943e-06, 1.3053e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.5314,  25.9331,  29.4929, 115.3637], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5902.0474, 5413.2744, 5014.1812, 7823.3516])\n",
            "l2norm ;  tensor([[2.2712],\n",
            "        [1.3597],\n",
            "        [2.3946],\n",
            "        [2.3008]], dtype=torch.float64)\n",
            "t :  69\n",
            "decayed_penalty_factor :  81.0\n",
            "ce:  tensor([ 18.6400,  26.3097,  29.9381, 114.3336], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.9802e-06, 1.4305e-06, 8.3446e-06, 1.3427e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.6402,  26.3099,  29.9388, 114.4424], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4000.0061, 3982.4644, 5475.2500, 7823.4004])\n",
            "l2norm ;  tensor([[0.6848],\n",
            "        [1.0990],\n",
            "        [1.2591],\n",
            "        [2.2279]], dtype=torch.float64)\n",
            "t :  70\n",
            "decayed_penalty_factor :  80.0\n",
            "ce:  tensor([ 18.4677,  25.9400,  29.8654, 113.4390], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.0266e-06, 1.1921e-06, 9.8943e-06, 1.3894e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.4678,  25.9401,  29.8662, 113.5502], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5427.6489, 3583.1379, 4033.7041, 7823.4829])\n",
            "l2norm ;  tensor([[1.2853],\n",
            "        [0.6789],\n",
            "        [1.0997],\n",
            "        [2.2262]], dtype=torch.float64)\n",
            "t :  71\n",
            "decayed_penalty_factor :  78.99999999999999\n",
            "ce:  tensor([ 18.6916,  26.4394,  30.0136, 112.5445], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-06, 1.3113e-06, 8.1062e-06, 1.4450e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.6918,  26.4395,  30.0142, 112.6586], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4252.2383, 6426.3667, 4613.4868, 7823.5908])\n",
            "l2norm ;  tensor([[0.9538],\n",
            "        [2.1707],\n",
            "        [1.2461],\n",
            "        [2.0797]], dtype=torch.float64)\n",
            "t :  72\n",
            "decayed_penalty_factor :  78.0\n",
            "ce:  tensor([ 18.4425,  26.2729,  30.0850, 111.7085], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6689e-06, 1.3113e-06, 1.0252e-05, 1.5020e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.4426,  26.2730,  30.0858, 111.8257], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4323.7754, 5523.1216, 3886.5701, 7823.6929])\n",
            "l2norm ;  tensor([[1.0989],\n",
            "        [1.2427],\n",
            "        [0.9073],\n",
            "        [1.9869]], dtype=torch.float64)\n",
            "t :  73\n",
            "decayed_penalty_factor :  77.0\n",
            "ce:  tensor([ 18.7722,  26.6725,  30.1067, 110.9488], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4305e-06, 1.5497e-06, 9.0599e-06, 1.5741e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.7723,  26.6726,  30.1074, 111.0700], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5574.8706, 3434.1343, 4760.8037, 7182.5723])\n",
            "l2norm ;  tensor([[1.2338],\n",
            "        [0.9195],\n",
            "        [1.4709],\n",
            "        [1.7022]], dtype=torch.float64)\n",
            "t :  74\n",
            "decayed_penalty_factor :  75.99999999999999\n",
            "ce:  tensor([ 19.0865,  26.4615,  30.3223, 110.2623], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7881e-06, 1.1921e-06, 1.0133e-05, 1.6528e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.0866,  26.4616,  30.3231, 110.3879], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5217.9629, 3511.3333, 3942.9595, 7182.7466])\n",
            "l2norm ;  tensor([[2.2946],\n",
            "        [1.2772],\n",
            "        [1.0258],\n",
            "        [1.6282]], dtype=torch.float64)\n",
            "t :  75\n",
            "decayed_penalty_factor :  75.0\n",
            "ce:  tensor([ 19.2217,  26.7817,  30.1096, 109.6504], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3113e-06, 1.1921e-06, 7.9870e-06, 1.7335e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.2218,  26.7817,  30.1102, 109.7804], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5574.8672, 5922.6431, 4613.4795, 7754.5503])\n",
            "l2norm ;  tensor([[1.0894],\n",
            "        [1.5737],\n",
            "        [1.4598],\n",
            "        [1.6065]], dtype=torch.float64)\n",
            "t :  76\n",
            "decayed_penalty_factor :  74.0\n",
            "ce:  tensor([ 19.2604,  26.9416,  30.6185, 109.1035], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5497e-06, 1.3113e-06, 9.0599e-06, 1.8391e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.2605,  26.9417,  30.6192, 109.2396], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3853.2405, 3036.4370, 5000.1167, 7123.2490])\n",
            "l2norm ;  tensor([[0.6468],\n",
            "        [1.3624],\n",
            "        [1.9175],\n",
            "        [1.4231]], dtype=torch.float64)\n",
            "t :  77\n",
            "decayed_penalty_factor :  73.0\n",
            "ce:  tensor([ 19.2108,  26.7150,  30.7103, 108.5267], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3113e-06, 9.5367e-07, 8.8214e-06, 1.9480e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.2109,  26.7151,  30.7109, 108.6689], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5574.8672, 4817.8896, 4342.7979, 7123.4893])\n",
            "l2norm ;  tensor([[1.1665],\n",
            "        [1.3330],\n",
            "        [1.1021],\n",
            "        [1.4206]], dtype=torch.float64)\n",
            "t :  78\n",
            "decayed_penalty_factor :  72.0\n",
            "ce:  tensor([ 19.4153,  27.0722,  30.6460, 107.9500], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5497e-06, 1.3113e-06, 7.8678e-06, 2.0722e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.4154,  27.0723,  30.6466, 108.0992], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5217.9580, 4914.9805, 5346.6123, 7123.7632])\n",
            "l2norm ;  tensor([[2.1199],\n",
            "        [2.4042],\n",
            "        [2.6750],\n",
            "        [1.3737]], dtype=torch.float64)\n",
            "t :  79\n",
            "decayed_penalty_factor :  71.00000000000001\n",
            "ce:  tensor([ 19.7220,  27.1757,  31.1421, 107.4050], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-06, 1.0729e-06, 9.7751e-06, 2.2048e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.7221,  27.1758,  31.1428, 107.5615], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6047.4849, 5015.8516, 3780.3665, 7749.7622])\n",
            "l2norm ;  tensor([[2.1347],\n",
            "        [1.3005],\n",
            "        [0.8990],\n",
            "        [1.5076]], dtype=torch.float64)\n",
            "t :  80\n",
            "decayed_penalty_factor :  70.0\n",
            "ce:  tensor([ 20.1866,  27.6224,  30.8817, 106.9493], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5497e-06, 1.4305e-06, 8.7022e-06, 2.3429e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.1867,  27.6225,  30.8823, 107.1133], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4399.1333, 4033.5925, 3288.1675, 7124.3213])\n",
            "l2norm ;  tensor([[1.0403],\n",
            "        [1.1145],\n",
            "        [0.6033],\n",
            "        [1.3286]], dtype=torch.float64)\n",
            "t :  81\n",
            "decayed_penalty_factor :  69.0\n",
            "ce:  tensor([ 19.8463,  27.3815,  31.1657, 106.4071], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0729e-06, 1.1921e-06, 7.9870e-06, 2.5075e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.8464,  27.3816,  31.1662, 106.5801], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3999.9707, 3036.4336, 4760.7778, 7124.6685])\n",
            "l2norm ;  tensor([[0.3789],\n",
            "        [0.5067],\n",
            "        [1.5321],\n",
            "        [1.3116]], dtype=torch.float64)\n",
            "t :  82\n",
            "decayed_penalty_factor :  68.0\n",
            "ce:  tensor([ 20.1067,  27.8932,  31.1742, 105.8886], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 1.1921e-06, 9.1791e-06, 2.7056e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.1068,  27.8933,  31.1749, 106.0726], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5427.6279, 5523.1172, 3543.6360, 6133.7373])\n",
            "l2norm ;  tensor([[1.2328],\n",
            "        [1.4901],\n",
            "        [0.8225],\n",
            "        [1.5337]], dtype=torch.float64)\n",
            "t :  83\n",
            "decayed_penalty_factor :  67.0\n",
            "ce:  tensor([ 20.0529,  27.6191,  31.1729, 105.8290], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 1.3113e-06, 8.3446e-06, 2.6736e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.0530,  27.6192,  31.1734, 106.0082], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4399.1245, 4342.7070, 4760.7788, 7124.8564])\n",
            "l2norm ;  tensor([[0.7905],\n",
            "        [1.1123],\n",
            "        [1.4686],\n",
            "        [1.7418]], dtype=torch.float64)\n",
            "t :  84\n",
            "decayed_penalty_factor :  65.99999999999999\n",
            "ce:  tensor([ 20.0713,  27.9009,  31.6651, 105.2953], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.0729e-06, 9.4175e-06, 2.8292e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.0714,  27.9010,  31.6657, 105.4821], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5427.6260, 5092.2480, 5518.7065, 6755.5923])\n",
            "l2norm ;  tensor([[1.2081],\n",
            "        [2.5991],\n",
            "        [2.5868],\n",
            "        [1.1187]], dtype=torch.float64)\n",
            "t :  85\n",
            "decayed_penalty_factor :  65.0\n",
            "ce:  tensor([ 20.1962,  28.0881,  31.6450, 105.1709], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 1.3113e-06, 8.2254e-06, 2.9025e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.1962,  28.0882,  31.6455, 105.3596], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4226.1460, 3689.7241, 5015.9170, 7125.1655])\n",
            "l2norm ;  tensor([[0.8508],\n",
            "        [1.6558],\n",
            "        [1.3306],\n",
            "        [1.2575]], dtype=torch.float64)\n",
            "t :  86\n",
            "decayed_penalty_factor :  63.99999999999999\n",
            "ce:  tensor([ 20.0568,  27.6451,  32.1226, 104.8057], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 9.5367e-07, 1.0371e-05, 3.1424e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.0568,  27.6452,  32.1233, 105.0068], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5427.6245, 4868.6553, 3543.6401, 6134.3389])\n",
            "l2norm ;  tensor([[1.0515],\n",
            "        [1.3223],\n",
            "        [1.5975],\n",
            "        [1.0760]], dtype=torch.float64)\n",
            "t :  87\n",
            "decayed_penalty_factor :  63.00000000000001\n",
            "ce:  tensor([ 20.3456,  28.1076,  31.6009, 104.7397], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 1.1921e-06, 7.7486e-06, 3.2036e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.3457,  28.1077,  31.6014, 104.9416], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4819.9844, 4914.9756, 4159.1797, 7751.3281])\n",
            "l2norm ;  tensor([[2.0114],\n",
            "        [2.4565],\n",
            "        [1.1587],\n",
            "        [1.2681]], dtype=torch.float64)\n",
            "t :  88\n",
            "decayed_penalty_factor :  62.0\n",
            "ce:  tensor([ 20.6958,  28.2216,  31.8684, 104.4708], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 9.5367e-07, 7.0333e-06, 3.4452e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.6959,  28.2217,  31.8688, 104.6844], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6445.5332, 3434.2529, 4613.4512, 6134.7837])\n",
            "l2norm ;  tensor([[1.8659],\n",
            "        [0.7067],\n",
            "        [0.9615],\n",
            "        [0.9966]], dtype=torch.float64)\n",
            "t :  89\n",
            "decayed_penalty_factor :  60.99999999999999\n",
            "ce:  tensor([ 21.1818,  28.1107,  32.1106, 104.3604], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 8.3446e-07, 8.1062e-06, 3.5194e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.1818,  28.1107,  32.1111, 104.5751], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3993.9961, 4613.3950, 4915.0405, 7751.7363])\n",
            "l2norm ;  tensor([[0.7246],\n",
            "        [1.4775],\n",
            "        [2.4149],\n",
            "        [1.6832]], dtype=torch.float64)\n",
            "t :  90\n",
            "decayed_penalty_factor :  60.0\n",
            "ce:  tensor([ 20.8920,  28.4270,  32.4981, 104.2596], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 9.5367e-07, 6.9141e-06, 3.7166e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.8920,  28.4271,  32.4985, 104.4826], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3993.9932, 3942.8435, 5015.8984, 6637.5391])\n",
            "l2norm ;  tensor([[0.3391],\n",
            "        [0.9729],\n",
            "        [1.3121],\n",
            "        [0.8986]], dtype=torch.float64)\n",
            "t :  91\n",
            "decayed_penalty_factor :  59.0\n",
            "ce:  tensor([ 21.1323,  28.2591,  32.8429, 103.9899], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 7.1526e-07, 8.7022e-06, 3.7555e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.1324,  28.2591,  32.8434, 104.2115], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5569.1958, 3288.0784, 4291.9707, 6040.3618])\n",
            "l2norm ;  tensor([[1.2306],\n",
            "        [0.4852],\n",
            "        [1.1552],\n",
            "        [0.9072]], dtype=torch.float64)\n",
            "t :  92\n",
            "decayed_penalty_factor :  58.00000000000001\n",
            "ce:  tensor([ 21.1488,  28.3518,  32.6652, 104.0188], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 8.3446e-07, 8.4638e-06, 3.8001e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.1489,  28.3519,  32.6657, 104.2392], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4393.3003, 4760.7021, 3288.1453, 7596.8672])\n",
            "l2norm ;  tensor([[0.9464],\n",
            "        [1.5072],\n",
            "        [0.4827],\n",
            "        [1.4214]], dtype=torch.float64)\n",
            "t :  93\n",
            "decayed_penalty_factor :  57.0\n",
            "ce:  tensor([ 21.1718,  28.5862,  32.8202, 103.8130], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 9.5367e-07, 7.8678e-06, 4.1350e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.1718,  28.5863,  32.8207, 104.0487], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5664.7632, 3543.5479, 5267.7534, 6040.8696])\n",
            "l2norm ;  tensor([[2.5795],\n",
            "        [0.8287],\n",
            "        [1.3730],\n",
            "        [0.8783]], dtype=torch.float64)\n",
            "t :  94\n",
            "decayed_penalty_factor :  55.99999999999999\n",
            "ce:  tensor([ 21.6033,  28.3223,  32.9976, 103.6732], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 8.3446e-07, 8.4638e-06, 4.2145e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.6033,  28.3223,  32.9981, 103.9092], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3993.9934, 4760.7021, 4546.4067, 7597.3828])\n",
            "l2norm ;  tensor([[0.7319],\n",
            "        [1.2593],\n",
            "        [1.4770],\n",
            "        [1.2420]], dtype=torch.float64)\n",
            "t :  95\n",
            "decayed_penalty_factor :  55.00000000000001\n",
            "ce:  tensor([ 21.3141,  28.8634,  33.0311, 103.6576], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.0729e-06, 7.1525e-06, 4.3826e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.3141,  28.8635,  33.0315, 103.8986], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5569.1948, 5060.3472, 4613.4429, 6040.9722])\n",
            "l2norm ;  tensor([[1.1561],\n",
            "        [2.4255],\n",
            "        [1.3577],\n",
            "        [0.8590]], dtype=torch.float64)\n",
            "t :  96\n",
            "decayed_penalty_factor :  54.0\n",
            "ce:  tensor([ 21.6672,  28.9068,  33.2713, 103.4394], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 8.3446e-07, 8.1062e-06, 4.4739e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.6672,  28.9069,  33.2717, 103.6810], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4483.1533, 4415.6509, 3942.8992, 7597.4683])\n",
            "l2norm ;  tensor([[0.8091],\n",
            "        [1.1674],\n",
            "        [1.0247],\n",
            "        [1.3570]], dtype=torch.float64)\n",
            "t :  97\n",
            "decayed_penalty_factor :  53.00000000000001\n",
            "ce:  tensor([ 21.5073,  29.0158,  33.0944, 103.5369], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 8.3446e-07, 6.4373e-06, 4.8503e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.5073,  29.0158,  33.0948, 103.7939], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3340.8047, 5015.8452, 4868.6934, 6041.5430])\n",
            "l2norm ;  tensor([[0.4918],\n",
            "        [1.4243],\n",
            "        [1.5046],\n",
            "        [0.8500]], dtype=torch.float64)\n",
            "t :  98\n",
            "decayed_penalty_factor :  52.0\n",
            "ce:  tensor([ 21.8168,  29.5358,  33.5674, 103.2652], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 9.5367e-07, 7.5102e-06, 4.9429e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.8168,  29.5359,  33.5678, 103.5222], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5569.1943, 4636.8311, 4382.5464, 6638.5244])\n",
            "l2norm ;  tensor([[1.1261],\n",
            "        [1.5025],\n",
            "        [2.2733],\n",
            "        [0.7796]], dtype=torch.float64)\n",
            "t :  99\n",
            "decayed_penalty_factor :  50.99999999999999\n",
            "ce:  tensor([ 21.8443,  29.3710,  33.0824, 103.3833], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 8.3446e-07, 5.8412e-06, 5.0363e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.8443,  29.3710,  33.0827, 103.6401], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5301.9238, 3288.0776, 3288.1155, 6996.6699])\n",
            "l2norm ;  tensor([[2.1906],\n",
            "        [0.5498],\n",
            "        [0.5715],\n",
            "        [1.2817]], dtype=torch.float64)\n",
            "t :  100\n",
            "decayed_penalty_factor :  50.00000000000001\n",
            "ce:  tensor([ 22.4620,  29.6178,  33.3697, 103.1550], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 8.3446e-07, 5.3644e-06, 5.3950e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.4620,  29.6178,  33.3699, 103.4247], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6170.9604, 4760.7007, 4613.4248, 6638.9160])\n",
            "l2norm ;  tensor([[2.5244],\n",
            "        [1.4533],\n",
            "        [1.4706],\n",
            "        [0.7502]], dtype=torch.float64)\n",
            "t :  101\n",
            "decayed_penalty_factor :  49.0\n",
            "ce:  tensor([ 22.5695,  29.7081,  33.5215, 103.1857], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 9.5367e-07, 6.4373e-06, 5.4620e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.5695,  29.7081,  33.5218, 103.4533], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4483.1528, 4144.4360, 4915.0103, 6996.9712])\n",
            "l2norm ;  tensor([[1.0544],\n",
            "        [2.0558],\n",
            "        [2.4720],\n",
            "        [0.7873]], dtype=torch.float64)\n",
            "t :  102\n",
            "decayed_penalty_factor :  47.99999999999999\n",
            "ce:  tensor([ 22.5030,  29.5220,  33.8269, 103.0155], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 7.1526e-07, 5.6028e-06, 5.9005e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.5030,  29.5220,  33.8271, 103.2987], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5569.1938, 4868.6509, 5492.3726, 6639.3203])\n",
            "l2norm ;  tensor([[1.0972],\n",
            "        [1.3853],\n",
            "        [2.2349],\n",
            "        [0.7529]], dtype=torch.float64)\n",
            "t :  103\n",
            "decayed_penalty_factor :  47.0\n",
            "ce:  tensor([ 22.5843,  29.7286,  34.1886, 103.1956], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 8.3446e-07, 7.5102e-06, 5.9760e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.5844,  29.7286,  34.1889, 103.4765], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4456.5049, 4033.5811, 4090.4097, 6997.3428])\n",
            "l2norm ;  tensor([[0.8907],\n",
            "        [1.1967],\n",
            "        [1.5040],\n",
            "        [1.3564]], dtype=torch.float64)\n",
            "t :  104\n",
            "decayed_penalty_factor :  46.0\n",
            "ce:  tensor([ 22.5199,  29.5883,  33.9097, 102.9121], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 7.1526e-07, 5.9604e-06, 6.2292e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.5199,  29.5884,  33.9099, 103.1987], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4855.6821, 5015.8433, 4868.6836, 6639.3184])\n",
            "l2norm ;  tensor([[1.2907],\n",
            "        [1.2347],\n",
            "        [1.2776],\n",
            "        [0.7441]], dtype=torch.float64)\n",
            "t :  105\n",
            "decayed_penalty_factor :  45.00000000000001\n",
            "ce:  tensor([ 22.7364,  29.9991,  34.3032, 103.0002], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 9.5367e-07, 7.9870e-06, 6.3148e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.7365,  29.9991,  34.3036, 103.2844], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3940.6426, 4517.4297, 3634.1841, 6997.3389])\n",
            "l2norm ;  tensor([[0.7230],\n",
            "        [2.3802],\n",
            "        [1.6977],\n",
            "        [1.2595]], dtype=torch.float64)\n",
            "t :  106\n",
            "decayed_penalty_factor :  44.0\n",
            "ce:  tensor([ 22.4603,  30.1890,  33.8828, 102.8307], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 8.3446e-07, 6.1989e-06, 6.7832e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.4603,  30.1890,  33.8831, 103.1292], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3787.0408, 6011.2119, 5266.4897, 6042.7075])\n",
            "l2norm ;  tensor([[0.4517],\n",
            "        [1.5137],\n",
            "        [1.1990],\n",
            "        [0.7901]], dtype=torch.float64)\n",
            "t :  107\n",
            "decayed_penalty_factor :  42.99999999999999\n",
            "ce:  tensor([ 22.7661,  30.5779,  34.3074, 102.8344], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 1.0729e-06, 6.7949e-06, 6.9016e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.7661,  30.5780,  34.3077, 103.1312], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5401.4692, 3641.4915, 4235.2480, 7598.9321])\n",
            "l2norm ;  tensor([[1.3424],\n",
            "        [0.7688],\n",
            "        [1.2731],\n",
            "        [0.9845]], dtype=torch.float64)\n",
            "t :  108\n",
            "decayed_penalty_factor :  42.00000000000001\n",
            "ce:  tensor([ 22.8043,  30.4055,  34.2503, 102.7778], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.1921e-06, 6.4373e-06, 7.4566e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.8043,  30.4056,  34.2506, 103.0910], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4762.8892, 5015.8457, 4613.4243, 6043.1489])\n",
            "l2norm ;  tensor([[2.2711],\n",
            "        [1.4671],\n",
            "        [1.4046],\n",
            "        [0.7879]], dtype=torch.float64)\n",
            "t :  109\n",
            "decayed_penalty_factor :  41.0\n",
            "ce:  tensor([ 23.3955,  30.9703,  34.6768, 102.7869], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.4305e-06, 7.6294e-06, 7.5981e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.3956,  30.9703,  34.6771, 103.0984], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6145.5796, 4792.0078, 5004.5508, 7599.3130])\n",
            "l2norm ;  tensor([[2.4554],\n",
            "        [1.6922],\n",
            "        [2.5371],\n",
            "        [1.2016]], dtype=torch.float64)\n",
            "t :  110\n",
            "decayed_penalty_factor :  40.00000000000001\n",
            "ce:  tensor([ 23.5861,  30.7634,  34.7091, 102.7169], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 1.3113e-06, 6.7949e-06, 7.8918e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.5861,  30.7635,  34.7094, 103.0326], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4366.1509, 3295.4082, 5104.6460, 6043.0991])\n",
            "l2norm ;  tensor([[0.9655],\n",
            "        [0.5099],\n",
            "        [1.2351],\n",
            "        [0.8417]], dtype=torch.float64)\n",
            "t :  111\n",
            "decayed_penalty_factor :  39.0\n",
            "ce:  tensor([ 23.5527,  30.9404,  35.1469, 102.6683], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.1921e-06, 9.1791e-06, 8.1199e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.5528,  30.9404,  35.1472, 102.9850], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5516.5566, 5238.0493, 4382.5396, 7599.3521])\n",
            "l2norm ;  tensor([[1.2999],\n",
            "        [2.5074],\n",
            "        [1.3875],\n",
            "        [1.2105]], dtype=torch.float64)\n",
            "t :  112\n",
            "decayed_penalty_factor :  37.99999999999999\n",
            "ce:  tensor([ 23.5605,  31.3245,  34.9678, 102.6327], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.5497e-06, 8.5830e-06, 8.7458e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.5605,  31.3246,  34.9681, 102.9651], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4339.9292, 4389.7593, 3288.1174, 6043.6133])\n",
            "l2norm ;  tensor([[0.7770],\n",
            "        [2.1519],\n",
            "        [0.5962],\n",
            "        [0.7457]], dtype=torch.float64)\n",
            "t :  113\n",
            "decayed_penalty_factor :  37.00000000000001\n",
            "ce:  tensor([ 23.4993,  30.8942,  35.1934, 102.5532], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.1921e-06, 7.8678e-06, 8.9075e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.4993,  30.8942,  35.1937, 102.8828], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4862.8818, 5273.6689, 5238.0820, 7599.6753])\n",
            "l2norm ;  tensor([[1.2548],\n",
            "        [1.3382],\n",
            "        [2.4982],\n",
            "        [0.8901]], dtype=torch.float64)\n",
            "t :  114\n",
            "decayed_penalty_factor :  36.0\n",
            "ce:  tensor([ 23.7663,  31.3960,  35.4817, 102.6388], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.4305e-06, 9.6559e-06, 9.4748e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.7663,  31.3960,  35.4820, 102.9799], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4192.9585, 3641.4917, 4382.5376, 6043.7832])\n",
            "l2norm ;  tensor([[1.5708],\n",
            "        [1.1286],\n",
            "        [2.2522],\n",
            "        [0.7388]], dtype=torch.float64)\n",
            "t :  115\n",
            "decayed_penalty_factor :  34.99999999999999\n",
            "ce:  tensor([ 23.3888,  31.0229,  35.2276, 102.5997], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 1.3113e-06, 7.7486e-06, 9.5459e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.3888,  31.0229,  35.2279, 102.9338], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5387.1313, 3441.5774, 4868.6816, 7599.6660])\n",
            "l2norm ;  tensor([[1.4284],\n",
            "        [0.4613],\n",
            "        [1.1014],\n",
            "        [1.3871]], dtype=torch.float64)\n",
            "t :  116\n",
            "decayed_penalty_factor :  34.0\n",
            "ce:  tensor([ 23.7453,  31.3089,  35.5335, 102.6306], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.3113e-06, 9.7751e-06, 9.8843e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.7453,  31.3090,  35.5338, 102.9666], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3794.3489, 5274.8857, 3942.8804, 6043.4507])\n",
            "l2norm ;  tensor([[0.7298],\n",
            "        [1.3227],\n",
            "        [1.1818],\n",
            "        [0.6660]], dtype=torch.float64)\n",
            "t :  117\n",
            "decayed_penalty_factor :  32.99999999999999\n",
            "ce:  tensor([ 23.5274,  31.3394,  35.3982, 102.5189], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 1.5497e-06, 7.9870e-06, 9.7727e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.5275,  31.3394,  35.3984, 102.8414], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4862.8809, 3950.1292, 4613.4219, 7599.1514])\n",
            "l2norm ;  tensor([[1.2100],\n",
            "        [1.0124],\n",
            "        [1.2439],\n",
            "        [0.8675]], dtype=torch.float64)\n",
            "t :  118\n",
            "decayed_penalty_factor :  32.00000000000001\n",
            "ce:  tensor([ 23.9883,  31.3590,  35.6853, 102.7062], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.1921e-06, 9.2983e-06, 1.0393e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.9883,  31.3590,  35.6856, 103.0388], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5249.8633, 5023.0327, 3942.5972, 6043.1841])\n",
            "l2norm ;  tensor([[2.3732],\n",
            "        [1.4682],\n",
            "        [0.8839],\n",
            "        [0.7691]], dtype=torch.float64)\n",
            "t :  119\n",
            "decayed_penalty_factor :  31.0\n",
            "ce:  tensor([ 24.1010,  31.6641,  35.3772, 102.6010], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.5497e-06, 8.2254e-06, 1.0558e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.1010,  31.6641,  35.3774, 102.9283], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6234.3789, 4151.7041, 3036.4548, 7599.1812])\n",
            "l2norm ;  tensor([[2.7129],\n",
            "        [1.2511],\n",
            "        [0.4686],\n",
            "        [1.2560]], dtype=torch.float64)\n",
            "t :  120\n",
            "decayed_penalty_factor :  29.999999999999993\n",
            "ce:  tensor([ 24.5825,  31.5502,  36.0705, 102.6838], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.4305e-06, 9.0599e-06, 1.1352e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.5825,  31.5503,  36.0708, 103.0244], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4456.5029, 4875.8379, 5922.6636, 6043.3516])\n",
            "l2norm ;  tensor([[1.6886],\n",
            "        [1.4103],\n",
            "        [1.4691],\n",
            "        [0.6268]], dtype=torch.float64)\n",
            "t :  121\n",
            "decayed_penalty_factor :  29.000000000000004\n",
            "ce:  tensor([ 24.0295,  31.9007,  35.8211, 102.5800], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 1.7881e-06, 1.0610e-05, 1.1255e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.0295,  31.9007,  35.8214, 102.9063], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5260.3398, 4553.6094, 5513.3545, 7599.0303])\n",
            "l2norm ;  tensor([[0.9149],\n",
            "        [2.1228],\n",
            "        [2.0181],\n",
            "        [1.0568]], dtype=torch.float64)\n",
            "t :  122\n",
            "decayed_penalty_factor :  27.999999999999996\n",
            "ce:  tensor([ 24.4422,  31.6440,  36.3680, 102.7635], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.3113e-06, 1.1325e-05, 1.1482e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.4422,  31.6440,  36.3683, 103.0850], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3884.7786, 4875.8374, 5015.8784, 6042.5171])\n",
            "l2norm ;  tensor([[0.8157],\n",
            "        [1.1780],\n",
            "        [1.4472],\n",
            "        [0.6915]], dtype=torch.float64)\n",
            "t :  123\n",
            "decayed_penalty_factor :  27.000000000000007\n",
            "ce:  tensor([ 24.2747,  32.1881,  36.5263, 102.6308], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.9073e-06, 1.3590e-05, 1.1619e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.2747,  32.1882,  36.5267, 102.9445], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5644.0000, 4922.2246, 3942.8835, 7598.4746])\n",
            "l2norm ;  tensor([[1.4796],\n",
            "        [2.5534],\n",
            "        [1.6751],\n",
            "        [1.2108]], dtype=torch.float64)\n",
            "t :  124\n",
            "decayed_penalty_factor :  26.0\n",
            "ce:  tensor([ 24.6007,  32.2165,  36.2940, 102.7975], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.6689e-06, 1.0252e-05, 1.2427e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.6008,  32.2165,  36.2943, 103.1206], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4192.9570, 5023.0337, 4868.6797, 6639.4121])\n",
            "l2norm ;  tensor([[0.8738],\n",
            "        [1.2165],\n",
            "        [1.1056],\n",
            "        [0.7087]], dtype=torch.float64)\n",
            "t :  125\n",
            "decayed_penalty_factor :  24.999999999999993\n",
            "ce:  tensor([ 24.4459,  32.4576,  36.5348, 102.6181], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.9073e-06, 1.3590e-05, 1.2266e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.4459,  32.4577,  36.5352, 102.9247], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5338.3896, 3043.7729, 4194.9473, 6041.7993])\n",
            "l2norm ;  tensor([[2.5389],\n",
            "        [1.0069],\n",
            "        [1.3553],\n",
            "        [0.5473]], dtype=torch.float64)\n",
            "t :  126\n",
            "decayed_penalty_factor :  24.000000000000004\n",
            "ce:  tensor([ 25.0012,  32.3500,  36.3222, 102.9846], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.6689e-06, 1.1086e-05, 1.2509e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.0013,  32.3501,  36.3224, 103.2848], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4339.9272, 5023.0327, 4613.4204, 7597.8877])\n",
            "l2norm ;  tensor([[0.7860],\n",
            "        [1.3652],\n",
            "        [0.8200],\n",
            "        [1.3942]], dtype=torch.float64)\n",
            "t :  127\n",
            "decayed_penalty_factor :  23.0\n",
            "ce:  tensor([ 24.8061,  32.6485,  36.7018, 102.6911], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 2.0266e-06, 1.3351e-05, 1.3072e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.8061,  32.6486,  36.7021, 102.9918], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3794.3484, 4299.1738, 4144.4702, 6041.4570])\n",
            "l2norm ;  tensor([[0.3566],\n",
            "        [1.1853],\n",
            "        [1.2547],\n",
            "        [0.5478]], dtype=torch.float64)\n",
            "t :  128\n",
            "decayed_penalty_factor :  21.999999999999993\n",
            "ce:  tensor([ 24.9467,  32.5105,  36.7435, 102.9389], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 2.0266e-06, 1.2636e-05, 1.3163e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.9467,  32.5105,  36.7437, 103.2285], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5643.9995, 4875.8384, 4868.6807, 7597.4321])\n",
            "l2norm ;  tensor([[1.5788],\n",
            "        [1.4640],\n",
            "        [1.2830],\n",
            "        [1.2601]], dtype=torch.float64)\n",
            "t :  129\n",
            "decayed_penalty_factor :  21.000000000000004\n",
            "ce:  tensor([ 25.2207,  33.0294,  36.9789, 102.7735], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 2.3842e-06, 1.4782e-05, 1.4083e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.2207,  33.0294,  36.9792, 103.0692], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5304.9443, 3950.1287, 3543.5796, 6041.1562])\n",
            "l2norm ;  tensor([[2.3329],\n",
            "        [1.6858],\n",
            "        [1.7403],\n",
            "        [0.6412]], dtype=torch.float64)\n",
            "t :  130\n",
            "decayed_penalty_factor :  19.999999999999996\n",
            "ce:  tensor([ 25.3667,  32.4766,  36.6835, 102.9182], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.7881e-06, 1.1563e-05, 1.3898e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.3667,  32.4766,  36.6837, 103.1962], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5542.9229, 3295.4048, 5744.0303, 7596.9492])\n",
            "l2norm ;  tensor([[1.2477],\n",
            "        [0.5914],\n",
            "        [2.3200],\n",
            "        [1.0515]], dtype=torch.float64)\n",
            "t :  131\n",
            "decayed_penalty_factor :  19.000000000000007\n",
            "ce:  tensor([ 25.4386,  32.8237,  37.1867, 102.8777], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 1.7881e-06, 1.5259e-05, 1.4246e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.4386,  32.8237,  37.1870, 103.1484], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4366.1479, 5167.7739, 5513.3511, 5639.0469])\n",
            "l2norm ;  tensor([[0.9439],\n",
            "        [1.4281],\n",
            "        [2.4534],\n",
            "        [0.7829]], dtype=torch.float64)\n",
            "t :  132\n",
            "decayed_penalty_factor :  18.0\n",
            "ce:  tensor([ 25.4233,  32.8434,  37.2890, 103.0389], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 2.2650e-06, 1.4305e-05, 1.4324e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.4233,  32.8435,  37.2893, 103.2967], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5016.1416, 4776.3140, 5015.8696, 7596.1909])\n",
            "l2norm ;  tensor([[1.6464],\n",
            "        [2.1915],\n",
            "        [1.3879],\n",
            "        [1.0459]], dtype=torch.float64)\n",
            "t :  133\n",
            "decayed_penalty_factor :  16.999999999999993\n",
            "ce:  tensor([ 25.7377,  33.2732,  37.7573, 102.9913], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 2.0266e-06, 1.7047e-05, 1.4745e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.7377,  33.2732,  37.7576, 103.2419], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3820.3811, 6003.4722, 4180.9858, 6039.3384])\n",
            "l2norm ;  tensor([[1.6292],\n",
            "        [2.1186],\n",
            "        [1.7823],\n",
            "        [0.6603]], dtype=torch.float64)\n",
            "t :  134\n",
            "decayed_penalty_factor :  16.000000000000004\n",
            "ce:  tensor([ 25.2240,  33.6560,  37.2492, 103.0975], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 2.7418e-06, 1.2994e-05, 1.5099e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.2240,  33.6560,  37.2494, 103.3391], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5260.3394, 4094.5435, 4868.6709, 7595.5410])\n",
            "l2norm ;  tensor([[0.8801],\n",
            "        [1.1903],\n",
            "        [1.0651],\n",
            "        [1.2394]], dtype=torch.float64)\n",
            "t :  135\n",
            "decayed_penalty_factor :  14.999999999999996\n",
            "ce:  tensor([ 25.7188,  33.4621,  37.7716, 103.0280], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 2.3842e-06, 1.7047e-05, 1.6201e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.7189,  33.4622,  37.7719, 103.2710], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3823.3354, 5019.9414, 4033.6079, 5637.8418])\n",
            "l2norm ;  tensor([[0.7488],\n",
            "        [1.2611],\n",
            "        [1.2769],\n",
            "        [0.9283]], dtype=torch.float64)\n",
            "t :  136\n",
            "decayed_penalty_factor :  14.000000000000007\n",
            "ce:  tensor([ 25.4257,  33.9127,  37.4511, 103.0676], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 3.0994e-06, 1.5020e-05, 1.6562e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.4257,  33.9127,  37.4513, 103.2995], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3794.3469, 3694.0784, 5015.8633, 7595.1240])\n",
            "l2norm ;  tensor([[0.3603],\n",
            "        [1.7448],\n",
            "        [1.2518],\n",
            "        [1.1387]], dtype=torch.float64)\n",
            "t :  137\n",
            "decayed_penalty_factor :  13.0\n",
            "ce:  tensor([ 25.8553,  33.3266,  38.0113, 103.0845], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 2.3842e-06, 1.6689e-05, 1.6972e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.8553,  33.3266,  38.0115, 103.3051], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5416.2695, 4872.6602, 4235.2329, 6038.0518])\n",
            "l2norm ;  tensor([[1.5475],\n",
            "        [1.1658],\n",
            "        [1.2260],\n",
            "        [0.6674]], dtype=torch.float64)\n",
            "t :  138\n",
            "decayed_penalty_factor :  11.999999999999995\n",
            "ce:  tensor([ 25.9101,  33.9184,  37.7999, 103.1235], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 2.7418e-06, 1.6212e-05, 1.6650e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.9101,  33.9184,  37.8001, 103.3233], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3695.1826, 4640.9683, 4613.4106, 7594.0229])\n",
            "l2norm ;  tensor([[1.5737],\n",
            "        [1.7221],\n",
            "        [1.4234],\n",
            "        [1.2820]], dtype=torch.float64)\n",
            "t :  139\n",
            "decayed_penalty_factor :  11.000000000000004\n",
            "ce:  tensor([ 25.7449,  33.6808,  38.2120, 103.1287], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 2.3842e-06, 1.8954e-05, 1.7890e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.7449,  33.6809,  38.2122, 103.3255], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5162.1953, 3292.2087, 3886.4653, 6037.1196])\n",
            "l2norm ;  tensor([[1.1008],\n",
            "        [0.5751],\n",
            "        [0.9614],\n",
            "        [0.5648]], dtype=torch.float64)\n",
            "t :  140\n",
            "decayed_penalty_factor :  9.999999999999998\n",
            "ce:  tensor([ 26.0009,  33.9723,  37.9106, 103.1523], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 2.3842e-06, 1.7166e-05, 1.7973e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.0009,  33.9723,  37.9108, 103.3320], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4635.5425, 5271.9937, 3036.4412, 7593.2847])\n",
            "l2norm ;  tensor([[2.3675],\n",
            "        [1.3870],\n",
            "        [0.4687],\n",
            "        [1.0483]], dtype=torch.float64)\n",
            "t :  141\n",
            "decayed_penalty_factor :  9.000000000000007\n",
            "ce:  tensor([ 26.4461,  33.8750,  38.4805, 103.2756], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 2.8610e-06, 1.9073e-05, 1.8446e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.4462,  33.8750,  38.4807, 103.4417], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6199.0264, 3585.4197, 5922.6484, 5634.8975])\n",
            "l2norm ;  tensor([[1.5554],\n",
            "        [0.9182],\n",
            "        [1.3741],\n",
            "        [0.6854]], dtype=torch.float64)\n",
            "t :  142\n",
            "decayed_penalty_factor :  8.000000000000002\n",
            "ce:  tensor([ 26.5183,  33.9841,  38.3600, 103.3256], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0729e-06, 2.5034e-06, 2.1696e-05, 1.8683e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.5183,  33.9841,  38.3602, 103.4750], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3695.1824, 5350.6528, 4544.2061, 7592.2485])\n",
            "l2norm ;  tensor([[0.8171],\n",
            "        [2.5989],\n",
            "        [2.0547],\n",
            "        [1.0361]], dtype=torch.float64)\n",
            "t :  143\n",
            "decayed_penalty_factor :  6.999999999999995\n",
            "ce:  tensor([ 26.5633,  34.4026,  38.4013, 103.4129], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 3.0994e-06, 1.8239e-05, 1.9440e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.5633,  34.4026,  38.4015, 103.5490], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5417.5527, 3694.0752, 5266.4668, 5633.7900])\n",
            "l2norm ;  tensor([[1.1603],\n",
            "        [1.2241],\n",
            "        [1.2367],\n",
            "        [0.9471]], dtype=torch.float64)\n",
            "t :  144\n",
            "decayed_penalty_factor :  6.000000000000005\n",
            "ce:  tensor([ 26.5614,  33.9713,  38.3349, 103.4252], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-06, 2.7418e-06, 2.1338e-05, 1.9481e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.5614,  33.9714,  38.3350, 103.5421], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4295.3354, 3292.2075, 3795.9429, 7591.1387])\n",
            "l2norm ;  tensor([[1.1146],\n",
            "        [0.3958],\n",
            "        [0.9536],\n",
            "        [1.2478]], dtype=torch.float64)\n",
            "t :  145\n",
            "decayed_penalty_factor :  4.999999999999999\n",
            "ce:  tensor([ 26.8161,  34.1270,  38.4122, 103.4194], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-06, 2.6226e-06, 1.9312e-05, 2.0953e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.8161,  34.1270,  38.4123, 103.5242], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4890.6367, 5271.9922, 5862.0234, 6033.6841])\n",
            "l2norm ;  tensor([[1.7189],\n",
            "        [1.2854],\n",
            "        [1.2178],\n",
            "        [0.7101]], dtype=torch.float64)\n",
            "t :  146\n",
            "decayed_penalty_factor :  3.9999999999999925\n",
            "ce:  tensor([ 26.8522,  34.6269,  38.5188, 103.3960], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5497e-06, 3.0994e-06, 2.2411e-05, 2.1556e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.8522,  34.6269,  38.5189, 103.4822], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3695.1821, 5612.3701, 3036.4302, 7590.1055])\n",
            "l2norm ;  tensor([[0.7675],\n",
            "        [2.8693],\n",
            "        [0.8648],\n",
            "        [1.1902]], dtype=torch.float64)\n",
            "t :  147\n",
            "decayed_penalty_factor :  3.0000000000000027\n",
            "ce:  tensor([ 26.8241,  34.5790,  38.7481, 103.4471], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3113e-06, 2.7418e-06, 2.1696e-05, 2.2510e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.8241,  34.5790,  38.7482, 103.5147], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5417.5522, 5527.3765, 5523.1113, 6032.3301])\n",
            "l2norm ;  tensor([[1.1850],\n",
            "        [1.0295],\n",
            "        [1.3206],\n",
            "        [0.7450]], dtype=torch.float64)\n",
            "t :  148\n",
            "decayed_penalty_factor :  1.9999999999999962\n",
            "ce:  tensor([ 26.9329,  34.8717,  38.7045, 103.4071], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6689e-06, 3.5763e-06, 2.4914e-05, 2.2292e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.9329,  34.8717,  38.7045, 103.4517], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4093.6987, 3946.9512, 4798.0435, 7588.7432])\n",
            "l2norm ;  tensor([[0.9432],\n",
            "        [1.1796],\n",
            "        [1.4827],\n",
            "        [1.1754]], dtype=torch.float64)\n",
            "t :  149\n",
            "decayed_penalty_factor :  1.0000000000000064\n",
            "ce:  tensor([ 26.8579,  34.7897,  38.9720, 103.4738], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3113e-06, 2.9802e-06, 2.2411e-05, 2.3823e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.8579,  34.7897,  38.9720, 103.4976], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5394.3652, 5019.9375, 4613.3892, 5629.8135])\n",
            "l2norm ;  tensor([[1.3842],\n",
            "        [1.4240],\n",
            "        [1.1329],\n",
            "        [0.8204]], dtype=torch.float64)\n",
            "PGD l2: Attack effectiveness 0.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([0.0006, 0.0078, -0.0000, -0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to9tOIafa0tD",
        "outputId": "a7225f66-aa82-4059-dd58-478ddcd3f72f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.0159,  -4.5420],\n",
              "        [  0.7008,  -1.1086],\n",
              "        [  0.8464,  -1.0425],\n",
              "        [-14.8106,  16.5576]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(mals.to(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga0MyFVia-nJ",
        "outputId": "bf0fc8ab-2a6e-4944-a440-c5855531acb2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-19.8462,  21.1819],\n",
              "        [-42.3733,  44.2564],\n",
              "        [-28.2794,  29.8791],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hpRfjZlVS-fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cEG-feOGS-cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zo93PmRES-u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        print('*********************************************************')\n",
        "        print('t : ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "        print('loss : ',loss)\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "            print('torch.abs(perturbation).sum(dim=-1) : ',torch.abs(perturbation).sum(dim=-1))\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            print('l2norm ; ',l2norm)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            print('max(grad) : ',val)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            outputs = model(x_next)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            done = (predicted != y).squeeze()\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "VAGvgkIzS_DW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gkde(x, y, model, penalty_factor, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        print('*************************************************')\n",
        "        print('t : ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        #y_model = model(x_var)\n",
        "        if t > 60:\n",
        "          decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "          #print('t : ',t)\n",
        "          #print('decayed_penalty_factor : ',decayed_penalty_factor)\n",
        "        else:\n",
        "          decayed_penalty_factor = penalty_factor\n",
        "\n",
        "        # Compute loss\n",
        "        loss, _ = get_loss_kde(x_var,y,model, decayed_penalty_factor)\n",
        "        print('loss : ',loss)\n",
        "        print('loss_natural : ' ,criterion(model(x_var), y.view(-1).long()))\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "            print('torch.abs(perturbation).sum(dim=-1) : ',torch.abs(perturbation).sum(dim=-1))\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            print('l2norm ; ',l2norm)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            #print('un_mod',un_mod.sum(dim=-1))\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            print('max_grad', val)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            _, done = get_loss_kde(x_next,y,model, penalty_factor)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, y.view(-1).long()).data\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    print('loss_natural : ',loss_natural)\n",
        "    print('loss_adv : ',loss_adv)\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "QN1EByvZTjAk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model, penalty_factor):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    print('ce: ', ce)\n",
        "    outputs_rbf = model_gaussian_1000(adv_x)\n",
        "    kde = criterion(outputs_rbf, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    #kde=0.\n",
        "    print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "_76-fZbLTjAl"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#comparing two approaches:\n",
        "\n",
        " 1: loss based on its class and maximize the loss\n",
        "\n",
        " 2: loss based on the goal's class and minimize the loss\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qYzL-xKWhTD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `l1 attack`"
      ],
      "metadata": {
        "id": "vl7nVQXTaAhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_AT_rFGSM, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgQwFdzgS3kz",
        "outputId": "6548758e-52f1-4e97-88a9-ea29105c0653"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*********************************************************\n",
            "t :  0\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.4870e-15, 1.1302e-34, 2.6278e-22, 0.0000e+00])\n",
            "max(grad) :  tensor([[4.3781e-18],\n",
            "        [5.2451e-38],\n",
            "        [6.5250e-26],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  1\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5985e-04, 6.1378e-28, 2.3369e-20, 0.0000e+00])\n",
            "max(grad) :  tensor([[9.3436e-08],\n",
            "        [2.5265e-31],\n",
            "        [5.4686e-24],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  2\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 3.7722e-21, 2.1269e-16, 0.0000e+00])\n",
            "max(grad) :  tensor([[1.6631e+00],\n",
            "        [1.2673e-24],\n",
            "        [4.7833e-20],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  3\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 2.6399e-15, 2.6725e-12, 0.0000e+00])\n",
            "max(grad) :  tensor([[1.6631e+00],\n",
            "        [7.9984e-19],\n",
            "        [5.7116e-16],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  4\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 3.1136e-10, 3.1988e-08, 0.0000e+00])\n",
            "max(grad) :  tensor([[1.6631e+00],\n",
            "        [8.9839e-14],\n",
            "        [6.1582e-12],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  5\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 1.4353e-05, 1.9638e-04, 0.0000e+00])\n",
            "max(grad) :  tensor([[1.6631e+00],\n",
            "        [3.8651e-09],\n",
            "        [3.5020e-08],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  6\n",
            "loss :  tensor([1.0299e+01, 5.0068e-06, 1.4304e-04, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 4.3532e-02, 1.6415e+00, 0.0000e+00])\n",
            "max(grad) :  tensor([[1.6631e+00],\n",
            "        [1.0837e-05],\n",
            "        [2.7402e-04],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  7\n",
            "loss :  tensor([10.2994,  0.0167,  0.3061, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8880.3486,  131.3973, 3233.3621,    0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [0.0367],\n",
            "        [0.1887],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  8\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  9\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  10\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  11\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  12\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  13\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  14\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  15\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  16\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  17\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  18\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  19\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  20\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  21\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  22\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  23\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  24\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  25\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  26\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  27\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  28\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  29\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  30\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  31\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  32\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  33\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  34\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  35\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  36\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  37\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  38\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  39\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  40\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  41\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  42\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  43\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  44\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  45\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  46\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  47\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  48\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  49\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "PGD l1: Attack effectiveness 75.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Myu2JdDPTiyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 0, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAqEfIhESwd_",
        "outputId": "03fb7d20-1eef-4f27-b4df-1883a2cf865f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t :  0\n",
            "loss :  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n",
            "max_grad tensor([[5.9220],\n",
            "        [4.4970],\n",
            "        [2.4442],\n",
            "        [5.5750]], dtype=torch.float64)\n",
            "t :  1\n",
            "loss :  tensor([ 17.2574,  71.0176,  53.6272, 164.5218], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10475.5771,  8753.7480,  9374.5732,  9018.6055])\n",
            "max_grad tensor([[6.1256],\n",
            "        [3.5946],\n",
            "        [2.1932],\n",
            "        [2.4330]], dtype=torch.float64)\n",
            "t :  2\n",
            "loss :  tensor([3.3616e-05, 5.5429e+01, 4.4622e+01, 1.5478e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1265e+03, 1.0463e+04, 9.0235e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.0219e+00],\n",
            "        [2.3581e+00],\n",
            "        [1.5561e+00]], dtype=torch.float64)\n",
            "t :  3\n",
            "loss :  tensor([3.3616e-05, 4.2018e+01, 3.5233e+01, 1.4863e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.5316e+03, 1.0955e+04, 8.8765e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.9064e+00],\n",
            "        [2.3421e+00],\n",
            "        [1.6096e+00]], dtype=torch.float64)\n",
            "t :  4\n",
            "loss :  tensor([3.3616e-05, 3.0319e+01, 2.5832e+01, 1.4469e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.3921e+03, 1.0962e+04, 8.4613e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.7028e+00],\n",
            "        [2.1177e+00],\n",
            "        [1.6392e+00]], dtype=torch.float64)\n",
            "t :  5\n",
            "loss :  tensor([3.3616e-05, 1.9540e+01, 1.7143e+01, 1.3839e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1422e+03, 1.1507e+04, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.4242e+00],\n",
            "        [2.0476e+00],\n",
            "        [1.2280e+00]], dtype=torch.float64)\n",
            "t :  6\n",
            "loss :  tensor([3.3616e-05, 1.2214e+01, 8.8525e+00, 1.3348e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0299e+01, 5.0068e-06, 1.4304e-04, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 8.7310e+03, 1.1474e+04, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.1735e+00],\n",
            "        [1.9154e+00],\n",
            "        [1.2060e+00]], dtype=torch.float64)\n",
            "t :  7\n",
            "loss :  tensor([3.3616e-05, 4.0993e+00, 1.3330e+00, 1.2865e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  0.0167,  0.3061, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 7.7917e+03, 9.0294e+03, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.1753e+00],\n",
            "        [5.2700e-01],\n",
            "        [1.1217e+00]], dtype=torch.float64)\n",
            "t :  8\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.2417e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.1173e+00]], dtype=torch.float64)\n",
            "t :  9\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1939e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.1097e+00]], dtype=torch.float64)\n",
            "t :  10\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1495e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0670e+00]], dtype=torch.float64)\n",
            "t :  11\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1068e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0610e+00]], dtype=torch.float64)\n",
            "t :  12\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0643e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0143e+00]], dtype=torch.float64)\n",
            "t :  13\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0237e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0043e+00]], dtype=torch.float64)\n",
            "t :  14\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.8351e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [9.9714e-01]], dtype=torch.float64)\n",
            "t :  15\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.4362e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [9.3243e-01]], dtype=torch.float64)\n",
            "t :  16\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.0639e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3357e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.5881e-01]], dtype=torch.float64)\n",
            "t :  17\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.7156e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.0538e-01]], dtype=torch.float64)\n",
            "t :  18\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.3935e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3143e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.9628e-01]], dtype=torch.float64)\n",
            "t :  19\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.0755e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.9117e-01]], dtype=torch.float64)\n",
            "t :  20\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.7752e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8621e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.1519e-01]], dtype=torch.float64)\n",
            "t :  21\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.4700e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.8368e-01]], dtype=torch.float64)\n",
            "t :  22\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.1965e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5682e-01]], dtype=torch.float64)\n",
            "t :  23\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.9337e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3132e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5225e-01]], dtype=torch.float64)\n",
            "t :  24\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.7578e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8157e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.9891e-01]], dtype=torch.float64)\n",
            "t :  25\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.4789e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8228e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.8515e-01]], dtype=torch.float64)\n",
            "t :  26\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2163e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2845e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5524e-01]], dtype=torch.float64)\n",
            "t :  27\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2409e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7232e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.0716e-01]], dtype=torch.float64)\n",
            "t :  28\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.9668e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8201e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.7152e-01]], dtype=torch.float64)\n",
            "t :  29\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.7031e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7293e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.2330e-01]], dtype=torch.float64)\n",
            "t :  30\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.4995e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2633e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.1782e-01]], dtype=torch.float64)\n",
            "t :  31\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.2756e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5679e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.9095e-01]], dtype=torch.float64)\n",
            "t :  32\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.0393e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.6147e-01]], dtype=torch.float64)\n",
            "t :  33\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.8147e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.5578e-01]], dtype=torch.float64)\n",
            "t :  34\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.7072e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0702e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4725e-01]], dtype=torch.float64)\n",
            "t :  35\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.4889e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4381e-01]], dtype=torch.float64)\n",
            "t :  36\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.2713e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4263e-01]], dtype=torch.float64)\n",
            "t :  37\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.0543e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4237e-01]], dtype=torch.float64)\n",
            "t :  38\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.8393e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9781e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.9568e-01]], dtype=torch.float64)\n",
            "t :  39\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.6430e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.6170e-01]], dtype=torch.float64)\n",
            "t :  40\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.4583e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.3553e-01]], dtype=torch.float64)\n",
            "t :  41\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2908e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3707e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.3911e-01]], dtype=torch.float64)\n",
            "t :  42\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2531e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.4075e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.3935e-01]], dtype=torch.float64)\n",
            "t :  43\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2872e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.4608e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.5223e+00]], dtype=torch.float64)\n",
            "t :  44\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2053e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.8152e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.3077e-01]], dtype=torch.float64)\n",
            "t :  45\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.0705e-01]], dtype=torch.float64)\n",
            "t :  46\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.5631e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.9829e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.6541e-01]], dtype=torch.float64)\n",
            "t :  47\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.3381e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8933e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.8362e-01]], dtype=torch.float64)\n",
            "t :  48\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1606e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 4.9637e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.9100e-01]], dtype=torch.float64)\n",
            "t :  49\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2428e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.7787e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.0003e-01]], dtype=torch.float64)\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([10.2994,  3.8019,  2.1209, -0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(mals.to(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQdsaaSDkJGt",
        "outputId": "b19fc239-43a7-4fc4-d1ba-9a840614dd19"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-19.8462,  21.1819],\n",
              "        [-42.3733,  44.2564],\n",
              "        [-28.2794,  29.8791],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY9WI2agXaPm",
        "outputId": "4e573d18-f462-49f9-93a7-dc731c13a005"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.8403,  -5.4591],\n",
              "        [  1.5538,  -2.2255],\n",
              "        [  0.8769,  -1.1162],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpbw4NJOXW8e",
        "outputId": "e287d641-9569-42cd-b623-59b58e323558"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.8403,  -5.4591],\n",
              "        [  1.5538,  -2.2255],\n",
              "        [  0.8769,  -1.1162],\n",
              "        [-14.3782,  16.4776]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pWJIcjGoaLxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `linf attack`"
      ],
      "metadata": {
        "id": "7kiaFrgiaMBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_AT_rFGSM, insertion_array, removal_array, k=100, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd722d5-0744-4c66-85cf-5f77cf14b419",
        "id": "MucmaxrCaMBo"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*********************************************************\n",
            "t :  0\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.4870e-15, 1.1302e-34, 2.6278e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([121., 225., 247.,   0.])\n",
            "*********************************************************\n",
            "t :  1\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.6104e-14, 2.6541e-32, 9.4535e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([114., 269., 199.,   0.])\n",
            "*********************************************************\n",
            "t :  2\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.9466e-13, 3.1007e-29, 5.3306e-19, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105., 316., 209.,   0.])\n",
            "*********************************************************\n",
            "t :  3\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.1073e-12, 3.0971e-26, 2.5778e-17, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([121., 327., 219.,   0.])\n",
            "*********************************************************\n",
            "t :  4\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.7257e-11, 8.3830e-23, 1.3431e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111., 337., 228.,   0.])\n",
            "*********************************************************\n",
            "t :  5\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.7650e-10, 3.0536e-21, 8.0913e-14, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([131., 259., 225.,   0.])\n",
            "*********************************************************\n",
            "t :  6\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.1742e-09, 1.6437e-19, 1.6523e-12, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([136., 246., 219.,   0.])\n",
            "*********************************************************\n",
            "t :  7\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.1507e-09, 9.5543e-18, 4.5661e-12, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([100., 243., 159.,   0.])\n",
            "*********************************************************\n",
            "t :  8\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.5897e-08, 1.0583e-16, 3.1140e-11, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([123., 155., 155.,   0.])\n",
            "*********************************************************\n",
            "t :  9\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.3366e-08, 1.2247e-15, 1.1673e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([103., 153., 122.,   0.])\n",
            "*********************************************************\n",
            "t :  10\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.4573e-07, 1.3879e-14, 5.2028e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 99., 153., 128.,   0.])\n",
            "*********************************************************\n",
            "t :  11\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.0291e-06, 1.6619e-13, 1.7374e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([106., 201., 120.,   0.])\n",
            "*********************************************************\n",
            "t :  12\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.2036e-06, 3.6093e-13, 1.3230e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 98., 141.,  87.,   0.])\n",
            "*********************************************************\n",
            "t :  13\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.6678e-06, 7.8356e-13, 2.7389e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 84., 108.,  96.,   0.])\n",
            "*********************************************************\n",
            "t :  14\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.4771e-06, 1.7149e-12, 3.9581e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([208., 108.,  87.,   0.])\n",
            "*********************************************************\n",
            "t :  15\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.0192e-06, 3.7534e-12, 6.4940e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109., 108., 119.,   0.])\n",
            "*********************************************************\n",
            "t :  16\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.7281e-06, 9.9066e-12, 2.7813e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 84., 142., 100.,   0.])\n",
            "*********************************************************\n",
            "t :  17\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.2480e-06, 3.8477e-12, 5.6265e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109., 129., 118.,   0.])\n",
            "*********************************************************\n",
            "t :  18\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.3089e-06, 8.0272e-12, 5.2267e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92., 129., 119.,   0.])\n",
            "*********************************************************\n",
            "t :  19\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.3284e-06, 1.8641e-11, 2.5452e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 84., 129., 100.,   0.])\n",
            "*********************************************************\n",
            "t :  20\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.4652e-06, 3.5751e-11, 4.4896e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 90., 130., 100.,   0.])\n",
            "*********************************************************\n",
            "t :  21\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.2551e-05, 1.5410e-11, 7.3787e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105., 129., 117.,   0.])\n",
            "*********************************************************\n",
            "t :  22\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.4426e-06, 3.2149e-11, 3.7648e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 88., 129., 110.,   0.])\n",
            "*********************************************************\n",
            "t :  23\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.0505e-05, 6.4371e-11, 4.9495e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87., 122.,  97.,   0.])\n",
            "*********************************************************\n",
            "t :  24\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.8071e-05, 1.7253e-10, 7.1295e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111., 185., 155.,   0.])\n",
            "*********************************************************\n",
            "t :  25\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5796e-05, 4.2677e-11, 2.5773e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([201., 112.,  85.,   0.])\n",
            "*********************************************************\n",
            "t :  26\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.5562e-06, 7.7367e-11, 3.0913e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 100.,  82.,   0.])\n",
            "*********************************************************\n",
            "t :  27\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.9581e-06, 7.2462e-11, 2.6442e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87., 123., 104.,   0.])\n",
            "*********************************************************\n",
            "t :  28\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.9243e-06, 3.4022e-11, 1.5375e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75., 100.,  82.,   0.])\n",
            "*********************************************************\n",
            "t :  29\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.0502e-06, 4.6957e-11, 1.4441e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 122., 111.,   0.])\n",
            "*********************************************************\n",
            "t :  30\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.4065e-07, 1.4101e-11, 6.1150e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([77., 95., 78.,  0.])\n",
            "*********************************************************\n",
            "t :  31\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.3122e-06, 2.2286e-11, 5.2846e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102., 121., 137.,   0.])\n",
            "*********************************************************\n",
            "t :  32\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.0846e-07, 6.3224e-12, 1.6260e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 76., 228.,  97.,   0.])\n",
            "*********************************************************\n",
            "t :  33\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.4732e-07, 7.9178e-13, 1.0777e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 67., 124., 102.,   0.])\n",
            "*********************************************************\n",
            "t :  34\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.4253e-07, 3.7322e-13, 4.7847e-11, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([146.,  68., 239.,   0.])\n",
            "*********************************************************\n",
            "t :  35\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.0982e-07, 3.8144e-13, 1.1913e-12, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75.,  88., 111.,   0.])\n",
            "*********************************************************\n",
            "t :  36\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.6743e-08, 2.0733e-13, 2.1224e-12, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([117., 117.,  85.,   0.])\n",
            "*********************************************************\n",
            "t :  37\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.0280e-08, 1.5712e-13, 8.6320e-13, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([97., 82., 87.,  0.])\n",
            "*********************************************************\n",
            "t :  38\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.1979e-08, 1.5707e-13, 8.3293e-13, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 71., 114., 139.,   0.])\n",
            "*********************************************************\n",
            "t :  39\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.6723e-08, 4.0591e-14, 1.5517e-13, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([74., 90., 78.,  0.])\n",
            "*********************************************************\n",
            "t :  40\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.1117e-08, 4.6377e-14, 1.9136e-13, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([97., 76., 55.,  0.])\n",
            "*********************************************************\n",
            "t :  41\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.3204e-09, 3.1243e-14, 1.5697e-13, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([188.,  84.,  93.,   0.])\n",
            "*********************************************************\n",
            "t :  42\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.0539e-10, 1.5208e-14, 7.4041e-14, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 94., 110.,  94.,   0.])\n",
            "*********************************************************\n",
            "t :  43\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.2089e-10, 1.0292e-14, 5.9167e-14, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([90., 88., 99.,  0.])\n",
            "*********************************************************\n",
            "t :  44\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.9714e-10, 5.9103e-15, 1.7089e-14, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 70., 116.,  91.,   0.])\n",
            "*********************************************************\n",
            "t :  45\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.7368e-10, 3.7699e-15, 2.7952e-14, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([101.,  77., 150.,   0.])\n",
            "*********************************************************\n",
            "t :  46\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.7646e-11, 6.9744e-15, 3.8062e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 65., 161.,  93.,   0.])\n",
            "*********************************************************\n",
            "t :  47\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.6085e-10, 7.0478e-16, 7.0350e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 99.,  92., 109.,   0.])\n",
            "*********************************************************\n",
            "t :  48\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.7801e-11, 1.5403e-15, 1.7172e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 109.,  95.,   0.])\n",
            "*********************************************************\n",
            "t :  49\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.4431e-11, 3.7060e-16, 2.4987e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([106., 111., 106.,   0.])\n",
            "*********************************************************\n",
            "t :  50\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.9539e-11, 4.5064e-16, 9.0057e-16, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([104.,  79.,  78.,   0.])\n",
            "*********************************************************\n",
            "t :  51\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.1047e-12, 3.3778e-16, 1.2846e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75., 110., 159.,   0.])\n",
            "*********************************************************\n",
            "t :  52\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.2810e-11, 1.4980e-16, 2.0522e-16, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 99., 143., 102.,   0.])\n",
            "*********************************************************\n",
            "t :  53\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.0188e-12, 1.0055e-16, 1.9296e-16, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 80., 104., 100.,   0.])\n",
            "*********************************************************\n",
            "t :  54\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.4522e-12, 4.7703e-17, 1.1903e-16, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([152., 225., 135.,   0.])\n",
            "*********************************************************\n",
            "t :  55\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.4224e-13, 4.1080e-18, 3.6852e-17, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 106., 138.,   0.])\n",
            "*********************************************************\n",
            "t :  56\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5087e-12, 6.7759e-18, 2.0690e-17, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([127., 111., 106.,   0.])\n",
            "*********************************************************\n",
            "t :  57\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.4455e-13, 3.1157e-18, 1.4269e-17, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([116., 119., 151.,   0.])\n",
            "*********************************************************\n",
            "t :  58\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.7156e-13, 2.6044e-18, 9.6755e-18, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 49., 134.,  65.,   0.])\n",
            "*********************************************************\n",
            "t :  59\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.7363e-13, 8.4409e-19, 4.8078e-18, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92., 127., 124.,   0.])\n",
            "*********************************************************\n",
            "t :  60\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.0508e-14, 1.8195e-18, 2.1180e-18, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 82.,  47., 137.,   0.])\n",
            "*********************************************************\n",
            "t :  61\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.6895e-14, 1.2836e-18, 1.1077e-18, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 93., 152.,  94.,   0.])\n",
            "*********************************************************\n",
            "t :  62\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.3913e-14, 2.5402e-19, 7.9855e-19, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([117., 100., 101.,   0.])\n",
            "*********************************************************\n",
            "t :  63\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.7289e-14, 5.5416e-19, 6.3977e-19, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92.,  48., 131.,   0.])\n",
            "*********************************************************\n",
            "t :  64\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.1366e-14, 3.0632e-19, 2.1672e-19, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 65., 132., 100.,   0.])\n",
            "*********************************************************\n",
            "t :  65\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5011e-14, 1.3088e-19, 3.4705e-19, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 37., 121., 213.,   0.])\n",
            "*********************************************************\n",
            "t :  66\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.4301e-14, 1.5219e-19, 5.9434e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([119., 122., 139.,   0.])\n",
            "*********************************************************\n",
            "t :  67\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.1214e-15, 9.4347e-20, 7.2861e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 97., 122.,  84.,   0.])\n",
            "*********************************************************\n",
            "t :  68\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.1734e-15, 8.7815e-20, 5.1372e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109., 112.,  51.,   0.])\n",
            "*********************************************************\n",
            "t :  69\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.7193e-15, 6.2737e-20, 7.4920e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 96., 117.,  63.,   0.])\n",
            "*********************************************************\n",
            "t :  70\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.3103e-15, 6.0999e-20, 5.0186e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([138., 149.,  46.,   0.])\n",
            "*********************************************************\n",
            "t :  71\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.1290e-16, 1.7765e-20, 5.4369e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([120., 140.,  35.,   0.])\n",
            "*********************************************************\n",
            "t :  72\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.4030e-16, 2.8274e-20, 4.6507e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 97.,  58., 145.,   0.])\n",
            "*********************************************************\n",
            "t :  73\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.2744e-16, 3.7434e-20, 7.8186e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 91., 140.,  97.,   0.])\n",
            "*********************************************************\n",
            "t :  74\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.9127e-16, 1.0557e-20, 1.6894e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([101.,  68.,  24.,   0.])\n",
            "*********************************************************\n",
            "t :  75\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.1814e-16, 1.0732e-20, 1.7972e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([119., 124.,  32.,   0.])\n",
            "*********************************************************\n",
            "t :  76\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.8538e-16, 4.2419e-21, 1.8289e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([100., 108.,  45.,   0.])\n",
            "*********************************************************\n",
            "t :  77\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.4346e-17, 6.6933e-21, 1.4695e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 76., 112.,  34.,   0.])\n",
            "*********************************************************\n",
            "t :  78\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.9673e-16, 3.0489e-21, 9.5550e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 90., 110., 109.,   0.])\n",
            "*********************************************************\n",
            "t :  79\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.2495e-17, 5.3769e-21, 5.0500e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([106.,  49., 111.,   0.])\n",
            "*********************************************************\n",
            "t :  80\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.2412e-17, 3.6719e-21, 7.4751e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102., 158.,  52.,   0.])\n",
            "*********************************************************\n",
            "t :  81\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.2692e-17, 7.1015e-22, 4.8686e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([151., 114., 150.,   0.])\n",
            "*********************************************************\n",
            "t :  82\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.3192e-17, 1.7553e-21, 1.2620e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 99.,  26., 144.,   0.])\n",
            "*********************************************************\n",
            "t :  83\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.6515e-17, 1.9228e-21, 1.3254e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87.,  39., 229.,   0.])\n",
            "*********************************************************\n",
            "t :  84\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.3621e-17, 1.0203e-21, 2.8593e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 97., 127.,  86.,   0.])\n",
            "*********************************************************\n",
            "t :  85\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.2115e-17, 5.3453e-22, 6.7982e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([104., 119.,  25.,   0.])\n",
            "*********************************************************\n",
            "t :  86\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.1460e-17, 8.4763e-22, 5.9915e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([129., 137.,  23.,   0.])\n",
            "*********************************************************\n",
            "t :  87\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.8994e-18, 2.7827e-22, 6.8695e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([114., 123.,  23.,   0.])\n",
            "*********************************************************\n",
            "t :  88\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.6506e-18, 7.3985e-22, 5.9447e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([118.,  24.,  21.,   0.])\n",
            "*********************************************************\n",
            "t :  89\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.1935e-18, 5.2345e-22, 6.7557e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 90., 136.,  24.,   0.])\n",
            "*********************************************************\n",
            "t :  90\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.3738e-18, 1.8587e-22, 5.8023e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([149., 114.,  21.,   0.])\n",
            "*********************************************************\n",
            "t :  91\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.7866e-19, 4.8751e-22, 6.6963e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([92., 49., 45.,  0.])\n",
            "*********************************************************\n",
            "t :  92\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5926e-18, 2.4685e-22, 4.7137e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([117., 123.,  42.,   0.])\n",
            "*********************************************************\n",
            "t :  93\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.2921e-19, 1.2642e-22, 5.7823e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([118., 112.,  58.,   0.])\n",
            "*********************************************************\n",
            "t :  94\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.1816e-19, 2.8247e-22, 4.2319e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([136., 167.,  44.,   0.])\n",
            "*********************************************************\n",
            "t :  95\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.1828e-19, 4.1906e-23, 5.6204e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([101., 116.,  68.,   0.])\n",
            "*********************************************************\n",
            "t :  96\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.7399e-19, 1.2198e-22, 3.2500e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([115., 131.,  49.,   0.])\n",
            "*********************************************************\n",
            "t :  97\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.7571e-19, 3.2483e-23, 4.7561e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([107.,  61.,  58.,   0.])\n",
            "*********************************************************\n",
            "t :  98\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9833e-19, 5.5510e-23, 3.1224e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([90., 32., 46.,  0.])\n",
            "*********************************************************\n",
            "t :  99\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.6262e-19, 4.7636e-23, 3.7931e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([121.,  28.,  17.,   0.])\n",
            "PGD linf: Attack effectiveness 0.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 0, insertion_array, removal_array, k=100, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b483c45-7801-4d97-d9d6-1303142b812f",
        "id": "n8EdiEvfaMBq"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "t :  0\n",
            "loss :  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([119., 224., 242., 269.])\n",
            "*************************************************\n",
            "t :  1\n",
            "loss :  tensor([ 38.9261,  81.0620,  54.4818, 180.4803], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10320.1094,  8620.9150,  9300.6074,  9011.1484])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102., 261., 197., 269.])\n",
            "*************************************************\n",
            "t :  2\n",
            "loss :  tensor([ 36.9672,  74.1730,  50.4399, 174.7070], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9165.1289, 9202.2500, 9227.6904, 8399.1846])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92., 308., 220., 262.])\n",
            "*************************************************\n",
            "t :  3\n",
            "loss :  tensor([ 34.5991,  67.0495,  46.4729, 168.9660], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8735.9189, 8263.8496, 8915.4727, 8258.7188])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111., 309., 203., 248.])\n",
            "*************************************************\n",
            "t :  4\n",
            "loss :  tensor([ 32.2973,  59.1113,  42.5275, 163.4096], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8493.3340, 7385.1299, 8754.5732, 8258.7188])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([103., 319., 216., 248.])\n",
            "*************************************************\n",
            "t :  5\n",
            "loss :  tensor([ 30.2587,  55.1975,  38.4088, 157.8634], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9281.1836, 7970.1445, 8738.1250, 8252.8262])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([122., 247., 217., 247.])\n",
            "*************************************************\n",
            "t :  6\n",
            "loss :  tensor([ 28.2272,  50.9528,  35.2546, 152.3443], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8219.1064, 6950.1992, 7885.7285, 8250.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([116., 243., 201., 247.])\n",
            "*************************************************\n",
            "t :  7\n",
            "loss :  tensor([ 26.1662,  46.8429,  33.8714, 146.8350], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6868.9570, 6875.8882, 6755.9170, 8250.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 91., 226., 147., 247.])\n",
            "*************************************************\n",
            "t :  8\n",
            "loss :  tensor([ 24.5901,  43.7140,  31.8959, 141.3257], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6750.8560, 6098.1050, 6719.6836, 8250.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87., 150., 145., 247.])\n",
            "*************************************************\n",
            "t :  9\n",
            "loss :  tensor([ 23.1277,  41.2342,  29.9907, 135.8538], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7547.0591, 6098.1050, 6676.7642, 8161.2568])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 94., 150., 143., 238.])\n",
            "*************************************************\n",
            "t :  10\n",
            "loss :  tensor([ 22.4542,  38.9035,  28.9155, 130.6019], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6336.0449, 7014.7983, 5607.2778, 8161.2568])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 81., 193., 117., 238.])\n",
            "*************************************************\n",
            "t :  11\n",
            "loss :  tensor([ 21.2590,  37.2616,  27.4847, 125.3665], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5902.6260, 6059.2842, 5569.2759, 8126.8125])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 78., 146., 114., 240.])\n",
            "*************************************************\n",
            "t :  12\n",
            "loss :  tensor([ 19.9286,  35.1469,  27.3365, 120.1605], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5871.0557, 5120.8809, 3988.7178, 8094.7358])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 82., 136.,  82., 236.])\n",
            "*************************************************\n",
            "t :  13\n",
            "loss :  tensor([ 18.6790,  33.7603,  26.7909, 115.2130], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5722.6396, 3284.2192, 3421.1265, 7974.3389])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 77., 112.,  85., 231.])\n",
            "*************************************************\n",
            "t :  14\n",
            "loss :  tensor([ 18.9175,  32.9630,  26.1729, 110.2807], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5107.4839, 3279.4324, 3477.6370, 7974.3389])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([134., 110.,  83., 231.])\n",
            "*************************************************\n",
            "t :  15\n",
            "loss :  tensor([ 19.2570,  32.1819,  25.8127, 106.1112], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4442.6294, 4856.6699, 4802.6626, 7280.1831])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 73., 131., 116., 211.])\n",
            "*************************************************\n",
            "t :  16\n",
            "loss :  tensor([ 19.0701,  32.5674,  26.3655, 102.5519], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5605.9072, 3787.5869, 4136.5845, 6288.3242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 83., 115., 103., 156.])\n",
            "*************************************************\n",
            "t :  17\n",
            "loss :  tensor([18.9791, 31.9369, 26.0897, 99.3398], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4034.7456, 3134.3682, 3165.9988, 6288.3242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 117.,  97., 156.])\n",
            "*************************************************\n",
            "t :  18\n",
            "loss :  tensor([18.2817, 31.1933, 25.7029, 96.1278], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4034.7456, 3134.3682, 5051.0332, 6288.3242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 117., 123., 156.])\n",
            "*************************************************\n",
            "t :  19\n",
            "loss :  tensor([17.5843, 30.4497, 26.3557, 92.9893], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4034.7456, 3134.3682, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 117.,  94., 150.])\n",
            "*************************************************\n",
            "t :  20\n",
            "loss :  tensor([16.8869, 29.8929, 25.7846, 89.8805], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4034.7454, 4709.4390, 3729.3491, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 122., 101., 150.])\n",
            "*************************************************\n",
            "t :  21\n",
            "loss :  tensor([16.5455, 30.5232, 25.5007, 86.7717], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5100.2427, 4614.0112, 5192.3447, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75., 237., 102., 150.])\n",
            "*************************************************\n",
            "t :  22\n",
            "loss :  tensor([16.4930, 31.0354, 26.0035, 83.6629], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4034.7454, 3134.3682, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 117.,  94., 150.])\n",
            "*************************************************\n",
            "t :  23\n",
            "loss :  tensor([15.8910, 30.5713, 25.4269, 80.5541], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3428.3442, 4709.4390, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59., 122.,  94., 150.])\n",
            "*************************************************\n",
            "t :  24\n",
            "loss :  tensor([15.2549, 30.8426, 25.3847, 78.1801], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3428.3438, 3134.3682, 6175.7275, 4611.9790])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59., 117., 149., 161.])\n",
            "*************************************************\n",
            "t :  25\n",
            "loss :  tensor([14.6676, 30.1644, 26.1598, 75.9270], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.7684e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5341.5239, 3550.8931, 3222.1963, 4462.4604])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 80.,  99.,  87., 136.])\n",
            "*************************************************\n",
            "t :  26\n",
            "loss :  tensor([15.0635, 29.6926, 25.6648, 73.9886], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3428.3433, 3036.4189, 4099.5752, 4062.1274])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([51., 91., 89., 86.])\n",
            "*************************************************\n",
            "t :  27\n",
            "loss :  tensor([14.8631, 29.8506, 26.2489, 74.5140], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.5763e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3653.8372, 4613.3867, 4768.4033, 6039.4648])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 49., 107.,  99.,  63.])\n",
            "*************************************************\n",
            "t :  28\n",
            "loss :  tensor([14.6755, 30.4484, 26.7233, 74.3617], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.7684e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3119.2571, 3550.8931, 3222.1963, 4062.1274])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59.,  86.,  77., 100.])\n",
            "*************************************************\n",
            "t :  29\n",
            "loss :  tensor([15.2084, 30.4031, 26.6611, 75.1037], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5722.4585, 3686.2048, 5954.7959, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 81.,  77., 100.,  61.])\n",
            "*************************************************\n",
            "t :  30\n",
            "loss :  tensor([15.3051, 30.5219, 27.5171, 74.7511], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3824.5381, 4868.6455, 3222.1963, 6039.4648])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 51., 112.,  73.,  35.])\n",
            "*************************************************\n",
            "t :  31\n",
            "loss :  tensor([15.1216, 31.4953, 27.4732, 74.9265], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5289.9375, 3550.8931, 5923.0322, 4462.4604])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 72.,  84., 130., 100.])\n",
            "*************************************************\n",
            "t :  32\n",
            "loss :  tensor([16.2197, 31.3611, 28.8655, 75.5406], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5127.4370, 4153.0273, 3729.3491, 5789.2070])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([149., 217.,  82.,  74.])\n",
            "*************************************************\n",
            "t :  33\n",
            "loss :  tensor([17.4013, 34.6743, 28.6891, 75.2225], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4933.9775, 5414.8091, 3618.8379, 6033.4912])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 62., 111.,  55.,  38.])\n",
            "*************************************************\n",
            "t :  34\n",
            "loss :  tensor([17.6353, 33.9646, 29.3002, 75.4099], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3911.3672, 3803.2217, 5051.0332, 4605.9878])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 44.,  77., 103., 101.])\n",
            "*************************************************\n",
            "t :  35\n",
            "loss :  tensor([17.5465, 34.4389, 29.7016, 76.0355], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3541.6221, 4875.8320, 4127.7192, 5634.1650])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59., 109.,  79.,  76.])\n",
            "*************************************************\n",
            "t :  36\n",
            "loss :  tensor([18.1478, 35.0887, 29.9151, 75.7448], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5160.7344, 3950.1208, 5051.0332, 6183.5649])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 68.,  92., 100.,  45.])\n",
            "*************************************************\n",
            "t :  37\n",
            "loss :  tensor([18.3078, 35.1338, 31.1448, 75.7992], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 3441.5703, 4192.1514, 4456.4258])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 47.,  57., 212., 104.])\n",
            "*************************************************\n",
            "t :  38\n",
            "loss :  tensor([18.2437, 35.1553, 34.5713, 76.5162], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3648.2214, 4767.8999, 6429.8174, 5783.4253])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 41., 113., 131.,  74.])\n",
            "*************************************************\n",
            "t :  39\n",
            "loss :  tensor([18.7624, 36.2596, 34.0355, 76.2071], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4672.6055, 3043.7659, 4379.0483, 6033.4912])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([71., 82., 72., 37.])\n",
            "*************************************************\n",
            "t :  40\n",
            "loss :  tensor([19.2109, 36.4460, 34.6355, 76.2051], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 4349.9844, 4795.8843, 4456.4258])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 47.,  91.,  91., 102.])\n",
            "*************************************************\n",
            "t :  41\n",
            "loss :  tensor([19.0794, 36.3411, 35.0546, 77.0117], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3911.3672, 3043.7659, 4134.9858, 5783.4253])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([42., 73., 77., 73.])\n",
            "*************************************************\n",
            "t :  42\n",
            "loss :  tensor([19.5648, 37.7912, 35.4185, 76.6674], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5616.8936, 5929.8252, 5058.1914, 6033.4912])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 99., 106.,  94.,  34.])\n",
            "*************************************************\n",
            "t :  43\n",
            "loss :  tensor([20.8563, 37.3917, 36.0776, 76.8565], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5213.0430, 3840.9678, 3626.1331, 5571.6934])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([145.,  68.,  61., 175.])\n",
            "*************************************************\n",
            "t :  44\n",
            "loss :  tensor([22.1939, 37.5848, 35.9757, 79.4907], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4758.4883, 4620.6113, 3950.5518, 5783.4253])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 62.,  94., 116.,  71.])\n",
            "*************************************************\n",
            "t :  45\n",
            "loss :  tensor([22.4232, 38.7595, 37.3291, 79.0914], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 4299.1665, 5855.1001, 6183.5649])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 46., 116.,  98.,  37.])\n",
            "*************************************************\n",
            "t :  46\n",
            "loss :  tensor([22.3561, 38.9738, 37.6031, 78.9088], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5422.3169, 3295.3997, 3883.0549, 5876.9805])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([59., 65., 82., 55.])\n",
            "*************************************************\n",
            "t :  47\n",
            "loss :  tensor([23.0926, 39.1467, 37.9628, 78.6741], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 6122.5845, 5448.5859, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 49., 154.,  85.,  51.])\n",
            "*************************************************\n",
            "t :  48\n",
            "loss :  tensor([22.9721, 40.4137, 38.2646, 78.9021], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3911.3672, 3288.9519, 4330.9453, 4296.1665])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 39.,  72., 115., 118.])\n",
            "*************************************************\n",
            "t :  49\n",
            "loss :  tensor([23.1417, 40.3063, 39.5162, 79.7308], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4672.6055, 4344.1343, 5596.6099, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([69., 85., 81., 87.])\n",
            "*************************************************\n",
            "t :  50\n",
            "loss :  tensor([23.9780, 40.7384, 39.2600, 79.3028], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 4617.5840, 3474.1106, 6833.7549])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 54.,  96.,  81., 108.])\n",
            "*************************************************\n",
            "t :  51\n",
            "loss :  tensor([23.7258, 41.4948, 40.1157, 79.9747], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3981.4170, 3547.6951, 5982.5942, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 32.,  91., 134.,  61.])\n",
            "*************************************************\n",
            "t :  52\n",
            "loss :  tensor([23.6885, 41.3669, 40.6419, 80.4517], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5422.3169, 5419.0410, 4879.6724, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 64., 112., 117., 117.])\n",
            "*************************************************\n",
            "t :  53\n",
            "loss :  tensor([24.5850, 42.2957, 42.0219, 80.7347], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5213.0430, 3040.1052, 5052.7095, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([149.,  96.,  87.,  94.])\n",
            "*************************************************\n",
            "t :  54\n",
            "loss :  tensor([26.5811, 42.4402, 41.8534, 80.7044], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5462.4043, 7482.7437, 4193.7007, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102., 174., 228., 119.])\n",
            "*************************************************\n",
            "t :  55\n",
            "loss :  tensor([27.0096, 43.6059, 47.1931, 81.3132], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4053.9656, 3837.8774, 7175.5098, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 56.,  88., 146.,  95.])\n",
            "*************************************************\n",
            "t :  56\n",
            "loss :  tensor([26.7271, 43.2892, 46.7588, 80.9192], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5670.7041, 3438.4768, 5596.6099, 4296.1665])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 73.,  42.,  53., 126.])\n",
            "*************************************************\n",
            "t :  57\n",
            "loss :  tensor([27.6096, 43.4300, 46.6079, 82.0546], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 5019.9370, 6104.4409, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 56., 103.,  55.,  92.])\n",
            "*************************************************\n",
            "t :  58\n",
            "loss :  tensor([27.2663, 44.4803, 46.4691, 81.7333], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3668.4836, 3946.9497, 5596.6099, 6581.1318])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 35., 119.,  42., 104.])\n",
            "*************************************************\n",
            "t :  59\n",
            "loss :  tensor([27.3590, 44.3622, 46.4287, 82.1789], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5803.0342, 5019.9370, 6553.4619, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 80., 112.,  64.,  63.])\n",
            "*************************************************\n",
            "t :  60\n",
            "loss :  tensor([28.1253, 45.1623, 46.6692, 82.2566], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3911.3672, 3800.1702, 5052.7095, 3895.4583])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 51., 100.,  54., 131.])\n",
            "*************************************************\n",
            "t :  61\n",
            "loss :  tensor([27.7749, 44.6970, 47.2206, 83.2882], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4437.9097, 3837.8774, 4380.3838, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 37.,  54., 102.,  92.])\n",
            "*************************************************\n",
            "t :  62\n",
            "loss :  tensor([27.8489, 44.8085, 47.8151, 82.6485], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4609.7915, 4872.6562, 5674.1445, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 68.,  99., 137.,  37.])\n",
            "*************************************************\n",
            "t :  63\n",
            "loss :  tensor([28.3224, 46.0295, 48.4111, 82.9330], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3807.4080, 4919.0776, 4620.0420, 5413.7148])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 46., 228., 114., 195.])\n",
            "*************************************************\n",
            "t :  64\n",
            "loss :  tensor([28.9293, 48.5752, 48.9117, 85.6939], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5647.8379, 5019.9370, 5052.7095, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 84., 104.,  87.,  85.])\n",
            "*************************************************\n",
            "t :  65\n",
            "loss :  tensor([29.1909, 47.8287, 48.7843, 85.0598], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4271.6348, 4639.2568, 4527.8179, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 54., 133., 105.,  33.])\n",
            "*************************************************\n",
            "t :  66\n",
            "loss :  tensor([29.0043, 49.2853, 49.5457, 85.0367], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5159.1011, 5019.9370, 5052.7095, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 82., 102.,  90.,  32.])\n",
            "*************************************************\n",
            "t :  67\n",
            "loss :  tensor([29.9156, 48.5424, 49.3420, 84.9836], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4271.6348, 5507.8164, 4367.9287, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 55.,  45., 124.,  33.])\n",
            "*************************************************\n",
            "t :  68\n",
            "loss :  tensor([29.4900, 48.8184, 50.7292, 85.0016], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4135.1279, 3382.5669, 5052.7095, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 25., 104.,  90.,  37.])\n",
            "*************************************************\n",
            "t :  69\n",
            "loss :  tensor([29.4953, 49.7679, 49.9877, 84.9960], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4271.6348, 5926.8262, 5448.5859, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 30., 113.,  27.,  34.])\n",
            "*************************************************\n",
            "t :  70\n",
            "loss :  tensor([29.5515, 49.1805, 50.0387, 84.9885], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3645.8015, 3130.8225, 4440.8359, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 35., 130., 204.,  37.])\n",
            "*************************************************\n",
            "t :  71\n",
            "loss :  tensor([29.8559, 51.0193, 54.4898, 85.1415], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5924.2217, 6524.4004, 6666.7964, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 82., 134., 145., 127.])\n",
            "*************************************************\n",
            "t :  72\n",
            "loss :  tensor([30.6592, 50.3045, 54.1612, 86.1305], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4808.5840, 5108.6631, 6104.4409, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([148.,  44.,  50.,  94.])\n",
            "*************************************************\n",
            "t :  73\n",
            "loss :  tensor([32.9352, 50.3456, 54.1037, 85.5583], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6822.7754, 4437.6265, 5596.6099, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([116., 117.,  29.,  31.])\n",
            "*************************************************\n",
            "t :  74\n",
            "loss :  tensor([32.9740, 51.3901, 54.0394, 85.5870], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4642.6738, 5019.9370, 5596.6099, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 49., 104.,  18.,  35.])\n",
            "*************************************************\n",
            "t :  75\n",
            "loss :  tensor([32.8534, 50.6782, 54.0304, 85.6780], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5281.8242, 5867.0674, 6104.4409, 6982.9194])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 78.,  45.,  35., 106.])\n",
            "*************************************************\n",
            "t :  76\n",
            "loss :  tensor([33.6236, 50.8088, 54.1365, 86.4323], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4127.5903, 3528.9597, 5646.6909, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 58., 105.,  48.,  63.])\n",
            "*************************************************\n",
            "t :  77\n",
            "loss :  tensor([33.0695, 51.7259, 54.3228, 86.3662], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5524.6982, 5419.0410, 5599.4731, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 67., 104.,  36., 124.])\n",
            "*************************************************\n",
            "t :  78\n",
            "loss :  tensor([33.8371, 51.2876, 54.2341, 87.2162], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 4491.8130, 5052.7095, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 154.,  35.,  90.])\n",
            "*************************************************\n",
            "t :  79\n",
            "loss :  tensor([33.4252, 52.9387, 54.6651, 86.6691], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5284.3442, 5019.9370, 5134.5366, 5876.9805])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 83., 112., 142.,  31.])\n",
            "*************************************************\n",
            "t :  80\n",
            "loss :  tensor([34.4931, 52.1520, 56.0316, 86.6731], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 6225.5488, 5055.3926, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 66., 130.,  90.,  29.])\n",
            "*************************************************\n",
            "t :  81\n",
            "loss :  tensor([33.9372, 53.0547, 55.3392, 86.6666], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3971.2996, 5108.6631, 5599.4731, 6029.9590])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([63., 67., 32., 29.])\n",
            "*************************************************\n",
            "t :  82\n",
            "loss :  tensor([34.4887, 52.9526, 55.4154, 86.7209], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5381.4346, 4437.6265, 5055.3926, 6432.9019])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 74., 125.,  31., 114.])\n",
            "*************************************************\n",
            "t :  83\n",
            "loss :  tensor([35.1901, 53.8903, 55.3727, 87.5753], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5048.4453, 5019.9370, 5599.4731, 6029.9590])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 111.,  32.,  63.])\n",
            "*************************************************\n",
            "t :  84\n",
            "loss :  tensor([35.3772, 53.1988, 55.4557, 87.5155], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4528.5103, 4346.9844, 5055.3926, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 65., 124.,  31., 116.])\n",
            "*************************************************\n",
            "t :  85\n",
            "loss :  tensor([35.5458, 54.2649, 55.6155, 88.3857], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5302.8442, 5019.9370, 5134.5366, 5629.0073])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75., 109., 145.,  91.])\n",
            "*************************************************\n",
            "t :  86\n",
            "loss :  tensor([35.7740, 53.4785, 57.2753, 87.8068], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3982.8694, 5213.5254, 5055.3926, 6029.9590])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([64., 56., 89., 29.])\n",
            "*************************************************\n",
            "t :  87\n",
            "loss :  tensor([35.7753, 53.6980, 56.5361, 87.8274], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5195.4038, 5419.0410, 5055.3926, 5468.5156])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([74., 52.,  8., 33.])\n",
            "*************************************************\n",
            "t :  88\n",
            "loss :  tensor([36.0220, 53.9955, 56.5262, 87.9705], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3982.8694, 3382.5669, 5202.0801, 5040.8652])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 63., 116.,  16., 142.])\n",
            "*************************************************\n",
            "t :  89\n",
            "loss :  tensor([35.9490, 54.8054, 56.5290, 89.4564], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5449.8081, 5419.0410, 5055.3926, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 84., 108.,  11.,  86.])\n",
            "*************************************************\n",
            "t :  90\n",
            "loss :  tensor([36.4710, 54.2273, 56.5202, 88.8896], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 3890.6902, 5202.0801, 6423.6553])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 68., 134.,  13., 106.])\n",
            "*************************************************\n",
            "t :  91\n",
            "loss :  tensor([36.2715, 55.3411, 56.5248, 89.7259], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5523.0210, 5419.0410, 5055.3926, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([106., 115.,  10.,  64.])\n",
            "*************************************************\n",
            "t :  92\n",
            "loss :  tensor([37.6637, 54.4431, 56.5529, 89.4049], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5449.2227, 5108.6631, 5599.4731, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([161.,  31.,  37.,  29.])\n",
            "*************************************************\n",
            "t :  93\n",
            "loss :  tensor([39.1612, 54.4256, 56.6786, 89.4335], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5411.7764, 4346.9844, 6007.9644, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 86., 127., 106.,  35.])\n",
            "*************************************************\n",
            "t :  94\n",
            "loss :  tensor([39.0137, 55.6142, 57.4950, 89.4127], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4089.9229, 5019.9370, 5202.0801, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 66., 110.,  50.,  26.])\n",
            "*************************************************\n",
            "t :  95\n",
            "loss :  tensor([39.1404, 54.7779, 57.2326, 89.4210], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5411.7764, 5108.6631, 5599.4731, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([84., 10., 31., 33.])\n",
            "*************************************************\n",
            "t :  96\n",
            "loss :  tensor([39.3585, 54.7737, 57.3370, 89.4396], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3943.1123, 5019.9370, 3477.0913, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 72.,  11., 103.,  27.])\n",
            "*************************************************\n",
            "t :  97\n",
            "loss :  tensor([39.3682, 54.7773, 58.5872, 89.4160], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5157.5010, 5108.6631, 6580.7925, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 77.,   9., 146.,  33.])\n",
            "*************************************************\n",
            "t :  98\n",
            "loss :  tensor([39.5434, 54.7722, 58.1241, 89.4638], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3944.8264, 5108.6631, 3477.0913, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 64.,   3., 109.,  27.])\n",
            "*************************************************\n",
            "t :  99\n",
            "loss :  tensor([39.5305, 54.7976, 59.0839, 89.4109], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5459.3418, 6015.5127, 6705.0693, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109.,  54., 122.,  34.])\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([-0., -0., -0., -0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(mals.to(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEoslyYCgMGz",
        "outputId": "d04ed703-35d1-44fa-bb55-49938c576154"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-19.8462,  21.1819],\n",
              "        [-42.3733,  44.2564],\n",
              "        [-28.2794,  29.8791],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae5b959-4e97-4951-b33a-61273d8abefb",
        "id": "dWT1KrbOaMBq"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-11.4985,  13.8264],\n",
              "        [-21.6522,  25.6011],\n",
              "        [-25.6268,  30.0696],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db86cec1-1e40-4af0-bedf-da009aefd427",
        "id": "klQwgaJnaMBr"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-15.0647,  16.9694],\n",
              "        [-21.0841,  23.9766],\n",
              "        [-19.3803,  23.2305],\n",
              "        [-35.6905,  40.3540]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#comparing two attacks:\n",
        "loss based on the goal's class and minimize the loss\n",
        "\n",
        " 1: without loss of rbf\n",
        "\n",
        " 2: with loss of rbf"
      ],
      "metadata": {
        "id": "geawDEM_iAMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yKLI-D28imiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `l1 attack`"
      ],
      "metadata": {
        "id": "oLk4eeuvkfUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adv = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 0, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766de510-fcb0-44ef-c425-75cf660f96b2",
        "id": "StYrbgUgkduu"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "t :  0\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n",
            "max_grad tensor([[5.9220],\n",
            "        [4.4970],\n",
            "        [2.4442],\n",
            "        [5.5750]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  1\n",
            "ce:  tensor([ 17.2574,  71.0176,  53.6272, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.1610, 6.9179, 7.9014, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.2574,  71.0176,  53.6272, 164.5218], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10475.5771,  8753.7480,  9374.5732,  9018.6055])\n",
            "max_grad tensor([[6.1256],\n",
            "        [3.5946],\n",
            "        [2.1932],\n",
            "        [2.4330]], dtype=torch.float64)\n",
            "ce:  tensor([ 17.2574,  71.0176,  53.6272, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.1610, 6.9179, 7.9014, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  2\n",
            "ce:  tensor([3.3616e-05, 5.5429e+01, 4.4622e+01, 1.5478e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.3994, 8.0200, 3.4887], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 5.5429e+01, 4.4622e+01, 1.5478e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1265e+03, 1.0463e+04, 9.0235e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.0219e+00],\n",
            "        [2.3581e+00],\n",
            "        [1.5561e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 5.5429e+01, 4.4622e+01, 1.5478e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.3994, 8.0200, 3.4887], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  3\n",
            "ce:  tensor([3.3616e-05, 4.2018e+01, 3.5233e+01, 1.4863e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.9749, 8.1421, 3.4971], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 4.2018e+01, 3.5233e+01, 1.4863e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.5316e+03, 1.0955e+04, 8.8765e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.9064e+00],\n",
            "        [2.3421e+00],\n",
            "        [1.6096e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 4.2018e+01, 3.5233e+01, 1.4863e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.9749, 8.1421, 3.4971], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  4\n",
            "ce:  tensor([3.3616e-05, 3.0319e+01, 2.5832e+01, 1.4469e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.5596, 8.2675, 3.5144], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 3.0319e+01, 2.5832e+01, 1.4469e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.3921e+03, 1.0962e+04, 8.4613e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.7028e+00],\n",
            "        [2.1177e+00],\n",
            "        [1.6392e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 3.0319e+01, 2.5832e+01, 1.4469e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.5596, 8.2675, 3.5144], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  5\n",
            "ce:  tensor([3.3616e-05, 1.9540e+01, 1.7143e+01, 1.3839e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.0290, 8.3965, 3.3179], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 1.9540e+01, 1.7143e+01, 1.3839e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1422e+03, 1.1507e+04, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.4242e+00],\n",
            "        [2.0476e+00],\n",
            "        [1.2280e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 1.9540e+01, 1.7143e+01, 1.3839e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.0290, 8.3965, 3.3179], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  6\n",
            "ce:  tensor([3.3616e-05, 1.2214e+01, 8.8525e+00, 1.3348e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 4.4829, 8.5291, 3.3215], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 1.2214e+01, 8.8525e+00, 1.3348e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0299e+01, 5.0068e-06, 1.4304e-04, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 8.7310e+03, 1.1474e+04, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.1735e+00],\n",
            "        [1.9154e+00],\n",
            "        [1.2060e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 1.2214e+01, 8.8525e+00, 1.3348e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 4.4829, 8.5291, 3.3215], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  7\n",
            "ce:  tensor([3.3616e-05, 4.0993e+00, 1.3330e+00, 1.2865e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 4.2261, 8.6654, 3.3252], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 4.0993e+00, 1.3330e+00, 1.2865e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  0.0167,  0.3061, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 7.7917e+03, 9.0294e+03, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.1753e+00],\n",
            "        [5.2700e-01],\n",
            "        [1.1217e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 4.0993e+00, 1.3330e+00, 1.2865e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 4.2261, 8.6654, 3.3252], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  8\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.2417e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3290], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.2417e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.1173e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.2417e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3290], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  9\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1939e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3727], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1939e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.1097e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1939e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3727], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  10\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1495e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3381], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1495e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0670e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1495e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3381], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  11\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1068e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3422], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1068e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0610e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1068e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3422], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  12\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0643e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3187], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0643e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0143e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0643e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3187], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  13\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0237e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3662], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0237e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0043e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0237e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3662], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  14\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.8351e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4699], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.8351e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [9.9714e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.8351e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4699], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  15\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.4362e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4776], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.4362e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [9.3243e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.4362e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4776], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  16\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.0639e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6308], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.0639e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3357e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.5881e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.0639e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6308], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  17\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.7156e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6984], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.7156e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.0538e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.7156e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6984], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  18\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.3935e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.7126], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.3935e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3143e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.9628e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.3935e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.7126], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  19\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.0755e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6848], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.0755e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.9117e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.0755e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6848], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  20\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.7752e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4857], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.7752e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8621e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.1519e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.7752e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4857], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  21\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.4700e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4939], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.4700e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.8368e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.4700e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4939], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  22\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.1965e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.5023], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.1965e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5682e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.1965e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.5023], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  23\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.9337e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4632], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.9337e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3132e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5225e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.9337e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4632], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  24\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.7578e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6252], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.7578e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8157e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.9891e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.7578e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6252], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  25\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.4789e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.8672], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.4789e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8228e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.8515e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.4789e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.8672], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  26\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2163e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.8861], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2163e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2845e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5524e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2163e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.8861], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  27\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2409e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4148], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2409e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7232e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.0716e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2409e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4148], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  28\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.9668e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4012], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.9668e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8201e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.7152e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.9668e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4012], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  29\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.7031e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.2164], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.7031e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7293e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.2330e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.7031e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.2164], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  30\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.4995e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0216], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.4995e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2633e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.1782e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.4995e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0216], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  31\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.2756e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.9558], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.2756e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5679e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.9095e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.2756e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.9558], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  32\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.0393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.9026], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.0393e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.6147e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.0393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.9026], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  33\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.8147e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.8468], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.8147e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.5578e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.8147e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.8468], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  34\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.7072e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0203], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.7072e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0702e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4725e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.7072e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0203], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  35\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.4889e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0155], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.4889e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4381e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.4889e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0155], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  36\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.2713e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0723], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.2713e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4263e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.2713e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0723], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  37\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.0543e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.1250], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.0543e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4237e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.0543e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.1250], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  38\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.8393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5892], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.8393e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9781e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.9568e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.8393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5892], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  39\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.6430e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5361], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.6430e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.6170e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.6430e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5361], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  40\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.4583e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5183], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.4583e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.3553e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.4583e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5183], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  41\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2908e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5225], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2908e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3707e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.3911e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2908e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5225], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  42\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2531e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.6161], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2531e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.4075e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.3935e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2531e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.6161], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  43\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2872e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4479], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2872e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.4608e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.5223e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2872e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4479], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  44\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2053e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.2608], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2053e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.8152e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.3077e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2053e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.2608], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  45\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.0267], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.0705e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.0267], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  46\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.5631e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5051], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.5631e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.9829e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.6541e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.5631e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5051], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  47\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.3381e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4828], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.3381e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8933e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.8362e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.3381e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4828], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  48\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1606e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4941], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1606e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 4.9637e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.9100e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1606e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4941], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  49\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2428e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.6191], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2428e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.7787e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.0003e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2428e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.6191], grad_fn=<NllLossBackward0>)\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([10.2994,  3.8019,  2.1209, -0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 10., insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFusQbf2knJA",
        "outputId": "8b054b13-4290-44f3-feba-b236547e35f9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "t :  0\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 86.8272, 160.0354, 131.3113, 225.5053], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12908.3301, 12200.0391, 12128.9160,  9213.8662])\n",
            "max_grad tensor([[8.5023],\n",
            "        [7.3571],\n",
            "        [7.0327],\n",
            "        [6.2066]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  1\n",
            "ce:  tensor([ 41.4521,  87.1468,  56.9110, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3975, 4.2835, 4.5723, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 55.4273, 129.9817, 102.6341, 200.4092], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12014.8213, 12182.2734, 12070.9980,  9225.7969])\n",
            "max_grad tensor([[7.1064],\n",
            "        [7.1157],\n",
            "        [6.5516],\n",
            "        [2.6466]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.4521,  87.1468,  56.9110, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3975, 4.2835, 4.5723, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  2\n",
            "ce:  tensor([ 17.9860,  86.5490,  57.6814, 154.7815], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.9643, 1.6738, 1.9881, 3.4887], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 27.6292, 103.2873,  77.5623, 189.6684], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([11407.0674, 10388.8174, 11772.3848,  9236.5176])\n",
            "max_grad tensor([[6.7228],\n",
            "        [5.4520],\n",
            "        [4.8363],\n",
            "        [1.7776]], dtype=torch.float64)\n",
            "ce:  tensor([ 17.9860,  86.5490,  57.6814, 154.7815], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.9643, 1.6738, 1.9881, 3.4887], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  3\n",
            "ce:  tensor([1.9203e-04, 7.9864e+01, 5.9809e+01, 1.5008e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.7019, 0.4528, 3.2918], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  86.8821,  64.3365, 183.0031], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739, 10865.0176, 10639.5020,  9121.3682])\n",
            "max_grad tensor([[4.2258],\n",
            "        [5.3384],\n",
            "        [2.4349],\n",
            "        [1.5102]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.9864e+01, 5.9809e+01, 1.5008e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.7019, 0.4528, 3.2918], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  4\n",
            "ce:  tensor([1.9203e-04, 6.2046e+01, 5.0805e+01, 1.4397e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.4414, 0.4125, 3.3144], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  66.4602,  54.9296, 177.1118], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739, 10118.6143, 10764.6777,  8560.1807])\n",
            "max_grad tensor([[4.2258],\n",
            "        [4.1851],\n",
            "        [2.4314],\n",
            "        [1.3745]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 6.2046e+01, 5.0805e+01, 1.4397e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.4414, 0.4125, 3.3144], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  5\n",
            "ce:  tensor([1.9203e-04, 4.8027e+01, 4.1444e+01, 1.3839e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.2649, 0.3742, 3.3179], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  50.6758,  45.1854, 171.5689], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739,  8729.1289, 11453.9707,  8566.5918])\n",
            "max_grad tensor([[4.2258],\n",
            "        [3.6175],\n",
            "        [2.4504],\n",
            "        [1.3673]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 4.8027e+01, 4.1444e+01, 1.3839e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.2649, 0.3742, 3.3179], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  6\n",
            "ce:  tensor([1.9203e-04, 3.4261e+01, 3.2356e+01, 1.3609e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.1354, 0.3379, 3.0051], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  35.6157,  35.7354, 166.1406], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739,  8880.4951, 11617.9658,  8547.9941])\n",
            "max_grad tensor([[4.2258],\n",
            "        [2.6689],\n",
            "        [2.1945],\n",
            "        [1.3411]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 3.4261e+01, 3.2356e+01, 1.3609e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.1354, 0.3379, 3.0051], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  7\n",
            "ce:  tensor([1.9203e-04, 2.1081e+01, 2.4095e+01, 1.3618e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.2683, 0.3038, 2.7243], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  23.7635,  27.1331, 163.4186], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739,  8800.2656, 12710.7617,  9223.3057])\n",
            "max_grad tensor([[4.2258],\n",
            "        [3.1691],\n",
            "        [2.2486],\n",
            "        [1.3826]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 2.1081e+01, 2.4095e+01, 1.3618e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.2683, 0.3038, 2.7243], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  8\n",
            "ce:  tensor([1.9203e-04, 1.4233e+01, 1.6045e+01, 1.3089e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0697, 0.2718, 2.7116], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  14.9304,  18.7637, 158.0015], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580e+00, 7.1526e-07, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739, 10373.1660, 12401.0254,  9229.3447])\n",
            "max_grad tensor([[4.2258],\n",
            "        [2.3994],\n",
            "        [2.1282],\n",
            "        [1.3747]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 1.4233e+01, 1.6045e+01, 1.3089e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0697, 0.2718, 2.7116], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  9\n",
            "ce:  tensor([1.9203e-04, 4.6814e+00, 1.0333e+01, 1.2546e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0454, 0.5256, 2.7353], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   5.1358,  15.5891, 152.8183], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580e+00, 9.3090e-03, 3.2544e-05, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739, 10979.6123, 12873.6641,  9091.2939])\n",
            "max_grad tensor([[4.2258],\n",
            "        [2.3688],\n",
            "        [2.6915],\n",
            "        [1.3345]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 4.6814e+00, 1.0333e+01, 1.2546e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0454, 0.5256, 2.7353], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  10\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 7.6136e+00, 1.2071e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0991, 2.6874], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   8.6045, 147.5829], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580e+00, 2.6260e+00, 4.9388e-04, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739,   661.5317, 12247.4385,  9097.2891])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [2.1425],\n",
            "        [1.2964]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 7.6136e+00, 1.2071e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0991, 2.6874], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  11\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.1578e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6737], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 142.5204], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9103.9688])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.2958]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.1578e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6737], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  12\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.1087e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6597], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 137.4640], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9110.8145])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.1863]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.1087e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6597], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  13\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.0665e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6198], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 132.8436], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9117.3154])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.1831]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.0665e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6198], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  14\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.0221e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6043], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 128.2520], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9124.4805])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.1707]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.0221e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6043], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  15\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.7830e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.5884], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 123.7139], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9131.8252])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.0918]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.7830e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.5884], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  16\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.3521e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6157], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 119.6780], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8588.1836])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.2655]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.3521e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6157], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  17\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.1365e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.4424], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 115.7887], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9135.9082])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.0871]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.1365e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.4424], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  18\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.9925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.1811], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 111.7360], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9121.8750])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.0303]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.9925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.1811], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  19\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.8814e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.0203], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 109.0167], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8563.9902])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.0201]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.8814e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.0203], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  20\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.5636e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9583], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 105.2195], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8568.7129])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9569]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.5636e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9583], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  21\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.2430e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9264], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 101.6943], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8575.0547])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9320]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.2430e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9264], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  22\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.8871e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9900], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 98.7701], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9131.4150])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.0242]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.8871e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9900], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  23\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.6566e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.8849], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 95.4143], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8572.6279])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9235]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.6566e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.8849], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  24\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.3045e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9006], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 92.0508], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8581.0137])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9134]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.3045e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9006], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  25\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.2464e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.7219], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 89.6827], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9119.9883])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9981]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.2464e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.7219], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  26\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.9192e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.6850], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 86.0426], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9125.4658])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9705]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.9192e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.6850], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  27\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.7232e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.5767], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 82.9992], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8569.7734])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9360]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.7232e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.5767], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  28\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.4604e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.5027], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 79.6307], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8571.8086])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8958]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.4604e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.5027], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  29\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.2166e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.4273], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 76.4389], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8556.7588])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8916]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.2166e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.4273], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  30\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.9423e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.3855], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 73.2773], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8577.0488])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8791]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.9423e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.3855], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  31\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.7096e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.3079], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 70.1752], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8560.6260])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8608]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.7096e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.3079], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  32\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.4513e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.2645], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 67.1589], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8527.3770])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8200]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.4513e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.2645], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  33\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.3965e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0531], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 64.4957], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8416.9258])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8108]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.3965e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0531], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  34\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.0362e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.1371], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 61.7334], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8450.8652])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.7912]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.0362e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.1371], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  35\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.8327e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0679], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 59.0064], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8448.2432])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.7668]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.8327e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0679], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  36\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.6152e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0229], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 56.3809], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8448.8584])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.7456]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.6152e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0229], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  37\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.4948e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8923], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 53.8713], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8432.8682])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.7037]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.4948e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8923], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  38\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.2691e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8890], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 51.5804], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8299.4023])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.6915]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.2691e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8890], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  39\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.0818e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8441], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 49.2588], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8297.8564])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.6774]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.0818e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8441], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  40\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.8648e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8345], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 46.9931], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8302.4336])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.6734]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.8648e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8345], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  41\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.7644e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.7642], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 45.2861], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7642.4419])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.7589]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.7644e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.7642], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  42\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.6973e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5917], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 42.8901], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7598.0254])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.5627]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.6973e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5917], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  43\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.5412e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5827], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 41.2390], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 6500.8940])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.3753]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.5412e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5827], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  44\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.5958e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4696], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 40.6546], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7486.9814])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.5302]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.5958e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4696], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  45\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.4653e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4313], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 38.9664], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7339.8442])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.5103]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.4653e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4313], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  46\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.3331e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.3959], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 37.2902], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7332.8423])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.5061]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.3331e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.3959], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  47\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.1061e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4593], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 35.6540], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7461.6235])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.4935]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.1061e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4593], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  48\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 2.8772e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5376], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 34.1481], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7453.0757])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.5048]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 2.8772e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5376], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  49\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 2.8271e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4409], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 32.6800], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7262.8149])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.4678]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 2.8271e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4409], grad_fn=<NllLossBackward0>)\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([8.5580, 2.6260, 0.6986, -0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(mals.to(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b7df71-fe3e-4219-9aa8-5d67fcca4309",
        "id": "gkdO0Dcakduv"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-19.8462,  21.1819],\n",
              "        [-42.3733,  44.2564],\n",
              "        [-28.2794,  29.8791],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f83046-8ba4-4cd7-edb6-dd8e022068bf",
        "id": "Np2bbEr6kduv"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.8403,  -5.4591],\n",
              "        [  1.5538,  -2.2255],\n",
              "        [  0.8769,  -1.1162],\n",
              "        [-14.3782,  16.4776]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef055bdc-7eea-4a90-80a4-ddc95b45d385",
        "id": "5CyX9TnQkduv"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.0159,  -4.5420],\n",
              "        [  1.0198,  -1.5311],\n",
              "        [ -0.0686,  -0.0795],\n",
              "        [-12.8020,  14.3310]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d_s-SAzt79Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `l2 attack`"
      ],
      "metadata": {
        "id": "moPvHddw79du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adv = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 0, insertion_array, removal_array, k=200, step_length=0.05, norm='l2', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236c5272-3803-49bc-fe81-aaecbea560fe",
        "id": "QRiy4br279dv"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "t :  0\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n",
            "l2norm ;  tensor([[ 9.5710],\n",
            "        [10.5145],\n",
            "        [ 7.2150],\n",
            "        [ 8.9417]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  1\n",
            "ce:  tensor([ 39.1132,  84.6820,  56.7476, 185.0569], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5578, 7.3161, 7.3356, 3.8596], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 39.1132,  84.6820,  56.7476, 185.0569], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10214.1045,  8661.5039,  9349.6436,  9011.1484])\n",
            "l2norm ;  tensor([[9.6013],\n",
            "        [9.9436],\n",
            "        [6.1447],\n",
            "        [8.9417]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  2\n",
            "ce:  tensor([ 37.3011,  82.6933,  55.5187, 183.2686], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5350, 7.3094, 7.3201, 3.8529], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 37.3011,  82.6933,  55.5187, 183.2686], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9837.0801, 8661.5039, 9349.6436, 9011.1484])\n",
            "l2norm ;  tensor([[8.7891],\n",
            "        [9.9436],\n",
            "        [6.1447],\n",
            "        [8.9417]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  3\n",
            "ce:  tensor([ 35.5433,  80.7040,  54.2854, 181.4802], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.4906, 7.3018, 7.3037, 3.8458], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 35.5433,  80.7040,  54.2854, 181.4802], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9837.0801, 8644.5400, 9284.2891, 9011.1484])\n",
            "l2norm ;  tensor([[8.7891],\n",
            "        [9.9730],\n",
            "        [6.1859],\n",
            "        [8.9417]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  4\n",
            "ce:  tensor([ 33.7752,  78.7074,  53.0451, 179.6919], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.4457, 7.2936, 7.2851, 3.8383], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 33.7752,  78.7074,  53.0451, 179.6919], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9910.2842, 8648.4805, 9251.0137, 9011.1484])\n",
            "l2norm ;  tensor([[8.8992],\n",
            "        [9.9896],\n",
            "        [6.2336],\n",
            "        [8.9417]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  5\n",
            "ce:  tensor([ 32.0236,  76.6906,  51.7978, 177.9035], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.4024, 7.2848, 7.2646, 3.8305], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 32.0236,  76.6906,  51.7978, 177.9035], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9826.4453, 8537.6660, 9288.4805, 9011.1484])\n",
            "l2norm ;  tensor([[ 8.7417],\n",
            "        [10.1371],\n",
            "        [ 6.2331],\n",
            "        [ 8.9417]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  6\n",
            "ce:  tensor([ 30.2753,  74.6631,  50.5572, 176.1152], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.3558, 7.2770, 7.2425, 3.8222], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 30.2753,  74.6631,  50.5572, 176.1152], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9826.4453, 8537.6660, 9358.0537, 9011.1484])\n",
            "l2norm ;  tensor([[ 8.7417],\n",
            "        [10.1371],\n",
            "        [ 6.1959],\n",
            "        [ 8.9417]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  7\n",
            "ce:  tensor([ 28.5269,  72.6298,  49.3107, 174.3268], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.3086, 7.2684, 7.2203, 3.8136], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.5269,  72.6298,  49.3107, 174.3268], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9826.4453, 8543.2715, 9322.7178, 9011.1484])\n",
            "l2norm ;  tensor([[ 8.7417],\n",
            "        [10.1803],\n",
            "        [ 6.2363],\n",
            "        [ 8.9417]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  8\n",
            "ce:  tensor([ 26.7882,  70.6124,  48.0634, 172.5385], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.2609, 7.2604, 7.1961, 3.8046], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.7882,  70.6124,  48.0634, 172.5385], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9727.9951, 8808.7295, 9322.7178, 9011.1484])\n",
            "l2norm ;  tensor([[ 8.6630],\n",
            "        [10.0340],\n",
            "        [ 6.2363],\n",
            "        [ 8.9417]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  9\n",
            "ce:  tensor([ 25.0830,  68.6056,  46.8167, 170.7502], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.2128, 7.2513, 7.1710, 3.7953], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.0830,  68.6056,  46.8167, 170.7502], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9459.5156, 8808.7295, 9327.4531, 9011.1484])\n",
            "l2norm ;  tensor([[ 8.4928],\n",
            "        [10.0340],\n",
            "        [ 6.2146],\n",
            "        [ 8.9417]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  10\n",
            "ce:  tensor([ 23.3807,  66.5988,  45.5738, 168.9623], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.1673, 7.2413, 7.1440, 3.7855], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.3807,  66.5988,  45.5738, 168.9623], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9472.0576, 8808.7295, 9327.4531, 9007.1738])\n",
            "l2norm ;  tensor([[ 8.5180],\n",
            "        [10.0340],\n",
            "        [ 6.2146],\n",
            "        [ 8.9267]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  11\n",
            "ce:  tensor([ 21.6740,  64.5921,  44.3331, 167.2323], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.1220, 7.2306, 7.1161, 3.7753], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.6740,  64.5921,  44.3331, 167.2323], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9589.7422, 8808.7295, 9316.1514, 8452.9004])\n",
            "l2norm ;  tensor([[ 8.6158],\n",
            "        [10.0340],\n",
            "        [ 6.1949],\n",
            "        [ 8.4093]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  12\n",
            "ce:  tensor([ 19.9509,  62.5853,  43.0942, 165.5505], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.0790, 7.2192, 7.0875, 3.7636], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.9509,  62.5853,  43.0942, 165.5505], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9589.7422, 8808.7295, 9316.1514, 8452.9004])\n",
            "l2norm ;  tensor([[ 8.6158],\n",
            "        [10.0340],\n",
            "        [ 6.1949],\n",
            "        [ 8.4093]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  13\n",
            "ce:  tensor([ 18.2356,  60.5785,  41.8597, 163.8686], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.0356, 7.2069, 7.0579, 3.7515], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.2356,  60.5785,  41.8597, 163.8686], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9825.3662, 8808.7295, 9260.9033, 8452.9004])\n",
            "l2norm ;  tensor([[ 8.7229],\n",
            "        [10.0340],\n",
            "        [ 6.0282],\n",
            "        [ 8.4093]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  14\n",
            "ce:  tensor([ 16.4216,  58.5717,  40.6622, 162.1868], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.9917, 7.1939, 7.0263, 3.7388], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.4216,  58.5717,  40.6622, 162.1868], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10368.5635,  8808.7295,  9327.4258,  8452.9004])\n",
            "l2norm ;  tensor([[ 9.0810],\n",
            "        [10.0340],\n",
            "        [ 5.9818],\n",
            "        [ 8.4093]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  15\n",
            "ce:  tensor([ 14.6292,  56.5644,  39.4658, 160.5049], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.9453, 7.1802, 6.9941, 3.7258], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 14.6292,  56.5644,  39.4658, 160.5049], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.7684e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10091.9189,  8797.4102,  9327.4258,  8452.9004])\n",
            "l2norm ;  tensor([[ 8.8706],\n",
            "        [10.0566],\n",
            "        [ 5.9818],\n",
            "        [ 8.4093]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  16\n",
            "ce:  tensor([ 12.8406,  54.5460,  38.2695, 158.8230], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.8984, 7.1620, 6.9609, 3.7123], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 12.8406,  54.5460,  38.2695, 158.8230], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.6226e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10292.0645,  8721.3887,  9327.4258,  8452.9004])\n",
            "l2norm ;  tensor([[ 2.9841],\n",
            "        [10.1018],\n",
            "        [ 5.9818],\n",
            "        [ 8.4093]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  17\n",
            "ce:  tensor([ 12.2438,  52.5206,  37.0724, 157.1412], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.8588, 7.1437, 6.9268, 3.6984], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 12.2438,  52.5206,  37.0724, 157.1412], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.7684e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10292.0420,  8721.2646,  9304.7324,  8452.9004])\n",
            "l2norm ;  tensor([[ 2.9841],\n",
            "        [10.1291],\n",
            "        [ 5.9888],\n",
            "        [ 6.5474]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  18\n",
            "ce:  tensor([ 11.6520,  50.4948,  35.8757, 155.8500], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.8189, 7.1251, 6.8912, 3.6937], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 11.6520,  50.4948,  35.8757, 155.8500], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.7022e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10103.7148,  8721.2646,  9299.2373,  8312.4521])\n",
            "l2norm ;  tensor([[ 2.9672],\n",
            "        [10.1291],\n",
            "        [ 5.9771],\n",
            "        [ 6.3947]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  19\n",
            "ce:  tensor([ 11.0553,  48.4712,  34.6788, 154.5711], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.7807, 7.1057, 6.8546, 3.6886], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 11.0553,  48.4712,  34.6788, 154.5711], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5855e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10475.0361,  8503.8652,  9308.3643,  8312.4521])\n",
            "l2norm ;  tensor([[ 3.0051],\n",
            "        [10.0843],\n",
            "        [ 5.9913],\n",
            "        [ 6.3947]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  20\n",
            "ce:  tensor([ 10.4303,  46.4543,  33.4863, 153.2922], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.7400, 7.0847, 6.8169, 3.6831], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 10.4303,  46.4543,  33.4863, 153.2922], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.9563e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10399.8174,  8503.8652,  9386.2939,  8312.4521])\n",
            "l2norm ;  tensor([[ 3.1510],\n",
            "        [10.0843],\n",
            "        [ 5.9566],\n",
            "        [ 6.3947]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  21\n",
            "ce:  tensor([  9.8001,  44.4397,  32.3208, 152.0132], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.7060, 7.0629, 6.7786, 3.6774], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  9.8001,  44.4397,  32.3208, 152.0132], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.5431e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10399.5479,  8499.6914,  9058.3799,  8312.4521])\n",
            "l2norm ;  tensor([[ 3.1509],\n",
            "        [10.0730],\n",
            "        [ 5.7311],\n",
            "        [ 6.3947]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  22\n",
            "ce:  tensor([  9.1699,  42.4230,  31.1761, 150.7343], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.6720, 7.0404, 6.7386, 3.6713], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  9.1699,  42.4230,  31.1761, 150.7343], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0001, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10399.0420,  8565.8486,  9106.9141,  8312.4521])\n",
            "l2norm ;  tensor([[ 3.1508],\n",
            "        [10.0738],\n",
            "        [ 5.7114],\n",
            "        [ 6.3947]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  23\n",
            "ce:  tensor([  8.5398,  40.4102,  30.0338, 149.4553], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.6378, 7.0181, 6.6989, 3.6650], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  8.5398,  40.4102,  30.0338, 149.4553], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0002, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10398.0908,  9642.7236,  9106.9141,  8312.4521])\n",
            "l2norm ;  tensor([[ 3.1505],\n",
            "        [10.7150],\n",
            "        [ 5.7114],\n",
            "        [ 6.3947]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  24\n",
            "ce:  tensor([  7.9190,  38.4829,  28.8841, 148.1763], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.6036, 6.9742, 6.6584, 3.6583], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.9190,  38.4829,  28.8841, 148.1763], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0004, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10242.0859,  8563.5068,  9056.4961,  8312.4521])\n",
            "l2norm ;  tensor([[ 2.0080],\n",
            "        [10.1475],\n",
            "        [ 5.7792],\n",
            "        [ 6.3947]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  25\n",
            "ce:  tensor([  7.5057,  36.4534,  27.7283, 146.8974], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.6129, 6.9511, 6.6165, 3.6514], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.5057,  36.4534,  27.7283, 146.8974], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0006, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10039.9199,  8563.5068,  9056.4961,  8312.4521])\n",
            "l2norm ;  tensor([[ 2.0547],\n",
            "        [10.1475],\n",
            "        [ 5.7792],\n",
            "        [ 6.3947]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  26\n",
            "ce:  tensor([  7.0940,  34.5731,  26.5725, 145.6172], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.6229, 6.9274, 6.5737, 3.6441], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.0940,  34.5731,  26.5725, 145.6172], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0008, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10024.3037,  8244.7451,  9056.4961,  8315.4766])\n",
            "l2norm ;  tensor([[2.0763],\n",
            "        [7.2255],\n",
            "        [5.7792],\n",
            "        [6.4076]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  27\n",
            "ce:  tensor([  6.6803,  33.1280,  25.4149, 144.3357], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.6356, 6.8895, 6.5302, 3.6365], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6803,  33.1280,  25.4149, 144.3357], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0013, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10015.9316,  8244.7451,  9061.5635,  8315.4766])\n",
            "l2norm ;  tensor([[2.0618],\n",
            "        [6.3896],\n",
            "        [5.7968],\n",
            "        [6.4076]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  28\n",
            "ce:  tensor([  6.2740,  31.8500,  24.2555, 143.0559], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.6485, 6.8611, 6.4861, 3.6285], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.2740,  31.8500,  24.2555, 143.0559], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0019, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9865.7617, 8244.7451, 9061.5635, 8312.9541])\n",
            "l2norm ;  tensor([[2.0130],\n",
            "        [6.3896],\n",
            "        [5.7968],\n",
            "        [6.3952]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  29\n",
            "ce:  tensor([  5.8809,  30.5739,  23.2032, 141.7768], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.6598, 6.8321, 6.4412, 3.6204], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  5.8809,  30.5739,  23.2032, 141.7768], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0028, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9860.4521, 8232.4785, 8512.5566, 8312.9541])\n",
            "l2norm ;  tensor([[1.9101],\n",
            "        [6.3696],\n",
            "        [4.4464],\n",
            "        [6.3952]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  30\n",
            "ce:  tensor([  5.5505,  29.3125,  22.3074, 140.4978], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.6855, 6.8021, 6.3598, 3.6118], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  5.5505,  29.3125,  22.3074, 140.4978], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0039, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10832.1865,  8222.4316,  8425.1660,  8312.9541])\n",
            "l2norm ;  tensor([[1.6378],\n",
            "        [6.2412],\n",
            "        [4.5043],\n",
            "        [6.3952]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  31\n",
            "ce:  tensor([  5.3215,  28.0643,  21.4292, 139.2188], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5784, 6.7693, 6.2751, 3.6030], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  5.3215,  28.0643,  21.4292, 139.2188], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0049, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10342.9502,  8222.4316,  8255.7842,  8312.9541])\n",
            "l2norm ;  tensor([[1.2581],\n",
            "        [5.6072],\n",
            "        [4.0397],\n",
            "        [6.3952]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  32\n",
            "ce:  tensor([  5.1617,  26.9728,  20.6572, 137.9397], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4053, 6.7439, 6.1855, 3.5939], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  5.1617,  26.9728,  20.6572, 137.9397], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0057, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9415.8105, 9292.4727, 7172.5601, 8312.9541])\n",
            "l2norm ;  tensor([[1.3189],\n",
            "        [5.8496],\n",
            "        [3.1154],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  33\n",
            "ce:  tensor([  4.9390,  25.9581,  20.0344, 136.7541], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4138, 6.6915, 6.1442, 3.5866], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  4.9390,  25.9581,  20.0344, 136.7541], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0072, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10326.0664,  8227.0332,  7159.5356,  8312.9541])\n",
            "l2norm ;  tensor([[1.2989],\n",
            "        [5.6027],\n",
            "        [2.7962],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  34\n",
            "ce:  tensor([  4.7320,  24.8717,  19.4751, 135.5685], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.2477, 6.6645, 6.0966, 3.5791], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  4.7320,  24.8717,  19.4751, 135.5685], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0088, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9386.6729, 8169.0190, 7159.5356, 8312.9541])\n",
            "l2norm ;  tensor([[1.1217],\n",
            "        [4.9905],\n",
            "        [2.5049],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  35\n",
            "ce:  tensor([  4.5676,  23.8734,  18.9803, 134.3830], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.2340, 6.6165, 6.0413, 3.5713], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  4.5676,  23.8734,  18.9803, 134.3830], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0104, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9857.1621, 8167.3613, 7203.1562, 8312.9541])\n",
            "l2norm ;  tensor([[1.2327],\n",
            "        [4.9791],\n",
            "        [2.1146],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  36\n",
            "ce:  tensor([  4.3828,  22.9312,  18.5574, 133.1974], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.0573, 6.5673, 5.9754, 3.5632], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  4.3828,  22.9312,  18.5574, 133.1974], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0126, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8932.6055, 9105.3711, 7203.1562, 8312.9541])\n",
            "l2norm ;  tensor([[1.0452],\n",
            "        [5.2479],\n",
            "        [2.1146],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  37\n",
            "ce:  tensor([  4.2014,  22.0172,  18.1701, 132.0118], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.0396, 6.4977, 5.9092, 3.5549], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  4.2014,  22.0172,  18.1701, 132.0118], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0151, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10155.6143,  8094.2354,  8292.8896,  8312.9541])\n",
            "l2norm ;  tensor([[1.2545],\n",
            "        [4.9376],\n",
            "        [2.8898],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  38\n",
            "ce:  tensor([  4.0296,  21.0297,  17.9004, 130.8263], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.8627, 6.4471, 5.7800, 3.5462], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  4.0296,  21.0297,  17.9004, 130.8263], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0179, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8760.0107, 8094.2354, 7247.3623, 8312.9541])\n",
            "l2norm ;  tensor([[1.0196],\n",
            "        [4.1676],\n",
            "        [2.0844],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  39\n",
            "ce:  tensor([  3.8946,  20.2224,  17.4814, 129.6407], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.8436, 6.4045, 5.7129, 3.5373], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  3.8946,  20.2224,  17.4814, 129.6407], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0206, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9089.7871, 9131.6328, 7182.8789, 8312.9541])\n",
            "l2norm ;  tensor([[0.9866],\n",
            "        [3.7009],\n",
            "        [2.1620],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  40\n",
            "ce:  tensor([  3.7926,  19.6105,  17.0593, 128.4551], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.6997, 6.3330, 5.6428, 3.5281], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  3.7926,  19.6105,  17.0593, 128.4551], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0228, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7783.8701, 8004.5703, 7066.1533, 8312.9541])\n",
            "l2norm ;  tensor([[0.8229],\n",
            "        [3.3587],\n",
            "        [2.0091],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  41\n",
            "ce:  tensor([  3.6473,  19.1655,  16.6698, 127.2696], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.7524, 6.3021, 5.5764, 3.5186], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  3.6473,  19.1655,  16.6698, 127.2696], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0264, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8692.4346, 8278.4619, 6975.7383, 8312.9541])\n",
            "l2norm ;  tensor([[0.9474],\n",
            "        [2.6686],\n",
            "        [1.9307],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  42\n",
            "ce:  tensor([  3.5389,  18.8629,  16.2868, 126.0840], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.6076, 6.1917, 5.5113, 3.5089], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  3.5389,  18.8629,  16.2868, 126.0840], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.9475e-02, -0.0000e+00, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7860.0654, 7262.9946, 6990.4365, 8312.9541])\n",
            "l2norm ;  tensor([[0.6937],\n",
            "        [2.4452],\n",
            "        [1.9098],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  43\n",
            "ce:  tensor([  3.4161,  18.3807,  15.9048, 124.8984], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.5656, 6.1262, 5.4451, 3.4988], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  3.4161,  18.3807,  15.9048, 124.8984], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.3390e-02, -0.0000e+00, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8253.9658, 7229.6025, 6990.4365, 8312.9541])\n",
            "l2norm ;  tensor([[0.8325],\n",
            "        [2.0836],\n",
            "        [1.9098],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  44\n",
            "ce:  tensor([  3.3279,  17.9931,  15.5228, 123.7128], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.5036, 6.0958, 5.3787, 3.4885], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  3.3279,  17.9931,  15.5228, 123.7128], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.6529e-02, -0.0000e+00, 2.3842e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7964.9907, 7533.7383, 6990.4360, 8312.9541])\n",
            "l2norm ;  tensor([[0.8385],\n",
            "        [2.4938],\n",
            "        [1.9098],\n",
            "        [5.9279]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  45\n",
            "ce:  tensor([  3.2488,  17.7801,  15.1419, 122.5295], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3600, 6.0264, 5.3122, 3.4780], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  3.2488,  17.7801,  15.1419, 122.5295], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.9594e-02, -0.0000e+00, 2.3842e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7104.8857, 6515.0015, 6978.7529, 8306.6855])\n",
            "l2norm ;  tensor([[0.7698],\n",
            "        [1.9201],\n",
            "        [1.8410],\n",
            "        [5.9090]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  46\n",
            "ce:  tensor([  3.0968,  17.4196,  14.7892, 121.3477], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3992, 6.0108, 5.2508, 3.4671], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  3.0968,  17.4196,  14.7892, 121.3477], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.6245e-02, -0.0000e+00, 3.5763e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7766.9019, 7157.2549, 7858.2993, 8306.6855])\n",
            "l2norm ;  tensor([[0.8602],\n",
            "        [2.0562],\n",
            "        [2.6203],\n",
            "        [5.9090]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  47\n",
            "ce:  tensor([  3.0163,  17.0890,  14.5590, 120.1659], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.2548, 5.9757, 5.1264, 3.4560], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  3.0163,  17.0890,  14.5590, 120.1659], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.0222e-02, -0.0000e+00, 4.7684e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7079.5605, 6245.9634, 6873.3604, 8306.6855])\n",
            "l2norm ;  tensor([[0.6047],\n",
            "        [1.7927],\n",
            "        [1.8962],\n",
            "        [5.9090]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  48\n",
            "ce:  tensor([  2.8927,  16.7305,  14.1815, 118.9849], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.2086, 5.9689, 5.0556, 3.4447], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.8927,  16.7305,  14.1815, 118.9849], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.7021e-02, -0.0000e+00, 7.1526e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6973.3540, 6245.9634, 6827.0986, 8304.2246])\n",
            "l2norm ;  tensor([[0.6394],\n",
            "        [1.7927],\n",
            "        [1.8460],\n",
            "        [5.9019]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  49\n",
            "ce:  tensor([  2.7880,  16.3810,  13.8123, 117.8045], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1544, 5.9617, 4.9826, 3.4330], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.7880,  16.3810,  13.8123, 117.8045], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.3521e-02, 1.1921e-07, 9.5367e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7293.7646, 7239.1675, 6827.0967, 8304.2246])\n",
            "l2norm ;  tensor([[0.6885],\n",
            "        [2.3901],\n",
            "        [1.8460],\n",
            "        [5.5589]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  50\n",
            "ce:  tensor([  2.7347,  16.2037,  13.4682, 116.6928], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.0791, 5.8847, 4.9096, 3.4245], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.7347,  16.2037,  13.4682, 116.6928], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.7114e-02, 1.1921e-07, 1.4305e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7491.7656, 6756.9961, 5229.0044, 8304.2246])\n",
            "l2norm ;  tensor([[0.7917],\n",
            "        [2.0530],\n",
            "        [1.5931],\n",
            "        [5.5589]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  51\n",
            "ce:  tensor([  2.6718,  15.8593,  13.3934, 115.5810], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9271, 5.8506, 4.7810, 3.4157], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.6718,  15.8593,  13.3934, 115.5810], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.1633e-02, 1.1921e-07, 1.5497e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6999.7163, 6114.2944, 6827.0923, 8304.2246])\n",
            "l2norm ;  tensor([[0.7863],\n",
            "        [1.8916],\n",
            "        [1.8460],\n",
            "        [5.5589]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  52\n",
            "ce:  tensor([  2.5908,  15.4878,  13.1199, 114.4692], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8985, 5.8341, 4.7082, 3.4068], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.5908,  15.4878,  13.1199, 114.4692], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.7922e-02, 2.3842e-07, 2.0266e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6431.0566, 6030.4375, 4776.0078, 8304.2246])\n",
            "l2norm ;  tensor([[0.5336],\n",
            "        [1.8331],\n",
            "        [1.2180],\n",
            "        [5.5589]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  53\n",
            "ce:  tensor([  2.4768,  15.1211,  13.0823, 113.3574], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8651, 5.8195, 4.6188, 3.3976], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.4768,  15.1211,  13.0823, 113.3574], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.7750e-02, 2.3842e-07, 2.0266e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6476.0488, 6030.4365, 6362.5483, 8304.2246])\n",
            "l2norm ;  tensor([[0.5128],\n",
            "        [1.8331],\n",
            "        [1.6651],\n",
            "        [5.5589]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  54\n",
            "ce:  tensor([  2.4182,  14.7773,  12.8635, 112.2456], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8139, 5.8045, 4.5596, 3.3882], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.4182,  14.7773,  12.8635, 112.2456], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.3302e-02, 3.5763e-07, 2.6226e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7235.0195, 7649.4507, 4776.0059, 8304.2246])\n",
            "l2norm ;  tensor([[0.7286],\n",
            "        [2.5839],\n",
            "        [1.2179],\n",
            "        [5.4272]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  55\n",
            "ce:  tensor([  2.3444,  14.6001,  12.7671, 111.1602], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6641, 5.6894, 4.4703, 3.3777], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.3444,  14.6001,  12.7671, 111.1602], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0082e-01, 4.7684e-07, 2.8610e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6293.1680, 5927.8755, 6362.5435, 8304.2246])\n",
            "l2norm ;  tensor([[0.4746],\n",
            "        [1.7848],\n",
            "        [1.6651],\n",
            "        [5.1487]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  56\n",
            "ce:  tensor([  2.3129,  14.2432,  12.6199, 110.1305], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5579, 5.6698, 4.4113, 3.3663], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.3129,  14.2432,  12.6199, 110.1305], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0423e-01, 5.9605e-07, 3.3379e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5870.4155, 5927.8740, 4161.0728, 8304.2246])\n",
            "l2norm ;  tensor([[0.4745],\n",
            "        [1.7848],\n",
            "        [0.7233],\n",
            "        [5.1487]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  57\n",
            "ce:  tensor([  2.2245,  13.8862,  12.5552, 109.1007], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5209, 5.6500, 4.2847, 3.3546], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.2245,  13.8862,  12.5552, 109.1007], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1443e-01, 9.5367e-07, 3.5763e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5545.2183, 5927.8721, 6242.3394, 8304.2246])\n",
            "l2norm ;  tensor([[0.3220],\n",
            "        [1.6597],\n",
            "        [1.8533],\n",
            "        [5.0268]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  58\n",
            "ce:  tensor([  2.2352,  13.5543,  12.7163, 108.0954], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4864, 5.6577, 4.2369, 3.3420], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.2352,  13.5543,  12.7163, 108.0954], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1313e-01, 1.3113e-06, 2.9802e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6451.3032, 5927.8706, 4161.0737, 8304.2246])\n",
            "l2norm ;  tensor([[0.5297],\n",
            "        [1.6597],\n",
            "        [0.7233],\n",
            "        [4.9012]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  59\n",
            "ce:  tensor([  2.1823,  13.3234,  12.5814, 107.1152], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3614, 5.6652, 4.1101, 3.3288], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.1823,  13.3234,  12.5814, 107.1152], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1967e-01, 1.6689e-06, 3.4571e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5823.7593, 5314.0991, 3969.1753, 8304.2246])\n",
            "l2norm ;  tensor([[0.3991],\n",
            "        [1.9765],\n",
            "        [0.6625],\n",
            "        [4.7751]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  60\n",
            "ce:  tensor([  2.1814,  13.4955,  12.4983, 106.1601], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2723, 5.5508, 3.9881, 3.3156], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.1814,  13.4955,  12.4983, 106.1601], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1977e-01, 1.4305e-06, 3.6955e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5445.0132, 5927.8701, 5561.1064, 8304.2246])\n",
            "l2norm ;  tensor([[0.3219],\n",
            "        [1.8788],\n",
            "        [1.3575],\n",
            "        [4.7751]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  61\n",
            "ce:  tensor([  2.1417,  13.2391,  12.5342, 105.2051], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2478, 5.5188, 3.9350, 3.3022], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.1417,  13.2391,  12.5342, 105.2051], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.2494e-01, 1.7881e-06, 3.5763e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6000.2471, 4333.6348, 3969.1748, 8304.2246])\n",
            "l2norm ;  tensor([[0.5057],\n",
            "        [0.9147],\n",
            "        [0.6738],\n",
            "        [4.6541]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  62\n",
            "ce:  tensor([  2.1561,  13.1014,  12.4099, 104.2743], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1267, 5.4286, 3.8261, 3.2882], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.1561,  13.1014,  12.4099, 104.2743], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.2305e-01, 2.0266e-06, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5606.9170, 5894.9175, 4455.0112, 8304.2246])\n",
            "l2norm ;  tensor([[0.4109],\n",
            "        [1.7984],\n",
            "        [1.0635],\n",
            "        [4.5321]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  63\n",
            "ce:  tensor([  2.1144,  13.1275,  12.3826, 103.3679], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0349, 5.4050, 3.7231, 3.2741], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.1144,  13.1275,  12.3826, 103.3679], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.2863e-01, 2.0266e-06, 4.1723e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5122.1143, 5277.2812, 3973.8037, 8304.2246])\n",
            "l2norm ;  tensor([[0.3585],\n",
            "        [1.9258],\n",
            "        [0.6700],\n",
            "        [4.3048]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  64\n",
            "ce:  tensor([  2.0426,  13.1148,  12.4324, 102.5069], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.9854, 5.2910, 3.6207, 3.2582], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.0426,  13.1148,  12.4324, 102.5069], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.3890e-01, 2.0266e-06, 3.9339e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5238.7114, 4315.5967, 5565.6978, 8304.2246])\n",
            "l2norm ;  tensor([[0.3654],\n",
            "        [0.9025],\n",
            "        [1.3817],\n",
            "        [4.1855]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  65\n",
            "ce:  tensor([  2.0161,  12.9852,  12.3345, 101.6698], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.9312, 5.2017, 3.5807, 3.2399], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  2.0161,  12.9852,  12.3345, 101.6698], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.4291e-01, 2.2650e-06, 4.4107e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6013.4980, 5894.9150, 3973.8027, 8304.2246])\n",
            "l2norm ;  tensor([[0.6696],\n",
            "        [1.7984],\n",
            "        [0.6734],\n",
            "        [4.1855]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  66\n",
            "ce:  tensor([  1.9743,  12.9977,  12.2394, 100.8327], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.8485, 5.1779, 3.4734, 3.2214], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.9743,  12.9977,  12.2394, 100.8327], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.4950e-01, 2.2650e-06, 4.8876e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5176.5146, 4503.2612, 5565.6929, 8304.2246])\n",
            "l2norm ;  tensor([[0.3916],\n",
            "        [0.9747],\n",
            "        [1.3561],\n",
            "        [4.1855]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  67\n",
            "ce:  tensor([ 1.8973, 12.8343, 12.3085, 99.9975], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.8064, 5.0820, 3.4218, 3.2027], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8973, 12.8343, 12.3085, 99.9975], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.6249e-01, 2.6226e-06, 4.5299e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5037.6880, 3915.3293, 4128.1426, 8287.9961])\n",
            "l2norm ;  tensor([[0.3836],\n",
            "        [0.7353],\n",
            "        [0.8921],\n",
            "        [4.1542]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  68\n",
            "ce:  tensor([ 1.8719, 12.7252, 12.2256, 99.1666], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.7720, 5.0280, 3.2446, 3.1838], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8719, 12.7252, 12.2256, 99.1666], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.6704e-01, 2.9802e-06, 4.8876e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5863.5869, 5680.7446, 4434.8818, 8287.9961])\n",
            "l2norm ;  tensor([[0.6823],\n",
            "        [1.7429],\n",
            "        [1.1541],\n",
            "        [4.0503]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  69\n",
            "ce:  tensor([ 1.8223, 12.7564, 12.2131, 98.3584], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.7003, 5.0013, 3.1453, 3.1619], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8223, 12.7564, 12.2131, 98.3584], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7632e-01, 2.8610e-06, 5.0068e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5039.4805, 4103.2300, 5241.1841, 8251.6992])\n",
            "l2norm ;  tensor([[0.3518],\n",
            "        [0.7689],\n",
            "        [1.0979],\n",
            "        [4.0202]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  70\n",
            "ce:  tensor([ 1.7642, 12.6026, 12.3222, 97.5806], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6843, 4.9302, 3.0944, 3.1397], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7642, 12.6026, 12.3222, 97.5806], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.8793e-01, 3.3379e-06, 4.4107e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5260.1465, 4103.2285, 3852.0938, 8175.7129])\n",
            "l2norm ;  tensor([[0.4915],\n",
            "        [0.7077],\n",
            "        [0.6464],\n",
            "        [3.7936]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  71\n",
            "ce:  tensor([ 1.7593, 12.4799, 12.2004, 96.8218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6450, 4.8387, 3.0159, 3.1162], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7593, 12.4799, 12.2004, 96.8218], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.8895e-01, 3.8147e-06, 5.0068e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5039.7266, 5493.7778, 3644.5918, 8175.7129])\n",
            "l2norm ;  tensor([[0.5191],\n",
            "        [1.7924],\n",
            "        [0.6000],\n",
            "        [3.7936]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  72\n",
            "ce:  tensor([ 1.7681, 12.6373, 12.2823, 96.0631], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.5695, 4.8161, 2.9467, 3.0925], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7681, 12.6373, 12.2823, 96.0631], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.8711e-01, 3.2186e-06, 4.6492e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4580.8550, 5063.7793, 5950.7876, 8175.7129])\n",
            "l2norm ;  tensor([[0.3521],\n",
            "        [1.8186],\n",
            "        [2.1042],\n",
            "        [3.7936]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  73\n",
            "ce:  tensor([ 1.6989, 12.5894, 12.3796, 95.3044], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.5993, 4.7412, 2.9527, 3.0686], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.6989, 12.5894, 12.3796, 95.3044], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.0198e-01, 3.4571e-06, 4.1723e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4361.2705, 4103.2275, 4193.6943, 8175.7129])\n",
            "l2norm ;  tensor([[0.2712],\n",
            "        [0.8235],\n",
            "        [0.9058],\n",
            "        [3.7936]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  74\n",
            "ce:  tensor([ 1.6589, 12.4485, 12.3260, 94.5453], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.5901, 4.6479, 2.7998, 3.0445], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.6589, 12.4485, 12.3260, 94.5453], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.1115e-01, 3.9339e-06, 4.4107e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4903.4058, 5493.7773, 5183.6123, 8126.8125])\n",
            "l2norm ;  tensor([[0.4997],\n",
            "        [1.7924],\n",
            "        [1.1063],\n",
            "        [3.7584]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  75\n",
            "ce:  tensor([ 1.6861, 12.4983, 12.3810, 93.7937], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.5335, 4.6254, 2.7401, 3.0199], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.6861, 12.4983, 12.3810, 93.7937], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.0485e-01, 3.6955e-06, 4.1723e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4361.4746, 4103.2266, 3606.5078, 8126.8125])\n",
            "l2norm ;  tensor([[0.2195],\n",
            "        [0.7603],\n",
            "        [0.6677],\n",
            "        [3.6838]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  76\n",
            "ce:  tensor([ 1.6427, 12.3462, 12.2725, 93.0569], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.5085, 4.5502, 2.6590, 2.9953], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.6427, 12.3462, 12.2725, 93.0569], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.1499e-01, 4.2915e-06, 4.6492e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4176.5708, 4103.2236, 6099.9839, 8126.8125])\n",
            "l2norm ;  tensor([[0.2245],\n",
            "        [0.7352],\n",
            "        [2.1105],\n",
            "        [3.6053]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  77\n",
            "ce:  tensor([ 1.6860, 12.2875, 12.5285, 92.3358], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.4891, 4.4826, 2.6619, 2.9727], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.6860, 12.2875, 12.5285, 92.3358], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.0488e-01, 4.6492e-06, 3.5763e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3920.0769, 6443.4014, 4193.6973, 8126.8125])\n",
            "l2norm ;  tensor([[0.9671],\n",
            "        [2.1239],\n",
            "        [0.9058],\n",
            "        [3.6053]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  78\n",
            "ce:  tensor([ 1.7946, 12.3846, 12.4274, 91.6148], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.4296, 4.3931, 2.5126, 2.9500], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7946, 12.3846, 12.4274, 91.6148], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.8175e-01, 4.1723e-06, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4570.2104, 3915.3237, 3497.9033, 8126.8125])\n",
            "l2norm ;  tensor([[0.8212],\n",
            "        [0.8299],\n",
            "        [0.6787],\n",
            "        [3.5299]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  79\n",
            "ce:  tensor([ 1.7266, 12.2202, 12.4612, 90.9084], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.4518, 4.2981, 2.4301, 2.9268], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7266, 12.2202, 12.4612, 90.9084], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.9588e-01, 4.8876e-06, 3.8147e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3351.0637, 4103.2212, 5517.5386, 8143.1626])\n",
            "l2norm ;  tensor([[0.3008],\n",
            "        [0.7352],\n",
            "        [1.4417],\n",
            "        [3.5469]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  80\n",
            "ce:  tensor([ 1.7797, 12.2613, 12.4183, 90.1990], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.4013, 4.2304, 2.3886, 2.9034], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7797, 12.2613, 12.4183, 90.1990], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.8474e-01, 4.7684e-06, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4484.0967, 5967.1475, 3685.5679, 8143.1626])\n",
            "l2norm ;  tensor([[0.8143],\n",
            "        [2.6276],\n",
            "        [0.7279],\n",
            "        [3.5469]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  81\n",
            "ce:  tensor([ 1.7882, 12.2639, 12.4829, 89.4897], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.4227, 4.2533, 2.3002, 2.8800], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7882, 12.2639, 12.4829, 89.4897], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.8304e-01, 4.7684e-06, 3.8147e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3915.7825, 4008.8398, 5539.6436, 8143.1626])\n",
            "l2norm ;  tensor([[1.0191],\n",
            "        [0.8526],\n",
            "        [2.0761],\n",
            "        [3.4801]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  82\n",
            "ce:  tensor([ 1.8211, 12.1023, 12.5593, 88.7936], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.3705, 4.2006, 2.2994, 2.8560], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8211, 12.1023, 12.5593, 88.7936], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7655e-01, 5.6028e-06, 3.4571e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4520.9639, 4784.0361, 3653.3174, 8143.1626])\n",
            "l2norm ;  tensor([[0.6010],\n",
            "        [1.7895],\n",
            "        [0.7254],\n",
            "        [3.4801]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  83\n",
            "ce:  tensor([ 1.8401, 12.3751, 12.4352, 88.0976], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.3548, 4.1458, 2.2156, 2.8320], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8401, 12.3751, 12.4352, 88.0976], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7293e-01, 4.1723e-06, 3.9339e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3429.1484, 5586.3218, 5139.7588, 8143.1626])\n",
            "l2norm ;  tensor([[0.5014],\n",
            "        [1.8561],\n",
            "        [1.1803],\n",
            "        [3.4801]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  84\n",
            "ce:  tensor([ 1.8444, 12.2147, 12.5486, 87.4016], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.3183, 4.0938, 2.1896, 2.8080], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8444, 12.2147, 12.5486, 87.4016], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7211e-01, 5.0068e-06, 3.5763e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4541.0991, 4409.2393, 3653.3174, 8143.1626])\n",
            "l2norm ;  tensor([[0.8316],\n",
            "        [1.0457],\n",
            "        [0.7290],\n",
            "        [3.4213]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  85\n",
            "ce:  tensor([ 1.8510, 12.1014, 12.5190, 86.7173], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.3362, 4.0110, 2.1027, 2.7841], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8510, 12.1014, 12.5190, 86.7173], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7089e-01, 5.6028e-06, 3.6955e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3436.1726, 5586.3149, 3428.6724, 8143.1626])\n",
            "l2norm ;  tensor([[0.3294],\n",
            "        [1.6279],\n",
            "        [1.1310],\n",
            "        [3.3620]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  86\n",
            "ce:  tensor([ 1.8185, 12.1244, 12.6610, 86.0449], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2979, 3.9679, 2.0482, 2.7599], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8185, 12.1244, 12.6610, 86.0449], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7705e-01, 5.4836e-06, 3.2186e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4458.3325, 4008.8372, 5370.4429, 8143.1626])\n",
            "l2norm ;  tensor([[0.8242],\n",
            "        [0.8526],\n",
            "        [1.4453],\n",
            "        [3.3620]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  87\n",
            "ce:  tensor([ 1.8972, 11.9735, 12.6867, 85.3725], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.3124, 3.9153, 2.0331, 2.7356], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8972, 11.9735, 12.6867, 85.3725], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.6251e-01, 6.3181e-06, 3.0994e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3391.4294, 4380.1113, 3653.3191, 8143.1626])\n",
            "l2norm ;  tensor([[0.5352],\n",
            "        [1.2486],\n",
            "        [0.7181],\n",
            "        [3.3620]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  88\n",
            "ce:  tensor([ 1.8174, 11.9676, 12.6542, 84.7338], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2762, 3.8812, 1.9575, 2.7113], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8174, 11.9676, 12.6542, 84.7338], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7727e-01, 6.3181e-06, 3.2186e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4202.1216, 4871.7749, 4481.4956, 7974.3389])\n",
            "l2norm ;  tensor([[0.4298],\n",
            "        [1.8910],\n",
            "        [1.1859],\n",
            "        [3.0703]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  89\n",
            "ce:  tensor([ 1.8796, 12.2309, 12.7397, 84.1197], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2818, 3.8084, 1.9358, 2.6876], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8796, 12.2309, 12.7397, 84.1197], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.6564e-01, 4.8876e-06, 2.9802e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3923.6204, 5484.7349, 4768.2139, 7974.3389])\n",
            "l2norm ;  tensor([[0.8476],\n",
            "        [1.6166],\n",
            "        [2.1512],\n",
            "        [3.0185]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  90\n",
            "ce:  tensor([ 1.9097, 12.0785, 12.9144, 83.5160], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2424, 3.7713, 1.8133, 2.6615], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.9097, 12.0785, 12.9144, 83.5160], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.6032e-01, 5.7220e-06, 2.5034e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3673.7695, 3909.5217, 5263.6143, 7974.3389])\n",
            "l2norm ;  tensor([[0.4376],\n",
            "        [0.7212],\n",
            "        [2.3629],\n",
            "        [2.9674]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  91\n",
            "ce:  tensor([ 1.8895, 12.0286, 13.1164, 83.0079], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2239, 3.6631, 1.8370, 2.6356], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8895, 12.0286, 13.1164, 83.0079], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.6388e-01, 5.9604e-06, 2.0266e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4275.6084, 5297.5874, 4079.2656, 7333.2197])\n",
            "l2norm ;  tensor([[0.4236],\n",
            "        [1.7582],\n",
            "        [0.9500],\n",
            "        [2.4952]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  92\n",
            "ce:  tensor([ 1.9438, 12.0378, 13.0250, 82.5089], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2296, 3.6260, 1.7003, 2.6212], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.9438, 12.0378, 13.0250, 82.5089], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5450e-01, 5.9604e-06, 2.1458e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3697.9268, 4308.2627, 2958.3604, 7333.2197])\n",
            "l2norm ;  tensor([[0.4106],\n",
            "        [1.0555],\n",
            "        [0.6350],\n",
            "        [2.4952]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  93\n",
            "ce:  tensor([ 1.8961, 11.9041, 13.2202, 82.0098], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2023, 3.4581, 1.6643, 2.6068], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8961, 11.9041, 13.2202, 82.0098], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.6270e-01, 6.7949e-06, 1.7881e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3665.0435, 3646.0569, 5955.6875, 7333.2197])\n",
            "l2norm ;  tensor([[0.3798],\n",
            "        [0.6721],\n",
            "        [2.1738],\n",
            "        [2.4952]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  94\n",
            "ce:  tensor([ 1.8880, 11.9160, 13.2081, 81.5108], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1846, 3.3707, 1.6776, 2.5924], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.8880, 11.9160, 13.2081, 81.5108], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.6414e-01, 6.6757e-06, 1.7881e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4814.5527, 5883.5327, 3653.3232, 7333.2197])\n",
            "l2norm ;  tensor([[0.5657],\n",
            "        [2.3642],\n",
            "        [0.7061],\n",
            "        [2.3671]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  95\n",
            "ce:  tensor([ 1.9440, 12.0084, 13.2273, 81.0374], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1648, 3.4203, 1.6150, 2.5743], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.9440, 12.0084, 13.2273, 81.0374], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5447e-01, 6.0797e-06, 1.7881e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3698.0347, 4871.7764, 4974.7153, 7333.2197])\n",
            "l2norm ;  tensor([[0.3177],\n",
            "        [2.4731],\n",
            "        [1.4925],\n",
            "        [2.3671]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  96\n",
            "ce:  tensor([ 1.9133, 11.9851, 13.3084, 80.5639], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1562, 3.2403, 1.6055, 2.5562], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.9133, 11.9851, 13.3084, 80.5639], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5970e-01, 6.1989e-06, 1.6689e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4683.6353, 5410.1875, 4135.8330, 7333.2197])\n",
            "l2norm ;  tensor([[0.5219],\n",
            "        [1.4716],\n",
            "        [0.9529],\n",
            "        [2.3671]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  97\n",
            "ce:  tensor([ 2.0207, 11.9174, 13.2766, 80.0905], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1626, 3.1849, 1.4793, 2.5382], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.0207, 11.9174, 13.2766, 80.0905], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.4221e-01, 6.6757e-06, 1.6689e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4227.7397, 3834.3230, 5065.9761, 7333.2197])\n",
            "l2norm ;  tensor([[1.1294],\n",
            "        [0.7503],\n",
            "        [2.1888],\n",
            "        [2.3248]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  98\n",
            "ce:  tensor([ 2.0032, 11.9026, 13.5393, 79.6256], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1395, 3.0422, 1.4968, 2.5204], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.0032, 11.9026, 13.5393, 79.6256], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.4491e-01, 6.7949e-06, 1.3113e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4784.9292, 5525.4990, 3737.5898, 7333.2197])\n",
            "l2norm ;  tensor([[1.0253],\n",
            "        [2.7609],\n",
            "        [0.7164],\n",
            "        [2.3248]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  99\n",
            "ce:  tensor([ 2.0983, 12.0087, 13.4041, 79.1606], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1560, 3.0673, 1.4340, 2.5028], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.0983, 12.0087, 13.4041, 79.1606], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.3087e-01, 6.0797e-06, 1.5497e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3664.8721, 3909.5203, 3560.8271, 7333.2197])\n",
            "l2norm ;  tensor([[0.5138],\n",
            "        [0.8351],\n",
            "        [0.5937],\n",
            "        [2.3248]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  100\n",
            "ce:  tensor([ 2.0219, 11.8475, 13.5665, 78.6957], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1413, 2.9318, 1.3866, 2.4852], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.0219, 11.8475, 13.5665, 78.6957], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.4203e-01, 7.1525e-06, 1.3113e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3907.5227, 3834.3210, 5065.9780, 7333.2197])\n",
            "l2norm ;  tensor([[0.3988],\n",
            "        [0.6907],\n",
            "        [2.1873],\n",
            "        [2.2611]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  101\n",
            "ce:  tensor([ 2.0264, 11.9167, 13.6583, 78.2435], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1354, 2.8345, 1.4056, 2.4671], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.0264, 11.9167, 13.6583, 78.2435], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.4135e-01, 6.6757e-06, 1.1921e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3959.6885, 5525.4990, 4709.9712, 7333.2197])\n",
            "l2norm ;  tensor([[0.6938],\n",
            "        [2.4722],\n",
            "        [1.5747],\n",
            "        [2.2314]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  102\n",
            "ce:  tensor([ 2.1496, 12.0363, 13.7616, 77.7972], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1358, 2.8980, 1.3283, 2.4490], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.1496, 12.0363, 13.7616, 77.7972], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.2390e-01, 5.9604e-06, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4606.9087, 4797.0972, 4589.6572, 7333.2197])\n",
            "l2norm ;  tensor([[0.5780],\n",
            "        [2.1041],\n",
            "        [1.1971],\n",
            "        [2.1967]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  103\n",
            "ce:  tensor([ 2.1616, 12.0874, 13.7912, 77.3578], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1469, 2.7813, 1.3015, 2.4326], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.1616, 12.0874, 13.7912, 77.3578], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.2233e-01, 5.6028e-06, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3473.3984, 5410.1909, 3709.6328, 7333.2197])\n",
            "l2norm ;  tensor([[0.4851],\n",
            "        [1.5958],\n",
            "        [0.7901],\n",
            "        [2.1967]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  104\n",
            "ce:  tensor([ 2.1654, 12.0616, 13.8652, 76.9185], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1315, 2.7478, 1.2492, 2.4162], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.1654, 12.0616, 13.8652, 76.9185], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.2184e-01, 5.7220e-06, 9.5367e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4500.3516, 3834.3267, 5506.1289, 7333.2197])\n",
            "l2norm ;  tensor([[1.1732],\n",
            "        [0.8121],\n",
            "        [2.2554],\n",
            "        [2.1967]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  105\n",
            "ce:  tensor([ 2.2541, 11.9464, 13.9850, 76.4792], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1436, 2.6210, 1.2674, 2.4000], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.2541, 11.9464, 13.9850, 76.4792], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1090e-01, 6.4373e-06, 8.3446e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4053.3003, 5237.1294, 4107.6963, 7333.2197])\n",
            "l2norm ;  tensor([[1.1681],\n",
            "        [1.6014],\n",
            "        [0.9857],\n",
            "        [2.0935]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  106\n",
            "ce:  tensor([ 2.2243, 11.9967, 13.9107, 76.0604], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1282, 2.5678, 1.1562, 2.3815], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.2243, 11.9967, 13.9107, 76.0604], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1445e-01, 6.1989e-06, 9.5367e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4770.0161, 3660.2556, 4374.9844, 7333.2197])\n",
            "l2norm ;  tensor([[1.0421],\n",
            "        [1.5182],\n",
            "        [1.2731],\n",
            "        [2.0935]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  107\n",
            "ce:  tensor([ 2.3709, 11.7558, 14.0475, 75.6418], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1434, 2.3846, 1.1792, 2.3631], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.3709, 11.7558, 14.0475, 75.6418], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.8047e-02, 7.8678e-06, 8.3446e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3652.9182, 5712.2993, 3709.6340, 7333.2197])\n",
            "l2norm ;  tensor([[0.6564],\n",
            "        [2.4235],\n",
            "        [0.6930],\n",
            "        [2.0211]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  108\n",
            "ce:  tensor([ 2.2515, 11.9830, 13.9576, 75.2448], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1316, 2.4460, 1.1238, 2.3481], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.2515, 11.9830, 13.9576, 75.2448], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1120e-01, 6.1989e-06, 8.3446e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3238.4631, 4625.6533, 3778.6384, 7280.1831])\n",
            "l2norm ;  tensor([[0.3292],\n",
            "        [2.1161],\n",
            "        [0.8901],\n",
            "        [1.9690]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  109\n",
            "ce:  tensor([ 2.3250, 11.9734, 13.9901, 74.8510], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1348, 2.3346, 1.0770, 2.3329], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.3250, 11.9734, 13.9901, 74.8510], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0290e-01, 6.3181e-06, 8.3446e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4586.4146, 3834.3242, 3459.4897, 7280.1831])\n",
            "l2norm ;  tensor([[1.1822],\n",
            "        [0.8175],\n",
            "        [0.7621],\n",
            "        [1.9329]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  110\n",
            "ce:  tensor([ 2.3946, 12.0106, 14.1776, 74.4645], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1490, 2.2364, 0.9870, 2.3165], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.3946, 12.0106, 14.1776, 74.4645], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.5641e-02, 6.0797e-06, 7.1526e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4115.6250, 5237.1313, 4843.7466, 7280.1831])\n",
            "l2norm ;  tensor([[1.1953],\n",
            "        [1.4754],\n",
            "        [1.5269],\n",
            "        [1.9088]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  111\n",
            "ce:  tensor([ 2.3844, 11.9249, 14.1034, 74.0827], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1331, 2.2456, 1.0076, 2.3002], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.3844, 11.9249, 14.1034, 74.0827], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.6671e-02, 6.6757e-06, 7.1526e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4855.5625, 3660.2544, 3922.6746, 7280.1831])\n",
            "l2norm ;  tensor([[1.0583],\n",
            "        [0.7010],\n",
            "        [0.8236],\n",
            "        [1.7574]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  112\n",
            "ce:  tensor([ 2.4921, 11.8631, 14.1787, 73.8235], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1495, 2.1170, 0.9174, 2.2870], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.4921, 11.8631, 14.1787, 73.8235], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.6363e-02, 7.0333e-06, 7.1526e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3668.3625, 5712.3042, 4589.6587, 6288.3242])\n",
            "l2norm ;  tensor([[0.5397],\n",
            "        [2.1228],\n",
            "        [1.4476],\n",
            "        [1.6391]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  113\n",
            "ce:  tensor([ 2.3976, 12.0400, 14.2531, 73.6168], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1404, 2.1685, 0.9446, 2.2705], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.3976, 12.0400, 14.2531, 73.6168], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.5340e-02, 5.9604e-06, 5.9605e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3262.9536, 3834.3257, 4463.1626, 7280.1831])\n",
            "l2norm ;  tensor([[0.3591],\n",
            "        [0.7956],\n",
            "        [2.0154],\n",
            "        [1.9397]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  114\n",
            "ce:  tensor([ 2.4543, 11.8907, 14.4221, 73.3949], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1452, 2.0559, 0.8899, 2.2616], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.4543, 11.8907, 14.4221, 73.3949], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.9841e-02, 6.7949e-06, 5.9605e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4619.2471, 3660.2532, 5934.0474, 6288.3242])\n",
            "l2norm ;  tensor([[1.2216],\n",
            "        [0.6006],\n",
            "        [1.3927],\n",
            "        [1.6161]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  115\n",
            "ce:  tensor([ 2.5864, 11.9307, 14.4728, 73.1283], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1617, 1.9781, 0.8931, 2.2447], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.5864, 11.9307, 14.4728, 73.1283], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.8275e-02, 6.5565e-06, 4.7684e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4346.9048, 5237.1284, 3202.2261, 7280.1831])\n",
            "l2norm ;  tensor([[1.3469],\n",
            "        [1.7254],\n",
            "        [0.7341],\n",
            "        [1.6641]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  116\n",
            "ce:  tensor([ 2.5358, 11.9758, 14.4979, 72.9602], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1433, 1.9536, 0.8749, 2.2240], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.5358, 11.9758, 14.4979, 72.9602], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.2512e-02, 6.3181e-06, 4.7684e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4360.8052, 5196.2969, 6220.9243, 6288.3242])\n",
            "l2norm ;  tensor([[0.7025],\n",
            "        [2.1727],\n",
            "        [2.3051],\n",
            "        [1.5877]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  117\n",
            "ce:  tensor([ 2.5808, 12.0176, 14.6787, 72.7052], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1550, 1.8164, 0.9141, 2.2072], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.5808, 12.0176, 14.6787, 72.7052], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.8734e-02, 6.0797e-06, 4.7684e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4158.1787, 5712.3101, 4709.9746, 7280.1831])\n",
            "l2norm ;  tensor([[1.2535],\n",
            "        [2.2906],\n",
            "        [1.7052],\n",
            "        [1.6170]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  118\n",
            "ce:  tensor([ 2.6423, 12.1617, 14.6237, 72.5180], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1401, 1.8995, 0.8474, 2.1944], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.6423, 12.1617, 14.6237, 72.5180], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.3856e-02, 5.2452e-06, 4.7684e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5157.3345, 3834.3284, 5030.8608, 6288.3242])\n",
            "l2norm ;  tensor([[1.1855],\n",
            "        [1.6218],\n",
            "        [1.2021],\n",
            "        [1.5841]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  119\n",
            "ce:  tensor([ 2.7018, 11.9233, 14.8137, 72.2947], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1580, 1.7486, 0.8260, 2.1777], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.7018, 11.9233, 14.8137, 72.2947], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.9438e-02, 6.6757e-06, 3.5763e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3886.0325, 5637.5952, 3709.6355, 7280.1831])\n",
            "l2norm ;  tensor([[0.7104],\n",
            "        [1.2887],\n",
            "        [0.7828],\n",
            "        [1.8557]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  120\n",
            "ce:  tensor([ 2.6198, 12.0183, 14.7397, 72.1203], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1461, 1.7842, 0.7913, 2.1688], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.6198, 12.0183, 14.7397, 72.1203], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.5602e-02, 6.0797e-06, 3.5763e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4890.1118, 3660.2563, 5252.9102, 6288.3242])\n",
            "l2norm ;  tensor([[1.3159],\n",
            "        [0.7169],\n",
            "        [2.5374],\n",
            "        [1.5785]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  121\n",
            "ce:  tensor([ 2.7551, 11.9134, 14.9894, 71.8405], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1628, 1.6870, 0.8359, 2.1521], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.7551, 11.9134, 14.9894, 71.8405], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.5716e-02, 6.6757e-06, 3.5763e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3706.7754, 5712.3062, 4107.6992, 7280.1831])\n",
            "l2norm ;  tensor([[0.5432],\n",
            "        [2.0061],\n",
            "        [0.9284],\n",
            "        [1.6247]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  122\n",
            "ce:  tensor([ 2.6555, 12.2684, 14.8877, 71.6979], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1502, 1.7738, 0.7539, 2.1315], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.6555, 12.2684, 14.8877, 71.6979], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.2855e-02, 4.6492e-06, 3.5763e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3409.0696, 4797.1025, 3960.4358, 6288.3242])\n",
            "l2norm ;  tensor([[0.3921],\n",
            "        [2.0145],\n",
            "        [0.5700],\n",
            "        [1.5785]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  123\n",
            "ce:  tensor([ 2.7152, 12.1994, 14.9038, 71.4325], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1521, 1.6853, 0.7319, 2.1149], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.7152, 12.1994, 14.9038, 71.4325], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.8481e-02, 5.0068e-06, 3.5763e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5734.7339, 3834.3289, 4589.6597, 7280.1831])\n",
            "l2norm ;  tensor([[1.2684],\n",
            "        [0.6949],\n",
            "        [1.4612],\n",
            "        [1.5206]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  124\n",
            "ce:  tensor([ 2.8563, 12.2331, 15.1182, 71.2678], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1638, 1.6172, 0.7601, 2.0994], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.8563, 12.2331, 15.1182, 71.2678], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.9196e-02, 4.8876e-06, 2.3842e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3879.3347, 5237.1377, 5076.1514, 6288.3242])\n",
            "l2norm ;  tensor([[0.6775],\n",
            "        [1.3657],\n",
            "        [2.2663],\n",
            "        [1.5578]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  125\n",
            "ce:  tensor([ 2.8081, 12.1973, 15.1220, 71.0550], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1499, 1.6632, 0.6898, 2.0810], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.8081, 12.1973, 15.1220, 71.0550], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.2215e-02, 5.0068e-06, 2.3842e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5112.6128, 4797.1011, 4843.7480, 7280.1831])\n",
            "l2norm ;  tensor([[1.4296],\n",
            "        [2.0145],\n",
            "        [1.4946],\n",
            "        [1.5852]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  126\n",
            "ce:  tensor([ 2.9191, 12.4455, 15.3354, 70.8695], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1665, 1.5776, 0.7092, 2.0590], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.9191, 12.4455, 15.3354, 70.8695], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.5493e-02, 3.9339e-06, 2.3842e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3893.7266, 5712.3218, 4107.6997, 6288.3242])\n",
            "l2norm ;  tensor([[0.5759],\n",
            "        [2.3715],\n",
            "        [1.1917],\n",
            "        [1.5038]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  127\n",
            "ce:  tensor([ 2.8158, 12.4632, 15.2286, 70.6832], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1524, 1.6431, 0.6423, 2.0415], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.8158, 12.4632, 15.2286, 70.6832], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.1724e-02, 3.8147e-06, 2.3842e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3595.7930, 4308.2720, 3671.9065, 7280.1831])\n",
            "l2norm ;  tensor([[0.2076],\n",
            "        [1.0026],\n",
            "        [1.0786],\n",
            "        [1.7646]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  128\n",
            "ce:  tensor([ 2.8467, 12.4066, 15.3082, 70.5151], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1440, 1.5326, 0.6156, 2.0321], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.8467, 12.4066, 15.3082, 70.5151], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.9785e-02, 4.0531e-06, 2.3842e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5125.0488, 5484.7393, 5624.5454, 6288.3242])\n",
            "l2norm ;  tensor([[1.4264],\n",
            "        [1.4498],\n",
            "        [1.4684],\n",
            "        [1.5038]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  129\n",
            "ce:  tensor([ 3.0398, 12.4290, 15.3998, 70.2785], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1571, 1.5248, 0.6162, 2.0148], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.0398, 12.4290, 15.3998, 70.2785], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.9027e-02, 4.0531e-06, 2.3842e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4592.4707, 3909.5278, 3598.5933, 7221.7490])\n",
            "l2norm ;  tensor([[1.3960],\n",
            "        [0.7861],\n",
            "        [0.8657],\n",
            "        [1.3871]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  130\n",
            "ce:  tensor([ 2.9510, 12.4072, 15.3439, 70.1313], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1397, 1.4419, 0.5605, 2.0028], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.9510, 12.4072, 15.3439, 70.1313], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.3705e-02, 4.0531e-06, 2.3842e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5101.6694, 5712.3213, 5030.8623, 6248.3584])\n",
            "l2norm ;  tensor([[0.7407],\n",
            "        [2.2666],\n",
            "        [1.4737],\n",
            "        [1.4425]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  131\n",
            "ce:  tensor([ 3.0500, 12.5901, 15.5428, 69.9687], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1491, 1.5335, 0.5746, 1.9848], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.0500, 12.5901, 15.5428, 69.9687], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.8518e-02, 3.4571e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3920.9807, 4871.7886, 4679.3828, 7221.7490])\n",
            "l2norm ;  tensor([[0.7223],\n",
            "        [2.4265],\n",
            "        [2.1668],\n",
            "        [1.3809]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  132\n",
            "ce:  tensor([ 2.9705, 12.5060, 15.6021, 69.7738], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1323, 1.3995, 0.5362, 1.9625], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 2.9705, 12.5060, 15.6021, 69.7738], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.2640e-02, 3.6955e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5161.8022, 5410.2012, 5934.0498, 6248.3584])\n",
            "l2norm ;  tensor([[1.4671],\n",
            "        [1.3052],\n",
            "        [1.3474],\n",
            "        [1.4212]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  133\n",
            "ce:  tensor([ 3.1149, 12.5057, 15.8039, 69.6682], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1454, 1.4041, 0.5432, 1.9447], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.1149, 12.5057, 15.8039, 69.6682], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.5400e-02, 3.6955e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4609.1616, 3589.4790, 3709.6362, 7221.7490])\n",
            "l2norm ;  tensor([[1.5177],\n",
            "        [0.6970],\n",
            "        [0.7556],\n",
            "        [1.6252]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  134\n",
            "ce:  tensor([ 3.0498, 12.5187, 15.6773, 69.4534], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1282, 1.3072, 0.5315, 1.9364], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.0498, 12.5187, 15.6773, 69.4534], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.8527e-02, 3.6955e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3973.6570, 5712.3232, 3202.2273, 6248.3584])\n",
            "l2norm ;  tensor([[0.6363],\n",
            "        [2.2410],\n",
            "        [0.5633],\n",
            "        [1.4212]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  135\n",
            "ce:  tensor([ 3.1045, 12.7303, 15.9090, 69.3189], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1328, 1.3926, 0.5226, 1.9189], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.1045, 12.7303, 15.9090, 69.3189], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.5886e-02, 2.9802e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4078.5232, 5270.8657, 6408.1729, 7221.7490])\n",
            "l2norm ;  tensor([[0.4811],\n",
            "        [2.1496],\n",
            "        [2.3311],\n",
            "        [1.3655]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  136\n",
            "ce:  tensor([ 3.1488, 12.7033, 15.9889, 69.1222], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1163, 1.2785, 0.5499, 1.8978], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.1488, 12.7033, 15.9889, 69.1222], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.3851e-02, 3.0994e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4874.2095, 4162.3174, 4709.9766, 6189.5356])\n",
            "l2norm ;  tensor([[0.8718],\n",
            "        [0.8355],\n",
            "        [1.4070],\n",
            "        [1.3705]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  137\n",
            "ce:  tensor([ 3.1463, 12.7716, 16.0815, 69.0481], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1240, 1.1852, 0.4996, 1.8809], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.1463, 12.7716, 16.0815, 69.0481], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.3963e-02, 2.8610e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3938.8833, 5866.8633, 4589.6616, 7145.4282])\n",
            "l2norm ;  tensor([[0.6250],\n",
            "        [2.6226],\n",
            "        [1.2248],\n",
            "        [1.2474]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  138\n",
            "ce:  tensor([ 3.0929, 12.8677, 16.1224, 68.8102], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1177, 1.2713, 0.4949, 1.8703], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.0929, 12.8677, 16.1224, 68.8102], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.6433e-02, 2.6226e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4861.6416, 3909.5337, 3709.6362, 6189.5356])\n",
            "l2norm ;  tensor([[0.8774],\n",
            "        [1.6005],\n",
            "        [0.7741],\n",
            "        [1.0055]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  139\n",
            "ce:  tensor([ 3.1947, 12.6765, 16.1232, 68.7655], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1254, 1.1382, 0.4717, 1.8578], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.1947, 12.6765, 16.1232, 68.7655], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.1843e-02, 3.0994e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4625.5840, 5661.7324, 5239.0508, 7145.4282])\n",
            "l2norm ;  tensor([[1.2926],\n",
            "        [1.1004],\n",
            "        [1.3810],\n",
            "        [1.5861]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  140\n",
            "ce:  tensor([ 3.1967, 12.7968, 16.2598, 68.6293], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1138, 1.1487, 0.4851, 1.8453], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.1967, 12.7968, 16.2598, 68.6293], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.1757e-02, 2.7418e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5496.4048, 4653.8486, 3709.6362, 6189.5356])\n",
            "l2norm ;  tensor([[1.3288],\n",
            "        [2.1108],\n",
            "        [0.6748],\n",
            "        [0.9890]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  141\n",
            "ce:  tensor([ 3.3531, 13.1116, 16.2204, 68.4315], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1291, 1.0887, 0.4599, 1.8332], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.3531, 13.1116, 16.2204, 68.4315], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.5603e-02, 2.0266e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3971.9497, 6095.3003, 5065.9849, 6189.5356])\n",
            "l2norm ;  tensor([[0.6506],\n",
            "        [2.2903],\n",
            "        [2.5649],\n",
            "        [0.9807]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  142\n",
            "ce:  tensor([ 3.2409, 13.1383, 16.5382, 68.3907], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1137, 1.1691, 0.4898, 1.8212], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.2409, 13.1383, 16.5382, 68.3907], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.9913e-02, 2.0266e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3675.0806, 3909.5361, 5678.3096, 7145.4282])\n",
            "l2norm ;  tensor([[0.2153],\n",
            "        [0.7144],\n",
            "        [2.5721],\n",
            "        [1.5666]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  143\n",
            "ce:  tensor([ 3.2569, 13.1140, 16.5419, 68.2592], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1084, 1.0725, 0.4370, 1.8092], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.2569, 13.1140, 16.5419, 68.2592], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.9268e-02, 2.0266e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5231.2866, 5389.7217, 3264.6006, 6189.5356])\n",
            "l2norm ;  tensor([[1.4833],\n",
            "        [1.8403],\n",
            "        [0.8256],\n",
            "        [0.9792]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  144\n",
            "ce:  tensor([ 3.3938, 13.1868, 16.5924, 68.0707], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1219, 1.0991, 0.4209, 1.7993], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.3938, 13.1868, 16.5924, 68.0707], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.4159e-02, 1.9073e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4052.9954, 3688.0337, 4776.7207, 7145.4282])\n",
            "l2norm ;  tensor([[0.7266],\n",
            "        [1.4904],\n",
            "        [1.4165],\n",
            "        [1.2669]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  145\n",
            "ce:  tensor([ 3.2564, 12.9400, 16.6330, 68.0635], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1095, 0.9803, 0.4385, 1.7824], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.2564, 12.9400, 16.6330, 68.0635], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.9288e-02, 2.3842e-06, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3752.2419, 5566.7373, 5076.1528, 6189.5356])\n",
            "l2norm ;  tensor([[0.2208],\n",
            "        [1.9690],\n",
            "        [2.2551],\n",
            "        [0.9792]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  146\n",
            "ce:  tensor([ 3.3295, 13.2190, 16.8674, 67.8677], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1039, 1.0503, 0.3957, 1.7729], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.3295, 13.2190, 16.8674, 67.8677], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.6467e-02, 1.7881e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5245.9585, 4086.2544, 5824.6001, 6189.5356])\n",
            "l2norm ;  tensor([[1.4622],\n",
            "        [0.8987],\n",
            "        [2.4493],\n",
            "        [0.9304]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  147\n",
            "ce:  tensor([ 3.4263, 13.1035, 16.9894, 67.7447], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1154, 0.9563, 0.4188, 1.7628], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.4263, 13.1035, 16.9894, 67.7447], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.3046e-02, 2.0266e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4187.2935, 3636.7466, 4358.2627, 7145.4282])\n",
            "l2norm ;  tensor([[0.4941],\n",
            "        [0.4839],\n",
            "        [1.5722],\n",
            "        [1.5164]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  148\n",
            "ce:  tensor([ 3.3365, 13.0985, 16.8467, 67.7137], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0981, 0.9232, 0.3609, 1.7514], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.3365, 13.0985, 16.8467, 67.7137], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.6209e-02, 2.0266e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3893.1458, 5262.7363, 5239.0508, 6189.5356])\n",
            "l2norm ;  tensor([[0.2110],\n",
            "        [1.0634],\n",
            "        [1.2816],\n",
            "        [1.3264]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  149\n",
            "ce:  tensor([ 3.3315, 13.3203, 16.9497, 67.4613], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0941, 0.9522, 0.3620, 1.7363], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.3315, 13.3203, 16.9497, 67.4613], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.6392e-02, 1.6689e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4880.1729, 5051.6865, 3709.6365, 7145.4282])\n",
            "l2norm ;  tensor([[0.8890],\n",
            "        [2.2240],\n",
            "        [0.8729],\n",
            "        [1.1810]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  150\n",
            "ce:  tensor([ 3.4889, 13.3811, 16.8987, 67.4505], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1032, 0.8728, 0.3486, 1.7185], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.4889, 13.3811, 16.8987, 67.4505], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.1012e-02, 1.5497e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5030.7705, 5791.7993, 4985.2490, 6189.5356])\n",
            "l2norm ;  tensor([[1.6157],\n",
            "        [1.9095],\n",
            "        [1.3069],\n",
            "        [0.9028]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  151\n",
            "ce:  tensor([ 3.4833, 13.4386, 17.0598, 67.2699], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0943, 0.8965, 0.3675, 1.7143], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.4833, 13.4386, 17.0598, 67.2699], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.1188e-02, 1.4305e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5954.8682, 3688.0349, 3919.0857, 6189.5356])\n",
            "l2norm ;  tensor([[1.4194],\n",
            "        [0.6696],\n",
            "        [0.9125],\n",
            "        [0.8778]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  152\n",
            "ce:  tensor([ 3.5861, 13.3819, 16.9705, 67.2571], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1075, 0.8279, 0.3227, 1.7088], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.5861, 13.3819, 16.9705, 67.2571], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.8098e-02, 1.5497e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4461.6587, 5566.7422, 3014.5825, 7145.4282])\n",
            "l2norm ;  tensor([[0.8158],\n",
            "        [2.3092],\n",
            "        [0.5520],\n",
            "        [1.4908]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  153\n",
            "ce:  tensor([ 3.4493, 13.6103, 17.2520, 67.1498], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0959, 0.8651, 0.3141, 1.7005], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.4493, 13.6103, 17.2520, 67.1498], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.2285e-02, 1.1921e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5634.5581, 3909.5391, 5736.3755, 6189.5356])\n",
            "l2norm ;  tensor([[1.5244],\n",
            "        [1.5845],\n",
            "        [2.4596],\n",
            "        [0.8714]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  154\n",
            "ce:  tensor([ 3.6359, 13.3147, 17.2961, 66.9988], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1074, 0.7615, 0.3330, 1.6962], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.6359, 13.3147, 17.2961, 66.9988], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.6715e-02, 1.6689e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4449.1802, 3767.3110, 4961.5649, 7145.4282])\n",
            "l2norm ;  tensor([[0.7318],\n",
            "        [0.5149],\n",
            "        [2.2005],\n",
            "        [1.0559]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  155\n",
            "ce:  tensor([ 3.5187, 13.3891, 17.2624, 67.0209], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0957, 0.7078, 0.2953, 1.6811], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.5187, 13.3891, 17.2624, 67.0209], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.0087e-02, 1.5497e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4014.9792, 5765.0103, 4755.1035, 6189.5356])\n",
            "l2norm ;  tensor([[0.2235],\n",
            "        [1.7453],\n",
            "        [1.2268],\n",
            "        [0.8365]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  156\n",
            "ce:  tensor([ 3.5047, 13.6115, 17.2630, 66.8536], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0918, 0.7471, 0.2920, 1.6774], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.5047, 13.6115, 17.2630, 66.8536], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.0516e-02, 1.1921e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5278.9766, 4653.8555, 4018.2629, 6189.5356])\n",
            "l2norm ;  tensor([[0.9109],\n",
            "        [2.1153],\n",
            "        [0.9588],\n",
            "        [0.7788]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  157\n",
            "ce:  tensor([ 3.6538, 13.6604, 17.4093, 66.8360], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0999, 0.7031, 0.2578, 1.6735], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.6538, 13.6604, 17.4093, 66.8360], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.6235e-02, 1.1921e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5101.1113, 5410.2144, 5230.9209, 7145.4282])\n",
            "l2norm ;  tensor([[1.4465],\n",
            "        [1.1825],\n",
            "        [2.6281],\n",
            "        [1.4278]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  158\n",
            "ce:  tensor([ 3.6196, 13.6630, 17.5099, 66.7717], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0929, 0.7048, 0.2756, 1.6654], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.6196, 13.6630, 17.5099, 66.7717], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.7159e-02, 1.1921e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5956.5693, 3688.0361, 4590.9253, 6189.5356])\n",
            "l2norm ;  tensor([[1.4152],\n",
            "        [0.6688],\n",
            "        [2.1270],\n",
            "        [0.8350]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  159\n",
            "ce:  tensor([ 3.7811, 13.7803, 17.7162, 66.6103], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1063, 0.6470, 0.2547, 1.6620], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.7811, 13.7803, 17.7162, 66.6103], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3062e-02, 1.0729e-06, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4433.6714, 5842.1538, 5934.0508, 7145.4282])\n",
            "l2norm ;  tensor([[0.8205],\n",
            "        [2.7275],\n",
            "        [1.2921],\n",
            "        [1.0128]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  160\n",
            "ce:  tensor([ 3.6442, 13.8613, 17.7335, 66.6604], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0960, 0.7113, 0.2598, 1.6471], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.6442, 13.8613, 17.7335, 66.6604], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.6490e-02, 9.5367e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3930.5544, 4871.8008, 3737.5947, 6189.5356])\n",
            "l2norm ;  tensor([[0.2280],\n",
            "        [1.9845],\n",
            "        [0.8625],\n",
            "        [1.2127]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  161\n",
            "ce:  tensor([ 3.6871, 13.9583, 17.7353, 66.4854], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0920, 0.6631, 0.2554, 1.6383], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.6871, 13.9583, 17.7353, 66.4854], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.5364e-02, 8.3446e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5643.2109, 5410.2158, 5239.0508, 7145.4282])\n",
            "l2norm ;  tensor([[1.5356],\n",
            "        [1.2520],\n",
            "        [1.3130],\n",
            "        [1.2844]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  162\n",
            "ce:  tensor([ 3.8096, 14.0095, 17.9253, 66.4962], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1042, 0.6699, 0.2670, 1.6390], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.8096, 14.0095, 17.9253, 66.4962], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.2406e-02, 8.3446e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4436.5830, 3763.2153, 4337.2065, 6189.5356])\n",
            "l2norm ;  tensor([[0.6740],\n",
            "        [0.6790],\n",
            "        [2.2037],\n",
            "        [0.7877]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  163\n",
            "ce:  tensor([ 3.6956, 14.0379, 17.7863, 66.3386], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0912, 0.6169, 0.2391, 1.6373], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.6956, 14.0379, 17.7863, 66.3386], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.5146e-02, 8.3446e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3987.1152, 5916.2939, 5372.2500, 6189.5356])\n",
            "l2norm ;  tensor([[0.2110],\n",
            "        [2.9883],\n",
            "        [1.9004],\n",
            "        [0.7622]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  164\n",
            "ce:  tensor([ 3.7571, 14.1728, 18.0261, 66.3841], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0882, 0.6569, 0.2439, 1.6343], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.7571, 14.1728, 18.0261, 66.3841], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3628e-02, 7.1526e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5328.3530, 4308.2847, 3709.6372, 7145.4282])\n",
            "l2norm ;  tensor([[1.1157],\n",
            "        [0.9117],\n",
            "        [1.0962],\n",
            "        [1.3944]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  165\n",
            "ce:  tensor([ 3.9125, 14.0777, 17.8731, 66.2732], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0974, 0.5826, 0.2333, 1.6275], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.9125, 14.0777, 17.8731, 66.2732], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.0192e-02, 7.1526e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5181.6870, 3763.2158, 5030.8633, 6189.5356])\n",
            "l2norm ;  tensor([[1.6443],\n",
            "        [0.4694],\n",
            "        [1.3796],\n",
            "        [0.7518]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  166\n",
            "ce:  tensor([ 3.8703, 14.1780, 18.2362, 66.1949], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0884, 0.5547, 0.2449, 1.6254], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.8703, 14.1780, 18.2362, 66.1949], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.1072e-02, 7.1526e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6263.4863, 5216.8608, 5706.0205, 7145.4282])\n",
            "l2norm ;  tensor([[1.6705],\n",
            "        [1.9180],\n",
            "        [3.0677],\n",
            "        [0.9305]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  167\n",
            "ce:  tensor([ 4.0007, 14.1895, 18.0761, 66.2106], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1037, 0.5761, 0.2121, 1.6097], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.0007, 14.1895, 18.0761, 66.2106], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.8471e-02, 7.1526e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4504.7231, 3763.2158, 5058.4233, 6189.5356])\n",
            "l2norm ;  tensor([[0.8054],\n",
            "        [1.5320],\n",
            "        [1.1653],\n",
            "        [0.7545]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  168\n",
            "ce:  tensor([ 3.8970, 14.0317, 18.2741, 66.1141], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0943, 0.5131, 0.2130, 1.6079], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 3.8970, 14.0317, 18.2741, 66.1141], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.0511e-02, 8.3446e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5505.8882, 5236.6367, 3626.6226, 7145.4282])\n",
            "l2norm ;  tensor([[0.8918],\n",
            "        [1.3399],\n",
            "        [0.8982],\n",
            "        [1.2632]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  169\n",
            "ce:  tensor([ 4.0255, 14.3012, 18.2071, 66.1549], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1054, 0.5513, 0.1938, 1.6094], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.0255, 14.3012, 18.2071, 66.1549], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.8015e-02, 5.9605e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5092.4233, 4482.5259, 5191.7422, 6189.5356])\n",
            "l2norm ;  tensor([[1.4263],\n",
            "        [2.1308],\n",
            "        [2.4712],\n",
            "        [0.7225]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  170\n",
            "ce:  tensor([ 4.0057, 14.4497, 18.4737, 66.0104], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0970, 0.5206, 0.2093, 1.6115], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.0057, 14.4497, 18.4737, 66.0104], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.8379e-02, 4.7684e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5802.4678, 6266.9253, 4135.8403, 6189.5356])\n",
            "l2norm ;  tensor([[1.5262],\n",
            "        [2.4080],\n",
            "        [0.9841],\n",
            "        [0.6528]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  171\n",
            "ce:  tensor([ 4.1756, 14.5834, 18.3301, 66.0615], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1114, 0.5529, 0.1862, 1.6051], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.1756, 14.5834, 18.3301, 66.0615], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5485e-02, 4.7684e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4501.5684, 3909.5420, 3175.1802, 5577.3354])\n",
            "l2norm ;  tensor([[0.7208],\n",
            "        [1.6289],\n",
            "        [0.4725],\n",
            "        [2.0999]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  172\n",
            "ce:  tensor([ 4.0526, 14.3989, 18.4079, 66.2338], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0996, 0.4820, 0.1822, 1.5833], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.0526, 14.3989, 18.4079, 66.2338], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7530e-02, 5.9605e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4137.6914, 4584.0386, 5551.5020, 6189.5356])\n",
            "l2norm ;  tensor([[0.2288],\n",
            "        [1.2483],\n",
            "        [1.3259],\n",
            "        [1.1974]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  173\n",
            "ce:  tensor([ 4.0367, 14.5619, 18.4635, 66.1094], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0994, 0.5339, 0.1864, 1.5769], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.0367, 14.5619, 18.4635, 66.1094], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7813e-02, 4.7684e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5611.8447, 5126.2212, 4135.8403, 7145.4282])\n",
            "l2norm ;  tensor([[1.1483],\n",
            "        [2.2669],\n",
            "        [0.9359],\n",
            "        [1.2558]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  174\n",
            "ce:  tensor([ 4.1919, 14.6784, 18.5084, 66.0884], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1108, 0.4855, 0.1644, 1.5790], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.1919, 14.6784, 18.5084, 66.0884], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5233e-02, 4.7684e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5125.1772, 5693.3145, 5319.4253, 6189.5356])\n",
            "l2norm ;  tensor([[1.5413],\n",
            "        [1.5939],\n",
            "        [2.5569],\n",
            "        [0.7129]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  175\n",
            "ce:  tensor([ 4.1669, 14.7688, 18.7203, 66.1002], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1014, 0.4959, 0.1785, 1.5818], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.1669, 14.7688, 18.7203, 66.1002], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5622e-02, 3.5763e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6215.2437, 3763.2170, 5307.7373, 5577.3354])\n",
            "l2norm ;  tensor([[1.7105],\n",
            "        [0.6976],\n",
            "        [2.9305],\n",
            "        [2.0621]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  176\n",
            "ce:  tensor([ 4.3274, 14.7317, 18.7532, 66.2958], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1186, 0.4569, 0.1561, 1.5595], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.3274, 14.7317, 18.7532, 66.2958], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.3290e-02, 3.5763e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4445.8008, 5281.0933, 4871.2021, 6189.5356])\n",
            "l2norm ;  tensor([[0.7134],\n",
            "        [2.3786],\n",
            "        [1.3149],\n",
            "        [0.9035]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  177\n",
            "ce:  tensor([ 4.2179, 14.9816, 18.8735, 66.1151], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1104, 0.5082, 0.1660, 1.5559], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.2179, 14.9816, 18.8735, 66.1151], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.4839e-02, 3.5763e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4215.3452, 3909.5427, 4283.2598, 6189.5356])\n",
            "l2norm ;  tensor([[0.2321],\n",
            "        [1.5867],\n",
            "        [1.3364],\n",
            "        [0.6290]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  178\n",
            "ce:  tensor([ 4.2036, 14.6817, 18.7672, 66.2653], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1098, 0.4414, 0.1476, 1.5593], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.2036, 14.6817, 18.7672, 66.2653], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5055e-02, 4.7684e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5510.3296, 4838.4307, 5058.4233, 5577.3354])\n",
            "l2norm ;  tensor([[1.1504],\n",
            "        [1.4557],\n",
            "        [1.0786],\n",
            "        [2.1147]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  179\n",
            "ce:  tensor([ 4.3288, 14.9113, 18.9426, 66.3423], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1217, 0.4376, 0.1470, 1.5386], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.3288, 14.9113, 18.9426, 66.3423], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.3271e-02, 3.5763e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5068.4805, 3763.2170, 4135.8403, 6189.5356])\n",
            "l2norm ;  tensor([[1.5197],\n",
            "        [0.6989],\n",
            "        [1.6924],\n",
            "        [0.7001]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  180\n",
            "ce:  tensor([ 4.3229, 14.7891, 18.8966, 66.2489], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1106, 0.3994, 0.1266, 1.5407], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.3229, 14.7891, 18.8966, 66.2489], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.3350e-02, 3.5763e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5826.4766, 3783.7092, 5714.2764, 4611.9790])\n",
            "l2norm ;  tensor([[2.0304],\n",
            "        [0.5203],\n",
            "        [2.3922],\n",
            "        [1.1022]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  181\n",
            "ce:  tensor([ 4.4729, 14.7999, 19.0435, 66.3885], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1288, 0.3883, 0.1373, 1.5308], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.4729, 14.7999, 19.0435, 66.3885], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1479e-02, 3.5763e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4711.7075, 5154.8125, 5103.9258, 6189.5356])\n",
            "l2norm ;  tensor([[0.7231],\n",
            "        [1.2044],\n",
            "        [2.2790],\n",
            "        [0.8509]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  182\n",
            "ce:  tensor([ 4.3785, 15.1354, 19.1438, 66.2650], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1154, 0.4255, 0.1237, 1.5304], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.3785, 15.1354, 19.1438, 66.2650], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.2624e-02, 2.3842e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4092.5342, 4728.5112, 4871.2021, 5577.3354])\n",
            "l2norm ;  tensor([[0.2895],\n",
            "        [2.1144],\n",
            "        [1.2719],\n",
            "        [1.7165]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  183\n",
            "ce:  tensor([ 4.3277, 15.1174, 19.3289, 66.6251], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1176, 0.4031, 0.1322, 1.5224], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.3277, 15.1174, 19.3289, 66.6251], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.3286e-02, 2.3842e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4211.1523, 6212.4590, 4283.2598, 6189.5356])\n",
            "l2norm ;  tensor([[0.2767],\n",
            "        [2.0775],\n",
            "        [1.1380],\n",
            "        [1.3651]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  184\n",
            "ce:  tensor([ 4.3114, 15.3796, 19.2208, 66.3521], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1201, 0.4366, 0.1176, 1.5195], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.3114, 15.3796, 19.2208, 66.3521], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.3505e-02, 2.3842e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4261.9531, 4308.2876, 4782.4473, 6189.5356])\n",
            "l2norm ;  tensor([[0.4299],\n",
            "        [0.9180],\n",
            "        [1.4062],\n",
            "        [0.5723]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  185\n",
            "ce:  tensor([ 4.4597, 15.2479, 19.4562, 66.4273], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1144, 0.3904, 0.1249, 1.5170], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.4597, 15.2479, 19.4562, 66.4273], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1633e-02, 2.3842e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5771.3896, 3909.5430, 4135.8403, 5577.3354])\n",
            "l2norm ;  tensor([[2.0406],\n",
            "        [0.4757],\n",
            "        [1.0028],\n",
            "        [2.1294]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  186\n",
            "ce:  tensor([ 4.4828, 15.4403, 19.3449, 66.5944], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1308, 0.3671, 0.1117, 1.4975], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.4828, 15.4403, 19.3449, 66.5944], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1366e-02, 2.3842e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5525.3579, 4711.0259, 3800.1411, 6189.5356])\n",
            "l2norm ;  tensor([[1.5184],\n",
            "        [2.0457],\n",
            "        [0.5399],\n",
            "        [0.6286]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  187\n",
            "ce:  tensor([ 4.5196, 15.4313, 19.6240, 66.4687], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1206, 0.3934, 0.1057, 1.5036], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.5196, 15.4313, 19.6240, 66.4687], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0953e-02, 2.3842e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5712.1074, 3763.2183, 5230.9209, 6189.5356])\n",
            "l2norm ;  tensor([[1.3325],\n",
            "        [1.5641],\n",
            "        [2.5846],\n",
            "        [0.5553]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  188\n",
            "ce:  tensor([ 4.5741, 15.3119, 19.6291, 66.6205], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1335, 0.3424, 0.1154, 1.5108], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.5741, 15.3119, 19.6291, 66.6205], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0369e-02, 2.3842e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4716.9434, 4838.4326, 4885.9771, 5577.3354])\n",
            "l2norm ;  tensor([[0.7765],\n",
            "        [1.2160],\n",
            "        [2.5985],\n",
            "        [2.1757]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  189\n",
            "ce:  tensor([ 4.4995, 15.4291, 19.6290, 66.7149], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1215, 0.3735, 0.1019, 1.4917], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.4995, 15.4291, 19.6290, 66.7149], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1177e-02, 2.3842e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5994.4580, 5051.6948, 5230.9209, 6189.5356])\n",
            "l2norm ;  tensor([[1.6895],\n",
            "        [2.2156],\n",
            "        [2.3719],\n",
            "        [0.8095]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  190\n",
            "ce:  tensor([ 4.6240, 15.6806, 19.7246, 66.6328], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1377, 0.3404, 0.1104, 1.4914], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.6240, 15.6806, 19.7246, 66.6328], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.8617e-03, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5533.6782, 6169.4463, 5103.9258, 4611.9790])\n",
            "l2norm ;  tensor([[1.6806],\n",
            "        [2.8431],\n",
            "        [2.3278],\n",
            "        [1.1197]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  191\n",
            "ce:  tensor([ 4.6522, 15.7574, 19.9724, 66.7451], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1252, 0.3654, 0.1002, 1.4819], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.6522, 15.7574, 19.9724, 66.7451], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.5865e-03, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5926.4697, 3909.5435, 5204.6274, 6189.5356])\n",
            "l2norm ;  tensor([[1.3198],\n",
            "        [1.6225],\n",
            "        [1.3186],\n",
            "        [0.7932]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  192\n",
            "ce:  tensor([ 4.7288, 15.5699, 19.9548, 66.6107], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1395, 0.3162, 0.1067, 1.4831], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.7288, 15.5699, 19.9548, 66.6107], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.8767e-03, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4723.9854, 4584.0405, 3737.5947, 4611.9790])\n",
            "l2norm ;  tensor([[0.6826],\n",
            "        [0.9331],\n",
            "        [1.9345],\n",
            "        [1.1980]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  193\n",
            "ce:  tensor([ 4.6369, 15.7308, 19.9217, 66.7785], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1272, 0.3378, 0.0958, 1.4641], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.6369, 15.7308, 19.9217, 66.7785], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.7350e-03, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4802.7271, 4161.3428, 5714.2764, 6189.5356])\n",
            "l2norm ;  tensor([[1.1402],\n",
            "        [0.9198],\n",
            "        [1.9311],\n",
            "        [0.7831]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  194\n",
            "ce:  tensor([ 4.7167, 15.7972, 20.0213, 66.6461], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1371, 0.3014, 0.0994, 1.4649], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.7167, 15.7972, 20.0213, 66.6461], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.9851e-03, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4723.4736, 5695.9106, 4134.9316, 7145.4282])\n",
            "l2norm ;  tensor([[0.6285],\n",
            "        [2.6468],\n",
            "        [1.2204],\n",
            "        [1.2986]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  195\n",
            "ce:  tensor([ 4.7369, 15.9519, 20.0201, 66.8199], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1219, 0.3359, 0.0939, 1.4697], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.7369, 15.9519, 20.0201, 66.8199], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.8042e-03, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5781.2705, 4871.8052, 5058.4233, 4611.9790])\n",
            "l2norm ;  tensor([[1.3346],\n",
            "        [1.7551],\n",
            "        [1.1341],\n",
            "        [1.3838]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  196\n",
            "ce:  tensor([ 4.7381, 16.0598, 20.1082, 66.8468], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1343, 0.3265, 0.0958, 1.4596], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.7381, 16.0598, 20.1082, 66.8468], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.7934e-03, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4574.3281, 4162.3296, 5103.9258, 6189.5356])\n",
            "l2norm ;  tensor([[0.7478],\n",
            "        [0.7458],\n",
            "        [2.3792],\n",
            "        [0.7675]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  197\n",
            "ce:  tensor([ 4.6981, 16.0843, 20.3399, 66.7407], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1219, 0.2996, 0.0871, 1.4605], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.6981, 16.0843, 20.3399, 66.7407], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.1546e-03, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5608.3936, 5105.1162, 5204.6274, 4611.9790])\n",
            "l2norm ;  tensor([[0.9628],\n",
            "        [1.9577],\n",
            "        [1.1124],\n",
            "        [1.2189]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  198\n",
            "ce:  tensor([ 4.7876, 16.1394, 20.3153, 66.8900], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1347, 0.3227, 0.0907, 1.4416], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.7876, 16.1394, 20.3153, 66.8900], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.3676e-03, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5206.8120, 3763.2188, 4337.2065, 6189.5356])\n",
            "l2norm ;  tensor([[1.6035],\n",
            "        [1.5394],\n",
            "        [1.3946],\n",
            "        [0.7094]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  199\n",
            "ce:  tensor([ 4.8473, 15.9692, 20.6250, 66.7481], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1254, 0.2808, 0.0880, 1.4425], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 4.8473, 15.9692, 20.6250, 66.7481], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.8802e-03, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6336.5205, 5236.6406, 5004.9590, 6189.5356])\n",
            "l2norm ;  tensor([[2.1075],\n",
            "        [1.1763],\n",
            "        [2.5184],\n",
            "        [0.4196]], dtype=torch.float64)\n",
            "PGD l2: Attack effectiveness 50.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([6.6363e+00, 2.6988e+00, 9.1906e-05, -0.0000e+00])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 10., insertion_array, removal_array, k=200, step_length=0.05, norm='l2', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c04e03-f3ca-4f5d-b9cb-5806e47b4272",
        "id": "cccUv9ac79dw"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "t :  0\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 86.8272, 160.0354, 131.3113, 225.5053], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12908.3301, 12200.0391, 12128.9160,  9213.8662])\n",
            "l2norm ;  tensor([[39.2907],\n",
            "        [35.4687],\n",
            "        [31.5366],\n",
            "        [ 9.6098]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  1\n",
            "ce:  tensor([ 41.5093,  86.7509,  58.7423, 185.1393], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.7467, 6.6161, 6.6243, 3.8441], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 78.9762, 152.9120, 124.9852, 223.5802], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12724.6670, 12209.9180, 12067.6064,  9216.2930])\n",
            "l2norm ;  tensor([[39.2006],\n",
            "        [35.7620],\n",
            "        [31.7978],\n",
            "        [ 9.6420]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  2\n",
            "ce:  tensor([ 41.9617,  86.8621,  59.3078, 183.4346], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.9262, 5.8871, 5.9303, 3.8214], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 71.2233, 145.7330, 118.6106, 221.6486], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12633.4805, 12217.3936, 12070.8076,  9218.7129])\n",
            "l2norm ;  tensor([[38.1602],\n",
            "        [36.0198],\n",
            "        [31.9416],\n",
            "        [ 9.6743]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  3\n",
            "ce:  tensor([ 42.3730,  86.9234,  59.8568, 181.7314], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1439, 5.1546, 5.2346, 3.7979], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 63.8119, 138.4695, 112.2031, 219.7104], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12449.4111, 12124.3379, 12074.0918,  9221.1260])\n",
            "l2norm ;  tensor([[35.6588],\n",
            "        [36.4404],\n",
            "        [32.0747],\n",
            "        [ 9.7069]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  4\n",
            "ce:  tensor([ 42.6872,  86.9959,  60.3894, 180.0296], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4430, 4.4200, 4.5391, 3.7736], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 57.1172, 131.1955, 105.7805, 217.7658], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12068.4990, 12268.9805, 12013.9863,  9223.5381])\n",
            "l2norm ;  tensor([[30.8807],\n",
            "        [36.4064],\n",
            "        [32.1349],\n",
            "        [ 9.7395]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  5\n",
            "ce:  tensor([ 42.8146,  87.0302,  60.9032, 178.3291], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.8820, 3.6894, 3.8467, 3.7486], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 51.6347, 123.9243,  99.3703, 215.8146], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12466.9053, 12231.2715, 11991.0664,  9225.9404])\n",
            "l2norm ;  tensor([[23.8971],\n",
            "        [36.2603],\n",
            "        [31.9239],\n",
            "        [ 9.7723]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  6\n",
            "ce:  tensor([ 42.5004,  87.0090,  61.4009, 176.6299], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.5064, 2.9702, 3.1635, 3.7227], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 47.5644, 116.7109,  93.0363, 213.8569], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([11905.3213, 11997.0977, 11948.9434,  9228.3369])\n",
            "l2norm ;  tensor([[17.3083],\n",
            "        [35.7058],\n",
            "        [31.3332],\n",
            "        [ 9.8052]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  7\n",
            "ce:  tensor([ 41.6512,  86.9574,  61.8743, 174.9320], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2965, 2.2767, 2.5008, 3.6961], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 44.6164, 109.7244,  86.8828, 211.8925], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10457.7051, 11918.6133, 11843.2725,  9230.7217])\n",
            "l2norm ;  tensor([[13.1878],\n",
            "        [33.9948],\n",
            "        [30.0713],\n",
            "        [ 9.8382]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  8\n",
            "ce:  tensor([ 40.4396,  86.8197,  62.2982, 173.2354], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1871, 1.6387, 1.8783, 3.6686], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 42.3104, 103.2063,  81.0816, 209.9216], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 9811.2891, 11587.9102, 11655.9414,  9233.0996])\n",
            "l2norm ;  tensor([[10.5912],\n",
            "        [30.9154],\n",
            "        [27.7296],\n",
            "        [ 9.8712]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  9\n",
            "ce:  tensor([ 39.0149,  86.5072,  62.6339, 171.5402], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1282, 1.0952, 1.3255, 3.6404], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 40.2973,  97.4595,  75.8893, 207.9441], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 9689.4795, 10984.0850, 11357.1387,  9235.4727])\n",
            "l2norm ;  tensor([[ 9.7102],\n",
            "        [26.4068],\n",
            "        [23.9738],\n",
            "        [ 9.9042]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  10\n",
            "ce:  tensor([ 37.4459,  85.9351,  62.8258, 169.8462], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0958, 0.6833, 0.8765, 3.6114], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 38.4041,  92.7685,  71.5912, 205.9599], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 9578.4902, 10634.6406, 10598.9297,  9237.8311])\n",
            "l2norm ;  tensor([[ 9.1994],\n",
            "        [20.7155],\n",
            "        [18.9376],\n",
            "        [ 9.9372]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  11\n",
            "ce:  tensor([ 35.8344,  84.9661,  62.9200, 168.1558], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0754, 0.4154, 0.5459, 3.5816], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 36.5881,  89.1200,  68.3793, 203.9715], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 9537.4404, 10225.9131, 10689.9609,  9236.1641])\n",
            "l2norm ;  tensor([[ 8.9865],\n",
            "        [16.2309],\n",
            "        [14.1367],\n",
            "        [ 9.9560]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  12\n",
            "ce:  tensor([ 34.1925,  83.5601,  62.5625, 166.5468], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0613, 0.2631, 0.3454, 3.5510], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 34.8054,  86.1909,  66.0170, 202.0564], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9424.5156, 8893.3594, 9944.7861, 8685.3115])\n",
            "l2norm ;  tensor([[ 8.8592],\n",
            "        [13.3020],\n",
            "        [10.3896],\n",
            "        [ 9.5567]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  13\n",
            "ce:  tensor([ 32.5328,  81.9744,  61.9314, 164.9623], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0510, 0.1736, 0.2240, 3.5179], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 33.0429,  83.7105,  64.1709, 200.1415], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9403.6914, 9801.7568, 9743.3291, 8687.7588])\n",
            "l2norm ;  tensor([[ 8.7735],\n",
            "        [12.3593],\n",
            "        [ 8.3903],\n",
            "        [ 9.5925]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  14\n",
            "ce:  tensor([ 30.8508,  80.2289,  61.0361, 163.3792], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0432, 0.1277, 0.1566, 3.4840], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 31.2830,  81.5054,  62.6024, 198.2194], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9452.9160, 8649.6455, 9623.7871, 8690.1895])\n",
            "l2norm ;  tensor([[ 8.8111],\n",
            "        [11.2458],\n",
            "        [ 7.4523],\n",
            "        [ 9.6283]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  15\n",
            "ce:  tensor([ 29.1647,  78.3378,  59.9850, 161.7972], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0372, 0.0961, 0.1179, 3.4493], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 29.5365,  79.2987,  61.1637, 196.2902], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9165.8213, 8590.1230, 9557.3535, 8692.6025])\n",
            "l2norm ;  tensor([[ 8.5837],\n",
            "        [10.8689],\n",
            "        [ 7.0012],\n",
            "        [ 9.6639]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  16\n",
            "ce:  tensor([ 27.4975,  76.3962,  58.8475, 160.2166], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0324, 0.0753, 0.0933, 3.4137], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 27.8212,  77.1491,  59.7807, 194.3539], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9118.7617, 8550.4971, 9474.7070, 8695.0039])\n",
            "l2norm ;  tensor([[ 8.5175],\n",
            "        [10.6503],\n",
            "        [ 6.8363],\n",
            "        [ 7.5421]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  17\n",
            "ce:  tensor([ 25.8466,  74.4265,  57.6647, 159.0388], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0284, 0.0608, 0.0764, 3.3803], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.1303,  75.0341,  58.4292, 192.8415], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9100.9102, 8522.5986, 9429.9697, 8697.9150])\n",
            "l2norm ;  tensor([[ 8.4192],\n",
            "        [10.5130],\n",
            "        [ 6.6986],\n",
            "        [ 7.5818]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  18\n",
            "ce:  tensor([ 24.1985,  72.4473,  56.4585, 157.8630], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0252, 0.0501, 0.0641, 3.3458], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.4500,  72.9485,  57.0999, 191.3211], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9108.4902, 8670.3906, 9409.1689, 8700.8135])\n",
            "l2norm ;  tensor([[ 8.3636],\n",
            "        [10.3895],\n",
            "        [ 6.6024],\n",
            "        [ 7.6218]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  19\n",
            "ce:  tensor([ 22.5541,  70.4583,  55.2398, 156.7153], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0225, 0.0419, 0.0547, 3.3103], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.7788,  70.8777,  55.7867, 189.8188], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9103.0459, 8654.8340, 9393.2207, 8564.0879])\n",
            "l2norm ;  tensor([[ 8.3486],\n",
            "        [10.3233],\n",
            "        [ 6.5343],\n",
            "        [ 7.5202]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  20\n",
            "ce:  tensor([ 20.9064,  68.4626,  54.0129, 155.5770], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0202, 0.0356, 0.0472, 3.2734], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.1082,  68.8182,  54.4851, 188.3107], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9171.2148, 8642.6270, 9380.0146, 8566.9883])\n",
            "l2norm ;  tensor([[ 8.3761],\n",
            "        [10.2748],\n",
            "        [ 6.4844],\n",
            "        [ 7.5610]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  21\n",
            "ce:  tensor([ 19.2516,  66.4624,  52.7756, 154.4405], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0182, 0.0305, 0.0412, 3.2354], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.4340,  66.7671,  53.1872, 186.7944], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9167.2451, 8632.8789, 9295.3828, 8569.8682])\n",
            "l2norm ;  tensor([[ 3.2497],\n",
            "        [10.2382],\n",
            "        [ 6.5225],\n",
            "        [ 7.6017]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  22\n",
            "ce:  tensor([ 18.6279,  64.4553,  51.5166, 153.3059], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0160, 0.0263, 0.0362, 3.1964], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.7884,  64.7187,  51.8784, 185.2700], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9098.6406, 8570.2578, 9213.5879, 8572.7285])\n",
            "l2norm ;  tensor([[ 3.1946],\n",
            "        [10.2405],\n",
            "        [ 6.5465],\n",
            "        [ 7.6424]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  23\n",
            "ce:  tensor([ 18.0080,  62.4431,  50.2795, 152.1733], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0143, 0.0230, 0.0320, 3.1564], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.1506,  62.6728,  50.5993, 183.7375], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9094.9453, 8563.7930, 9209.9102, 8575.5586])\n",
            "l2norm ;  tensor([[ 3.1840],\n",
            "        [10.2186],\n",
            "        [ 6.3199],\n",
            "        [ 7.6831]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  24\n",
            "ce:  tensor([ 17.3844,  60.4279,  49.0539, 151.0426], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0128, 0.0202, 0.0284, 3.1154], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.5122,  60.6294,  49.3375, 182.1968], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9020.3838, 8551.9600, 9203.5898, 8578.3555])\n",
            "l2norm ;  tensor([[ 3.1988],\n",
            "        [10.2217],\n",
            "        [ 6.2990],\n",
            "        [ 7.7236]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  25\n",
            "ce:  tensor([ 16.7582,  58.4087,  47.8276, 149.9126], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0115, 0.0178, 0.0253, 3.0734], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.8732,  58.5866,  48.0805, 180.6469], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9017.6963, 8547.3730, 9203.0547, 8584.2402])\n",
            "l2norm ;  tensor([[ 3.1918],\n",
            "        [10.2073],\n",
            "        [ 6.2580],\n",
            "        [ 7.7773]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  26\n",
            "ce:  tensor([ 16.1313,  56.3853,  46.6040, 148.7828], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0104, 0.0158, 0.0226, 3.0305], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.2354,  56.5430,  46.8304, 179.0876], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9015.4355, 8511.8857, 9198.4473, 8584.3076])\n",
            "l2norm ;  tensor([[ 3.1862],\n",
            "        [10.2373],\n",
            "        [ 6.2435],\n",
            "        [ 7.8045]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  27\n",
            "ce:  tensor([ 15.5016,  54.3868,  45.3917, 147.6573], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0095, 0.0140, 0.0203, 2.9865], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 15.5966,  54.5270,  45.5951, 177.5227], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8987.9199, 8489.8242, 9193.2764, 8586.9756])\n",
            "l2norm ;  tensor([[ 3.1922],\n",
            "        [10.0486],\n",
            "        [ 6.1037],\n",
            "        [ 7.8444]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  28\n",
            "ce:  tensor([ 14.8721,  52.3830,  44.1922, 146.5334], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0086, 0.0125, 0.0183, 2.9416], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 14.9586,  52.5083,  44.3754, 175.9499], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.5763e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8986.1523, 8413.4590, 9189.7617, 8589.6172])\n",
            "l2norm ;  tensor([[ 2.1996],\n",
            "        [10.1075],\n",
            "        [ 6.0931],\n",
            "        [ 7.8838]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  29\n",
            "ce:  tensor([ 14.4259,  50.3753,  42.9864, 145.4113], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0082, 0.0112, 0.0165, 2.8958], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 14.5075,  50.4876,  43.1518, 174.3692], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.9605e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8806.7119, 8410.9082, 9071.3496, 8592.1992])\n",
            "l2norm ;  tensor([[ 2.3875],\n",
            "        [10.1003],\n",
            "        [ 6.1758],\n",
            "        [ 7.9229]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  30\n",
            "ce:  tensor([ 13.9815,  48.3874,  41.7730, 144.2908], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0077, 0.0101, 0.0150, 2.8490], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 14.0588,  48.4883,  41.9228, 172.7808], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.3446e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9790.5791, 8412.0400, 9086.3408, 8594.7148])\n",
            "l2norm ;  tensor([[2.2491],\n",
            "        [9.9616],\n",
            "        [6.1335],\n",
            "        [7.9614]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  31\n",
            "ce:  tensor([ 13.6417,  46.4057,  40.5623, 143.1720], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0067, 0.0091, 0.0136, 2.8013], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 13.7083,  46.4966,  40.6984, 171.1847], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8790.8545, 8410.0771, 9077.9395, 8597.1572])\n",
            "l2norm ;  tensor([[2.3513],\n",
            "        [9.9562],\n",
            "        [6.1154],\n",
            "        [7.9994]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  32\n",
            "ce:  tensor([ 13.2267,  44.4238,  39.3545, 142.0548], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0064, 0.0082, 0.0124, 2.7526], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 13.2903,  44.5058,  39.4784, 169.5811], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7881e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9787.7471, 8408.3369, 9084.4834, 8599.5215])\n",
            "l2norm ;  tensor([[2.2385],\n",
            "        [9.9515],\n",
            "        [6.0867],\n",
            "        [7.5393]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  33\n",
            "ce:  tensor([ 12.8653,  42.4418,  38.1487, 141.0425], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0055, 0.0074, 0.0113, 2.7027], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 12.9205,  42.5159,  38.2616, 168.0694], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.6226e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8667.2686, 8406.7930, 9082.5303, 8601.8613])\n",
            "l2norm ;  tensor([[2.2822],\n",
            "        [9.2049],\n",
            "        [6.0814],\n",
            "        [7.5770]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  34\n",
            "ce:  tensor([ 12.6733,  40.6021,  36.9411, 140.0317], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0053, 0.0068, 0.0103, 2.6519], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 12.7264,  40.6699,  37.0442, 166.5503], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.0994e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9127.4258, 8383.5996, 9069.7080, 8604.1084])\n",
            "l2norm ;  tensor([[1.7641],\n",
            "        [9.2562],\n",
            "        [6.1154],\n",
            "        [7.6139]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  35\n",
            "ce:  tensor([ 12.4134,  38.9601,  35.7512, 139.0246], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0043, 0.0062, 0.0095, 2.6002], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 12.4561,  39.0221,  35.8459, 165.0264], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.0531e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8147.2959, 7915.8730, 8956.4570, 9157.7725])\n",
            "l2norm ;  tensor([[1.5959],\n",
            "        [6.5402],\n",
            "        [5.9785],\n",
            "        [7.8983]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  36\n",
            "ce:  tensor([ 12.1494,  37.6508,  34.5639, 138.0504], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0039, 0.0055, 0.0087, 2.5507], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 12.1884,  37.7059,  34.6506, 163.5572], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.2452e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9126.9072, 7798.7544, 8955.0156, 8608.2930])\n",
            "l2norm ;  tensor([[1.7578],\n",
            "        [6.6254],\n",
            "        [5.9747],\n",
            "        [7.6832]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  37\n",
            "ce:  tensor([ 11.9186,  36.3302,  33.3765, 137.0435], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0031, 0.0049, 0.0079, 2.4974], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 11.9501,  36.3792,  33.4560, 162.0171], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.6757e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8032.7720, 7774.2539, 8953.7178, 8610.2441])\n",
            "l2norm ;  tensor([[1.5065],\n",
            "        [6.6202],\n",
            "        [5.9713],\n",
            "        [7.7170]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  38\n",
            "ce:  tensor([ 11.6713,  35.0190,  32.1996, 136.0377], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0029, 0.0044, 0.0073, 2.4433], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 11.7004,  35.0628,  32.2726, 160.4704], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5830e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8321.5215, 7813.9355, 8400.5312, 8612.0605])\n",
            "l2norm ;  tensor([[1.3514],\n",
            "        [5.6938],\n",
            "        [5.3036],\n",
            "        [7.7496]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  39\n",
            "ce:  tensor([ 11.5313,  33.8867,  31.1466, 135.0329], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0024, 0.0039, 0.0065, 2.3884], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 11.5555,  33.9258,  31.2116, 158.9174], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.7751e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7362.0952, 7745.1631, 8277.4990, 8613.7432])\n",
            "l2norm ;  tensor([[1.2709],\n",
            "        [5.5583],\n",
            "        [5.3302],\n",
            "        [7.7807]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  40\n",
            "ce:  tensor([ 11.2990,  32.8150,  30.0883, 134.0289], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0024, 0.0035, 0.0058, 2.3329], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 11.3229,  32.8500,  30.1460, 157.3582], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.2398e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8313.3330, 8775.7930, 8276.1543, 8615.2695])\n",
            "l2norm ;  tensor([[1.3586],\n",
            "        [5.9487],\n",
            "        [4.6841],\n",
            "        [7.8103]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  41\n",
            "ce:  tensor([ 11.1664,  31.8222,  29.1566, 133.0256], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9921e-03, 3.0759e-03, 5.1035e-03, 2.2768e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 11.1863,  31.8530,  29.2076, 155.7934], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.4186e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7336.9062, 7740.6255, 8244.2402, 8616.6270])\n",
            "l2norm ;  tensor([[1.2869],\n",
            "        [5.5303],\n",
            "        [4.7114],\n",
            "        [7.8382]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  42\n",
            "ce:  tensor([ 10.9181,  30.7240,  28.2438, 132.0228], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9651e-03, 2.7586e-03, 4.5228e-03, 2.2200e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 10.9377,  30.7516,  28.2891, 154.2231], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.8120e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8295.6523, 7684.8691, 8049.7261, 8617.8018])\n",
            "l2norm ;  tensor([[1.3844],\n",
            "        [5.4698],\n",
            "        [4.2019],\n",
            "        [7.8643]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  43\n",
            "ce:  tensor([ 10.8028,  29.6330,  27.7202, 131.0302], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6490e-03, 2.4796e-03, 4.0169e-03, 2.1627e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 10.8193,  29.6578,  27.7603, 152.6576], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.0385e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7293.1079, 7684.2959, 6977.2896, 9170.1328])\n",
            "l2norm ;  tensor([[1.2625],\n",
            "        [5.4682],\n",
            "        [3.1750],\n",
            "        [7.9258]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  44\n",
            "ce:  tensor([ 10.5463,  28.5725,  27.0885, 130.0916], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6378e-03, 2.2328e-03, 3.7010e-03, 2.1101e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 10.5627,  28.5948,  27.1255, 151.1930], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.6345e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7129.8730, 8702.7100, 6976.7119, 8619.6602])\n",
            "l2norm ;  tensor([[1.2866],\n",
            "        [5.8335],\n",
            "        [2.8847],\n",
            "        [7.6105]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  45\n",
            "ce:  tensor([ 10.4644,  27.6748,  26.5146, 129.1298], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6409e-03, 1.9939e-03, 3.4080e-03, 2.0539e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 10.4808,  27.6948,  26.5487, 149.6689], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.8491e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8053.1128, 7019.0615, 6976.1748, 8620.3408])\n",
            "l2norm ;  tensor([[1.2749],\n",
            "        [5.0666],\n",
            "        [2.6088],\n",
            "        [7.6301]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  46\n",
            "ce:  tensor([ 10.2723,  26.6605,  25.9957, 128.1680], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3953e-03, 1.8860e-03, 3.1359e-03, 1.9973e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 10.2863,  26.6793,  26.0271, 148.1411], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.4570e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6916.7588, 7021.4453, 6975.6719, 8620.7979])\n",
            "l2norm ;  tensor([[1.0598],\n",
            "        [4.5479],\n",
            "        [2.3094],\n",
            "        [7.6474]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  47\n",
            "ce:  tensor([ 10.0990,  26.0592,  25.5389, 127.2086], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3831e-03, 1.8476e-03, 2.8799e-03, 1.9404e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 10.1128,  26.0777,  25.5677, 146.6128], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.1126e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7845.1172, 6453.0620, 6920.6035, 8614.5889])\n",
            "l2norm ;  tensor([[1.3345],\n",
            "        [2.6198],\n",
            "        [2.2102],\n",
            "        [7.6441]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  48\n",
            "ce:  tensor([  9.9750,  25.5455,  25.1027, 126.2503], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1751e-03, 1.7689e-03, 2.6551e-03, 1.8832e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  9.9868,  25.5632,  25.1293, 145.0827], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.6610e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6865.6724, 7098.9932, 6870.6411, 8614.5527])\n",
            "l2norm ;  tensor([[1.0857],\n",
            "        [2.7940],\n",
            "        [2.1404],\n",
            "        [7.6564]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  49\n",
            "ce:  tensor([  9.7583,  25.1353,  24.6768, 125.2912], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1298e-03, 1.6442e-03, 2.4538e-03, 1.8259e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  9.7696,  25.1518,  24.7013, 143.5504], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.7815e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6865.5044, 6273.3906, 6870.2666, 8614.2520])\n",
            "l2norm ;  tensor([[1.0855],\n",
            "        [2.1981],\n",
            "        [2.1395],\n",
            "        [7.6660]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  50\n",
            "ce:  tensor([  9.5421,  24.6970,  24.2471, 124.3311], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0883e-03, 1.5229e-03, 2.2724e-03, 1.7685e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  9.5530,  24.7122,  24.2698, 142.0165], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.1761e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6765.4600, 6273.1431, 6829.5884, 8613.6680])\n",
            "l2norm ;  tensor([[1.0725],\n",
            "        [2.1562],\n",
            "        [2.1712],\n",
            "        [7.6726]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  51\n",
            "ce:  tensor([  9.3942,  24.2671,  23.8146, 123.3656], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0469e-03, 1.3982e-03, 2.1043e-03, 1.7112e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  9.4047,  24.2810,  23.8357, 140.4774], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.3205e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7679.9736, 6272.8887, 6829.2739, 8558.8203])\n",
            "l2norm ;  tensor([[1.3697],\n",
            "        [2.1555],\n",
            "        [2.1704],\n",
            "        [7.7362]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  52\n",
            "ce:  tensor([  9.2697,  23.8371,  23.3900, 122.3974], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.7902e-04, 1.2863e-03, 1.9526e-03, 1.6533e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  9.2785,  23.8500,  23.4095, 138.9301], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.4290e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6764.8882, 6272.6597, 6729.9839, 8557.5645])\n",
            "l2norm ;  tensor([[0.9921],\n",
            "        [2.1550],\n",
            "        [2.0629],\n",
            "        [7.7362]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  53\n",
            "ce:  tensor([  9.0717,  23.4072,  22.9788, 121.4273], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.4126e-04, 1.1857e-03, 1.8151e-03, 1.5956e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  9.0801,  23.4190,  22.9970, 137.3831], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0001, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6764.6729, 6272.4521, 6744.9849, 8555.9727])\n",
            "l2norm ;  tensor([[0.9919],\n",
            "        [2.1545],\n",
            "        [2.0805],\n",
            "        [7.7328]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  54\n",
            "ce:  tensor([  8.8957,  23.0241,  22.5668, 120.4550], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.0648e-04, 1.0951e-03, 1.6906e-03, 1.5382e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  8.9038,  23.0350,  22.5837, 135.8372], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0001, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7679.0742, 5950.3354, 6690.7988, 8554.0332])\n",
            "l2norm ;  tensor([[1.3820],\n",
            "        [1.9472],\n",
            "        [2.0166],\n",
            "        [7.7259]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  55\n",
            "ce:  tensor([  8.8283,  22.6623,  22.1646, 119.4803], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.6616e-04, 1.0188e-03, 1.5778e-03, 1.4813e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  8.8350,  22.6724,  22.1804, 134.2930], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0001, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6764.1074, 6953.1460, 6690.5869, 8551.7373])\n",
            "l2norm ;  tensor([[1.0251],\n",
            "        [2.7494],\n",
            "        [2.0160],\n",
            "        [7.5653]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  56\n",
            "ce:  tensor([  8.6235,  22.4038,  21.8091, 118.5061], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.5043e-04, 9.1892e-04, 1.4753e-03, 1.4275e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  8.6300,  22.4130,  21.8239, 132.7810], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0002, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6763.8501, 5855.0620, 6270.2651, 8549.4727])\n",
            "l2norm ;  tensor([[0.9026],\n",
            "        [2.0547],\n",
            "        [1.8461],\n",
            "        [7.5548]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  57\n",
            "ce:  tensor([  8.4354,  21.9934,  21.4408, 117.5292], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.8372e-04, 8.6806e-04, 1.3894e-03, 1.3742e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  8.4413,  22.0021,  21.4547, 131.2713], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0002, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6735.0850, 5854.9585, 6270.1055, 8546.8584])\n",
            "l2norm ;  tensor([[0.9507],\n",
            "        [2.0181],\n",
            "        [1.8457],\n",
            "        [7.3913]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  58\n",
            "ce:  tensor([  8.2459,  21.5904,  21.0815, 116.5858], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.2391e-04, 8.1292e-04, 1.3109e-03, 1.3209e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  8.2512,  21.5985,  21.0947, 129.7948], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0003, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6734.6592, 5854.8467, 6224.2725, 8543.7930])\n",
            "l2norm ;  tensor([[0.9503],\n",
            "        [2.0179],\n",
            "        [1.7941],\n",
            "        [7.3731]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  59\n",
            "ce:  tensor([  8.0700,  21.2010,  20.7462, 115.6392], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7124e-04, 7.6277e-04, 1.2358e-03, 1.2683e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  8.0747,  21.2087,  20.7586, 128.3223], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0003, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7626.0366, 5775.1245, 7216.9316, 8540.3691])\n",
            "l2norm ;  tensor([[1.4432],\n",
            "        [1.9209],\n",
            "        [2.6235],\n",
            "        [7.3514]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  60\n",
            "ce:  tensor([  7.9937,  20.8191,  20.5389, 114.6889], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.9117e-04, 7.1369e-04, 1.1135e-03, 1.2166e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.9976,  20.8262,  20.5500, 126.8545], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0003, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6662.0962, 5748.7021, 6223.9092, 8536.5898])\n",
            "l2norm ;  tensor([[1.0288],\n",
            "        [1.8938],\n",
            "        [1.7422],\n",
            "        [7.3263]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  61\n",
            "ce:  tensor([  7.7883,  20.4408,  20.1908, 113.7347], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5744e-04, 6.7021e-04, 1.0771e-03, 1.1657e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.7908,  20.4454,  20.1983, 121.8365], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0004, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6661.2969, 5748.1968, 6223.2495, 8440.2764])\n",
            "l2norm ;  tensor([[1.0281],\n",
            "        [1.8930],\n",
            "        [1.7416],\n",
            "        [6.4801]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  62\n",
            "ce:  tensor([  7.6066,  20.0627,  19.8427, 112.7011], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.2753e-04, 6.3149e-04, 1.0448e-03, 1.1281e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.6089,  20.0670,  19.8499, 120.4853], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0005, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6303.2163, 5714.8369, 6223.1968, 8437.0664])\n",
            "l2norm ;  tensor([[0.8659],\n",
            "        [1.8647],\n",
            "        [1.7415],\n",
            "        [6.4591]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  63\n",
            "ce:  tensor([  7.4344,  19.6900,  19.4989, 111.6650], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.9869e-04, 5.9599e-04, 1.0151e-03, 1.0913e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.4364,  19.6941,  19.5059, 119.1402], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0006, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6303.3457, 5714.7812, 6179.8242, 8433.7500])\n",
            "l2norm ;  tensor([[0.8576],\n",
            "        [1.8646],\n",
            "        [1.7088],\n",
            "        [6.4372]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  64\n",
            "ce:  tensor([  7.2660,  19.3173,  19.1631, 110.6265], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.7283e-04, 5.6346e-04, 9.8800e-04, 1.0551e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.2678,  19.3211,  19.1698, 117.8013], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0007, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5935.3755, 5714.7300, 5568.3276, 8430.3330])\n",
            "l2norm ;  tensor([[0.7952],\n",
            "        [1.7908],\n",
            "        [1.4672],\n",
            "        [6.0275]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  65\n",
            "ce:  tensor([  7.1819,  18.9593,  19.1527, 109.6660], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.4185e-04, 5.4607e-04, 9.4250e-04, 1.0193e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.1835,  18.9629,  19.1591, 116.5463], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0008, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6722.8516, 5714.7002, 3954.1926, 8426.7188])\n",
            "l2norm ;  tensor([[1.1896],\n",
            "        [1.7907],\n",
            "        [0.8317],\n",
            "        [6.0035]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  66\n",
            "ce:  tensor([  7.1349,  18.6421,  18.9872, 108.7026], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.0192e-04, 5.3010e-04, 8.2423e-04, 9.8439e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.1362,  18.6456,  18.9927, 115.2980], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0008, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5579.9780, 6270.0757, 3954.0427, 8423.0293])\n",
            "l2norm ;  tensor([[0.8918],\n",
            "        [2.3425],\n",
            "        [0.8312],\n",
            "        [5.9790]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  67\n",
            "ce:  tensor([  6.9650,  18.4964,  18.9927, 107.7364], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.0657e-04, 4.9555e-04, 7.2203e-04, 9.5037e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.9664,  18.4997,  18.9975, 114.0563], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0009, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5910.4487, 5313.0244, 5547.1421, 8419.2705])\n",
            "l2norm ;  tensor([[0.6913],\n",
            "        [1.7928],\n",
            "        [1.4873],\n",
            "        [5.6956]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  68\n",
            "ce:  tensor([  6.9044,  18.1530,  18.9488, 106.8257], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9096e-04, 4.6540e-04, 6.9141e-04, 9.1629e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.9057,  18.1560,  18.9533, 112.8732], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0010, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6254.6279, 3732.8997, 4940.7388, 8415.2998])\n",
            "l2norm ;  tensor([[0.9176],\n",
            "        [0.9504],\n",
            "        [2.1516],\n",
            "        [5.4430]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  69\n",
            "ce:  tensor([  6.8945,  18.1654,  19.0351, 105.9508], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7320e-04, 4.3657e-04, 6.1922e-04, 8.8424e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.8956,  18.1683,  19.0391, 111.7426], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0010, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5444.2227, 5312.9380, 5508.1582, 8395.1836])\n",
            "l2norm ;  tensor([[0.5337],\n",
            "        [1.8062],\n",
            "        [1.4566],\n",
            "        [5.3869]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  70\n",
            "ce:  tensor([  6.8009,  18.0381,  19.0635, 105.0793], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6593e-04, 4.2036e-04, 5.9361e-04, 8.5308e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.8020,  18.0408,  19.0673, 110.6243], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0011, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5813.6050, 3732.8311, 3927.5444, 8391.2842])\n",
            "l2norm ;  tensor([[0.5293],\n",
            "        [0.9502],\n",
            "        [0.8118],\n",
            "        [5.3613]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  71\n",
            "ce:  tensor([  6.8751,  17.8482,  18.9016, 104.2048], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6736e-04, 3.9498e-04, 5.2260e-04, 8.2294e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.8762,  17.8508,  18.9050, 109.5127], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0010, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4977.5361, 3732.7939, 3927.4570, 8387.3672])\n",
            "l2norm ;  tensor([[1.4524],\n",
            "        [0.8353],\n",
            "        [0.8115],\n",
            "        [5.2181]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  72\n",
            "ce:  tensor([  6.9768,  17.7878,  18.8632, 103.3719], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5138e-04, 3.6340e-04, 4.6076e-04, 7.9364e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.9778,  17.7901,  18.8662, 108.4512], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0009, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5444.6260, 6269.8281, 5507.9653, 8310.0410])\n",
            "l2norm ;  tensor([[0.6051],\n",
            "        [2.4823],\n",
            "        [1.4563],\n",
            "        [4.9535]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  73\n",
            "ce:  tensor([  6.9767,  17.8338,  18.8256, 102.5683], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5329e-04, 3.3266e-04, 4.4324e-04, 7.6471e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.9777,  17.8359,  18.8285, 107.4242], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0009, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4586.4409, 3732.7058, 3927.3564, 8306.0430])\n",
            "l2norm ;  tensor([[0.8115],\n",
            "        [0.8765],\n",
            "        [0.8111],\n",
            "        [4.9274]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  74\n",
            "ce:  tensor([  7.0588,  17.6586,  18.6757, 101.7615], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3565e-04, 3.1288e-04, 3.9165e-04, 7.3687e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.0596,  17.6606,  18.6781, 106.4038], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0009, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5821.9507, 3732.6777, 3675.0439, 8302.0615])\n",
            "l2norm ;  tensor([[1.5328],\n",
            "        [0.8175],\n",
            "        [0.7061],\n",
            "        [4.8324]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  75\n",
            "ce:  tensor([  7.0120,  17.5803,  18.9190, 100.9718], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5007e-04, 2.8356e-04, 3.5637e-04, 7.0912e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.0129,  17.5821,  18.9212, 105.4038], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0009, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5256.9824, 5312.7212, 5729.4712, 8298.0508])\n",
            "l2norm ;  tensor([[1.3023],\n",
            "        [1.7823],\n",
            "        [2.0817],\n",
            "        [4.8061]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  76\n",
            "ce:  tensor([  7.1860,  17.5770,  18.8470, 100.1792], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3219e-04, 2.7069e-04, 3.6090e-04, 6.8245e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.1869,  17.5786,  18.8493, 104.4104], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0008, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5445.5571, 3732.6179, 4074.8735, 8294.0811])\n",
            "l2norm ;  tensor([[0.8072],\n",
            "        [0.8763],\n",
            "        [0.9349],\n",
            "        [4.6658]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  77\n",
            "ce:  tensor([ 7.1973, 17.4018, 18.8521, 99.4104], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4769e-04, 2.5555e-04, 3.0084e-04, 6.5626e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.1982,  17.4034,  18.8540, 103.4464], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0007, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4587.2754, 3732.5967, 5251.5981, 8290.0557])\n",
            "l2norm ;  tensor([[0.8117],\n",
            "        [0.8173],\n",
            "        [1.2841],\n",
            "        [4.6395]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  78\n",
            "ce:  tensor([ 7.2068, 17.2385, 18.8459, 98.6389], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3076e-04, 2.3255e-04, 2.9059e-04, 6.3115e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.2076,  17.2399,  18.8476, 102.4889], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0007, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5822.6284, 3732.5654, 3674.9185, 8286.1123])\n",
            "l2norm ;  tensor([[1.1113],\n",
            "        [0.8172],\n",
            "        [0.7057],\n",
            "        [4.6138]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  79\n",
            "ce:  tensor([ 7.2519, 17.1690, 18.8364, 97.8649], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3053e-04, 2.1193e-04, 2.6556e-04, 6.0708e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.2527,  17.1703,  18.8380, 101.5377], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0007, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4361.1079, 6269.6157, 5729.3604, 8282.2578])\n",
            "l2norm ;  tensor([[0.7611],\n",
            "        [2.4560],\n",
            "        [2.0817],\n",
            "        [4.5887]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  80\n",
            "ce:  tensor([ 7.2955, 17.2343, 18.9960, 97.0887], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1265e-04, 1.9250e-04, 2.6997e-04, 5.8399e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  7.2961,  17.2354,  18.9976, 100.5927], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0007, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5742.7495, 3732.5115, 3674.8909, 8278.4609])\n",
            "l2norm ;  tensor([[1.5276],\n",
            "        [0.8011],\n",
            "        [0.8028],\n",
            "        [4.5643]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  81\n",
            "ce:  tensor([ 7.3443, 17.0742, 18.8356, 96.3104], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2516e-04, 1.7391e-04, 2.4399e-04, 5.6188e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 7.3451, 17.0752, 18.8371, 99.6536], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0006, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5169.7471, 3732.4873, 3674.8606, 8274.7402])\n",
            "l2norm ;  tensor([[1.5973],\n",
            "        [0.8011],\n",
            "        [0.7005],\n",
            "        [4.4616]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  82\n",
            "ce:  tensor([ 7.4450, 16.9394, 19.0738, 95.5480], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0943e-04, 1.5734e-04, 2.2373e-04, 5.4092e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 7.4456, 16.9403, 19.0751, 98.7395], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0006, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5782.4634, 5312.5518, 5729.3086, 8236.5869])\n",
            "l2norm ;  tensor([[0.7176],\n",
            "        [1.7305],\n",
            "        [2.0477],\n",
            "        [4.2914]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  83\n",
            "ce:  tensor([ 7.3867, 17.0062, 19.0018, 94.8161], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2314e-04, 1.4948e-04, 2.2814e-04, 5.1983e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 7.3874, 17.0070, 19.0031, 97.8571], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0006, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4360.3130, 3732.4546, 4074.7068, 8232.8691])\n",
            "l2norm ;  tensor([[0.5440],\n",
            "        [0.9202],\n",
            "        [1.0580],\n",
            "        [4.1855]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  84\n",
            "ce:  tensor([ 7.5112, 16.8222, 19.0603, 94.0987], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0740e-04, 1.3899e-04, 1.9096e-04, 4.9968e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 7.5118, 16.8230, 19.0614, 96.9968], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0005, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6224.8140, 3732.4404, 5251.4668, 8229.2188])\n",
            "l2norm ;  tensor([[1.8013],\n",
            "        [0.8611],\n",
            "        [1.2429],\n",
            "        [4.1624]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  85\n",
            "ce:  tensor([ 7.5730, 16.6694, 18.9998, 93.3794], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1968e-04, 1.3136e-04, 1.8559e-04, 4.8046e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 7.5737, 16.6702, 19.0009, 96.1421], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0005, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5259.6338, 5312.5161, 3674.7910, 8225.6748])\n",
            "l2norm ;  tensor([[1.6417],\n",
            "        [1.7052],\n",
            "        [0.7981],\n",
            "        [4.0459]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  86\n",
            "ce:  tensor([ 7.6470, 16.8147, 19.1186, 92.6795], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0347e-04, 1.2647e-04, 1.6855e-04, 4.6177e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 7.6476, 16.8154, 19.1195, 95.3116], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0005, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5782.2207, 4704.5425, 5729.2446, 8222.1553])\n",
            "l2norm ;  tensor([[0.6881],\n",
            "        [2.0645],\n",
            "        [2.0478],\n",
            "        [4.0238]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  87\n",
            "ce:  tensor([ 7.6651, 16.8189, 19.1394, 91.9779], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0549e-04, 1.1849e-04, 1.7248e-04, 4.4397e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 7.6657, 16.8196, 19.1403, 94.4863], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0005, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4661.2793, 3732.4126, 3674.7744, 8218.7363])\n",
            "l2norm ;  tensor([[0.8030],\n",
            "        [0.9030],\n",
            "        [0.7981],\n",
            "        [3.9250]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  88\n",
            "ce:  tensor([ 7.8119, 16.6387, 19.0709, 91.2880], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.1549e-05, 1.0669e-04, 1.5699e-04, 4.2706e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 7.8124, 16.6393, 19.0718, 93.6795], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0004, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6225.6768, 3723.9785, 5251.4258, 8231.7715])\n",
            "l2norm ;  tensor([[1.8016],\n",
            "        [0.7425],\n",
            "        [1.2429],\n",
            "        [3.8545]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  89\n",
            "ce:  tensor([ 7.7587, 16.5991, 19.1090, 90.6068], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0204e-04, 9.9773e-05, 1.5305e-04, 4.1131e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 7.7592, 16.5996, 19.1099, 92.8896], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.2715e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5553.9517, 5300.7539, 3674.7515, 8228.5908])\n",
            "l2norm ;  tensor([[1.4413],\n",
            "        [1.6290],\n",
            "        [0.7980],\n",
            "        [3.7646]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  90\n",
            "ce:  tensor([ 7.9176, 16.6057, 19.1387, 89.9380], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.8330e-05, 9.7508e-05, 1.3958e-04, 3.9641e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 7.9181, 16.6063, 19.1395, 92.1183], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.6436e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6225.9248, 3723.9653, 5729.2095, 8225.5117])\n",
            "l2norm ;  tensor([[1.8017],\n",
            "        [0.8682],\n",
            "        [2.0478],\n",
            "        [3.7466]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  91\n",
            "ce:  tensor([ 8.0222, 16.4321, 19.2486, 89.2678], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.8581e-05, 9.3456e-05, 1.4328e-04, 3.8228e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.0228, 16.4326, 19.2494, 91.3513], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.2813e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4831.8955, 3723.9597, 3674.7393, 8222.5645])\n",
            "l2norm ;  tensor([[0.8361],\n",
            "        [0.6884],\n",
            "        [0.7971],\n",
            "        [3.6691]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  92\n",
            "ce:  tensor([ 7.9682, 16.4209, 19.0928, 88.6120], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.5827e-05, 8.5827e-05, 1.3160e-04, 3.6913e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 7.9686, 16.4214, 19.0935, 90.6052], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.4636e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5782.9541, 6256.5996, 4145.2764, 8171.2773])\n",
            "l2norm ;  tensor([[0.6882],\n",
            "        [2.3003],\n",
            "        [1.0971],\n",
            "        [3.4914]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  93\n",
            "ce:  tensor([ 8.0523, 16.4908, 19.2412, 87.9922], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.7853e-05, 7.9271e-05, 1.2325e-04, 3.5559e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.0528, 16.4912, 19.2418, 89.8946], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.1848e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4775.1006, 3723.9424, 5650.0957, 8047.9004])\n",
            "l2norm ;  tensor([[0.8999],\n",
            "        [0.7560],\n",
            "        [1.2973],\n",
            "        [3.1409]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  94\n",
            "ce:  tensor([ 8.0798, 16.3805, 19.2549, 87.4296], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.7483e-05, 7.6291e-05, 1.2302e-04, 3.4356e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.0803, 16.3810, 19.2556, 89.2504], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.0978e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6099.1465, 5152.9521, 3674.7163, 8045.2915])\n",
            "l2norm ;  tensor([[1.8413],\n",
            "        [1.5351],\n",
            "        [0.7933],\n",
            "        [3.1263]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  95\n",
            "ce:  tensor([ 8.1960, 16.4878, 19.2331, 86.8660], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.6781e-05, 7.4861e-05, 1.1467e-04, 3.3214e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.1965, 16.4882, 19.2337, 88.6097], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.7581e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5499.1562, 3577.7961, 4741.1152, 8042.7808])\n",
            "l2norm ;  tensor([[1.5721],\n",
            "        [0.7682],\n",
            "        [1.3986],\n",
            "        [3.1123]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  96\n",
            "ce:  tensor([ 8.1807, 16.3352, 19.3295, 86.3014], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.6529e-05, 7.3311e-05, 1.2004e-04, 3.2131e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.1811, 16.3355, 19.3301, 87.9723], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.8010e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5897.4224, 3723.9336, 4074.5759, 8040.3657])\n",
            "l2norm ;  tensor([[0.9745],\n",
            "        [0.6883],\n",
            "        [1.0949],\n",
            "        [3.0615]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  97\n",
            "ce:  tensor([ 8.3423, 16.3282, 19.2150, 85.7745], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.6900e-05, 6.7709e-05, 1.0251e-04, 3.1090e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.3427, 16.3285, 19.2156, 87.3756], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3827e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4775.4785, 5152.9409, 4741.1030, 7396.5449])\n",
            "l2norm ;  tensor([[0.9000],\n",
            "        [1.5351],\n",
            "        [1.3986],\n",
            "        [2.7229]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  98\n",
            "ce:  tensor([ 8.2699, 16.4026, 19.3849, 85.2849], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.6649e-05, 6.6636e-05, 1.0752e-04, 3.0042e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.2703, 16.4030, 19.3855, 86.8171], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.5615e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4601.4668, 4551.2524, 3674.6975, 7394.2617])\n",
            "l2norm ;  tensor([[0.8210],\n",
            "        [1.9751],\n",
            "        [0.7876],\n",
            "        [2.7103]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  99\n",
            "ce:  tensor([ 8.2748, 16.4910, 19.2428, 84.7944], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.8556e-05, 6.5325e-05, 1.0120e-04, 2.9050e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.2752, 16.4913, 19.2433, 86.2614], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.5484e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5427.1504, 3577.7832, 3160.6589, 7392.0811])\n",
            "l2norm ;  tensor([[1.5674],\n",
            "        [0.7987],\n",
            "        [0.6100],\n",
            "        [2.5579]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  100\n",
            "ce:  tensor([ 8.5364, 16.5077, 19.4198, 84.3255], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.9497e-05, 6.2464e-05, 1.0156e-04, 2.8221e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.5368, 16.5080, 19.4203, 85.7365], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.9620e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6099.8267, 5063.9922, 6114.4976, 7390.1680])\n",
            "l2norm ;  tensor([[1.8415],\n",
            "        [1.5488],\n",
            "        [2.1945],\n",
            "        [2.4813]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  101\n",
            "ce:  tensor([ 8.5560, 16.5176, 19.4968, 83.8686], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.7960e-05, 6.1152e-05, 1.1384e-04, 2.7448e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.5564, 16.5179, 19.4974, 85.2273], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.9239e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4775.6851, 3977.1094, 4065.9092, 7388.3403])\n",
            "l2norm ;  tensor([[1.0107],\n",
            "        [0.9576],\n",
            "        [1.0340],\n",
            "        [2.4721]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  102\n",
            "ce:  tensor([ 8.5821, 16.4096, 19.4454, 83.4109], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.9377e-05, 5.6384e-05, 9.8224e-05, 2.6719e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.5824, 16.4099, 19.4459, 84.7202], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.8750e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5656.3359, 5063.9849, 4734.5317, 7386.5933])\n",
            "l2norm ;  tensor([[0.8253],\n",
            "        [1.5488],\n",
            "        [1.3229],\n",
            "        [2.4073]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  103\n",
            "ce:  tensor([ 8.5450, 16.5344, 19.5783, 82.9642], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.3430e-05, 5.5192e-05, 1.0693e-04, 2.6024e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.5453, 16.5346, 19.5788, 84.2264], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.9453e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4775.6689, 3577.7705, 3667.6904, 7384.8984])\n",
            "l2norm ;  tensor([[0.9000],\n",
            "        [0.7625],\n",
            "        [0.8666],\n",
            "        [2.3470]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  104\n",
            "ce:  tensor([ 8.6637, 16.3992, 19.4373, 82.5275], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.4967e-05, 5.4358e-05, 1.0001e-04, 2.5363e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.6640, 16.3994, 19.4378, 83.7449], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7272e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6099.9629, 3487.1191, 5241.0850, 7383.2539])\n",
            "l2norm ;  tensor([[1.8423],\n",
            "        [0.6018],\n",
            "        [1.2639],\n",
            "        [2.3391]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  105\n",
            "ce:  tensor([ 8.7239, 16.4862, 19.5864, 82.0902], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.3073e-05, 5.3047e-05, 1.0669e-04, 2.4740e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.7243, 16.4864, 19.5869, 83.2653], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.6271e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5669.2568, 5611.7046, 3557.1365, 7381.6812])\n",
            "l2norm ;  tensor([[1.5180],\n",
            "        [1.6282],\n",
            "        [0.7747],\n",
            "        [2.3184]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  106\n",
            "ce:  tensor([ 8.7982, 16.5209, 19.5072, 81.6540], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.5563e-05, 5.1616e-05, 9.5601e-05, 2.4173e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.7985, 16.5211, 19.5077, 82.7901], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5103e-04, 1.1921e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5966.8027, 4461.9146, 3630.8926, 7380.2183])\n",
            "l2norm ;  tensor([[0.9802],\n",
            "        [1.9900],\n",
            "        [1.1801],\n",
            "        [2.2614]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  107\n",
            "ce:  tensor([ 8.8381, 16.6525, 19.5502, 81.2250], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.5457e-05, 5.0543e-05, 9.7032e-05, 2.3687e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.8384, 16.6527, 19.5507, 82.3265], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0001, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4703.6587, 5104.5098, 6594.5864, 7378.8984])\n",
            "l2norm ;  tensor([[0.9948],\n",
            "        [1.7521],\n",
            "        [2.1431],\n",
            "        [2.2554]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  108\n",
            "ce:  tensor([ 8.8326, 16.7818, 19.7498, 80.7956], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.7351e-05, 5.2093e-05, 9.6793e-05, 2.3232e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.8329, 16.7821, 19.7503, 81.8643], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0001, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6100.1260, 3487.1150, 3160.6465, 7377.6445])\n",
            "l2norm ;  tensor([[1.8424],\n",
            "        [0.7468],\n",
            "        [0.6551],\n",
            "        [2.2497]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  109\n",
            "ce:  tensor([ 9.0396, 16.6481, 19.7298, 80.3657], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.5814e-05, 5.0305e-05, 9.9773e-05, 2.2806e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.0399, 16.6484, 19.7303, 81.4033], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0001, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5809.3027, 2980.1140, 5638.1768, 7376.4453])\n",
            "l2norm ;  tensor([[1.8330],\n",
            "        [0.5116],\n",
            "        [1.2670],\n",
            "        [2.2224]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  110\n",
            "ce:  tensor([ 8.9155, 16.8273, 19.8029, 79.9373], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.5921e-05, 4.9590e-05, 1.0633e-04, 2.2460e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 8.9158, 16.8275, 19.8034, 80.9480], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0001, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5966.8994, 5611.6992, 3667.6824, 7375.3960])\n",
            "l2norm ;  tensor([[0.8222],\n",
            "        [1.5717],\n",
            "        [0.7842],\n",
            "        [2.2178]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  111\n",
            "ce:  tensor([ 9.0453, 16.7574, 19.7584, 79.5086], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.0808e-05, 4.9113e-05, 1.0001e-04, 2.2138e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.0456, 16.7576, 19.7588, 80.4937], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0001, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5597.2437, 3487.1106, 4734.5244, 7374.3896])\n",
            "l2norm ;  tensor([[1.5304],\n",
            "        [0.6600],\n",
            "        [1.3229],\n",
            "        [2.2134]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  112\n",
            "ce:  tensor([ 9.2171, 16.7715, 19.8797, 79.0796], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.4133e-05, 4.8636e-05, 1.0919e-04, 2.1839e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.2174, 16.7717, 19.8801, 80.0405], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.9296e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6409.2158, 4955.7627, 4065.8928, 7373.4253])\n",
            "l2norm ;  tensor([[1.7583],\n",
            "        [1.5641],\n",
            "        [1.0824],\n",
            "        [2.2093]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  113\n",
            "ce:  tensor([ 9.2614, 16.9509, 19.7654, 78.6502], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1642e-05, 5.1259e-05, 9.5124e-05, 2.1562e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.2617, 16.9511, 19.7658, 79.5882], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.5005e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4917.6899, 4461.9102, 3160.6404, 7372.5005])\n",
            "l2norm ;  tensor([[0.9666],\n",
            "        [2.1256],\n",
            "        [0.5973],\n",
            "        [2.2053]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  114\n",
            "ce:  tensor([ 9.1869, 17.0193, 20.0347, 78.2257], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.3060e-05, 4.9828e-05, 9.8104e-05, 2.1306e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.1872, 17.0195, 20.0351, 79.1418], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([0.0001, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6065.5132, 3633.2871, 5212.6445, 7318.5488])\n",
            "l2norm ;  tensor([[1.8428],\n",
            "        [0.6202],\n",
            "        [2.4527],\n",
            "        [2.0294]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  115\n",
            "ce:  tensor([ 9.3889, 17.1229, 20.0119, 77.8312], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1642e-05, 4.7921e-05, 1.1181e-04, 2.1048e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.3892, 17.1231, 20.0124, 78.7257], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.3681e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5774.6616, 4812.5840, 4065.8918, 7317.6724])\n",
            "l2norm ;  tensor([[1.8669],\n",
            "        [1.6878],\n",
            "        [0.9584],\n",
            "        [1.9986]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  116\n",
            "ce:  tensor([ 9.2993, 17.1940, 20.0386, 77.4419], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.4252e-05, 4.9828e-05, 9.8343e-05, 2.0810e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.2995, 17.1942, 20.0391, 78.3159], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.1549e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4437.4053, 3886.3330, 5241.0728, 7316.8389])\n",
            "l2norm ;  tensor([[0.6593],\n",
            "        [0.7740],\n",
            "        [1.2304],\n",
            "        [1.9951]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  117\n",
            "ce:  tensor([ 9.4517, 17.1189, 20.0376, 77.0523], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.5205e-05, 4.7206e-05, 1.0454e-04, 2.0592e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.4520, 17.1191, 20.0381, 77.9069], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.8556e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6065.6572, 3231.6523, 3667.6743, 7316.0396])\n",
            "l2norm ;  tensor([[1.8673],\n",
            "        [0.5195],\n",
            "        [0.8664],\n",
            "        [1.9723]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  118\n",
            "ce:  tensor([ 9.4559, 17.1233, 20.0511, 76.6669], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.4026e-05, 4.4822e-05, 9.8939e-05, 2.0380e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.4562, 17.1235, 20.0515, 77.5025], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.8198e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4882.4502, 4704.7686, 4734.5171, 7315.2622])\n",
            "l2norm ;  tensor([[1.1345],\n",
            "        [1.6251],\n",
            "        [1.2887],\n",
            "        [1.9325]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  119\n",
            "ce:  tensor([ 9.3915, 17.2946, 20.1368, 76.2864], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.5444e-05, 4.6967e-05, 1.0955e-04, 2.0240e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.3918, 17.2948, 20.1373, 77.1062], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.3443e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6065.6270, 3886.3293, 4065.8857, 7314.5957])\n",
            "l2norm ;  tensor([[1.4531],\n",
            "        [0.8999],\n",
            "        [1.2100],\n",
            "        [1.8402]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  120\n",
            "ce:  tensor([ 9.6279, 17.1656, 20.1392, 75.9252], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.8305e-05, 4.3868e-05, 9.6078e-05, 2.0078e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.6282, 17.1658, 20.1395, 76.7283], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.5921e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5774.7573, 2980.1028, 6217.0811, 7313.8794])\n",
            "l2norm ;  tensor([[1.8236],\n",
            "        [0.5362],\n",
            "        [2.9118],\n",
            "        [1.7568]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  121\n",
            "ce:  tensor([ 9.5956, 17.3654, 20.2903, 75.7379], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.1391e-05, 4.5418e-05, 1.0514e-04, 1.9868e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.5958, 17.3656, 20.2907, 76.5227], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.8066e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6004.5869, 6421.2090, 3724.0579, 6321.5405])\n",
            "l2norm ;  tensor([[1.0159],\n",
            "        [2.3091],\n",
            "        [0.8895],\n",
            "        [1.7940]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  122\n",
            "ce:  tensor([ 9.6684, 17.3435, 20.1865, 75.4673], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.0689e-05, 4.3630e-05, 1.0359e-04, 1.9439e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.6687, 17.3436, 20.1869, 76.2254], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.3298e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5702.6382, 3633.2778, 5187.1201, 7312.1182])\n",
            "l2norm ;  tensor([[1.8660],\n",
            "        [0.8195],\n",
            "        [1.2101],\n",
            "        [2.0164]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  123\n",
            "ce:  tensor([ 9.7538, 17.2995, 20.4310, 75.3062], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.3537e-05, 4.1126e-05, 1.1575e-04, 1.9181e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.7540, 17.2996, 20.4315, 76.0446], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.8053e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6196.9399, 4557.3984, 4693.6836, 6319.6660])\n",
            "l2norm ;  tensor([[1.8503],\n",
            "        [1.6006],\n",
            "        [2.2568],\n",
            "        [1.7790]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  124\n",
            "ce:  tensor([ 9.8625, 17.4542, 20.4587, 74.9662], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1642e-05, 4.3391e-05, 1.0871e-04, 1.8791e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.8628, 17.4544, 20.4592, 75.6803], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.2093e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4886.3921, 3886.3240, 3865.3103, 7310.3618])\n",
            "l2norm ;  tensor([[0.8654],\n",
            "        [0.7285],\n",
            "        [0.6411],\n",
            "        [1.6246]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  125\n",
            "ce:  tensor([ 9.7144, 17.4663, 20.5919, 74.8447], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.6517e-05, 4.1484e-05, 1.0466e-04, 1.8609e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.7146, 17.4664, 20.5923, 75.5425], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.0437e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4227.5322, 4202.4238, 5268.3833, 6318.0142])\n",
            "l2norm ;  tensor([[0.5838],\n",
            "        [1.8609],\n",
            "        [2.4074],\n",
            "        [1.6744]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  126\n",
            "ce:  tensor([ 9.8376, 17.6590, 20.7399, 74.5649], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.9139e-05, 4.1603e-05, 1.1920e-04, 1.8231e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.8379, 17.6592, 20.7404, 75.2394], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.3404e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5998.4048, 5279.6060, 3724.0615, 7308.7622])\n",
            "l2norm ;  tensor([[1.9203],\n",
            "        [1.6115],\n",
            "        [0.9136],\n",
            "        [1.5734]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  127\n",
            "ce:  tensor([10.0358, 17.7735, 20.6464, 74.4006], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.8794e-05, 4.1722e-05, 1.1300e-04, 1.8089e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.0360, 17.7736, 20.6468, 75.0608], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.3749e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5621.7266, 4033.9524, 5045.7900, 6316.4810])\n",
            "l2norm ;  tensor([[1.9681],\n",
            "        [1.0958],\n",
            "        [1.2342],\n",
            "        [1.6433]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  128\n",
            "ce:  tensor([ 9.9259, 17.6919, 20.8613, 74.1803], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.9854e-05, 3.6239e-05, 1.1837e-04, 1.7763e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 9.9261, 17.6920, 20.8617, 74.8198], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.8875e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5554.1621, 3043.6624, 4122.4360, 7307.3232])\n",
            "l2norm ;  tensor([[1.0508],\n",
            "        [0.5217],\n",
            "        [1.0393],\n",
            "        [1.8261]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  129\n",
            "ce:  tensor([10.0651, 17.7404, 20.7273, 74.0155], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.9986e-05, 3.4689e-05, 1.0442e-04, 1.7734e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.0654, 17.7406, 20.7277, 74.6450], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.2557e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5581.5649, 4557.3916, 4790.6577, 6315.1904])\n",
            "l2norm ;  tensor([[1.8773],\n",
            "        [1.5281],\n",
            "        [1.2329],\n",
            "        [1.6381]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  130\n",
            "ce:  tensor([10.1505, 17.8462, 20.9517, 73.7414], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.2596e-05, 3.6716e-05, 1.1455e-04, 1.7437e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.1508, 17.8464, 20.9521, 74.3517], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.9100e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6770.1338, 3487.0923, 4122.4316, 7306.0815])\n",
            "l2norm ;  tensor([[1.7252],\n",
            "        [0.7380],\n",
            "        [1.0393],\n",
            "        [1.5541]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  131\n",
            "ce:  tensor([10.1880, 17.7276, 20.8032, 73.5933], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3920e-05, 3.6001e-05, 1.0120e-04, 1.7347e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.1882, 17.7277, 20.8036, 74.1917], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.7669e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4886.4658, 3777.3804, 3724.0457, 6215.0796])\n",
            "l2norm ;  tensor([[1.1213],\n",
            "        [0.7854],\n",
            "        [0.5692],\n",
            "        [1.5595]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  132\n",
            "ce:  tensor([10.1144, 17.8467, 21.0846, 73.3860], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.7125e-05, 3.5047e-05, 1.0406e-04, 1.7084e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.1147, 17.8468, 21.0850, 73.9668], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.0530e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5998.4824, 5063.9541, 5522.0098, 7169.9927])\n",
            "l2norm ;  tensor([[1.4978],\n",
            "        [1.4117],\n",
            "        [2.4750],\n",
            "        [1.3992]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  133\n",
            "ce:  tensor([10.3381, 17.8535, 21.1146, 73.2007], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.1059e-05, 3.4928e-05, 1.1980e-04, 1.7002e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.3384, 17.8536, 21.1150, 73.7703], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.2424e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5415.1216, 3487.0898, 5091.1265, 6213.8657])\n",
            "l2norm ;  tensor([[1.7030],\n",
            "        [0.8007],\n",
            "        [2.3797],\n",
            "        [1.4508]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  134\n",
            "ce:  tensor([10.3451, 17.8455, 21.3006, 73.0737], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.6053e-05, 3.2544e-05, 1.0812e-04, 1.6665e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.3453, 17.8456, 21.3010, 73.6237], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.2186e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6012.1035, 4812.5649, 5051.0889, 7168.7051])\n",
            "l2norm ;  tensor([[0.9842],\n",
            "        [1.5742],\n",
            "        [1.3359],\n",
            "        [1.6991]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  135\n",
            "ce:  tensor([10.4528, 17.9831, 21.3526, 72.9235], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.8807e-05, 3.3855e-05, 1.1980e-04, 1.6529e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.4530, 17.9832, 21.3530, 73.4607], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.8848e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4886.5088, 3377.8420, 4127.7837, 6212.5103])\n",
            "l2norm ;  tensor([[0.8082],\n",
            "        [0.7559],\n",
            "        [1.0813],\n",
            "        [1.0338]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  136\n",
            "ce:  tensor([10.3329, 17.9092, 21.3161, 72.7226], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.8794e-05, 3.0636e-05, 1.0681e-04, 1.6354e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.3332, 17.9093, 21.3165, 73.2459], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.2544e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4809.4570, 2980.0874, 4790.6523, 6211.9434])\n",
            "l2norm ;  tensor([[0.9373],\n",
            "        [0.5185],\n",
            "        [1.2545],\n",
            "        [0.9724]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  137\n",
            "ce:  tensor([10.4387, 18.0637, 21.4412, 72.6359], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.9033e-05, 3.1113e-05, 1.1753e-04, 1.6227e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.4390, 18.0638, 21.4415, 73.1471], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.9325e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5797.8066, 5466.8350, 3729.4092, 7167.0679])\n",
            "l2norm ;  tensor([[1.6258],\n",
            "        [1.5630],\n",
            "        [0.8305],\n",
            "        [1.5423]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  138\n",
            "ce:  tensor([10.6194, 18.1180, 21.3638, 72.5366], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.0808e-05, 3.1232e-05, 1.1205e-04, 1.6315e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.6197, 18.1181, 21.3641, 73.0423], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.4438e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5937.9609, 4710.5049, 5273.6445, 6211.1367])\n",
            "l2norm ;  tensor([[0.9790],\n",
            "        [2.0030],\n",
            "        [2.3969],\n",
            "        [0.9638]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  139\n",
            "ce:  tensor([10.5517, 18.1954, 21.7077, 72.3458], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.2609e-05, 3.0636e-05, 1.2814e-04, 1.6255e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.5519, 18.1955, 21.7081, 72.8416], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.6106e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4593.3540, 5866.3208, 5096.2549, 6210.7139])\n",
            "l2norm ;  tensor([[0.6954],\n",
            "        [1.7243],\n",
            "        [2.3193],\n",
            "        [0.9430]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  140\n",
            "ce:  tensor([10.6441, 18.2847, 21.6943, 72.2382], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.3549e-05, 3.1113e-05, 1.1646e-04, 1.6123e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.6444, 18.2847, 21.6947, 72.7219], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6173.1284, 2980.0867, 3980.5942, 7165.8467])\n",
            "l2norm ;  tensor([[1.9860],\n",
            "        [0.7030],\n",
            "        [0.7479],\n",
            "        [1.6223]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  141\n",
            "ce:  tensor([10.7758, 18.2402, 21.8224, 72.1839], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.4516e-05, 2.9563e-05, 1.1670e-04, 1.6087e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.7760, 18.2403, 21.8227, 72.6585], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.0861e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5198.9912, 5466.8335, 5447.1899, 6209.7524])\n",
            "l2norm ;  tensor([[1.7547],\n",
            "        [1.4902],\n",
            "        [1.2443],\n",
            "        [0.9448]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  142\n",
            "ce:  tensor([10.8259, 18.3519, 21.8543, 71.9951], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.9867e-05, 2.9921e-05, 1.3005e-04, 1.6086e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.8262, 18.3520, 21.8546, 72.4616], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.9908e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5938.2368, 2980.0857, 3729.4099, 6209.3975])\n",
            "l2norm ;  tensor([[1.1706],\n",
            "        [0.5492],\n",
            "        [0.8241],\n",
            "        [0.9334]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  143\n",
            "ce:  tensor([10.8259, 18.2856, 21.9021, 71.8653], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.3456e-05, 2.9206e-05, 1.2469e-04, 1.6067e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.8262, 18.2857, 21.9025, 72.3232], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.9908e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4810.9512, 3886.0154, 4795.9385, 7164.6787])\n",
            "l2norm ;  tensor([[0.8927],\n",
            "        [0.5658],\n",
            "        [1.2503],\n",
            "        [1.5060]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  144\n",
            "ce:  tensor([10.8031, 18.3576, 21.9597, 71.8266], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.2370e-05, 2.8371e-05, 1.3911e-04, 1.6257e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.8033, 18.3577, 21.9601, 72.2818], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.0385e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6173.1519, 4557.3833, 4127.7827, 6208.8101])\n",
            "l2norm ;  tensor([[1.5882],\n",
            "        [1.5171],\n",
            "        [0.9016],\n",
            "        [0.9417]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  145\n",
            "ce:  tensor([10.9968, 18.4840, 21.9714, 71.6376], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.6781e-05, 3.0398e-05, 1.2540e-04, 1.6288e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.9970, 18.4841, 21.9717, 72.0855], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.6808e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5722.9805, 4859.5557, 5086.6587, 6208.4839])\n",
            "l2norm ;  tensor([[1.8436],\n",
            "        [2.4444],\n",
            "        [2.4352],\n",
            "        [0.9224]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  146\n",
            "ce:  tensor([11.0227, 18.5428, 22.2518, 71.4983], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.6887e-05, 2.7299e-05, 1.4328e-04, 1.6231e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.0229, 18.5428, 22.2522, 71.9365], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.6332e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5938.2529, 4959.6729, 5096.2534, 7163.7319])\n",
            "l2norm ;  tensor([[1.0949],\n",
            "        [1.3463],\n",
            "        [2.3479],\n",
            "        [1.5374]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  147\n",
            "ce:  tensor([11.0789, 18.7876, 22.2850, 71.4902], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.8569e-05, 3.0398e-05, 1.2957e-04, 1.6263e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.0791, 18.7877, 22.2854, 71.9212], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5378e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4667.5488, 3886.3069, 5370.2656, 6207.6816])\n",
            "l2norm ;  tensor([[0.6662],\n",
            "        [1.0012],\n",
            "        [1.2196],\n",
            "        [0.9047]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  148\n",
            "ce:  tensor([11.0430, 18.6934, 22.4500, 71.3069], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.7245e-05, 2.6345e-05, 1.3839e-04, 1.6357e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.0432, 18.6935, 22.4504, 71.7322], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5974e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6246.8682, 3706.1079, 4127.7778, 6207.4019])\n",
            "l2norm ;  tensor([[1.9671],\n",
            "        [1.2085],\n",
            "        [1.1837],\n",
            "        [0.8578]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  149\n",
            "ce:  tensor([11.2081, 18.7381, 22.3012, 71.1697], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.9045e-05, 2.6106e-05, 1.2218e-04, 1.6469e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.2083, 18.7382, 22.3016, 71.5897], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.3590e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4810.9736, 3886.0120, 3473.2454, 7162.8188])\n",
            "l2norm ;  tensor([[0.8275],\n",
            "        [0.5381],\n",
            "        [0.4963],\n",
            "        [1.5558]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  150\n",
            "ce:  tensor([11.0975, 18.7197, 22.3933, 71.1755], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.8675e-05, 2.3961e-05, 1.2600e-04, 1.6549e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.0977, 18.7197, 22.3936, 71.5893], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5139e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4210.9956, 4557.3789, 5302.7793, 6206.7959])\n",
            "l2norm ;  tensor([[0.3553],\n",
            "        [1.5171],\n",
            "        [1.1886],\n",
            "        [0.8720]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  151\n",
            "ce:  tensor([11.0851, 18.9295, 22.4214, 70.9976], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.8317e-05, 2.5749e-05, 1.3756e-04, 1.6697e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.0853, 18.9296, 22.4217, 71.4067], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5378e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6176.6758, 3886.3035, 4127.7734, 6206.5625])\n",
            "l2norm ;  tensor([[0.9702],\n",
            "        [1.5611],\n",
            "        [0.8860],\n",
            "        [0.8343]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  152\n",
            "ce:  tensor([11.3036, 18.6873, 22.4261, 70.8882], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.9880e-05, 2.1100e-05, 1.2802e-04, 1.6855e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.3038, 18.6874, 22.4264, 71.2927], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.2278e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5189.6348, 3231.6230, 5086.6523, 7162.0249])\n",
            "l2norm ;  tensor([[1.7644],\n",
            "        [0.5646],\n",
            "        [2.4340],\n",
            "        [1.4910]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  153\n",
            "ce:  tensor([11.2721, 18.7994, 22.7434, 70.8899], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.2728e-05, 2.0265e-05, 1.4638e-04, 1.6920e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.2723, 18.7995, 22.7437, 71.2876], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.2755e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6310.5781, 4955.7300, 5096.2456, 6205.9707])\n",
            "l2norm ;  tensor([[0.9053],\n",
            "        [1.4520],\n",
            "        [2.0826],\n",
            "        [1.2520]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  154\n",
            "ce:  tensor([11.3503, 18.8448, 22.7710, 70.6427], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.4171e-05, 2.2053e-05, 1.3541e-04, 1.6790e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.3505, 18.8449, 22.7714, 71.0289], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1802e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4583.6279, 3487.0771, 3792.3962, 6205.5029])\n",
            "l2norm ;  tensor([[0.7790],\n",
            "        [0.7097],\n",
            "        [0.8685],\n",
            "        [0.7889]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  155\n",
            "ce:  tensor([11.3383, 18.7669, 22.8694, 70.6741], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.2966e-05, 2.0385e-05, 1.3196e-04, 1.6910e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.3385, 18.7669, 22.8697, 71.0546], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6164.0151, 4557.3770, 5051.0776, 7160.9419])\n",
            "l2norm ;  tensor([[2.0121],\n",
            "        [1.4967],\n",
            "        [1.3068],\n",
            "        [1.3577]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  156\n",
            "ce:  tensor([11.4865, 19.0283, 22.9088, 70.5485], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.6197e-05, 2.1696e-05, 1.4638e-04, 1.7185e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.4867, 19.0283, 22.9091, 70.9266], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0252e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5713.7256, 4889.4902, 4127.7705, 6205.0435])\n",
            "l2norm ;  tensor([[1.8230],\n",
            "        [1.5222],\n",
            "        [0.9748],\n",
            "        [0.7718]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  157\n",
            "ce:  tensor([11.4867, 18.9753, 22.8908, 70.4642], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.5708e-05, 1.9789e-05, 1.2993e-04, 1.7348e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.4869, 18.9753, 22.8910, 70.8372], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0252e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5929.0283, 2980.0771, 4795.9258, 7160.5151])\n",
            "l2norm ;  tensor([[1.0879],\n",
            "        [0.4686],\n",
            "        [1.1810],\n",
            "        [1.1168]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  158\n",
            "ce:  tensor([11.6069, 19.0245, 23.0128, 70.4449], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.7985e-05, 1.9550e-05, 1.4495e-04, 1.7319e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.6071, 19.0245, 23.0132, 70.8086], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.0599e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4657.8843, 4959.6675, 4127.7676, 6204.3662])\n",
            "l2norm ;  tensor([[0.7485],\n",
            "        [1.5724],\n",
            "        [1.0274],\n",
            "        [0.7651]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  159\n",
            "ce:  tensor([11.5034, 19.2627, 22.9407, 70.3143], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.7734e-05, 2.1100e-05, 1.2898e-04, 1.7478e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.5036, 19.2627, 22.9410, 70.6726], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0133e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6164.0254, 5712.6094, 4863.8052, 7159.8296])\n",
            "l2norm ;  tensor([[1.6005],\n",
            "        [2.3954],\n",
            "        [1.2928],\n",
            "        [1.3212]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  160\n",
            "ce:  tensor([11.7549, 19.2817, 23.2227, 70.3605], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.4528e-05, 1.9908e-05, 1.4376e-04, 1.7778e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.7551, 19.2817, 23.2230, 70.7160], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.8678e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4801.4595, 3377.9189, 4698.8252, 6203.9160])\n",
            "l2norm ;  tensor([[1.0183],\n",
            "        [0.5684],\n",
            "        [2.0460],\n",
            "        [0.7547]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  161\n",
            "ce:  tensor([11.6193, 19.3278, 23.2799, 70.2052], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.4635e-05, 1.9073e-05, 1.3792e-04, 1.8003e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.6195, 19.3279, 23.2801, 70.5562], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.9407e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4275.6450, 4557.3750, 4379.0898, 6203.6963])\n",
            "l2norm ;  tensor([[0.3489],\n",
            "        [1.4657],\n",
            "        [0.6444],\n",
            "        [0.6487]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  162\n",
            "ce:  tensor([11.6749, 19.4614, 23.4070, 70.0997], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.2013e-05, 2.0385e-05, 1.3649e-04, 1.8188e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.6750, 19.4615, 23.4072, 70.4452], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.4638e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5786.2109, 3886.2988, 5086.6440, 7159.1484])\n",
            "l2norm ;  tensor([[1.0929],\n",
            "        [1.5280],\n",
            "        [2.3930],\n",
            "        [1.4318]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  163\n",
            "ce:  tensor([11.7688, 19.2366, 23.6016, 70.1563], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.2741e-05, 1.6689e-05, 1.5663e-04, 1.8325e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.7689, 19.2367, 23.6019, 70.4953], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.7486e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5571.7881, 4812.5508, 3541.0959, 6203.0933])\n",
            "l2norm ;  tensor([[1.8026],\n",
            "        [1.2272],\n",
            "        [1.0273],\n",
            "        [0.7475]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  164\n",
            "ce:  tensor([11.8864, 19.4880, 23.4725, 70.0026], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.2847e-05, 1.8000e-05, 1.4602e-04, 1.8554e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.8866, 19.4881, 23.4727, 70.3366], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.9141e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6687.6606, 3538.1313, 5051.0718, 6202.8530])\n",
            "l2norm ;  tensor([[1.8131],\n",
            "        [0.7659],\n",
            "        [1.1628],\n",
            "        [0.6996]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  165\n",
            "ce:  tensor([11.9511, 19.3589, 23.6867, 69.9812], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.7151e-05, 1.6928e-05, 1.5758e-04, 1.8762e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.9513, 19.3590, 23.6870, 70.3095], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.4373e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4275.6572, 3125.2634, 3729.3914, 7158.3262])\n",
            "l2norm ;  tensor([[0.6816],\n",
            "        [0.4262],\n",
            "        [0.8171],\n",
            "        [1.3846]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  166\n",
            "ce:  tensor([11.8684, 19.4645, 23.5325, 69.9513], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.0714e-05, 1.6689e-05, 1.4912e-04, 1.8878e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.8686, 19.4645, 23.5327, 70.2722], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.0333e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6093.0381, 5768.8428, 3473.2351, 6202.2388])\n",
            "l2norm ;  tensor([[0.9100],\n",
            "        [1.4550],\n",
            "        [0.5039],\n",
            "        [0.7259]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  167\n",
            "ce:  tensor([11.9527, 19.5583, 23.6835, 69.8023], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.9535e-05, 1.7762e-05, 1.5424e-04, 1.9112e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.9529, 19.5583, 23.6838, 70.1176], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.4373e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4275.6558, 4139.0742, 6086.9600, 6201.9824])\n",
            "l2norm ;  tensor([[0.5606],\n",
            "        [1.0498],\n",
            "        [2.0811],\n",
            "        [0.6948]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  168\n",
            "ce:  tensor([11.8928, 19.5535, 23.8481, 69.8815], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.2264e-05, 1.7881e-05, 1.7272e-04, 1.9367e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.8929, 19.5536, 23.8483, 70.1914], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([6.7949e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6164.0391, 4812.5508, 4038.0605, 7157.4702])\n",
            "l2norm ;  tensor([[2.0121],\n",
            "        [1.5174],\n",
            "        [1.0253],\n",
            "        [1.4032]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  169\n",
            "ce:  tensor([12.1549, 19.7576, 23.7705, 69.7515], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0704e-04, 1.9193e-05, 1.5222e-04, 1.9511e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.1551, 19.7577, 23.7707, 70.0539], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.2452e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5713.7441, 3538.1309, 5026.6074, 6201.3706])\n",
            "l2norm ;  tensor([[1.7919],\n",
            "        [0.7659],\n",
            "        [1.1333],\n",
            "        [0.7120]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  170\n",
            "ce:  tensor([12.0934, 19.6472, 23.9231, 69.6961], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5482e-05, 1.8120e-05, 1.6485e-04, 1.9754e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.0935, 19.6472, 23.9233, 69.9924], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.6028e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5929.0474, 3031.0122, 4698.8179, 6755.1567])\n",
            "l2norm ;  tensor([[0.9092],\n",
            "        [0.4664],\n",
            "        [2.0364],\n",
            "        [1.0094]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  171\n",
            "ce:  tensor([12.2107, 19.8765, 24.0863, 69.7307], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0180e-04, 1.9073e-05, 1.5865e-04, 1.9852e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.2109, 19.8765, 24.0865, 70.0186], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.0068e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4657.8921, 6005.9146, 5259.4409, 6200.7197])\n",
            "l2norm ;  tensor([[0.8959],\n",
            "        [1.5621],\n",
            "        [1.2297],\n",
            "        [1.1908]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  172\n",
            "ce:  tensor([12.1662, 19.8407, 24.3085, 69.6145], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.1906e-05, 1.9908e-05, 1.7975e-04, 1.9799e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.1663, 19.8408, 24.3087, 69.8917], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.2452e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6164.0454, 4512.2979, 3729.3870, 6754.3701])\n",
            "l2norm ;  tensor([[2.0141],\n",
            "        [1.9436],\n",
            "        [0.9946],\n",
            "        [1.3277]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  173\n",
            "ce:  tensor([12.3042, 20.1987, 24.1295, 69.6117], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0657e-04, 2.0504e-05, 1.6891e-04, 2.0191e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.3043, 20.1987, 24.1297, 69.8843], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.5299e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4801.4668, 5409.5176, 3473.2310, 6200.0630])\n",
            "l2norm ;  tensor([[0.8900],\n",
            "        [1.8323],\n",
            "        [0.5266],\n",
            "        [0.7267]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  174\n",
            "ce:  tensor([12.2084, 20.1955, 24.2469, 69.4665], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5005e-05, 2.1457e-05, 1.7415e-04, 2.0506e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.2086, 20.1955, 24.2471, 69.7330], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.0068e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4201.4683, 3937.2026, 5699.7803, 7155.5513])\n",
            "l2norm ;  tensor([[0.3511],\n",
            "        [1.5489],\n",
            "        [1.0334],\n",
            "        [1.0393]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  175\n",
            "ce:  tensor([12.2564, 20.0149, 24.2617, 69.5653], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.4648e-05, 1.8120e-05, 1.8952e-04, 2.0583e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.2565, 20.0149, 24.2619, 69.8226], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.7684e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5786.2256, 4863.3198, 4127.7554, 5798.8936])\n",
            "l2norm ;  tensor([[1.0929],\n",
            "        [1.2521],\n",
            "        [1.0148],\n",
            "        [0.8293]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  176\n",
            "ce:  tensor([12.4332, 20.2148, 24.3810, 69.4248], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0716e-04, 2.0623e-05, 1.6938e-04, 2.0970e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.4333, 20.2148, 24.3812, 69.6764], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.9339e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5571.8008, 3428.6980, 5273.6191, 6199.1455])\n",
            "l2norm ;  tensor([[1.8757],\n",
            "        [0.8741],\n",
            "        [2.3085],\n",
            "        [0.6357]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  177\n",
            "ce:  tensor([12.4459, 20.1004, 24.4846, 69.4203], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5959e-05, 1.8716e-05, 1.9441e-04, 2.1259e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.4460, 20.1004, 24.4848, 69.6648], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.9339e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6121.4087, 3505.9617, 3729.3821, 7154.6030])\n",
            "l2norm ;  tensor([[2.0322],\n",
            "        [1.3118],\n",
            "        [1.6419],\n",
            "        [1.3173]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  178\n",
            "ce:  tensor([12.5409, 20.2828, 24.3233, 69.4149], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1205e-04, 1.8716e-05, 1.7177e-04, 2.1404e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.5410, 20.2829, 24.3234, 69.6504], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.5763e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4757.5708, 6515.0986, 5259.4346, 5797.9648])\n",
            "l2norm ;  tensor([[0.9843],\n",
            "        [1.7394],\n",
            "        [1.1591],\n",
            "        [0.8030]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  179\n",
            "ce:  tensor([12.4552, 20.3447, 24.4858, 69.3122], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0299e-04, 1.9312e-05, 1.9548e-04, 2.1766e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.4553, 20.3447, 24.4860, 69.5408], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.9339e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5743.2441, 2980.0728, 3222.2266, 7153.9365])\n",
            "l2norm ;  tensor([[0.9840],\n",
            "        [0.6179],\n",
            "        [0.8144],\n",
            "        [0.9236]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  180\n",
            "ce:  tensor([12.5726, 20.3757, 24.4000, 69.3864], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0967e-04, 1.8477e-05, 1.8976e-04, 2.1785e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.5727, 20.3758, 24.4002, 69.6042], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.4571e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5670.2148, 5517.7676, 5699.7749, 5797.2480])\n",
            "l2norm ;  tensor([[1.8887],\n",
            "        [1.4329],\n",
            "        [0.8981],\n",
            "        [1.0839]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  181\n",
            "ce:  tensor([12.6352, 20.4686, 24.5459, 69.2757], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.8462e-05, 1.9073e-05, 2.0085e-04, 2.1800e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.6353, 20.4686, 24.5460, 69.4828], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.2186e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6195.0322, 4429.7129, 4192.1802, 7153.1016])\n",
            "l2norm ;  tensor([[1.9973],\n",
            "        [1.3298],\n",
            "        [2.2447],\n",
            "        [0.8716]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  182\n",
            "ce:  tensor([12.7242, 20.4372, 24.8397, 69.2803], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1539e-04, 1.8239e-05, 1.9334e-04, 2.2220e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.7243, 20.4373, 24.8399, 69.4803], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.9802e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4757.5703, 3031.0100, 6363.9072, 5796.5288])\n",
            "l2norm ;  tensor([[1.0288],\n",
            "        [0.5005],\n",
            "        [1.2223],\n",
            "        [0.7766]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  183\n",
            "ce:  tensor([12.6288, 20.6561, 24.8424, 69.2708], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0633e-04, 1.8716e-05, 1.9989e-04, 2.2562e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.6289, 20.6561, 24.8426, 69.4626], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.2186e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5743.2446, 4959.6626, 3222.2207, 7152.4619])\n",
            "l2norm ;  tensor([[1.1351],\n",
            "        [1.5526],\n",
            "        [0.9403],\n",
            "        [1.2991]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  184\n",
            "ce:  tensor([12.7642, 20.6943, 24.9551, 69.2697], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2075e-04, 2.0385e-05, 1.9918e-04, 2.2732e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.7643, 20.6943, 24.9552, 69.4516], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.8610e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5670.2158, 5055.2275, 6429.8403, 6196.2725])\n",
            "l2norm ;  tensor([[1.9321],\n",
            "        [2.3819],\n",
            "        [2.0962],\n",
            "        [0.6211]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  185\n",
            "ce:  tensor([12.7492, 20.8094, 25.0305, 69.1444], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0931e-04, 1.8596e-05, 2.2790e-04, 2.2878e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.7493, 20.8094, 25.0307, 69.3159], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.8610e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5743.2456, 5517.7661, 4329.3906, 6195.8770])\n",
            "l2norm ;  tensor([[1.1486],\n",
            "        [1.5188],\n",
            "        [1.1695],\n",
            "        [0.5893]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  186\n",
            "ce:  tensor([12.8116, 20.8200, 25.1328, 69.2534], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2612e-04, 1.9193e-05, 2.2135e-04, 2.3023e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.8116, 20.8200, 25.1330, 69.4145], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.7418e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4757.5688, 3031.0098, 4863.7871, 6749.6021])\n",
            "l2norm ;  tensor([[0.7973],\n",
            "        [0.6422],\n",
            "        [1.1814],\n",
            "        [1.3392]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  187\n",
            "ce:  tensor([12.7099, 20.8540, 25.2114, 69.1719], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1670e-04, 1.9312e-05, 2.4399e-04, 2.3263e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.7100, 20.8540, 25.2116, 69.3231], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.9802e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4232.0356, 5517.7661, 3729.3721, 6195.0781])\n",
            "l2norm ;  tensor([[0.3831],\n",
            "        [1.3014],\n",
            "        [1.7456],\n",
            "        [1.1064]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  188\n",
            "ce:  tensor([12.7668, 20.9091, 25.1466, 69.1196], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1551e-04, 2.1338e-05, 2.1479e-04, 2.3156e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.7669, 20.9092, 25.1467, 69.2586], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.8610e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6189.8042, 3031.0093, 5735.6758, 6748.7720])\n",
            "l2norm ;  tensor([[2.0130],\n",
            "        [0.5185],\n",
            "        [1.9258],\n",
            "        [0.9405]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  189\n",
            "ce:  tensor([13.0027, 20.9898, 25.3040, 69.1122], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3434e-04, 2.1815e-05, 2.3863e-04, 2.3298e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.0028, 20.9898, 25.3042, 69.2403], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.2650e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5523.3940, 6515.0967, 3729.3682, 6194.2144])\n",
            "l2norm ;  tensor([[1.9330],\n",
            "        [1.5083],\n",
            "        [1.1940],\n",
            "        [0.6128]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  190\n",
            "ce:  tensor([12.9629, 21.0565, 25.2550, 69.1113], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2135e-04, 2.2053e-05, 2.2540e-04, 2.3606e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.9629, 21.0565, 25.2551, 69.2294], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5880.3286, 3176.0635, 4795.8994, 7149.6519])\n",
            "l2norm ;  tensor([[1.1914],\n",
            "        [0.5764],\n",
            "        [1.1319],\n",
            "        [1.2701]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  191\n",
            "ce:  tensor([12.9593, 20.9798, 25.4772, 69.1015], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2540e-04, 2.1219e-05, 2.4959e-04, 2.3784e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.9594, 20.9798, 25.4773, 69.2086], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5141.2183, 5370.0674, 5699.5991, 5787.2246])\n",
            "l2norm ;  tensor([[1.8601],\n",
            "        [1.4327],\n",
            "        [2.7441],\n",
            "        [0.7330]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  192\n",
            "ce:  tensor([13.1879, 21.2034, 25.5644, 69.0382], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1861e-04, 2.2530e-05, 2.3148e-04, 2.4187e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.1879, 21.2034, 25.5645, 69.1350], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.9073e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6799.4126, 4909.8887, 5051.0459, 7143.2847])\n",
            "l2norm ;  tensor([[2.1031],\n",
            "        [2.2333],\n",
            "        [1.0989],\n",
            "        [0.9249]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  193\n",
            "ce:  tensor([13.0631, 21.2960, 25.6655, 69.1312], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3064e-04, 2.0981e-05, 2.5841e-04, 2.4197e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.0631, 21.2960, 25.6656, 69.2159], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.1458e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4127.1118, 3428.9170, 4127.7324, 6186.6265])\n",
            "l2norm ;  tensor([[0.8104],\n",
            "        [0.4531],\n",
            "        [1.7701],\n",
            "        [0.5832]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  194\n",
            "ce:  tensor([13.0785, 21.3050, 25.5871, 69.0195], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2135e-04, 2.1338e-05, 2.2099e-04, 2.4526e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.0785, 21.3050, 25.5872, 69.0931], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.1458e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5638.9033, 4608.0562, 5735.6665, 7142.4380])\n",
            "l2norm ;  tensor([[1.1796],\n",
            "        [1.4535],\n",
            "        [2.0283],\n",
            "        [1.2865]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  195\n",
            "ce:  tensor([13.1459, 21.5189, 25.7501, 69.1334], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3935e-04, 2.3007e-05, 2.4554e-04, 2.4651e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.1459, 21.5189, 25.7501, 69.1951], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.9073e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5653.2427, 4688.7354, 3729.3577, 6185.7769])\n",
            "l2norm ;  tensor([[1.9414],\n",
            "        [2.2455],\n",
            "        [1.0140],\n",
            "        [0.5896]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  196\n",
            "ce:  tensor([13.2344, 21.3259, 25.7232, 69.0571], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2504e-04, 1.9908e-05, 2.3160e-04, 2.5000e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.2344, 21.3259, 25.7233, 69.1071], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7881e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6177.6172, 5086.9370, 5051.0391, 4607.9004])\n",
            "l2norm ;  tensor([[1.9603],\n",
            "        [2.2965],\n",
            "        [1.1739],\n",
            "        [1.3717]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  197\n",
            "ce:  tensor([13.2651, 21.6281, 25.8545, 69.2522], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4697e-04, 2.2888e-05, 2.5496e-04, 2.4618e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.2652, 21.6281, 25.8545, 69.2891], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7881e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4739.7695, 4084.9856, 5096.1943, 6739.3052])\n",
            "l2norm ;  tensor([[0.9922],\n",
            "        [1.0170],\n",
            "        [2.6724],\n",
            "        [1.6495]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  198\n",
            "ce:  tensor([13.2501, 21.5124, 25.9685, 69.2076], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3398e-04, 2.0861e-05, 2.2623e-04, 2.4915e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.2501, 21.5124, 25.9686, 69.2325], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.7881e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5725.1738, 3282.7290, 5051.0361, 6184.4556])\n",
            "l2norm ;  tensor([[1.1020],\n",
            "        [0.4043],\n",
            "        [1.1315],\n",
            "        [1.0993]], dtype=torch.float64)\n",
            "*************************************************\n",
            "t :  199\n",
            "ce:  tensor([13.3414, 21.5190, 26.0034, 69.0793], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4983e-04, 2.0861e-05, 2.5138e-04, 2.4837e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.3414, 21.5190, 26.0034, 69.0917], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.5497e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5098.8076, 5262.3638, 4730.4121, 5171.0659])\n",
            "l2norm ;  tensor([[2.0128],\n",
            "        [1.4506],\n",
            "        [1.7928],\n",
            "        [2.0991]], dtype=torch.float64)\n",
            "PGD l2: Attack effectiveness 50.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([3.8264e+00, 3.9643e+00, 3.9603e-03, -0.0000e+00])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(mals.to(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70e5a2c-b525-4d76-ee0e-49a91b41c4c7",
        "id": "utDXWu0779dx"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-19.8462,  21.1819],\n",
              "        [-42.3733,  44.2564],\n",
              "        [-28.2794,  29.8791],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c060ea-687f-4a30-a8df-37c214f87c29",
        "id": "3aIILysZ79dx"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2.7636,  -3.8715],\n",
              "        [  1.0458,  -1.5833],\n",
              "        [ -4.3548,   4.9399],\n",
              "        [-14.6555,  17.6070]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4755a3-89b3-43c8-bef6-ca31d264b99d",
        "id": "RDyj-FS579dy"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1.5029,  -2.3014],\n",
              "        [  1.7673,  -2.1779],\n",
              "        [ -2.5506,   2.9788],\n",
              "        [-12.6903,  16.1456]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ia575x369KM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `linf attack`"
      ],
      "metadata": {
        "id": "MMGJ5hyQ9L5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adv = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 0, insertion_array, removal_array, k=200, step_length=0.01, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1684dc59-2bd8-4b14-887d-26b6717b18ad",
        "id": "wfGEREtd9L5U"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "t :  0\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([119., 224., 242., 269.])\n",
            "*************************************************\n",
            "t :  1\n",
            "ce:  tensor([ 39.7414,  83.8590,  56.2299, 183.6628], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.3323, 7.0148, 6.9912, 3.8433], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 39.7414,  83.8590,  56.2299, 183.6628], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9534.6865, 8728.3252, 9188.6270, 9011.1484])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 94., 234., 208., 269.])\n",
            "*************************************************\n",
            "t :  2\n",
            "ce:  tensor([ 38.5673,  80.8797,  54.1434, 180.4803], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.9903, 6.7151, 6.6756, 3.8171], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 38.5673,  80.8797,  54.1434, 180.4803], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9249.8037, 9699.0928, 9224.5107, 9011.1484])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 89., 250., 207., 269.])\n",
            "*************************************************\n",
            "t :  3\n",
            "ce:  tensor([ 37.4851,  77.7561,  52.1360, 177.3786], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.7439, 6.3565, 6.3362, 3.7876], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 37.4851,  77.7561,  52.1360, 177.3786], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10225.0068,  8350.2969,  9370.4238,  8399.1846])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111., 293., 193., 262.])\n",
            "*************************************************\n",
            "t :  4\n",
            "ce:  tensor([ 36.4630,  74.0931,  50.0976, 174.4825], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4589, 5.9518, 6.0081, 3.7542], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 36.4630,  74.0931,  50.0976, 174.4825], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9165.1289, 9202.2500, 9227.6904, 8399.1846])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92., 308., 220., 262.])\n",
            "*************************************************\n",
            "t :  5\n",
            "ce:  tensor([ 35.2848,  70.5018,  48.0770, 171.5864], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.1540, 5.4424, 5.6298, 3.7171], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 35.2848,  70.5018,  48.0770, 171.5864], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8787.5293, 8296.2715, 8962.9121, 8399.1846])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([104., 310., 206., 262.])\n",
            "*************************************************\n",
            "t :  6\n",
            "ce:  tensor([ 34.0731,  66.6413,  46.0463, 168.7223], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.8450, 4.9595, 5.3100, 3.6765], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 34.0731,  66.6413,  46.0463, 168.7223], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8783.3018, 9332.6182, 8874.1816, 8258.7188])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105., 306., 211., 248.])\n",
            "*************************************************\n",
            "t :  7\n",
            "ce:  tensor([ 33.0507,  63.0734,  44.0755, 165.9441], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.5597, 4.4502, 4.9636, 3.6293], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 33.0507,  63.0734,  44.0755, 165.9441], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9583.4434, 8135.2012, 8909.3164, 8258.7188])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105., 345., 202., 248.])\n",
            "*************************************************\n",
            "t :  8\n",
            "ce:  tensor([ 32.0720,  59.0404,  42.1130, 163.1660], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.2603, 3.9076, 4.6293, 3.5786], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 32.0720,  59.0404,  42.1130, 163.1660], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8491.6562, 8097.3691, 8872.8047, 8258.7188])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([101., 338., 207., 248.])\n",
            "*************************************************\n",
            "t :  9\n",
            "ce:  tensor([ 30.9218,  56.6611,  40.0686, 160.3878], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9746, 3.3950, 4.2938, 3.5244], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 30.9218,  56.6611,  40.0686, 160.3878], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8391.4814, 7972.7222, 8739.1240, 8258.7188])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([107., 249., 217., 248.])\n",
            "*************************************************\n",
            "t :  10\n",
            "ce:  tensor([ 29.8025,  54.6293,  38.0029, 157.6188], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7217, 2.8709, 3.9184, 3.4670], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 29.8025,  54.6293,  38.0029, 157.6188], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9380.0586, 6937.6426, 8575.0801, 8252.8262])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([114., 245., 216., 247.])\n",
            "*************************************************\n",
            "t :  11\n",
            "ce:  tensor([ 28.8842,  52.4740,  36.1643, 154.8586], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4505, 2.3962, 3.5571, 3.4089], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.8842,  52.4740,  36.1643, 154.8586], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8360.2783, 6903.0225, 7973.7285, 8252.8262])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109., 243., 209., 247.])\n",
            "*************************************************\n",
            "t :  12\n",
            "ce:  tensor([ 27.6957,  50.3270,  34.8257, 152.0995], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2315, 1.9549, 3.1898, 3.3480], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 27.6957,  50.3270,  34.8257, 152.0995], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8189.5991, 6950.1992, 6850.1113, 8250.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([122., 243., 153., 247.])\n",
            "*************************************************\n",
            "t :  13\n",
            "ce:  tensor([ 26.4214,  48.2480,  33.7462, 149.3449], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0364, 1.5392, 2.9058, 3.2843], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.4214,  48.2480,  33.7462, 149.3449], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8065.4712, 6917.5391, 6802.2070, 8250.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([114., 234., 152., 247.])\n",
            "*************************************************\n",
            "t :  14\n",
            "ce:  tensor([ 25.6846,  46.2423,  32.6892, 146.5902], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.8691, 1.1739, 2.6270, 3.2182], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.6846,  46.2423,  32.6892, 146.5902], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7841.7988, 7891.7891, 6802.2070, 8250.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 236., 152., 247.])\n",
            "*************************************************\n",
            "t :  15\n",
            "ce:  tensor([ 25.1582,  44.5762,  31.6860, 143.8356], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.7056, 0.8671, 2.3548, 3.1499], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.1582,  44.5762,  31.6860, 143.8356], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6820.5103, 6798.6387, 6718.5898, 8250.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 89., 222., 149., 247.])\n",
            "*************************************************\n",
            "t :  16\n",
            "ce:  tensor([ 24.3860,  43.3565,  30.7097, 141.0809], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.5847, 0.6355, 2.0958, 3.0796], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.3860,  43.3565,  30.7097, 141.0809], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6757.4233, 6098.1050, 6665.5801, 8250.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 89., 150., 143., 247.])\n",
            "*************************************************\n",
            "t :  17\n",
            "ce:  tensor([ 23.6201,  42.1166,  29.7523, 138.3302], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.4781, 0.4792, 1.8631, 3.0076], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.6201,  42.1166,  29.7523, 138.3302], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6757.4233, 6098.1050, 6619.7393, 8234.2109])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 89., 150., 142., 245.])\n",
            "*************************************************\n",
            "t :  18\n",
            "ce:  tensor([ 22.8634,  40.8767,  28.8074, 135.6098], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.3875, 0.3554, 1.6340, 2.9345], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.8634,  40.8767,  28.8074, 135.6098], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6717.8228, 6098.1050, 6619.7393, 8161.2568])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87., 150., 142., 238.])\n",
            "*************************************************\n",
            "t :  19\n",
            "ce:  tensor([ 22.2445,  39.6577,  28.1746, 132.9839], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.3127, 0.2603, 1.4193, 2.8627], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.2445,  39.6577,  28.1746, 132.9839], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6599.6562, 6059.2842, 5546.2979, 8161.2568])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 72., 146., 115., 238.])\n",
            "*************************************************\n",
            "t :  20\n",
            "ce:  tensor([ 21.6773,  38.4394,  27.4440, 130.3579], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2470, 0.1925, 1.2822, 2.7901], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.6773,  38.4394,  27.4440, 130.3579], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7411.9121, 6059.2842, 5546.2979, 8161.2568])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102., 146., 115., 238.])\n",
            "*************************************************\n",
            "t :  21\n",
            "ce:  tensor([ 21.3144,  37.2211,  26.7133, 127.7320], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1977, 0.1417, 1.1530, 2.7169], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.3144,  37.2211,  26.7133, 127.7320], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6066.3564, 6059.2842, 5546.2979, 8161.2568])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75., 146., 115., 238.])\n",
            "*************************************************\n",
            "t :  22\n",
            "ce:  tensor([ 20.6696,  36.0028,  25.9998, 125.1140], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1652, 0.1042, 1.0323, 2.6433], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.6696,  36.0028,  25.9998, 125.1140], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6066.3564, 6059.2842, 5507.4502, 8126.8125])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75., 146., 113., 240.])\n",
            "*************************************************\n",
            "t :  23\n",
            "ce:  tensor([ 20.0131,  34.8255,  25.9024, 122.5010], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1379, 0.0767, 0.9290, 2.5668], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.0131,  34.8255,  25.9024, 122.5010], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6030.9277, 5631.8965, 3983.3027, 8143.1626])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 72., 139.,  82., 239.])\n",
            "*************************************************\n",
            "t :  24\n",
            "ce:  tensor([ 19.4570,  33.9031,  25.5619, 119.9067], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1174, 0.0624, 0.8127, 2.4908], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.4570,  33.9031,  25.5619, 119.9067], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6828.9346, 6075.8853, 3926.8508, 8094.7358])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 98., 179.,  86., 236.])\n",
            "*************************************************\n",
            "t :  25\n",
            "ce:  tensor([ 19.1278,  33.2644,  25.2276, 117.4221], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0957, 0.0478, 0.6905, 2.4183], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.1278,  33.2644,  25.2276, 117.4221], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5850.7798, 4864.7637, 3472.2178, 7974.3389])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 76., 131.,  84., 231.])\n",
            "*************************************************\n",
            "t :  26\n",
            "ce:  tensor([ 18.4997,  33.0383,  25.0675, 114.9560], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0842, 0.0394, 0.6191, 2.3460], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.4997,  33.0383,  25.0675, 114.9560], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5850.7798, 3284.2192, 5962.4912, 7974.3389])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 76., 112., 120., 231.])\n",
            "*************************************************\n",
            "t :  27\n",
            "ce:  tensor([ 18.3012,  32.6391,  25.2135, 112.4899], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0742, 0.0302, 0.5242, 2.2747], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.3012,  32.6391,  25.2135, 112.4899], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4277.7090, 3279.4324, 3477.6370, 7974.3389])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 52., 110.,  83., 231.])\n",
            "*************************************************\n",
            "t :  28\n",
            "ce:  tensor([ 17.9662,  32.2412,  24.9026, 110.0237], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0620, 0.0232, 0.4682, 2.2048], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.9662,  32.2412,  24.9026, 110.0237], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4277.7090, 3279.4324, 3421.1265, 7974.3389])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 52., 110.,  85., 231.])\n",
            "*************************************************\n",
            "t :  29\n",
            "ce:  tensor([ 17.6313,  31.8433,  24.5934, 107.8877], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0517, 0.0178, 0.4133, 2.1364], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.6313,  31.8433,  24.5934, 107.8877], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4277.7090, 3279.4324, 3477.6370, 7333.2197])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 52., 110.,  83., 215.])\n",
            "*************************************************\n",
            "t :  30\n",
            "ce:  tensor([ 17.3124,  31.4453,  24.4083, 105.7332], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0432, 0.0137, 0.3678, 2.0734], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.3124,  31.4453,  24.4083, 105.7332], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5839.0278, 3279.4324, 5313.2109, 7280.1831])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 76., 110., 103., 211.])\n",
            "*************************************************\n",
            "t :  31\n",
            "ce:  tensor([ 17.3729,  31.0474,  24.5849, 103.6088], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0381, 0.0106, 0.3214, 2.0163], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.3729,  31.0474,  24.5849, 103.6088], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4163.5312, 3279.4324, 3169.3125, 7280.1831])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 110.,  98., 211.])\n",
            "*************************************************\n",
            "t :  32\n",
            "ce:  tensor([ 17.0199,  30.7581,  24.3537, 102.3635], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0292, 0.0082, 0.2780, 1.9607], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.0199,  30.7581,  24.3537, 102.3635], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4163.5312, 4856.6699, 3618.8379, 6288.3242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 131.,  79., 156.])\n",
            "*************************************************\n",
            "t :  33\n",
            "ce:  tensor([ 16.6670,  30.8575,  24.1900, 100.7575], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0224, 0.0069, 0.2303, 1.9048], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.6670,  30.8575,  24.1900, 100.7575], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4163.5312, 3134.3682, 4795.8843, 6288.3242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 117., 116., 156.])\n",
            "*************************************************\n",
            "t :  34\n",
            "ce:  tensor([16.3140, 30.5063, 24.4510, 99.1514], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0172, 0.0055, 0.2120, 1.8492], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.3140, 30.5063, 24.4510, 99.1514], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4163.5312, 3641.4839, 3222.1963, 6288.3242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 121.,  94., 156.])\n",
            "*************************************************\n",
            "t :  35\n",
            "ce:  tensor([15.9611, 30.1937, 24.2407, 97.5454], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0132, 0.0043, 0.1842, 1.7944], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.9611, 30.1937, 24.2407, 97.5454], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4163.5312, 3134.3682, 4127.7192, 6288.3242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 117., 104., 156.])\n",
            "*************************************************\n",
            "t :  36\n",
            "ce:  tensor([15.7649, 29.8914, 24.1002, 95.9394], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0102, 0.0035, 0.1383, 1.7402], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.7649, 29.8914, 24.1002, 95.9394], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5734.3306, 5665.0645, 4739.7373, 6288.3242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 81., 175., 115., 156.])\n",
            "*************************************************\n",
            "t :  37\n",
            "ce:  tensor([15.7066, 30.3201, 24.4149, 94.3481], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0090, 0.0028, 0.1271, 1.6870], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.7066, 30.3201, 24.4149, 94.3481], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4163.5312, 3134.3682, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 117.,  94., 150.])\n",
            "*************************************************\n",
            "t :  38\n",
            "ce:  tensor([15.3537, 29.9483, 24.1266, 92.7937], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0070, 0.0023, 0.1104, 1.6329], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.3537, 29.9483, 24.1266, 92.7937], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4163.5303, 3134.3682, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 117.,  94., 150.])\n",
            "*************************************************\n",
            "t :  39\n",
            "ce:  tensor([15.0007, 29.5765, 23.9941, 91.2393], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0054, 0.0019, 0.0960, 1.5800], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.0007, 29.5765, 23.9941, 91.2393], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.5763e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4163.5298, 3134.3682, 6175.7275, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 117., 149., 150.])\n",
            "*************************************************\n",
            "t :  40\n",
            "ce:  tensor([14.6583, 29.4235, 24.4931, 89.6849], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0042, 0.0015, 0.0769, 1.5282], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.6583, 29.4235, 24.4931, 89.6849], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.7684e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4041.7549, 5216.2471, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 57., 129.,  94., 150.])\n",
            "*************************************************\n",
            "t :  41\n",
            "ce:  tensor([14.4519, 29.4518, 24.2243, 88.1305], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.3513e-03, 1.3689e-03, 6.7124e-02, 1.4778e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.4519, 29.4518, 24.2243, 88.1305], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.7684e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4977.5840, 3134.3682, 4127.7192, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 79., 117., 104., 150.])\n",
            "*************************************************\n",
            "t :  42\n",
            "ce:  tensor([14.5559, 29.0800, 24.1015, 86.5761], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.2531e-03, 1.1446e-03, 5.0504e-02, 1.4289e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.5559, 29.0800, 24.1015, 86.5761], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.7684e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3466.6445, 3134.3682, 4795.8843, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 63., 117., 116., 150.])\n",
            "*************************************************\n",
            "t :  43\n",
            "ce:  tensor([14.2512, 28.7082, 24.4655, 85.0217], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.6040e-03, 9.6430e-04, 4.7239e-02, 1.3815e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.2512, 28.7082, 24.4655, 85.0217], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([5.9605e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3954.9062, 3134.3682, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59., 117.,  94., 150.])\n",
            "*************************************************\n",
            "t :  44\n",
            "ce:  tensor([13.9619, 28.5323, 24.1771, 83.4673], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1098e-03, 8.1887e-04, 4.1474e-02, 1.3358e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.9619, 28.5323, 24.1771, 83.4673], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.3446e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4386.9697, 5216.2471, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([157., 129.,  94., 150.])\n",
            "*************************************************\n",
            "t :  45\n",
            "ce:  tensor([14.9780, 28.5835, 23.9056, 81.9129], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4233e-03, 7.4502e-04, 3.6541e-02, 1.2919e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.9780, 28.5835, 23.9056, 81.9129], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.5763e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5465.8496, 3134.3682, 3729.3491, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 83., 117., 101., 150.])\n",
            "*************************************************\n",
            "t :  46\n",
            "ce:  tensor([14.5189, 28.2280, 24.2219, 80.3585], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2848e-03, 6.4054e-04, 3.0171e-02, 1.2497e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.5189, 28.2280, 24.2219, 80.3585], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.7684e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3954.9065, 3043.7659, 5669.2310, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59., 113., 151., 150.])\n",
            "*************************************************\n",
            "t :  47\n",
            "ce:  tensor([14.2291, 27.9509, 24.3633, 78.8041], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0506e-03, 5.4964e-04, 2.5092e-02, 1.2095e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.2291, 27.9509, 24.3633, 78.8041], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.1526e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3290.4417, 4010.3372, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 62., 255.,  94., 150.])\n",
            "*************************************************\n",
            "t :  48\n",
            "ce:  tensor([14.1647, 29.2559, 24.0801, 77.9347], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.9450e-04, 4.2001e-04, 2.2322e-02, 1.1712e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.1647, 29.2559, 24.0801, 77.9347], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.1526e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5290.2568, 5375.3848, 3618.8379, 4611.9790])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 83., 137.,  79., 161.])\n",
            "*************************************************\n",
            "t :  49\n",
            "ce:  tensor([14.1523, 28.7133, 24.1580, 76.7699], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3852e-04, 3.8211e-04, 1.8775e-02, 1.1110e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.1523, 28.7133, 24.1580, 76.7699], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.1526e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3666.4011, 3043.7659, 4795.8843, 4611.9790])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 71., 113., 116., 161.])\n",
            "*************************************************\n",
            "t :  50\n",
            "ce:  tensor([13.9104, 28.3731, 24.2402, 75.6888], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.0588e-04, 3.3445e-04, 1.7938e-02, 1.0531e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.9104, 28.3731, 24.2402, 75.6888], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.5367e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3284.6108, 3036.4189, 3729.3491, 4462.4604])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 112., 101., 156.])\n",
            "*************************************************\n",
            "t :  51\n",
            "ce:  tensor([13.6225, 28.3501, 24.0022, 74.6057], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.5905e-04, 2.9333e-04, 1.5088e-02, 9.9400e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.6225, 28.3501, 24.0022, 74.6057], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3772.9446, 5120.0854, 3194.3450, 4062.1274])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 51., 114.,  83.,  88.])\n",
            "*************************************************\n",
            "t :  52\n",
            "ce:  tensor([13.6755, 28.4868, 24.3389, 74.6159], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.1604e-04, 2.9119e-04, 1.4151e-02, 9.7175e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.6755, 28.4868, 24.3389, 74.6159], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4796.6260, 3036.4189, 5164.6729, 6039.4648])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([75., 93., 91., 70.])\n",
            "*************************************************\n",
            "t :  53\n",
            "ce:  tensor([13.9513, 28.5060, 24.3418, 74.7716], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.5810e-04, 2.7474e-04, 1.3702e-02, 9.7736e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.9513, 28.5060, 24.3418, 74.7716], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.3446e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3949.3623, 5774.1621, 3729.3491, 4462.4604])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 51., 120.,  87.,  78.])\n",
            "*************************************************\n",
            "t :  54\n",
            "ce:  tensor([13.8458, 28.8516, 24.7177, 74.7007], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.9102e-04, 2.5448e-04, 1.2145e-02, 9.5226e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.8458, 28.8516, 24.7177, 74.7007], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.5367e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4156.0815, 3036.4189, 5895.5815, 5639.8896])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 51.,  88., 136.,  76.])\n",
            "*************************************************\n",
            "t :  55\n",
            "ce:  tensor([13.8181, 28.8080, 25.0383, 74.9538], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.1500e-04, 2.4506e-04, 1.0980e-02, 9.6048e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.8181, 28.8080, 25.0383, 74.9538], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([9.5367e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3284.6106, 4194.9004, 3222.1963, 4462.4604])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([53., 99., 78., 80.])\n",
            "*************************************************\n",
            "t :  56\n",
            "ce:  tensor([14.0910, 28.9350, 25.1667, 74.8613], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.2465e-04, 2.1491e-04, 1.0530e-02, 9.3816e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.0910, 28.9350, 25.1667, 74.8613], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.1526e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5460.5850, 4613.3867, 6909.5684, 5639.8896])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 77., 106., 144.,  76.])\n",
            "*************************************************\n",
            "t :  57\n",
            "ce:  tensor([14.1524, 29.3242, 25.6433, 75.1591], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.3144e-04, 2.2337e-04, 9.7955e-03, 9.4709e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.1524, 29.3242, 25.6433, 75.1591], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([7.1526e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5250.6797, 3043.7659, 3222.1963, 4462.4604])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([143.,  87.,  77.,  95.])\n",
            "*************************************************\n",
            "t :  58\n",
            "ce:  tensor([15.1402, 29.3137, 25.7941, 75.0889], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.0334e-04, 2.2552e-04, 9.6693e-03, 9.2305e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.1402, 29.3137, 25.7941, 75.0889], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4796.6309, 4145.6919, 5419.4580, 5639.8896])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 72., 100.,  96.,  74.])\n",
            "*************************************************\n",
            "t :  59\n",
            "ce:  tensor([15.0296, 29.5291, 26.0179, 75.2403], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.3814e-04, 1.9715e-04, 9.7264e-03, 9.3361e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.0296, 29.5291, 26.0179, 75.2403], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3842.7644, 4868.6455, 3729.3491, 4462.4604])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 54., 112.,  84.,  96.])\n",
            "*************************************************\n",
            "t :  60\n",
            "ce:  tensor([15.1518, 29.9648, 26.2412, 75.3357], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.9274e-04, 2.1670e-04, 9.0831e-03, 9.1021e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.1518, 29.9648, 26.2412, 75.3357], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5460.5884, 4524.6543, 5895.5815, 5639.8896])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 74., 216., 133.,  74.])\n",
            "*************************************************\n",
            "t :  61\n",
            "ce:  tensor([15.2977, 31.0526, 26.7512, 75.3179], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.0799e-04, 2.0407e-04, 8.7108e-03, 9.2126e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.2977, 31.0526, 26.7512, 75.3179], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4332.2012, 5023.0273, 3222.1963, 4462.4604])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 54., 119.,  75.,  96.])\n",
            "*************************************************\n",
            "t :  62\n",
            "ce:  tensor([15.2666, 31.0649, 26.6724, 75.6096], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.6616e-04, 2.2504e-04, 8.7574e-03, 8.9878e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.2666, 31.0649, 26.6724, 75.6096], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3460.8279, 3043.7659, 4127.7192, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([50., 85., 84., 60.])\n",
            "*************************************************\n",
            "t :  63\n",
            "ce:  tensor([15.4492, 31.3229, 27.2381, 75.4459], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.5055e-04, 2.3243e-04, 7.7821e-03, 9.0564e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.4492, 31.3229, 27.2381, 75.4459], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5460.5884, 5929.8252, 5051.0332, 6039.4648])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 74., 115., 105.,  37.])\n",
            "*************************************************\n",
            "t :  64\n",
            "ce:  tensor([15.5109, 31.5227, 27.2016, 75.5522], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.6223e-04, 2.3899e-04, 8.3388e-03, 9.0872e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.5109, 31.5227, 27.2016, 75.5522], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3842.7646, 3043.7659, 3222.1963, 4462.4604])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 53.,  81.,  74., 100.])\n",
            "*************************************************\n",
            "t :  65\n",
            "ce:  tensor([15.5226, 31.6060, 27.6539, 75.8587], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3041e-04, 2.5222e-04, 8.4332e-03, 8.8577e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.5226, 31.6060, 27.6539, 75.8587], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5435.0273, 5929.8252, 7381.4102, 5783.4253])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 72., 115., 152.,  74.])\n",
            "*************************************************\n",
            "t :  66\n",
            "ce:  tensor([15.9464, 31.9935, 28.0397, 75.6646], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.4304e-04, 2.6246e-04, 8.2061e-03, 8.9771e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.9464, 31.9935, 28.0397, 75.6646], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5225.4541, 3043.7659, 3618.8379, 6033.4912])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([139.,  78.,  58.,  39.])\n",
            "*************************************************\n",
            "t :  67\n",
            "ce:  tensor([16.6251, 32.0856, 28.1521, 75.7938], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8464e-04, 2.8177e-04, 7.9074e-03, 8.9872e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.6251, 32.0856, 28.1521, 75.7938], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4882.5845, 4349.9844, 5051.0332, 4605.9878])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 65.,  97., 103., 100.])\n",
            "*************************************************\n",
            "t :  68\n",
            "ce:  tensor([16.7455, 32.1023, 28.5223, 76.0909], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.0705e-04, 2.6008e-04, 8.5494e-03, 8.7681e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.7455, 32.1023, 28.5223, 76.0909], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4036.2524, 5023.0273, 3222.1963, 5634.1650])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 44., 113.,  74.,  75.])\n",
            "*************************************************\n",
            "t :  69\n",
            "ce:  tensor([16.6817, 32.6209, 28.5034, 75.9269], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9668e-04, 3.0132e-04, 8.7167e-03, 8.8677e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.6817, 32.6209, 28.5034, 75.9269], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3752.9429, 3043.7659, 5699.7466, 6183.5649])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([53., 79., 95., 46.])\n",
            "*************************************************\n",
            "t :  70\n",
            "ce:  tensor([16.9591, 32.6842, 28.9117, 75.9964], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7987e-04, 3.2372e-04, 8.6412e-03, 8.8452e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.9591, 32.6842, 28.9117, 75.9964], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5345.8218, 5317.1675, 3618.8379, 4456.4258])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 73., 197.,  55., 102.])\n",
            "*************************************************\n",
            "t :  71\n",
            "ce:  tensor([17.0542, 33.7380, 28.9319, 76.3363], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9179e-04, 3.0620e-04, 8.3844e-03, 8.6679e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.0542, 33.7380, 28.9319, 76.3363], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4393.3105, 5023.0273, 3692.2107, 5783.4253])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 50., 116., 121.,  74.])\n",
            "*************************************************\n",
            "t :  72\n",
            "ce:  tensor([17.0539, 33.7330, 29.4931, 76.1548], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6748e-04, 3.5149e-04, 7.9015e-03, 8.8149e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.0539, 33.7330, 29.4931, 76.1548], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3259.2422, 3550.8931, 5954.7959, 6033.4912])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([52., 78., 98., 37.])\n",
            "*************************************************\n",
            "t :  73\n",
            "ce:  tensor([17.4262, 33.8465, 29.6553, 76.2099], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7820e-04, 3.7317e-04, 7.9644e-03, 8.8491e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.4262, 33.8465, 29.6553, 76.2099], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5371.3159, 5422.0186, 3222.1963, 4056.0886])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 71., 109.,  73., 113.])\n",
            "*************************************************\n",
            "t :  74\n",
            "ce:  tensor([17.4789, 34.2937, 29.8840, 76.6659], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8869e-04, 4.0451e-04, 8.2232e-03, 8.6027e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.4789, 34.2937, 29.8840, 76.6659], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5336.2388, 3043.7659, 6909.5684, 6183.5649])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([139.,  76., 141.,  68.])\n",
            "*************************************************\n",
            "t :  75\n",
            "ce:  tensor([18.5805, 34.3099, 30.2884, 76.4470], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4793e-04, 4.4336e-04, 8.2151e-03, 8.6971e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.5805, 34.3099, 30.2884, 76.4470], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4882.5850, 4349.9844, 3222.1963, 6033.4912])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([62., 96., 75., 33.])\n",
            "*************************************************\n",
            "t :  76\n",
            "ce:  tensor([18.3548, 34.4413, 30.5266, 76.4312], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6473e-04, 4.1536e-04, 8.5182e-03, 8.7479e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.3548, 34.4413, 30.5266, 76.4312], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5927.3892, 4620.6113, 5447.1362, 4605.9878])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 68., 104.,  91.,  99.])\n",
            "*************************************************\n",
            "t :  77\n",
            "ce:  tensor([18.7094, 34.9007, 30.7376, 76.8601], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6676e-04, 4.8018e-04, 8.9131e-03, 8.5653e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.7094, 34.9007, 30.7376, 76.8601], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3547.4165, 3550.8931, 4127.7192, 5634.1650])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([48., 79., 79., 75.])\n",
            "*************************************************\n",
            "t :  78\n",
            "ce:  tensor([18.6890, 34.9299, 30.8142, 76.7272], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7463e-04, 5.0997e-04, 8.2677e-03, 8.6951e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.6890, 34.9299, 30.8142, 76.7272], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4418.7959, 3840.9678, 4795.8843, 6183.5649])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([50., 73., 93., 45.])\n",
            "*************************************************\n",
            "t :  79\n",
            "ce:  tensor([18.8258, 34.9417, 31.2277, 76.6518], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4995e-04, 5.1497e-04, 8.8232e-03, 8.7076e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.8258, 34.9417, 31.2277, 76.6518], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5428.2407, 3043.7659, 3618.8379, 6033.4912])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([89., 73., 57., 32.])\n",
            "*************************************************\n",
            "t :  80\n",
            "ce:  tensor([19.4238, 35.4987, 31.2242, 76.7831], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5842e-04, 5.6799e-04, 8.5525e-03, 8.7666e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.4238, 35.4987, 31.2242, 76.7831], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4393.3115, 5422.0186, 3943.2976, 4605.9878])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 47., 103., 120., 100.])\n",
            "*************************************************\n",
            "t :  81\n",
            "ce:  tensor([19.3303, 35.5603, 31.6524, 77.0663], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3792e-04, 6.3018e-04, 7.9497e-03, 8.5949e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.3303, 35.5603, 31.6524, 77.0663], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4010.8267, 4667.9570, 5699.7466, 5634.1650])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 38., 202.,  97.,  75.])\n",
            "*************************************************\n",
            "t :  82\n",
            "ce:  tensor([19.3846, 36.8799, 31.9396, 76.9223], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3577e-04, 6.5365e-04, 8.1626e-03, 8.7330e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.3846, 36.8799, 31.9396, 76.9223], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5665.5654, 5023.0273, 3222.1963, 6183.5649])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 71., 109.,  74.,  45.])\n",
            "*************************************************\n",
            "t :  83\n",
            "ce:  tensor([19.7436, 36.6958, 32.0797, 76.9787], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3875e-04, 7.6789e-04, 8.4090e-03, 8.7539e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.7436, 36.6958, 32.0797, 76.9787], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4843.9102, 3840.9678, 6909.5684, 4456.4258])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([137.,  71., 142., 101.])\n",
            "*************************************************\n",
            "t :  84\n",
            "ce:  tensor([20.7543, 36.7238, 32.5650, 77.3135], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2552e-04, 7.5812e-04, 8.7394e-03, 8.5959e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([20.7543, 36.7238, 32.5650, 77.3135], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5439.0215, 4620.6113, 3222.1963, 5783.4253])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([64., 96., 77., 71.])\n",
            "*************************************************\n",
            "t :  85\n",
            "ce:  tensor([20.7141, 37.3003, 32.7599, 77.2522], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3577e-04, 8.5115e-04, 8.9586e-03, 8.7568e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([20.7141, 37.3003, 32.7599, 77.2522], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4418.7959, 3550.8931, 5954.7959, 6990.2280])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([48., 84., 95., 91.])\n",
            "*************************************************\n",
            "t :  86\n",
            "ce:  tensor([20.8399, 37.3266, 32.9801, 77.4369], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1932e-04, 8.9248e-04, 9.5116e-03, 8.8020e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([20.8399, 37.3266, 32.9801, 77.4369], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5058.0571, 3840.9678, 3618.8379, 6183.5649])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([62., 67., 56., 38.])\n",
            "*************************************************\n",
            "t :  87\n",
            "ce:  tensor([21.0959, 37.2947, 32.9106, 77.5213], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3935e-04, 9.0308e-04, 9.3560e-03, 8.8054e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.0959, 37.2947, 32.9106, 77.5213], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4418.7959, 3441.5703, 4795.8843, 4056.0886])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 49.,  51.,  93., 112.])\n",
            "*************************************************\n",
            "t :  88\n",
            "ce:  tensor([21.1129, 37.3889, 33.4817, 77.9177], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2290e-04, 9.1701e-04, 1.0157e-02, 8.5983e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.1129, 37.3889, 33.4817, 77.9177], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3996.8647, 5675.0059, 4127.7192, 6183.5649])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 72., 102.,  76.,  64.])\n",
            "*************************************************\n",
            "t :  89\n",
            "ce:  tensor([21.4863, 37.7867, 33.4910, 77.7039], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1646e-04, 1.0281e-03, 9.4828e-03, 8.7048e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.4863, 37.7867, 33.4910, 77.7039], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6175.7021, 3043.7659, 3480.5066, 6033.4912])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([70., 81., 64., 30.])\n",
            "*************************************************\n",
            "t :  90\n",
            "ce:  tensor([21.7380, 37.8590, 33.6974, 77.7550], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2266e-04, 1.1293e-03, 9.8538e-03, 8.7607e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.7380, 37.8590, 33.6974, 77.7550], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4036.2529, 5929.8252, 5527.2485, 5571.6934])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 42., 108., 129., 176.])\n",
            "*************************************************\n",
            "t :  91\n",
            "ce:  tensor([21.6769, 38.2817, 34.2894, 79.1310], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2135e-04, 1.2327e-03, 1.0258e-02, 8.6989e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.6769, 38.2817, 34.2894, 79.1310], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4087.7905, 3295.3997, 5248.8394, 5783.4253])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 35.,  68., 192.,  70.])\n",
            "*************************************************\n",
            "t :  92\n",
            "ce:  tensor([21.7143, 38.2824, 35.2881, 78.9309], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1801e-04, 1.3047e-03, 9.4534e-03, 8.8245e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.7143, 38.2824, 35.2881, 78.9309], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5284.9844, 4559.1118, 5058.1914, 6183.5649])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 63., 200.,  98.,  37.])\n",
            "*************************************************\n",
            "t :  93\n",
            "ce:  tensor([22.1131, 39.6761, 35.3583, 78.8291], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3124e-04, 1.3362e-03, 1.0442e-02, 8.8364e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.1131, 39.6761, 35.3583, 78.8291], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4418.7959, 5530.2788, 4282.4531, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 44., 104.,  81.,  54.])\n",
            "*************************************************\n",
            "t :  94\n",
            "ce:  tensor([22.1153, 39.4334, 35.6304, 78.7205], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1944e-04, 1.5095e-03, 9.5234e-03, 8.8628e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.1153, 39.4334, 35.6304, 78.7205], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3706.3625, 3532.0894, 5058.1914, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([38., 72., 93., 60.])\n",
            "*************************************************\n",
            "t :  95\n",
            "ce:  tensor([22.0937, 39.5742, 35.8770, 78.9082], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2314e-04, 1.5204e-03, 1.0407e-02, 8.9563e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.0937, 39.5742, 35.8770, 78.9082], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5074.5400, 6527.5713, 3736.6021, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([136., 128.,  89., 109.])\n",
            "*************************************************\n",
            "t :  96\n",
            "ce:  tensor([23.6171, 40.0206, 36.1660, 79.1379], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0371e-04, 1.6310e-03, 1.0254e-02, 8.7606e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([23.6171, 40.0206, 36.1660, 79.1379], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5761.4141, 3134.3682, 6076.3335, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 78.,  86., 125.,  88.])\n",
            "*************************************************\n",
            "t :  97\n",
            "ce:  tensor([23.4604, 40.1220, 36.5722, 79.0454], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1408e-04, 1.7958e-03, 1.0631e-02, 8.8949e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([23.4604, 40.1220, 36.5722, 79.0454], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6175.7021, 5929.8252, 3773.5154, 4296.1665])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 63., 109.,  72., 116.])\n",
            "*************************************************\n",
            "t :  98\n",
            "ce:  tensor([23.7435, 40.5081, 36.4950, 79.5215], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2099e-04, 1.9735e-03, 1.0232e-02, 8.6872e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([23.7435, 40.5081, 36.4950, 79.5215], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4036.2529, 3137.5005, 5058.1914, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([44., 97., 95., 86.])\n",
            "*************************************************\n",
            "t :  99\n",
            "ce:  tensor([23.6692, 40.6556, 37.0363, 79.3094], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1765e-04, 2.1802e-03, 1.1222e-02, 8.8431e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([23.6692, 40.6556, 37.0363, 79.3094], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4282.4858, 5932.6035, 4282.4531, 6432.9019])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 32., 108.,  85., 102.])\n",
            "*************************************************\n",
            "t :  100\n",
            "ce:  tensor([23.7121, 40.9868, 36.9294, 79.6459], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1956e-04, 2.3764e-03, 1.0264e-02, 8.9369e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([23.7121, 40.9868, 36.9294, 79.6459], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5511.0020, 3535.3945, 3480.5066, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 69.,  82.,  60., 105.])\n",
            "*************************************************\n",
            "t :  101\n",
            "ce:  tensor([24.1461, 40.8681, 37.3035, 80.0360], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3136e-04, 2.4394e-03, 1.0743e-02, 8.7520e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([24.1461, 40.8681, 37.3035, 80.0360], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4036.2529, 3591.7812, 6110.1924, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([43., 64., 96., 88.])\n",
            "*************************************************\n",
            "t :  102\n",
            "ce:  tensor([24.0378, 41.0538, 37.3378, 79.7685], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2874e-04, 2.4981e-03, 1.1440e-02, 8.9182e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([24.0378, 41.0538, 37.3378, 79.7685], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3859.8052, 4872.6562, 3222.9758, 4296.1665])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 29., 100.,  89., 117.])\n",
            "*************************************************\n",
            "t :  103\n",
            "ce:  tensor([24.0780, 41.4986, 38.0247, 80.3766], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2910e-04, 2.8308e-03, 1.1590e-02, 8.7263e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([24.0780, 41.4986, 38.0247, 80.3766], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5913.8164, 5668.0283, 7175.5098, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 74., 220., 149.,  93.])\n",
            "*************************************************\n",
            "t :  104\n",
            "ce:  tensor([24.5168, 42.7207, 38.1355, 80.0522], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4161e-04, 2.6847e-03, 1.2276e-02, 8.9061e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([24.5168, 42.7207, 38.1355, 80.0522], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4036.2529, 5019.9370, 4734.0596, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 44.,  95., 189.,  50.])\n",
            "*************************************************\n",
            "t :  105\n",
            "ce:  tensor([24.4456, 42.5863, 39.8591, 80.3798], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3303e-04, 3.0227e-03, 1.1604e-02, 8.9960e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([24.4456, 42.5863, 39.8591, 80.3798], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3734.8230, 4037.2888, 5674.1445, 5413.7148])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 64.,  98., 130., 187.])\n",
            "*************************************************\n",
            "t :  106\n",
            "ce:  tensor([24.8144, 42.8553, 39.8092, 81.5018], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2588e-04, 2.9221e-03, 1.2353e-02, 8.9333e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([24.8144, 42.8553, 39.8092, 81.5018], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6175.7021, 5419.0410, 6702.2910, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 68., 103.,  96.,  87.])\n",
            "*************************************************\n",
            "t :  107\n",
            "ce:  tensor([25.1224, 42.9602, 39.9197, 81.1926], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3351e-04, 3.2388e-03, 1.2551e-02, 9.0778e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([25.1224, 42.9602, 39.9197, 81.1926], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4418.7959, 3130.8225, 3474.1106, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 50., 111.,  82.,  47.])\n",
            "*************************************************\n",
            "t :  108\n",
            "ce:  tensor([25.0315, 43.5033, 40.3174, 81.1111], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1694e-04, 3.3997e-03, 1.2874e-02, 9.1250e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([25.0315, 43.5033, 40.3174, 81.1111], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4285.4678, 5926.8262, 6104.4409, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 23., 113., 103.,  48.])\n",
            "*************************************************\n",
            "t :  109\n",
            "ce:  tensor([25.0783, 43.3181, 40.2141, 81.2433], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1849e-04, 3.7459e-03, 1.3973e-02, 9.2028e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([25.0783, 43.3181, 40.2141, 81.2433], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4933.9775, 3528.9597, 3368.9814, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61.,  96.,  94., 118.])\n",
            "*************************************************\n",
            "t :  110\n",
            "ce:  tensor([25.4672, 43.6245, 40.7408, 81.6206], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3756e-04, 3.6786e-03, 1.3842e-02, 9.0051e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([25.4672, 43.6245, 40.7408, 81.6206], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5215.8384, 5926.8262, 6104.4409, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([150., 107., 103.,  95.])\n",
            "*************************************************\n",
            "t :  111\n",
            "ce:  tensor([26.4396, 43.6022, 40.6057, 81.3735], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2087e-04, 4.0691e-03, 1.5086e-02, 9.1578e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.4396, 43.6022, 40.6057, 81.3735], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5640.1587, 3130.8225, 4472.5088, 5876.9805])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 98., 123.,  95.,  37.])\n",
            "*************************************************\n",
            "t :  112\n",
            "ce:  tensor([26.6781, 44.3098, 41.0969, 81.4587], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2838e-04, 4.1677e-03, 1.4169e-02, 9.1362e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.6781, 44.3098, 41.0969, 81.4587], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4160.5962, 6524.4004, 5528.8252, 5413.7148])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 40., 134., 130., 187.])\n",
            "*************************************************\n",
            "t :  113\n",
            "ce:  tensor([26.5341, 44.0294, 41.4157, 82.8752], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2171e-04, 4.4851e-03, 1.4855e-02, 9.0805e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.5341, 44.0294, 41.4157, 82.8752], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5673.4570, 5270.5859, 4276.5112, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 72.,  59., 101.,  85.])\n",
            "*************************************************\n",
            "t :  114\n",
            "ce:  tensor([26.9977, 44.3427, 41.8239, 82.5369], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3494e-04, 4.7478e-03, 1.3946e-02, 9.2137e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.9977, 44.3427, 41.8239, 82.5369], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4297.0835, 4351.2515, 5199.2969, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 49., 222.,  97.,  41.])\n",
            "*************************************************\n",
            "t :  115\n",
            "ce:  tensor([26.8628, 46.0424, 41.7120, 82.5355], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2123e-04, 4.8374e-03, 1.4878e-02, 9.2053e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.8628, 46.0424, 41.7120, 82.5355], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3914.3486, 6015.5127, 4983.7261, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 27.,  99., 117.,  45.])\n",
            "*************************************************\n",
            "t :  116\n",
            "ce:  tensor([26.8338, 45.6582, 42.4434, 82.4919], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2218e-04, 5.2206e-03, 1.3597e-02, 9.2909e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.8338, 45.6582, 42.4434, 82.4919], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3914.3486, 5507.8164, 5199.2969, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([21., 44., 91., 41.])\n",
            "*************************************************\n",
            "t :  117\n",
            "ce:  tensor([26.9992, 45.6006, 42.1608, 82.5669], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2302e-04, 5.5177e-03, 1.4550e-02, 9.2790e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.9992, 45.6006, 42.1608, 82.5669], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5879.0439, 5616.1987, 3767.2747, 3895.4583])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 78.,  48.,  87., 131.])\n",
            "*************************************************\n",
            "t :  118\n",
            "ce:  tensor([27.3681, 45.6786, 42.7006, 83.1516], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3839e-04, 5.8113e-03, 1.3631e-02, 9.1317e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.3681, 45.6786, 42.7006, 83.1516], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3914.3486, 4529.5034, 6005.1001, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 45., 116., 141.,  92.])\n",
            "*************************************************\n",
            "t :  119\n",
            "ce:  tensor([27.2327, 46.2673, 42.7241, 82.8385], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3458e-04, 5.3954e-03, 1.4418e-02, 9.2767e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.2327, 46.2673, 42.7241, 82.8385], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3425.2725, 5108.6631, 5448.5859, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([28., 89., 57., 38.])\n",
            "*************************************************\n",
            "t :  120\n",
            "ce:  tensor([27.3539, 45.9831, 42.8760, 82.8100], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4149e-04, 6.1366e-03, 1.4938e-02, 9.3577e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.3539, 45.9831, 42.8760, 82.8100], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5805.8774, 5760.9009, 3871.6394, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([71., 57., 68., 38.])\n",
            "*************************************************\n",
            "t :  121\n",
            "ce:  tensor([27.6861, 46.1214, 43.0432, 82.9249], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5746e-04, 6.2472e-03, 1.4104e-02, 9.3498e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.6861, 46.1214, 43.0432, 82.9249], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3914.3486, 3382.5669, 5674.1445, 3895.4583])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 45., 108., 137., 132.])\n",
            "*************************************************\n",
            "t :  122\n",
            "ce:  tensor([27.5549, 46.6214, 43.6197, 83.4858], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5150e-04, 5.9236e-03, 1.4757e-02, 9.2061e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.5549, 46.6214, 43.6197, 83.4858], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4297.0835, 5507.8164, 4879.6724, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 30.,  95., 127.,  92.])\n",
            "*************************************************\n",
            "t :  123\n",
            "ce:  tensor([27.5928, 46.2718, 43.9091, 83.2789], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4364e-04, 6.6933e-03, 1.3528e-02, 9.3581e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.5928, 46.2718, 43.9091, 83.2789], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5673.4570, 3890.6902, 5052.7095, 6982.9194])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 74., 119.,  96., 106.])\n",
            "*************************************************\n",
            "t :  124\n",
            "ce:  tensor([28.0414, 46.9617, 43.9573, 83.5897], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6199e-04, 6.2292e-03, 1.4757e-02, 9.4629e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.0414, 46.9617, 43.9573, 83.5897], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4297.0835, 5507.8164, 3871.6394, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([50., 97., 72., 65.])\n",
            "*************************************************\n",
            "t :  125\n",
            "ce:  tensor([27.9317, 46.5884, 43.9965, 83.5793], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4376e-04, 7.0442e-03, 1.3741e-02, 9.5265e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.9317, 46.5884, 43.9965, 83.5793], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3425.2725, 5700.3252, 5199.2969, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 29.,  58.,  94., 125.])\n",
            "*************************************************\n",
            "t :  126\n",
            "ce:  tensor([27.9203, 46.7043, 44.2506, 83.9830], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5055e-04, 6.9795e-03, 1.4797e-02, 9.3329e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.9203, 46.7043, 44.2506, 83.9830], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3914.3486, 4961.4976, 4472.5088, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 22.,  60., 104.,  94.])\n",
            "*************************************************\n",
            "t :  127\n",
            "ce:  tensor([28.0593, 47.0685, 44.4203, 83.7132], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4745e-04, 7.3141e-03, 1.3528e-02, 9.5110e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.0593, 47.0685, 44.4203, 83.7132], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5879.0439, 5154.4316, 6151.3740, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 81., 227., 130.,  38.])\n",
            "*************************************************\n",
            "t :  128\n",
            "ce:  tensor([28.4615, 48.5231, 44.7158, 83.7757], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6473e-04, 6.9459e-03, 1.4272e-02, 9.4994e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.4615, 48.5231, 44.7158, 83.7757], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3914.3486, 5108.6631, 4018.8694, 3895.4583])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 47.,  97.,  74., 132.])\n",
            "*************************************************\n",
            "t :  129\n",
            "ce:  tensor([28.3229, 48.1768, 44.8379, 84.3942], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5937e-04, 7.7925e-03, 1.3583e-02, 9.3666e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.3229, 48.1768, 44.8379, 84.3942], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4297.0835, 6015.5127, 5528.8252, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 28.,  41., 137.,  89.])\n",
            "*************************************************\n",
            "t :  130\n",
            "ce:  tensor([28.3421, 48.1777, 45.4002, 84.2023], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5091e-04, 7.7417e-03, 1.4323e-02, 9.5331e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.3421, 48.1777, 45.4002, 84.2023], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3914.3486, 5108.6631, 4527.8179, 6581.1318])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 24.,  43., 102., 111.])\n",
            "*************************************************\n",
            "t :  131\n",
            "ce:  tensor([28.4192, 48.2139, 45.2782, 84.5083], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5258e-04, 8.1117e-03, 1.3313e-02, 9.6577e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.4192, 48.2139, 45.2782, 84.5083], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5392.6021, 6613.1499, 5052.7095, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([75., 66., 94., 59.])\n",
            "*************************************************\n",
            "t :  132\n",
            "ce:  tensor([28.8302, 48.3370, 45.7091, 84.3666], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7594e-04, 7.7986e-03, 1.4440e-02, 9.6829e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.8302, 48.3370, 45.7091, 84.3666], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4297.0835, 4961.4976, 4879.6724, 4043.6084])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 49.,  59., 137., 115.])\n",
            "*************************************************\n",
            "t :  133\n",
            "ce:  tensor([28.7090, 48.5362, 46.0352, 84.9040], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5734e-04, 8.1659e-03, 1.3123e-02, 9.5693e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.7090, 48.5362, 46.0352, 84.9040], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4119.5527, 4437.6265, 5052.7095, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 67., 119.,  95.,  83.])\n",
            "*************************************************\n",
            "t :  134\n",
            "ce:  tensor([29.0373, 48.8346, 46.0766, 84.6624], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5520e-04, 7.6164e-03, 1.4412e-02, 9.7292e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([29.0373, 48.8346, 46.0766, 84.6624], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4440.7798, 5108.6631, 4018.8694, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([45., 93., 78., 38.])\n",
            "*************************************************\n",
            "t :  135\n",
            "ce:  tensor([28.9355, 48.6759, 46.1457, 84.6597], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4495e-04, 8.4437e-03, 1.3243e-02, 9.8272e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.9355, 48.6759, 46.1457, 84.6597], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3671.2698, 4437.6265, 5052.7095, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 37., 114.,  94.,  32.])\n",
            "*************************************************\n",
            "t :  136\n",
            "ce:  tensor([29.1073, 49.0816, 46.3850, 84.6849], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5186e-04, 7.7967e-03, 1.4534e-02, 9.8525e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([29.1073, 49.0816, 46.3850, 84.6849], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6198.2720, 4961.4976, 5585.1743, 3895.4583])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 84.,  99., 198., 129.])\n",
            "*************************************************\n",
            "t :  137\n",
            "ce:  tensor([29.6099, 48.9194, 47.7178, 85.3463], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7034e-04, 8.4440e-03, 1.3790e-02, 9.7318e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([29.6099, 48.9194, 47.7178, 85.3463], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5388.7842, 4185.2021, 5674.1445, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([151., 134., 126.,  85.])\n",
            "*************************************************\n",
            "t :  138\n",
            "ce:  tensor([30.3951, 49.5435, 47.6155, 85.0970], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5079e-04, 7.9910e-03, 1.4342e-02, 9.9258e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([30.3951, 49.5435, 47.6155, 85.0970], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5497.9746, 4872.6562, 5596.6099, 6581.1318])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75., 109.,  50., 113.])\n",
            "*************************************************\n",
            "t :  139\n",
            "ce:  tensor([30.4350, 49.2846, 47.6255, 85.4639], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7117e-04, 8.8269e-03, 1.4642e-02, 1.0070e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([30.4350, 49.2846, 47.6255, 85.4639], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4178.0952, 4639.2568, 3981.7954, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 55., 142.,  97.,  57.])\n",
            "*************************************************\n",
            "t :  140\n",
            "ce:  tensor([30.3844, 49.9957, 48.1492, 85.3074], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5746e-04, 8.1132e-03, 1.3805e-02, 1.0121e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([30.3844, 49.9957, 48.1492, 85.3074], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5857.4336, 4872.6562, 5596.6099, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 73., 101.,  94.,  31.])\n",
            "*************************************************\n",
            "t :  141\n",
            "ce:  tensor([30.7204, 49.6478, 47.8460, 85.4073], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7403e-04, 9.0147e-03, 1.4946e-02, 1.0189e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([30.7204, 49.6478, 47.8460, 85.4073], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 6015.5127, 3871.6394, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60.,  49.,  75., 125.])\n",
            "*************************************************\n",
            "t :  142\n",
            "ce:  tensor([30.6153, 49.7056, 48.1813, 85.8692], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5293e-04, 9.0537e-03, 1.3944e-02, 1.0001e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([30.6153, 49.7056, 48.1813, 85.8692], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5919.6084, 3382.5669, 5199.2969, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111., 115.,  91.,  87.])\n",
            "*************************************************\n",
            "t :  143\n",
            "ce:  tensor([31.3995, 50.2592, 48.1129, 85.5726], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6473e-04, 8.5112e-03, 1.5220e-02, 1.0196e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.3995, 50.2592, 48.1129, 85.5726], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4526.5088, 5419.0410, 4472.5088, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59., 106., 109.,  30.])\n",
            "*************************************************\n",
            "t :  144\n",
            "ce:  tensor([31.1739, 49.9089, 48.5777, 85.6053], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4936e-04, 9.3378e-03, 1.4035e-02, 1.0199e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.1739, 49.9089, 48.5777, 85.6053], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4233.2017, 5958.8301, 5199.2969, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([32., 64., 85., 35.])\n",
            "*************************************************\n",
            "t :  145\n",
            "ce:  tensor([31.1483, 50.0328, 48.3050, 85.5873], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4304e-04, 9.4722e-03, 1.5250e-02, 1.0270e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.1483, 50.0328, 48.3050, 85.5873], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 3780.6240, 3871.6394, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 36., 111.,  80.,  30.])\n",
            "*************************************************\n",
            "t :  146\n",
            "ce:  tensor([31.2858, 50.4922, 48.8005, 85.6867], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3589e-04, 9.0639e-03, 1.4094e-02, 1.0267e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.2858, 50.4922, 48.8005, 85.6867], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5300.8667, 5527.3755, 5674.1445, 4866.2031])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 78., 104., 133., 218.])\n",
            "*************************************************\n",
            "t :  147\n",
            "ce:  tensor([31.7044, 50.2009, 48.8593, 87.4969], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5341e-04, 1.0055e-02, 1.5111e-02, 1.0289e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.7044, 50.2009, 48.8593, 87.4969], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 3276.1934, 4879.6724, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 127., 136.,  85.])\n",
            "*************************************************\n",
            "t :  148\n",
            "ce:  tensor([31.4816, 50.8124, 49.6578, 87.1547], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3601e-04, 9.4215e-03, 1.4051e-02, 1.0396e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.4816, 50.8124, 49.6578, 87.1547], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3766.7300, 5926.8262, 5052.7095, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 29., 109.,  92.,  15.])\n",
            "*************************************************\n",
            "t :  149\n",
            "ce:  tensor([31.4946, 50.4082, 49.2708, 87.1331], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3649e-04, 1.0356e-02, 1.5529e-02, 1.0438e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.4946, 50.4082, 49.2708, 87.1331], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 5467.1333, 5052.7095, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([39., 57., 28., 14.])\n",
            "*************************************************\n",
            "t :  150\n",
            "ce:  tensor([31.7128, 50.5549, 49.3913, 87.1345], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2993e-04, 1.0308e-02, 1.5992e-02, 1.0473e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.7128, 50.5549, 49.3913, 87.1345], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5447.6450, 4346.9844, 4982.5581, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 85., 113., 189.,  29.])\n",
            "*************************************************\n",
            "t :  151\n",
            "ce:  tensor([32.0753, 50.9854, 51.0075, 87.1406], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4995e-04, 9.7897e-03, 1.5220e-02, 1.0534e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([32.0753, 50.9854, 51.0075, 87.1406], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 5019.9370, 5199.2969, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 103.,  76.,  28.])\n",
            "*************************************************\n",
            "t :  152\n",
            "ce:  tensor([31.8697, 50.7819, 50.6723, 87.1223], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3029e-04, 1.0785e-02, 1.6535e-02, 1.0532e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.8697, 50.7819, 50.6723, 87.1223], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6081.6450, 4289.6421, 6193.0381, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([100., 124.,  56.,  28.])\n",
            "*************************************************\n",
            "t :  153\n",
            "ce:  tensor([32.6253, 51.3275, 50.8153, 87.1358], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4662e-04, 9.9811e-03, 1.6532e-02, 1.0590e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([32.6253, 51.3275, 50.8153, 87.1358], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4526.5088, 5019.9370, 5052.7095, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 109.,  46.,  27.])\n",
            "*************************************************\n",
            "t :  154\n",
            "ce:  tensor([32.3731, 50.9646, 50.7304, 87.1137], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3231e-04, 1.1043e-02, 1.7403e-02, 1.0585e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([32.3731, 50.9646, 50.7304, 87.1137], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3725.7896, 3946.9497, 6104.4409, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 36., 130.,  49.,  27.])\n",
            "*************************************************\n",
            "t :  155\n",
            "ce:  tensor([32.4133, 51.7910, 50.7825, 87.1664], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3017e-04, 1.0111e-02, 1.7625e-02, 1.0641e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([32.4133, 51.7910, 50.7825, 87.1664], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4526.5088, 5019.9370, 5052.7095, 6624.5796])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 40., 109.,  43.,  58.])\n",
            "*************************************************\n",
            "t :  156\n",
            "ce:  tensor([32.4396, 51.4956, 50.8532, 87.2364], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2874e-04, 1.1278e-02, 1.8240e-02, 1.0600e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([32.4396, 51.4956, 50.8532, 87.2364], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5627.4492, 7080.8564, 4620.0420, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 76., 141., 115.,  37.])\n",
            "*************************************************\n",
            "t :  157\n",
            "ce:  tensor([32.9917, 51.9364, 51.6459, 87.1945], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4435e-04, 1.1166e-02, 1.6746e-02, 1.0697e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([32.9917, 51.9364, 51.6459, 87.1945], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5338.8975, 5019.9370, 5528.8252, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([161.,  75., 134.,  26.])\n",
            "*************************************************\n",
            "t :  158\n",
            "ce:  tensor([33.9036, 51.9109, 51.4927, 87.1825], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2480e-04, 1.1882e-02, 1.8181e-02, 1.0690e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([33.9036, 51.9109, 51.4927, 87.1825], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5447.6450, 4437.6265, 6702.2910, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 85., 120.,  88.,  28.])\n",
            "*************************************************\n",
            "t :  159\n",
            "ce:  tensor([33.8261, 52.3489, 51.6063, 87.1942], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4435e-04, 1.1152e-02, 1.8509e-02, 1.0748e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([33.8261, 52.3489, 51.6063, 87.1942], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3871.7646, 5019.9370, 5052.7095, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 51., 108.,  49.,  26.])\n",
            "*************************************************\n",
            "t :  160\n",
            "ce:  tensor([33.8131, 52.0961, 51.7273, 87.1849], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3064e-04, 1.2136e-02, 1.9412e-02, 1.0743e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([33.8131, 52.0961, 51.7273, 87.1849], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6316.3989, 4199.0859, 4527.8179, 6223.0596])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([113., 115., 112.,  57.])\n",
            "*************************************************\n",
            "t :  161\n",
            "ce:  tensor([34.4467, 52.5840, 52.1629, 87.3067], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3887e-04, 1.1379e-02, 1.8135e-02, 1.0753e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.4467, 52.5840, 52.1629, 87.3067], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4127.5903, 5019.9370, 5052.7095, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59., 109.,  89.,  36.])\n",
            "*************************************************\n",
            "t :  162\n",
            "ce:  tensor([34.1597, 52.2843, 51.9164, 87.2368], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3184e-04, 1.2493e-02, 2.0118e-02, 1.0785e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.1597, 52.2843, 51.9164, 87.2368], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3871.7646, 3800.1702, 3623.6011, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 27., 113.,  87., 115.])\n",
            "*************************************************\n",
            "t :  163\n",
            "ce:  tensor([34.1689, 52.7932, 52.2568, 87.8345], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3279e-04, 1.1769e-02, 1.8684e-02, 1.0619e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.1689, 52.7932, 52.2568, 87.8345], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4127.5903, 5419.0410, 6005.1001, 5117.7295])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 31., 110., 132.,  99.])\n",
            "*************************************************\n",
            "t :  164\n",
            "ce:  tensor([34.2128, 52.5014, 52.3376, 87.7081], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3255e-04, 1.2989e-02, 2.0455e-02, 1.0819e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.2128, 52.5014, 52.3376, 87.7081], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5300.8667, 4491.8130, 5599.4731, 6985.9580])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 80., 156.,  54., 119.])\n",
            "*************************************************\n",
            "t :  165\n",
            "ce:  tensor([34.7134, 53.3824, 52.4122, 88.0227], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5162e-04, 1.2186e-02, 2.1134e-02, 1.0912e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.7134, 53.3824, 52.4122, 88.0227], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4526.5088, 5419.0410, 3477.0913, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 112.,  94.,  55.])\n",
            "*************************************************\n",
            "t :  166\n",
            "ce:  tensor([34.4339, 52.9552, 52.7640, 87.8621], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3625e-04, 1.3418e-02, 2.0329e-02, 1.0971e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.4339, 52.9552, 52.7640, 87.8621], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4233.2017, 5379.7334, 5596.6099, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([33., 50., 93., 29.])\n",
            "*************************************************\n",
            "t :  167\n",
            "ce:  tensor([34.4849, 53.0377, 52.5786, 87.8539], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3386e-04, 1.3801e-02, 2.2017e-02, 1.0952e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.4849, 53.0377, 52.5786, 87.8539], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6096.8525, 6372.9980, 4383.4482, 5465.7588])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87., 124., 106.,  34.])\n",
            "*************************************************\n",
            "t :  168\n",
            "ce:  tensor([34.9768, 53.3965, 53.0307, 87.9454], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5246e-04, 1.3930e-02, 2.0964e-02, 1.0991e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.9768, 53.3965, 53.0307, 87.9454], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3981.1953, 5108.6631, 5674.1445, 4437.6265])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 55.,  63., 141., 121.])\n",
            "*************************************************\n",
            "t :  169\n",
            "ce:  tensor([34.7129, 53.4712, 53.1448, 88.3964], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4423e-04, 1.4804e-02, 2.2552e-02, 1.0818e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.7129, 53.4712, 53.1448, 88.3964], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3871.7646, 4437.6265, 5134.5366, 5613.3345])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 25., 122., 133.,  88.])\n",
            "*************************************************\n",
            "t :  170\n",
            "ce:  tensor([34.7351, 53.8333, 53.6641, 88.1470], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4662e-04, 1.3876e-02, 2.1427e-02, 1.1008e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.7351, 53.8333, 53.6641, 88.1470], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 5019.9370, 5055.3926, 6464.2217])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 37., 110.,  91.,  51.])\n",
            "*************************************************\n",
            "t :  171\n",
            "ce:  tensor([34.7899, 53.6186, 53.3061, 88.2228], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3970e-04, 1.5160e-02, 2.3451e-02, 1.0945e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.7899, 53.6186, 53.3061, 88.2228], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5447.6450, 4289.6421, 3225.9370, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 85., 130., 112.,  40.])\n",
            "*************************************************\n",
            "t :  172\n",
            "ce:  tensor([35.3096, 54.1612, 54.1102, 88.2264], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6307e-04, 1.4211e-02, 2.2332e-02, 1.1060e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([35.3096, 54.1612, 54.1102, 88.2264], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 5019.9370, 6552.3452, 6822.9453])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 64., 114., 138., 108.])\n",
            "*************************************************\n",
            "t :  173\n",
            "ce:  tensor([35.0372, 53.7834, 53.9987, 88.6001], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4304e-04, 1.5756e-02, 2.4174e-02, 1.1113e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([35.0372, 53.7834, 53.9987, 88.6001], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3620.0469, 3800.1702, 5055.3926, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 27., 115.,  53.,  58.])\n",
            "*************************************************\n",
            "t :  174\n",
            "ce:  tensor([35.0687, 54.3382, 53.9355, 88.4783], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4983e-04, 1.4777e-02, 2.5183e-02, 1.1127e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([35.0687, 54.3382, 53.9355, 88.4783], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5807.1021, 5419.0410, 6107.3540, 4034.1177])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 83., 112.,  44., 116.])\n",
            "*************************************************\n",
            "t :  175\n",
            "ce:  tensor([35.6255, 53.9662, 53.9199, 89.0249], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6736e-04, 1.6207e-02, 2.5381e-02, 1.0968e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([35.6255, 53.9662, 53.9199, 89.0249], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6086.7563, 5976.3291, 5055.3926, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([179.,  68.,  39.,  81.])\n",
            "*************************************************\n",
            "t :  176\n",
            "ce:  tensor([36.6208, 54.0854, 54.0684, 88.7372], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4197e-04, 1.6227e-02, 2.6117e-02, 1.1159e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([36.6208, 54.0854, 54.0684, 88.7372], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5919.6084, 5419.0410, 5134.5366, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([108.,  58., 141.,  11.])\n",
            "*************************************************\n",
            "t :  177\n",
            "ce:  tensor([36.8482, 54.2169, 54.7998, 88.7463], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5556e-04, 1.6641e-02, 2.4529e-02, 1.1170e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([36.8482, 54.2169, 54.7998, 88.7463], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3620.0469, 3890.6902, 5055.3926, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 65., 131.,  91.,  29.])\n",
            "*************************************************\n",
            "t :  178\n",
            "ce:  tensor([36.7259, 54.7230, 54.4401, 88.7782], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4626e-04, 1.5698e-02, 2.6828e-02, 1.1220e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([36.7259, 54.7230, 54.4401, 88.7782], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5449.8081, 5419.0410, 5599.4731, 6613.1499])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 85., 116.,  34.,  54.])\n",
            "*************************************************\n",
            "t :  179\n",
            "ce:  tensor([37.1213, 54.3361, 54.4864, 88.8760], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6748e-04, 1.7147e-02, 2.7187e-02, 1.1156e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([37.1213, 54.3361, 54.4864, 88.8760], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3981.1953, 4860.0625, 5055.3926, 5468.5156])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 62., 236.,  31.,  44.])\n",
            "*************************************************\n",
            "t :  180\n",
            "ce:  tensor([36.8101, 56.1409, 54.5153, 88.8676], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5091e-04, 1.7078e-02, 2.7955e-02, 1.1269e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([36.8101, 56.1409, 54.5153, 88.8676], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3621.9978, 5419.0410, 6405.3071, 4437.6265])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 25., 111.,  98., 121.])\n",
            "*************************************************\n",
            "t :  181\n",
            "ce:  tensor([36.9241, 55.6508, 54.9001, 89.3663], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5758e-04, 1.8071e-02, 2.8184e-02, 1.1106e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([36.9241, 55.6508, 54.9001, 89.3663], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5807.1021, 5507.8164, 5202.0801, 4961.4976])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 85.,  15.,  53., 106.])\n",
            "*************************************************\n",
            "t :  182\n",
            "ce:  tensor([37.3420, 55.6453, 54.8595, 89.3381], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7534e-04, 1.8395e-02, 2.9230e-02, 1.1251e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([37.3420, 55.6453, 54.8595, 89.3381], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4381.1660, 5108.6631, 4475.3584, 7572.0200])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 65.,  34., 118., 132.])\n",
            "*************************************************\n",
            "t :  183\n",
            "ce:  tensor([37.0408, 55.6899, 55.5812, 89.6209], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5687e-04, 1.8962e-02, 2.7266e-02, 1.1361e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([37.0408, 55.6899, 55.5812, 89.6209], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3727.6331, 6015.5127, 5676.6309, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 37.,  49., 130.,  60.])\n",
            "*************************************************\n",
            "t :  184\n",
            "ce:  tensor([37.1709, 55.6996, 55.4327, 89.5274], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5854e-04, 1.8600e-02, 2.9467e-02, 1.1478e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([37.1709, 55.6996, 55.4327, 89.5274], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6098.8696, 5108.6631, 5709.7090, 4437.6265])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 88.,  46.,  46., 125.])\n",
            "*************************************************\n",
            "t :  185\n",
            "ce:  tensor([37.5676, 55.7148, 55.3933, 90.0072], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7498e-04, 1.9398e-02, 2.9971e-02, 1.1302e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([37.5676, 55.7148, 55.3933, 90.0072], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3473.8315, 6015.5127, 5055.3926, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([62., 48., 31., 89.])\n",
            "*************************************************\n",
            "t :  186\n",
            "ce:  tensor([37.3895, 55.7165, 55.4153, 89.7483], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6819e-04, 1.9038e-02, 3.0711e-02, 1.1506e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([37.3895, 55.7165, 55.4153, 89.7483], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6173.5972, 5108.6631, 4530.9438, 5867.0674])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111.,  46., 114.,  30.])\n",
            "*************************************************\n",
            "t :  187\n",
            "ce:  tensor([38.1262, 55.7407, 56.0149, 89.7394], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9036e-04, 1.9857e-02, 2.8979e-02, 1.1459e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([38.1262, 55.7407, 56.0149, 89.7394], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5089.9888, 6015.5127, 5055.3926, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([92., 48., 90., 28.])\n",
            "*************************************************\n",
            "t :  188\n",
            "ce:  tensor([38.0329, 55.7334, 55.6266, 89.7536], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7546e-04, 1.9497e-02, 3.1373e-02, 1.1525e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([38.0329, 55.7334, 55.6266, 89.7536], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3689.7529, 5108.6631, 5202.0801, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([45., 45., 14., 31.])\n",
            "*************************************************\n",
            "t :  189\n",
            "ce:  tensor([38.0363, 55.7811, 55.6249, 89.7414], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7010e-04, 2.0343e-02, 3.1463e-02, 1.1498e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([38.0363, 55.7811, 55.6249, 89.7414], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5117.5166, 6613.1499, 5055.3926, 5468.5156])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([82., 71., 14., 36.])\n",
            "*************************************************\n",
            "t :  190\n",
            "ce:  tensor([38.3347, 55.9089, 55.6353, 89.8187], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8643e-04, 1.9611e-02, 3.1842e-02, 1.1533e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([38.3347, 55.9089, 55.6353, 89.8187], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4362.2007, 5108.6631, 5709.7090, 6613.1499])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([189.,  50.,  36.,  59.])\n",
            "*************************************************\n",
            "t :  191\n",
            "ce:  tensor([40.1728, 55.8414, 55.6750, 89.8673], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7165e-04, 2.0720e-02, 3.1772e-02, 1.1478e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.1728, 55.8414, 55.6750, 89.8673], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6748.0952, 6015.5127, 5055.3926, 5468.5156])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([128.,  48.,  32.,  47.])\n",
            "*************************************************\n",
            "t :  192\n",
            "ce:  tensor([39.7683, 55.8691, 55.6610, 90.0974], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8571e-04, 2.0358e-02, 3.2532e-02, 1.1585e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([39.7683, 55.8691, 55.6610, 90.0974], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4903.7593, 5108.6631, 6195.8037, 5404.0410])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 86.,  46.,  63., 204.])\n",
            "*************************************************\n",
            "t :  193\n",
            "ce:  tensor([40.2279, 55.8655, 55.8491, 91.3684], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7844e-04, 2.1214e-02, 3.2397e-02, 1.1550e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.2279, 55.8655, 55.8491, 91.3684], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5372.1870, 6015.5127, 6007.9644, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 80.,  48., 104.,  89.])\n",
            "*************************************************\n",
            "t :  194\n",
            "ce:  tensor([40.0132, 55.8862, 56.1882, 91.0744], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9751e-04, 2.0851e-02, 3.3335e-02, 1.1734e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.0132, 55.8862, 56.1882, 91.0744], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4450.2222, 5108.6631, 5202.0801, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([77., 46., 52., 31.])\n",
            "*************************************************\n",
            "t :  195\n",
            "ce:  tensor([40.4358, 55.8897, 56.2232, 91.0501], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7916e-04, 2.1730e-02, 3.4186e-02, 1.1709e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.4358, 55.8897, 56.2232, 91.0501], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5225.2920, 6015.5127, 4530.9438, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 89.,  50., 113.,  29.])\n",
            "*************************************************\n",
            "t :  196\n",
            "ce:  tensor([40.2485, 55.9038, 56.6715, 91.1103], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.0156e-04, 2.1300e-02, 3.2379e-02, 1.1759e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.2485, 55.9038, 56.6715, 91.1103], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4302.6353, 5108.6631, 5055.3926, 6613.1499])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([88., 46., 91., 54.])\n",
            "*************************************************\n",
            "t :  197\n",
            "ce:  tensor([40.7330, 55.9229, 56.2893, 91.1694], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7963e-04, 2.2198e-02, 3.4984e-02, 1.1690e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.7330, 55.9229, 56.2893, 91.1694], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5225.2920, 5040.8652, 3623.6011, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92., 161.,  94.,  38.])\n",
            "*************************************************\n",
            "t :  198\n",
            "ce:  tensor([40.5139, 56.8291, 56.7291, 91.1393], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.0526e-04, 2.0631e-02, 3.2178e-02, 1.1802e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.5139, 56.8291, 56.7291, 91.1393], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3541.4980, 5019.9370, 5202.0801, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 74., 107.,  85.,  32.])\n",
            "*************************************************\n",
            "t :  199\n",
            "ce:  tensor([40.7752, 56.4293, 56.3600, 91.1174], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8428e-04, 2.2612e-02, 3.5141e-02, 1.1776e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.7752, 56.4293, 56.3600, 91.1174], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5445.2754, 5108.6631, 5055.3926, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([112.,   9.,  11.,  28.])\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([-0., -0., -0., -0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 10., insertion_array, removal_array, k=200, step_length=0.01, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c18e99-6e0f-40bb-a887-063badf1f0df",
        "id": "tHbUckPO9L5U"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "t :  0\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 86.8272, 160.0354, 131.3113, 225.5053], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12908.3301, 12200.0391, 12128.9160,  9213.8662])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([569., 649., 634., 314.])\n",
            "*************************************************\n",
            "t :  1\n",
            "ce:  tensor([ 48.1498,  90.9962,  62.7146, 183.9560], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7040, 4.6597, 4.8681, 3.7831], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 65.1894, 137.5929, 111.3960, 221.7865], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12323.3936, 11944.3076, 11665.9707,  9221.0312])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([571., 699., 653., 314.])\n",
            "*************************************************\n",
            "t :  2\n",
            "ce:  tensor([ 53.5375,  95.0374,  67.5724, 181.0575], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1950, 1.9808, 2.4139, 3.6933], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 55.4876, 114.8456,  91.7118, 217.9907], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8984.9307, 10486.6992, 11218.1074,  9172.3535])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([257., 697., 658., 327.])\n",
            "*************************************************\n",
            "t :  3\n",
            "ce:  tensor([ 53.2219,  98.3542,  71.4043, 178.2169], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0398, 0.3295, 0.5893, 3.5910], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 53.6202, 101.6490,  77.2972, 214.1271], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9644.8926, 9857.9824, 9794.9971, 8625.4941])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([192., 465., 508., 322.])\n",
            "*************************************************\n",
            "t :  4\n",
            "ce:  tensor([ 51.8183,  95.4745,  72.1735, 175.6501], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0206, 0.0671, 0.0984, 3.4782], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 52.0245,  96.1457,  73.1573, 210.4322], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8335.4844, 9332.0615, 9057.8213, 8632.3584])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([184., 370., 285., 321.])\n",
            "*************************************************\n",
            "t :  5\n",
            "ce:  tensor([ 50.2181,  91.6276,  70.2498, 173.0988], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0110, 0.0260, 0.0401, 3.3575], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 50.3285,  91.8880,  70.6510, 206.6734], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8230.0332, 8204.4971, 8996.9727, 8639.7686])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([186., 358., 246., 326.])\n",
            "*************************************************\n",
            "t :  6\n",
            "ce:  tensor([ 48.5641,  87.7574,  68.0802, 170.5886], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0066, 0.0121, 0.0231, 3.2268], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 48.6303,  87.8780,  68.3113, 202.8569], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8069.8223, 9237.4297, 8944.5361, 8504.8184])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([177., 327., 241., 329.])\n",
            "*************************************************\n",
            "t :  7\n",
            "ce:  tensor([ 46.8502,  84.0041,  65.8575, 168.2425], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0041, 0.0065, 0.0143, 3.0822], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 46.8912,  84.0688,  66.0009, 199.0647], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8001.6416, 8147.2720, 8917.8076, 8510.6748])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([186., 338., 237., 329.])\n",
            "*************************************************\n",
            "t :  8\n",
            "ce:  tensor([ 45.1035,  80.3365,  63.6410, 165.8963], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.5896e-03, 3.7129e-03, 9.4467e-03, 2.9314e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 45.1294,  80.3736,  63.7355, 195.2106], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7891.8486, 8169.0342, 8697.0664, 8515.6660])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([199., 319., 237., 329.])\n",
            "*************************************************\n",
            "t :  9\n",
            "ce:  tensor([ 43.4642,  77.0902,  61.4412, 163.5549], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6364e-03, 2.2904e-03, 6.0540e-03, 2.7753e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 43.4805,  77.1131,  61.5018, 191.3080], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8623.9639, 9121.0469, 8651.7109, 8513.6318])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([186., 293., 255., 329.])\n",
            "*************************************************\n",
            "t :  10\n",
            "ce:  tensor([ 42.1778,  74.3623,  59.1309, 161.2488], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0612e-03, 1.3600e-03, 3.8065e-03, 2.6129e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 42.1884,  74.3759,  59.1689, 187.3775], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7615.9131, 7669.2969, 8629.9160, 8516.4658])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([184., 268., 250., 330.])\n",
            "*************************************************\n",
            "t :  11\n",
            "ce:  tensor([ 40.8911,  72.0542,  56.9368, 158.9548], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.9642e-04, 8.1411e-04, 2.4419e-03, 2.4460e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 40.8981,  72.0624,  56.9612, 183.4146], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6940.4463, 6951.6855, 8071.6504, 8515.8809])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([173., 243., 234., 327.])\n",
            "*************************************************\n",
            "t :  12\n",
            "ce:  tensor([ 39.7846,  69.9168,  55.1029, 156.6599], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.6600e-04, 4.9960e-04, 1.5491e-03, 2.2771e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 39.7893,  69.9218,  55.1184, 179.4310], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6281.7017, 6943.7329, 7997.5684, 8516.4346])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([157., 241., 219., 322.])\n",
            "*************************************************\n",
            "t :  13\n",
            "ce:  tensor([ 38.6977,  67.8741,  53.6987, 154.3669], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.3671e-04, 3.1085e-04, 1.0581e-03, 2.1068e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 38.7010,  67.8772,  53.7093, 175.4352], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6112.4438, 7925.3628, 6916.5850, 8515.5186])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([150., 240., 178., 319.])\n",
            "*************************************************\n",
            "t :  14\n",
            "ce:  tensor([ 37.6230,  66.1362,  52.4527, 152.0664], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.4042e-04, 1.9668e-04, 7.2405e-04, 1.9375e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 37.6254,  66.1382,  52.4599, 171.4417], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6058.9365, 6876.2422, 6916.0200, 8512.8281])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([145., 226., 177., 313.])\n",
            "*************************************************\n",
            "t :  15\n",
            "ce:  tensor([ 36.5680,  64.1202,  51.2395, 149.7376], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7713e-04, 1.2814e-04, 5.0997e-04, 1.7727e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 36.5698,  64.1215,  51.2446, 167.4650], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6023.3604, 6876.1172, 6748.3545, 8508.3789])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([145., 226., 161., 310.])\n",
            "*************************************************\n",
            "t :  16\n",
            "ce:  tensor([ 35.6880,  62.2191,  50.1049, 147.4214], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3172e-04, 8.4993e-05, 3.6471e-04, 1.6109e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 35.6894,  62.2200,  50.1086, 163.5305], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6851.7920, 6296.3110, 6614.6855, 8485.8555])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([172., 173., 151., 303.])\n",
            "*************************************************\n",
            "t :  17\n",
            "ce:  tensor([ 35.1042,  60.7531,  49.0357, 145.1427], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.9284e-05, 5.7934e-05, 2.6401e-04, 1.4562e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 35.1051,  60.7537,  49.0384, 159.7049], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5895.5190, 6296.2622, 6627.4800, 8404.6543])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([136., 173., 152., 288.])\n",
            "*************************************************\n",
            "t :  18\n",
            "ce:  tensor([ 34.1996,  59.5370,  47.9731, 142.8766], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.4371e-05, 4.0054e-05, 1.9298e-04, 1.3098e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 34.2003,  59.5374,  47.9750, 155.9748], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5895.4688, 6098.1758, 6587.2217, 8229.2695])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([136., 150., 149., 305.])\n",
            "*************************************************\n",
            "t :  19\n",
            "ce:  tensor([ 33.3953,  58.2971,  46.9291, 140.5181], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.6967e-05, 2.8252e-05, 1.4280e-04, 1.1723e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 33.3957,  58.2974,  46.9305, 152.2415], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5496.1230, 6098.1543, 6587.1382, 8218.2305])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([121., 150., 149., 303.])\n",
            "*************************************************\n",
            "t :  20\n",
            "ce:  tensor([ 32.5505,  57.0573,  45.8851, 138.1465], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.7073e-05, 2.0146e-05, 1.0693e-04, 1.0437e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 32.5509,  57.0575,  45.8862, 148.5839], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5496.1035, 6098.1401, 6587.0781, 8205.8486])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([121., 150., 149., 297.])\n",
            "*************************************************\n",
            "t :  21\n",
            "ce:  tensor([ 31.6945,  55.8975,  44.9363, 135.7290], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.9563e-05, 1.4663e-05, 8.1178e-05, 9.2808e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 31.6948,  55.8977,  44.9371, 145.0098], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5461.6089, 7014.8242, 5965.5518, 8162.7075])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([130., 193., 131., 286.])\n",
            "*************************************************\n",
            "t :  22\n",
            "ce:  tensor([ 30.8096,  55.0655,  44.1276, 133.3081], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3126e-05, 1.0729e-05, 6.5801e-05, 8.2240e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 30.8098,  55.0656,  44.1282, 141.5321], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5461.5962, 6059.3027, 5475.2456, 8163.9717])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([130., 146., 125., 290.])\n",
            "*************************************************\n",
            "t :  23\n",
            "ce:  tensor([ 29.9246,  53.8472,  43.3519, 130.9013], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8239e-05, 7.9870e-06, 5.8768e-05, 7.2841e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 29.9248,  53.8473,  43.3525, 138.1854], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5461.5864, 6059.2979, 5475.2344, 8100.2959])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([130., 146., 125., 276.])\n",
            "*************************************************\n",
            "t :  24\n",
            "ce:  tensor([ 29.8598,  52.6289,  42.5763, 128.5566], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4543e-05, 6.1989e-06, 5.3047e-05, 6.4276e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 29.8600,  52.6290,  42.5768, 134.9842], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3733.9722, 6059.2944, 5475.2251, 7972.1992])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([117., 146., 125., 257.])\n",
            "*************************************************\n",
            "t :  25\n",
            "ce:  tensor([ 29.4367,  51.4106,  41.8007, 126.2353], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0490e-05, 4.7684e-06, 4.8279e-05, 5.6682e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 29.4368,  51.4106,  41.8011, 131.9035], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3733.9639, 6059.2925, 5475.2173, 7958.6187])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([117., 146., 125., 246.])\n",
            "*************************************************\n",
            "t :  26\n",
            "ce:  tensor([ 29.1448,  50.1923,  41.0250, 123.8894], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.6294e-06, 3.8147e-06, 4.4345e-05, 5.0078e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 29.1449,  50.1924,  41.0255, 128.8972], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5312.3008, 6059.2905, 5475.2114, 7945.7583])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([118., 146., 125., 243.])\n",
            "*************************************************\n",
            "t :  27\n",
            "ce:  tensor([ 29.1203,  48.9907,  40.3111, 121.5120], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.1989e-06, 2.9802e-06, 4.1246e-05, 4.4456e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 29.1204,  48.9907,  40.3115, 125.9575], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3708.0122, 5658.2021, 4964.7861, 7934.1196])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([118., 139., 123., 239.])\n",
            "*************************************************\n",
            "t :  28\n",
            "ce:  tensor([ 28.8218,  47.9031,  40.3015, 119.0901], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5299e-06, 2.6226e-06, 3.8623e-05, 3.9847e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.8219,  47.9032,  40.3019, 123.0749], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3595.4290, 5141.1592, 3382.4968, 7924.0972])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 91., 138.,  97., 232.])\n",
            "*************************************************\n",
            "t :  29\n",
            "ce:  tensor([ 28.5199,  46.8336,  39.9508, 116.6644], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4571e-06, 2.3842e-06, 3.1590e-05, 3.5944e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.5199,  46.8336,  39.9511, 120.2588], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3196.9641, 5141.1587, 3894.1763, 7845.7134])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 138., 118., 229.])\n",
            "*************************************************\n",
            "t :  30\n",
            "ce:  tensor([ 28.5894,  45.7828,  39.6455, 114.2663], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.7418e-06, 2.1458e-06, 2.4557e-05, 3.2535e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.5894,  45.7828,  39.6458, 117.5198], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4775.0801, 5626.1025, 3382.4744, 7837.5977])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([125., 142.,  97., 226.])\n",
            "*************************************************\n",
            "t :  31\n",
            "ce:  tensor([ 28.4391,  45.5778,  39.3104, 112.3939], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-06, 2.0266e-06, 2.0385e-05, 2.9590e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.4391,  45.5779,  39.3106, 115.3529], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3196.9622, 4243.8477, 4964.7539, 6219.6035])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 250., 123., 187.])\n",
            "*************************************************\n",
            "t :  32\n",
            "ce:  tensor([ 28.1631,  46.1936,  39.5332, 110.8108], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9073e-06, 1.5497e-06, 1.9431e-05, 2.5553e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.1631,  46.1936,  39.5334, 113.3660], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4539.6646, 5105.9067, 3382.4663, 6209.3765])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([229., 141.,  97., 182.])\n",
            "*************************************************\n",
            "t :  33\n",
            "ce:  tensor([ 29.4096,  46.1242,  39.1777, 109.2173], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-06, 1.4305e-06, 1.6332e-05, 2.2103e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 29.4096,  46.1242,  39.1778, 111.4276], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4747.7051, 3272.9910, 3382.4614, 6200.1318])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([125., 110.,  97., 181.])\n",
            "*************************************************\n",
            "t :  34\n",
            "ce:  tensor([ 28.8378,  45.7303,  38.8444, 107.6199], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0729e-06, 1.1921e-06, 1.3709e-05, 1.9126e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.8378,  45.7303,  38.8445, 109.5326], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3193.6321, 3272.9907, 3894.1475, 6191.7817])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 110., 118., 180.])\n",
            "*************************************************\n",
            "t :  35\n",
            "ce:  tensor([ 28.8147,  45.3363,  38.5217, 106.0061], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 9.5367e-07, 1.1086e-05, 1.6678e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.8147,  45.3364,  38.5218, 107.6739], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5645.4248, 3272.9902, 3382.4529, 6184.6406])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([135., 110.,  97., 179.])\n",
            "*************************************************\n",
            "t :  36\n",
            "ce:  tensor([ 28.7782,  44.9424,  38.2016, 104.4173], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 8.3446e-07, 9.4175e-06, 1.4567e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.7782,  44.9424,  38.2017, 105.8740], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3165.5740, 3272.9900, 4964.7383, 6083.1836])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 110., 123., 174.])\n",
            "*************************************************\n",
            "t :  37\n",
            "ce:  tensor([ 28.4033,  44.5762,  38.5101, 102.8514], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 7.1526e-07, 9.2983e-06, 1.2773e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.4033,  44.5762,  38.5102, 104.1287], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3165.5737, 3127.6472, 3129.9844, 6077.6309])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 121., 113., 171.])\n",
            "*************************************************\n",
            "t :  38\n",
            "ce:  tensor([ 28.4339,  44.2310,  38.2223, 101.2669], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 5.9605e-07, 7.7486e-06, 1.1336e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.4339,  44.2310,  38.2224, 102.4004], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5645.4248, 4703.6230, 4041.9563, 6067.4766])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([135., 130., 120., 177.])\n",
            "*************************************************\n",
            "t :  39\n",
            "ce:  tensor([28.3433, 44.5805, 38.0320, 99.6701], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5763e-07, 4.7684e-07, 6.4373e-06, 1.0031e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.3433,  44.5805,  38.0321, 100.6732], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3165.5730, 3635.1665, 3129.9797, 6063.1865])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 117., 113., 176.])\n",
            "*************************************************\n",
            "t :  40\n",
            "ce:  tensor([28.0083, 44.2724, 38.0909, 98.0688], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-07, 4.7684e-07, 5.4836e-06, 8.9388e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.0083, 44.2724, 38.0910, 98.9627], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3562.2217, 3127.6465, 4708.4746, 6059.5146])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92., 121., 116., 173.])\n",
            "*************************************************\n",
            "t :  41\n",
            "ce:  tensor([27.8149, 43.9102, 38.0309, 96.4611], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-07, 3.5763e-07, 5.4836e-06, 8.0475e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.8149, 43.9102, 38.0310, 97.2659], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4740.9165, 3127.6465, 3129.9783, 6056.5044])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([126., 121., 113., 170.])\n",
            "*************************************************\n",
            "t :  42\n",
            "ce:  tensor([28.0035, 43.5479, 37.7061, 94.8475], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-07, 3.5763e-07, 4.7684e-06, 7.3225e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.0035, 43.5479, 37.7062, 95.5797], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3165.5730, 3127.6465, 3129.9771, 6054.0293])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 121., 113., 170.])\n",
            "*************************************************\n",
            "t :  43\n",
            "ce:  tensor([27.6589, 43.3337, 37.7928, 93.2340], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-07, 2.3842e-07, 4.1723e-06, 6.6882e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.6589, 43.3337, 37.7928, 93.9028], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4070.9316, 4703.6226, 5475.1504, 6051.8208])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 130., 125., 169.])\n",
            "*************************************************\n",
            "t :  44\n",
            "ce:  tensor([27.4492, 43.5485, 37.7423, 91.6199], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 2.3842e-07, 4.2915e-06, 6.1392e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.4492, 43.5485, 37.7423, 92.2339], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3165.5728, 3635.1663, 3129.9763, 6049.8730])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 117., 113., 167.])\n",
            "*************************************************\n",
            "t :  45\n",
            "ce:  tensor([27.4465, 43.2441, 37.4329, 90.0043], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 2.3842e-07, 3.8147e-06, 5.6750e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.4465, 43.2441, 37.4330, 90.5718], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4740.9165, 3127.6462, 3529.2395, 6048.2021])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([126., 121., 107., 168.])\n",
            "*************************************************\n",
            "t :  46\n",
            "ce:  tensor([27.3950, 42.8819, 37.4465, 88.3885], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 2.3842e-07, 3.3379e-06, 5.2728e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.3950, 42.8819, 37.4466, 88.9158], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3165.5728, 3127.6462, 4708.4712, 6046.7280])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 121., 116., 168.])\n",
            "*************************************************\n",
            "t :  47\n",
            "ce:  tensor([27.0608, 42.5197, 37.5146, 86.8049], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 1.1921e-07, 3.4571e-06, 4.9257e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.0608, 42.5197, 37.5146, 87.2975], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3562.2209, 3127.6462, 3640.8442, 5644.2319])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92., 121., 116., 163.])\n",
            "*************************************************\n",
            "t :  48\n",
            "ce:  tensor([26.7758, 42.4385, 37.2579, 85.4848], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 1.1921e-07, 2.9802e-06, 4.6232e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.7758, 42.4385, 37.2579, 85.9471], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4740.9165, 4958.8604, 3129.9741, 4062.5420])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([126., 127., 113., 158.])\n",
            "*************************************************\n",
            "t :  49\n",
            "ce:  tensor([27.0725, 42.5084, 37.1652, 84.5113], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 1.1921e-07, 2.7418e-06, 3.9938e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.0725, 42.5084, 37.1653, 84.9107], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3672.7515, 3635.1663, 4708.4702, 4060.1504])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([118., 117., 116., 158.])\n",
            "*************************************************\n",
            "t :  50\n",
            "ce:  tensor([26.7547, 42.2136, 37.3681, 83.6559], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 1.1921e-07, 2.8610e-06, 3.4685e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.7547, 42.2136, 37.3681, 84.0028], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3562.2209, 3127.6462, 4103.7832, 5639.1602])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92., 121., 251., 162.])\n",
            "*************************************************\n",
            "t :  51\n",
            "ce:  tensor([26.4612, 41.8992, 38.2069, 83.1103], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 1.1921e-07, 2.6226e-06, 3.3033e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.4612, 41.8992, 38.2069, 83.4407], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3165.5728, 4100.8721, 5875.5298, 3909.4097])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 98., 236., 114.,  98.])\n",
            "*************************************************\n",
            "t :  52\n",
            "ce:  tensor([26.5958, 43.4995, 38.1732, 82.9388], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 1.1921e-07, 2.8610e-06, 3.2010e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.5958, 43.4995, 38.1733, 83.2589], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5137.5547, 5356.5728, 3129.9736, 3908.9788])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([108., 121., 100.,  93.])\n",
            "*************************************************\n",
            "t :  53\n",
            "ce:  tensor([26.7812, 43.0602, 38.3270, 83.0141], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 1.1921e-07, 2.9802e-06, 3.1298e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.7812, 43.0602, 38.3270, 83.3271], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3672.7515, 5210.6816, 5108.3540, 5488.7305])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105., 119., 110.,  98.])\n",
            "*************************************************\n",
            "t :  54\n",
            "ce:  tensor([26.7637, 43.3450, 38.5118, 83.1480], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 2.3842e-07, 3.2186e-06, 3.2999e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([26.7637, 43.3450, 38.5118, 83.4780], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6093.7764, 3127.6462, 3640.8438, 3909.2764])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([156.,  99., 100.,  93.])\n",
            "*************************************************\n",
            "t :  55\n",
            "ce:  tensor([27.3929, 43.2214, 38.5342, 83.1157], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 2.3842e-07, 3.3379e-06, 3.2307e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.3929, 43.2214, 38.5343, 83.4388], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3165.5728, 3777.4531, 4964.7280, 5638.1978])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 93.,  84., 102.,  87.])\n",
            "*************************************************\n",
            "t :  56\n",
            "ce:  tensor([27.4703, 43.3982, 38.9017, 83.3972], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 2.3842e-07, 3.8147e-06, 3.4721e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.4703, 43.3983, 38.9017, 83.7444], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5900.5068, 4703.6226, 3640.8445, 4879.6533])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([117., 106.,  96., 203.])\n",
            "*************************************************\n",
            "t :  57\n",
            "ce:  tensor([27.7754, 43.7643, 38.8298, 84.5624], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 2.3842e-07, 3.8147e-06, 3.5567e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.7754, 43.7643, 38.8299, 84.9181], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3165.5728, 3635.1663, 3529.2390, 5639.2168])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([91., 94., 87., 75.])\n",
            "*************************************************\n",
            "t :  58\n",
            "ce:  tensor([27.7783, 43.6760, 39.2684, 84.2478], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 2.3842e-07, 3.6955e-06, 3.7691e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([27.7783, 43.6760, 39.2685, 84.6247], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5645.4233, 3777.4531, 4964.7285, 5639.8647])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([114.,  81., 103.,  55.])\n",
            "*************************************************\n",
            "t :  59\n",
            "ce:  tensor([28.1691, 43.7858, 39.2590, 84.2352], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 2.3842e-07, 4.2915e-06, 3.9448e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.1691, 43.7858, 39.2590, 84.6297], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3562.2209, 4703.6226, 3129.9756, 4059.5781])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 72., 107.,  91., 100.])\n",
            "*************************************************\n",
            "t :  60\n",
            "ce:  tensor([28.1159, 44.2176, 39.5576, 84.5048], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 3.5763e-07, 4.5299e-06, 3.7793e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.1159, 44.2176, 39.5577, 84.8828], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3417.1394, 3635.1663, 5875.5317, 5639.9048])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 78.,  93., 102.,  77.])\n",
            "*************************************************\n",
            "t :  61\n",
            "ce:  tensor([28.1541, 44.2119, 39.6106, 84.2670], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 3.5763e-07, 5.0068e-06, 4.0801e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.1541, 44.2119, 39.6106, 84.5506], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5645.4233, 4891.4805, 3129.9744, 4054.9453])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([115., 197.,  89.,  97.])\n",
            "*************************************************\n",
            "t :  62\n",
            "ce:  tensor([28.5246, 45.3469, 39.8732, 84.6517], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 3.5763e-07, 5.2452e-06, 3.9361e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.5246, 45.3469, 39.8732, 84.9233], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3165.5723, 4958.8604, 5364.0786, 5635.8833])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87., 108.,  96.,  75.])\n",
            "*************************************************\n",
            "t :  63\n",
            "ce:  tensor([28.6680, 45.2195, 40.0217, 84.3967], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 4.7684e-07, 5.9604e-06, 4.2617e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([28.6680, 45.2195, 40.0218, 84.6887], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6855.4624, 3635.1663, 3640.8445, 5487.2974])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([158.,  89.,  93.,  63.])\n",
            "*************************************************\n",
            "t :  64\n",
            "ce:  tensor([29.1600, 45.4733, 40.2061, 84.6543], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 4.7684e-07, 6.1989e-06, 4.4433e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([29.1600, 45.4733, 40.2062, 84.9564], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3165.5723, 5105.9043, 5911.6846, 5277.5918])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87., 111., 152., 198.])\n",
            "*************************************************\n",
            "t :  65\n",
            "ce:  tensor([29.2752, 45.7103, 40.6623, 85.9789], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-07, 7.1526e-07, 6.9141e-06, 4.5351e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([29.2752, 45.7103, 40.6624, 86.2850], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5392.5835, 3127.6465, 3524.6484, 5636.8774])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105.,  90.,  87.,  70.])\n",
            "*************************************************\n",
            "t :  66\n",
            "ce:  tensor([29.6477, 45.8286, 40.7486, 85.6670], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-07, 7.1526e-07, 7.1525e-06, 4.8503e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([29.6477, 45.8286, 40.7486, 85.9920], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4070.9316, 6012.6807, 4957.4819, 5637.3970])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 86., 112., 101.,  45.])\n",
            "*************************************************\n",
            "t :  67\n",
            "ce:  tensor([29.6678, 46.1657, 41.1166, 85.5406], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-07, 9.5367e-07, 8.5830e-06, 5.1026e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([29.6678, 46.1657, 41.1166, 85.8799], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3417.1394, 3525.6724, 3634.1387, 6039.1157])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([75., 69., 92., 47.])\n",
            "*************************************************\n",
            "t :  68\n",
            "ce:  tensor([29.7294, 46.1599, 41.0297, 85.6734], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-07, 9.5367e-07, 8.9407e-06, 5.3212e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([29.7294, 46.1599, 41.0297, 86.0246], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4907.4121, 3525.4126, 3434.1199, 3909.0044])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([108.,  82.,  78., 109.])\n",
            "*************************************************\n",
            "t :  69\n",
            "ce:  tensor([30.1584, 46.1133, 41.4927, 86.0653], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-07, 1.0729e-06, 9.1791e-06, 5.1424e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([30.1584, 46.1133, 41.4928, 86.4021], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4064.8674, 3379.3923, 4868.6523, 6039.0190])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 93.,  69., 106.,  79.])\n",
            "*************************************************\n",
            "t :  70\n",
            "ce:  tensor([30.1681, 46.3498, 41.5461, 85.8025], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-07, 1.0729e-06, 1.1206e-05, 5.5766e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([30.1681, 46.3498, 41.5462, 86.1649], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3069.1121, 5358.2124, 3543.5479, 5638.3984])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 90., 109.,  81.,  46.])\n",
            "*************************************************\n",
            "t :  71\n",
            "ce:  tensor([30.7478, 46.6552, 41.6733, 85.9384], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-07, 1.3113e-06, 1.1921e-05, 5.8322e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([30.7478, 46.6552, 41.6734, 86.3146], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6252.8594, 4497.7002, 4868.6543, 4057.7905])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([162., 219., 102., 103.])\n",
            "*************************************************\n",
            "t :  72\n",
            "ce:  tensor([30.8613, 48.0374, 42.0741, 86.1738], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5763e-07, 1.4305e-06, 1.4782e-05, 5.6352e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([30.8613, 48.0374, 42.0742, 86.5345], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3410.8264, 5613.3354, 3434.1240, 6039.6255])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 82., 107.,  80.,  74.])\n",
            "*************************************************\n",
            "t :  73\n",
            "ce:  tensor([31.1005, 47.7497, 41.9880, 86.0638], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5763e-07, 1.9073e-06, 1.5378e-05, 6.0650e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.1005, 47.7497, 41.9881, 86.4489], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6028.3311, 3382.5684, 3036.4309, 4879.6255])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([153.,  72.,  80., 210.])\n",
            "*************************************************\n",
            "t :  74\n",
            "ce:  tensor([31.5811, 47.9674, 42.5895, 87.8195], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5763e-07, 2.0266e-06, 1.6332e-05, 6.2553e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.5811, 47.9674, 42.5896, 88.2136], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3159.1069, 4853.6226, 6729.3984, 6043.3174])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87., 105., 154.,  71.])\n",
            "*************************************************\n",
            "t :  75\n",
            "ce:  tensor([31.7754, 48.2875, 42.6410, 87.5089], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 2.6226e-06, 1.8477e-05, 6.6423e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([31.7754, 48.2875, 42.6411, 87.9241], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5954.5615, 4640.9658, 4868.6587, 5642.6260])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([117., 130., 102.,  49.])\n",
            "*************************************************\n",
            "t :  76\n",
            "ce:  tensor([32.0931, 48.5117, 43.2123, 87.4265], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 2.6226e-06, 2.3126e-05, 6.9504e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([32.0931, 48.5117, 43.2125, 87.8575], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3666.9863, 4961.4990, 3543.5554, 6044.2612])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105., 103.,  76.,  44.])\n",
            "*************************************************\n",
            "t :  77\n",
            "ce:  tensor([32.2025, 49.0425, 43.1163, 87.3238], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 3.4571e-06, 2.4438e-05, 7.2351e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([32.2025, 49.0425, 43.1165, 87.7688], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6400.0645, 3130.8252, 3434.1294, 5643.3887])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([159.,  89.,  73.,  46.])\n",
            "*************************************************\n",
            "t :  78\n",
            "ce:  tensor([32.8822, 48.9866, 43.3305, 87.2995], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 3.9339e-06, 2.5868e-05, 7.5307e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([32.8822, 48.9867, 43.3307, 87.7589], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3159.1069, 4037.2915, 4868.6621, 4465.1436])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 85.,  80., 104., 103.])\n",
            "*************************************************\n",
            "t :  79\n",
            "ce:  tensor([33.0091, 49.0356, 43.6822, 87.7298], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 4.4107e-06, 3.2305e-05, 7.3215e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([33.0091, 49.0356, 43.6823, 88.1728], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5446.4189, 5253.1909, 3543.5605, 5640.3872])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110.,  99.,  76.,  68.])\n",
            "*************************************************\n",
            "t :  80\n",
            "ce:  tensor([33.4101, 49.5088, 43.5970, 87.4925], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 5.3644e-06, 3.4093e-05, 7.8103e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([33.4101, 49.5089, 43.5972, 87.9612], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4067.9492, 3130.8264, 3686.2275, 6045.1431])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([87., 85., 65., 41.])\n",
            "*************************************************\n",
            "t :  81\n",
            "ce:  tensor([33.4978, 49.5340, 43.8411, 87.5116], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 6.1989e-06, 3.5166e-05, 8.1017e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([33.4978, 49.5340, 43.8413, 87.9936], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3323.6340, 4437.6313, 4613.4082, 4063.7905])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 71.,  94.,  95., 100.])\n",
            "*************************************************\n",
            "t :  82\n",
            "ce:  tensor([33.5691, 49.6772, 44.2857, 87.9580], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 6.7949e-06, 4.1126e-05, 7.8163e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([33.5691, 49.6772, 44.2860, 88.4192], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4796.1768, 5108.6670, 4517.4492, 6997.3867])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([107.,  98., 213., 131.])\n",
            "*************************************************\n",
            "t :  83\n",
            "ce:  tensor([33.9800, 50.0693, 45.6493, 88.1122], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-06, 8.9407e-06, 4.4226e-05, 8.5979e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([33.9800, 50.0693, 45.6496, 88.6152], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4229.7207, 3130.8281, 5414.8359, 5492.6084])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 74.,  88., 101.,  60.])\n",
            "*************************************************\n",
            "t :  84\n",
            "ce:  tensor([34.0028, 50.2187, 45.3691, 88.0489], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3113e-06, 1.0014e-05, 5.1259e-05, 8.8645e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.0028, 50.2188, 45.3694, 88.5631], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3072.0410, 6008.1030, 3942.5876, 4466.4102])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 85., 199.,  74., 105.])\n",
            "*************************************************\n",
            "t :  85\n",
            "ce:  tensor([34.4367, 51.5061, 45.6559, 88.4868], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4305e-06, 1.1086e-05, 5.4477e-05, 8.6628e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.4367, 51.5062, 45.6562, 88.9849], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6876.9370, 5108.6694, 4760.7261, 5641.5913])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([170., 100., 103.,  68.])\n",
            "*************************************************\n",
            "t :  86\n",
            "ce:  tensor([34.8422, 51.2454, 45.8987, 88.2429], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6689e-06, 1.4067e-05, 6.3417e-05, 9.2707e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.8422, 51.2455, 45.8990, 88.7713], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3958.6870, 3276.2021, 3795.9646, 5495.9180])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([69., 76., 78., 46.])\n",
            "*************************************************\n",
            "t :  87\n",
            "ce:  tensor([34.8752, 51.5682, 45.8835, 88.3544], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7881e-06, 1.5259e-05, 6.5682e-05, 9.5045e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([34.8753, 51.5683, 45.8839, 88.8914], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3072.0413, 6015.5215, 3434.1504, 4466.8799])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 83., 100.,  74., 105.])\n",
            "*************************************************\n",
            "t :  88\n",
            "ce:  tensor([35.5109, 51.6774, 46.3369, 88.7122], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.0266e-06, 1.8477e-05, 6.9020e-05, 9.2939e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([35.5109, 51.6775, 46.3372, 89.2327], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6554.6768, 3130.8335, 5015.8745, 5495.6411])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([133.,  92., 100.,  75.])\n",
            "*************************************************\n",
            "t :  89\n",
            "ce:  tensor([35.4521, 52.0725, 46.3969, 88.6353], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-06, 2.0623e-05, 8.4635e-05, 9.8877e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([35.4521, 52.0726, 46.3973, 89.1841], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3072.0415, 6015.5234, 3543.5854, 5286.2456])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 85., 101.,  86., 195.])\n",
            "*************************************************\n",
            "t :  90\n",
            "ce:  tensor([36.0305, 52.1452, 46.7033, 90.2528], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.7418e-06, 2.4914e-05, 8.7019e-05, 1.0047e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([36.0306, 52.1454, 46.7038, 90.8054], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5957.2681, 3928.2437, 5414.8555, 5645.5723])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([114.,  82.,  95.,  68.])\n",
            "*************************************************\n",
            "t :  91\n",
            "ce:  tensor([35.9857, 52.0277, 46.8245, 89.9400], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.3379e-06, 2.5868e-05, 1.0168e-04, 1.0680e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([35.9858, 52.0278, 46.8251, 90.5220], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3307.8428, 4961.5112, 3634.9165, 5646.2070])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 70.,  91., 109.,  28.])\n",
            "*************************************************\n",
            "t :  92\n",
            "ce:  tensor([36.3538, 52.7436, 47.2715, 89.8779], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.6955e-06, 3.1590e-05, 1.0430e-04, 1.1021e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([36.3538, 52.7438, 47.2721, 90.4731], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6255.6724, 5757.8853, 5523.1553, 6047.7617])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([157., 222., 101.,  39.])\n",
            "*************************************************\n",
            "t :  93\n",
            "ce:  tensor([36.7124, 53.7219, 47.2091, 89.8416], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5299e-06, 3.2186e-05, 1.2659e-04, 1.1342e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([36.7124, 53.7221, 47.2098, 90.4484], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4125.6157, 5108.6787, 3434.1777, 5646.7114])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([82., 91., 95., 34.])\n",
            "*************************************************\n",
            "t :  94\n",
            "ce:  tensor([36.9291, 53.6107, 47.5884, 89.7741], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.6492e-06, 4.0530e-05, 1.2242e-04, 1.1705e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([36.9291, 53.6110, 47.5890, 90.3945], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4904.4209, 4037.3098, 5523.1616, 6048.2783])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109.,  95., 101.,  36.])\n",
            "*************************************************\n",
            "t :  95\n",
            "ce:  tensor([37.3763, 53.8943, 47.6513, 89.7476], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.7220e-06, 3.9934e-05, 1.5067e-04, 1.2006e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([37.3763, 53.8946, 47.6521, 90.3779], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3787.8062, 5253.2075, 4257.9761, 5497.9478])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([103.,  92., 213.,  42.])\n",
            "*************************************************\n",
            "t :  96\n",
            "ce:  tensor([37.3872, 53.9360, 49.3839, 89.9175], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.1989e-06, 4.7325e-05, 1.5639e-04, 1.2153e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([37.3873, 53.9362, 49.3847, 90.5494], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5449.2690, 3890.7141, 6520.4395, 5435.1816])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 98., 109., 108., 196.])\n",
            "*************************************************\n",
            "t :  97\n",
            "ce:  tensor([37.8600, 54.2594, 49.2095, 91.2891], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.3909e-06, 4.7802e-05, 1.7784e-04, 1.2453e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([37.8601, 54.2596, 49.2104, 91.9304], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3697.7275, 5253.2104, 5107.4443, 5647.3188])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([99., 95., 62., 63.])\n",
            "*************************************************\n",
            "t :  98\n",
            "ce:  tensor([37.9637, 54.2557, 49.0596, 90.9894], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.7022e-06, 5.6980e-05, 2.0776e-04, 1.3138e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([37.9638, 54.2560, 49.0607, 91.6594], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4469.9492, 4639.2847, 5212.0352, 5647.8823])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([103., 127.,  63.,  18.])\n",
            "*************************************************\n",
            "t :  99\n",
            "ce:  tensor([38.3826, 54.7597, 49.3661, 90.9513], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.1791e-06, 5.6861e-05, 2.2445e-04, 1.3452e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([38.3826, 54.7599, 49.3672, 91.6307], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5381.7715, 4706.4570, 4528.3486, 6049.3364])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([135.,  88., 106.,  35.])\n",
            "*************************************************\n",
            "t :  100\n",
            "ce:  tensor([39.0047, 54.7456, 49.6334, 90.9217], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0848e-05, 6.7589e-05, 2.1932e-04, 1.3751e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([39.0048, 54.7460, 49.6345, 91.6093], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5122.9609, 3928.2615, 4705.1763, 5648.1802])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([198.,  94.,  78.,  30.])\n",
            "*************************************************\n",
            "t :  101\n",
            "ce:  tensor([40.0525, 54.9632, 49.7425, 90.8672], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1206e-05, 6.6159e-05, 2.5865e-04, 1.4124e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.0526, 54.9635, 49.7437, 91.5663], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5078.5830, 4706.4604, 3889.6470, 6049.6816])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([104.,  89., 101.,  29.])\n",
            "*************************************************\n",
            "t :  102\n",
            "ce:  tensor([39.8422, 55.1053, 49.9857, 90.8819], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3709e-05, 7.7602e-05, 2.5758e-04, 1.4285e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([39.8423, 55.1057, 49.9870, 91.5819], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4587.8213, 4437.6616, 5163.4546, 5499.1748])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([107., 119.,  90.,  37.])\n",
            "*************************************************\n",
            "t :  103\n",
            "ce:  tensor([40.3782, 55.2848, 50.0878, 90.9434], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4186e-05, 7.5814e-05, 2.9941e-04, 1.4317e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.3783, 55.2851, 50.0892, 91.6378], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.8608, 4706.4634, 4490.5068, 5072.6934])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 98.,  93., 132., 139.])\n",
            "*************************************************\n",
            "t :  104\n",
            "ce:  tensor([40.3809, 55.4274, 50.6496, 91.7487], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7285e-05, 8.7973e-05, 2.9178e-04, 1.4061e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.3810, 55.4278, 50.6510, 92.4236], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4096.1836, 4437.6650, 4763.6201, 5647.7314])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([108., 120.,  98.,  67.])\n",
            "*************************************************\n",
            "t :  105\n",
            "ce:  tensor([40.8970, 55.6187, 50.5952, 91.4815], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8120e-05, 8.5827e-05, 3.4374e-04, 1.4865e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.8971, 55.6191, 50.5968, 92.1876], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5078.5854, 4617.6187, 3779.8628, 5499.1074])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109.,  93.,  92.,  26.])\n",
            "*************************************************\n",
            "t :  106\n",
            "ce:  tensor([40.8640, 55.8934, 50.8706, 91.4922], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.2173e-05, 9.8700e-05, 3.3290e-04, 1.4771e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([40.8641, 55.8938, 50.8722, 92.1865], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4497.8760, 5258.1489, 5018.6689, 5648.0225])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([107., 213.,  92.,  19.])\n",
            "*************************************************\n",
            "t :  107\n",
            "ce:  tensor([41.2249, 57.1492, 51.0866, 91.4834], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.2173e-05, 9.6078e-05, 4.0737e-04, 1.5084e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([41.2250, 57.1497, 51.0885, 92.1848], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4676.7520, 5108.6992, 5007.4136, 6602.8901])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105.,  91., 217., 110.])\n",
            "*************************************************\n",
            "t :  108\n",
            "ce:  tensor([41.4984, 56.7940, 52.7573, 91.8906], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.6106e-05, 1.1622e-04, 3.9403e-04, 1.5556e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([41.4985, 56.7945, 52.7591, 92.6062], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4257.8618, 5616.2427, 5018.6855, 6049.6401])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([89., 42., 90., 47.])\n",
            "*************************************************\n",
            "t :  109\n",
            "ce:  tensor([41.4365, 56.7567, 52.5036, 91.7545], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.6703e-05, 1.2397e-04, 4.7470e-04, 1.5873e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([41.4366, 56.7573, 52.5057, 92.4768], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4823.7729, 5507.8628, 5609.1851, 5648.4111])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([103.,  44.,  48.,  22.])\n",
            "*************************************************\n",
            "t :  110\n",
            "ce:  tensor([42.0426, 56.8919, 52.4428, 91.7339], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.0994e-05, 1.3041e-04, 5.1152e-04, 1.6121e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([42.0428, 56.8925, 52.4451, 92.4593], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4459.7305, 3638.2961, 6606.1484, 6049.7319])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([114., 118.,  71.,  24.])\n",
            "*************************************************\n",
            "t :  111\n",
            "ce:  tensor([41.9862, 57.6451, 52.6072, 91.7961], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.1828e-05, 1.2743e-04, 5.2152e-04, 1.6239e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([41.9864, 57.6457, 52.6096, 92.5187], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3245.8279, 5507.8628, 4954.4775, 4068.3389])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 68.,  95.,  57., 107.])\n",
            "*************************************************\n",
            "t :  112\n",
            "ce:  tensor([42.3354, 57.2559, 52.7654, 92.2072], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4212e-05, 1.5341e-04, 5.6751e-04, 1.5613e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([42.3355, 57.2566, 52.7679, 92.8942], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5328.5342, 6015.5679, 3777.4858, 5647.5830])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([106.,  44., 109.,  67.])\n",
            "*************************************************\n",
            "t :  113\n",
            "ce:  tensor([42.6110, 57.3171, 53.1725, 91.9663], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.0054e-05, 1.6068e-04, 5.4643e-04, 1.6588e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([42.6112, 57.3178, 53.1748, 92.6879], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5580.6406, 3382.6270, 5500.7979, 5899.4883])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([229., 108.,  83.,  30.])\n",
            "*************************************************\n",
            "t :  114\n",
            "ce:  tensor([44.1511, 57.9248, 52.9859, 91.9776], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.0411e-05, 1.5341e-04, 6.4579e-04, 1.6655e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([44.1513, 57.9255, 52.9887, 92.6937], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5078.5933, 6613.2041, 3721.7378, 5648.0000])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102., 117., 131.,  21.])\n",
            "*************************************************\n",
            "t :  115\n",
            "ce:  tensor([43.9174, 57.7603, 53.9096, 91.9727], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7921e-05, 1.7486e-04, 6.2434e-04, 1.6879e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([43.9176, 57.7610, 53.9123, 92.6901], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3986.8125, 4961.5566, 5412.0498, 4320.2905])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 89.,  57.,  95., 126.])\n",
            "*************************************************\n",
            "t :  116\n",
            "ce:  tensor([44.2205, 57.9684, 53.6680, 92.6233], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.6729e-05, 1.8976e-04, 7.1941e-04, 1.6248e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([44.2207, 57.9692, 53.6710, 93.3057], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5078.5952, 5154.4976, 5461.5732, 5647.2539])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 226.,  46.,  75.])\n",
            "*************************************************\n",
            "t :  117\n",
            "ce:  tensor([44.3232, 59.5751, 53.6681, 92.3340], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.6146e-05, 1.8869e-04, 7.6563e-04, 1.7197e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([44.3235, 59.5758, 53.6713, 93.0477], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4699.0112, 5108.7227, 5352.3281, 5647.7642])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([149.,  95.,  39.,   7.])\n",
            "*************************************************\n",
            "t :  118\n",
            "ce:  tensor([45.0950, 59.1751, 53.6572, 92.3199], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.4596e-05, 2.2075e-04, 7.7778e-04, 1.7373e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([45.0952, 59.1761, 53.6604, 93.0322], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5078.5972, 5108.7314, 6058.0977, 5647.6899])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110.,  28.,  69.,   8.])\n",
            "*************************************************\n",
            "t :  119\n",
            "ce:  tensor([44.8730, 59.2044, 53.8994, 92.3315], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.5444e-05, 2.3517e-04, 7.9683e-04, 1.7573e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([44.8732, 59.2054, 53.9026, 93.0432], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3336.0266, 6015.5874, 3773.5476, 6646.2305])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([103.,  40., 103.,  53.])\n",
            "*************************************************\n",
            "t :  120\n",
            "ce:  tensor([45.3575, 59.1914, 54.1874, 92.4590], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.5325e-05, 2.3684e-04, 7.5407e-04, 1.7718e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([45.3578, 59.1923, 54.1905, 93.1677], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5984.9951, 5108.7339, 5101.6919, 5498.2505])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([104.,  39.,  87.,  45.])\n",
            "*************************************************\n",
            "t :  121\n",
            "ce:  tensor([45.2132, 59.2265, 54.1676, 92.5011], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.6768e-05, 2.5365e-04, 9.0094e-04, 1.7736e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([45.2135, 59.2275, 54.1712, 93.2017], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3441.7651, 6015.5898, 5001.7319, 7003.8242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 97.,  41., 232., 113.])\n",
            "*************************************************\n",
            "t :  122\n",
            "ce:  tensor([45.6480, 59.2183, 56.1720, 92.8190], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.5457e-05, 2.5376e-04, 8.5127e-04, 1.8415e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([45.6483, 59.2192, 56.1753, 93.5372], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7057.3853, 5555.9111, 5101.7090, 5498.2471])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([164.,  60.,  92.,  54.])\n",
            "*************************************************\n",
            "t :  123\n",
            "ce:  tensor([45.8854, 59.4282, 55.8437, 92.7109], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.5589e-05, 2.5281e-04, 9.9764e-04, 1.8553e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([45.8857, 59.4292, 55.8476, 93.4252], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3190.1257, 4437.7051, 5500.8872, 4469.0293])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([108., 117.,  35., 114.])\n",
            "*************************************************\n",
            "t :  124\n",
            "ce:  tensor([46.5064, 59.8725, 55.8544, 93.2291], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.5589e-05, 2.4554e-04, 1.0274e-03, 1.8152e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([46.5067, 59.8734, 55.8583, 93.9189], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5476.9629, 4961.5684, 6206.3604, 5646.8379])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([107.,  96.,  63.,  72.])\n",
            "*************************************************\n",
            "t :  125\n",
            "ce:  tensor([46.1449, 59.6703, 55.9563, 92.9536], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.7270e-05, 2.7462e-04, 1.0616e-03, 1.9089e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([46.1452, 59.6714, 55.9603, 93.6694], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4348.0674, 4185.2837, 5500.8945, 5497.9717])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([100., 139.,  43.,  24.])\n",
            "*************************************************\n",
            "t :  126\n",
            "ce:  tensor([46.6969, 60.3921, 55.9153, 92.9708], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.2502e-05, 2.6235e-04, 1.1102e-03, 1.9028e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([46.6973, 60.3930, 55.9194, 93.6749], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5078.6055, 5108.7344, 4954.5850, 6048.2578])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111.,  96.,  45.,  33.])\n",
            "*************************************************\n",
            "t :  127\n",
            "ce:  tensor([46.5182, 60.0624, 55.9740, 92.9787], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0669e-04, 3.1061e-04, 1.1617e-03, 1.9334e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([46.5186, 60.0635, 55.9783, 93.6844], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4335.2422, 5468.5986, 6606.2666, 5497.6367])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([125.,  39.,  78.,  32.])\n",
            "*************************************************\n",
            "t :  128\n",
            "ce:  tensor([47.0672, 60.0732, 56.1228, 92.9734], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.8820e-05, 3.1907e-04, 1.1735e-03, 1.9328e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([47.0675, 60.0743, 56.1271, 93.6692], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.8833, 5108.7456, 4954.5894, 6645.2305])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([104.,  38.,  51.,  59.])\n",
            "*************************************************\n",
            "t :  129\n",
            "ce:  tensor([46.9126, 60.1786, 56.0431, 93.0933], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1479e-04, 3.4231e-04, 1.2415e-03, 1.9619e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([46.9130, 60.1799, 56.0475, 93.7898], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4243.8394, 4892.8896, 5860.1807, 5497.2949])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111., 151.,  49.,  42.])\n",
            "*************************************************\n",
            "t :  130\n",
            "ce:  tensor([47.4348, 61.0761, 56.0906, 93.1007], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0752e-04, 3.1347e-04, 1.2551e-03, 1.9654e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([47.4351, 61.0772, 56.0950, 93.7886], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.8848, 5108.7417, 3375.5803, 4066.1086])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([108.,  91., 106., 100.])\n",
            "*************************************************\n",
            "t :  131\n",
            "ce:  tensor([47.2533, 60.7484, 56.6626, 93.4717], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2409e-04, 3.6984e-04, 1.1891e-03, 1.9074e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([47.2537, 60.7497, 56.6667, 94.1297], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4096.3970, 5108.7534, 6008.6060, 6047.0591])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([106.,  22.,  96.,  74.])\n",
            "*************************************************\n",
            "t :  132\n",
            "ce:  tensor([47.5774, 60.7224, 56.4225, 93.2471], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1670e-04, 3.9176e-04, 1.3638e-03, 2.0164e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([47.5778, 60.7238, 56.4272, 93.9326], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5328.5522, 5108.7563, 4954.6113, 6452.7754])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102.,  21.,  46., 116.])\n",
            "*************************************************\n",
            "t :  133\n",
            "ce:  tensor([47.5849, 60.7860, 56.4900, 93.6153], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3267e-04, 4.1429e-04, 1.4310e-03, 2.0764e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([47.5853, 60.7874, 56.4948, 94.3108], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4298.3896, 4289.7495, 4781.8740, 5646.2627])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([146., 125., 161.,  44.])\n",
            "*************************************************\n",
            "t :  134\n",
            "ce:  tensor([48.2552, 61.4263, 57.4990, 93.6075], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2814e-04, 3.8187e-04, 1.3550e-03, 2.1255e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([48.2556, 61.4275, 57.5035, 94.3089], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5476.9692, 5108.7510, 4954.5991, 4467.7896])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105.,  96.,  92., 116.])\n",
            "*************************************************\n",
            "t :  135\n",
            "ce:  tensor([47.9853, 61.0819, 57.1748, 94.0179], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4447e-04, 4.5277e-04, 1.5384e-03, 2.0640e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([47.9858, 61.0834, 57.1798, 94.6887], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3190.1357, 5616.3018, 5101.8003, 5645.6875])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109.,  28.,  29.,  75.])\n",
            "*************************************************\n",
            "t :  136\n",
            "ce:  tensor([48.7295, 61.1045, 57.1521, 93.7153], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4066e-04, 4.6814e-04, 1.6378e-03, 2.1679e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([48.7299, 61.1060, 57.1573, 94.4090], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5476.9712, 5359.4014, 4961.8423, 5496.6904])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110.,  35.,  31.,  25.])\n",
            "*************************************************\n",
            "t :  137\n",
            "ce:  tensor([48.3095, 61.1496, 57.1629, 93.7482], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5997e-04, 4.7255e-04, 1.6723e-03, 2.1598e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([48.3100, 61.1511, 57.1681, 94.4285], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4348.0771, 4037.4016, 5616.5400, 6046.9795])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([103., 109.,  35.,  33.])\n",
            "*************************************************\n",
            "t :  138\n",
            "ce:  tensor([48.8625, 61.6866, 57.1903, 93.7956], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5103e-04, 4.4741e-04, 1.7267e-03, 2.1933e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([48.8629, 61.6879, 57.1957, 94.4755], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5078.6138, 5507.9146, 3382.9473, 4517.7119])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([112.,  90., 116., 143.])\n",
            "*************************************************\n",
            "t :  139\n",
            "ce:  tensor([48.6031, 61.3675, 57.8025, 94.6116], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7641e-04, 5.2033e-04, 1.5870e-03, 2.1339e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([48.6036, 61.3691, 57.8073, 95.2625], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4096.2197, 4706.5439, 6606.2915, 5645.0161])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([124.,  49., 119.,  72.])\n",
            "*************************************************\n",
            "t :  140\n",
            "ce:  tensor([49.2855, 61.5158, 57.6754, 94.3184], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6450e-04, 5.2998e-04, 1.7911e-03, 2.2518e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([49.2860, 61.5174, 57.6807, 94.9939], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5078.6157, 5040.9834, 4961.8447, 6046.6357])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([113., 157.,  56.,  30.])\n",
            "*************************************************\n",
            "t :  141\n",
            "ce:  tensor([48.9302, 62.3463, 57.5835, 94.3344], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9227e-04, 5.1378e-04, 1.8761e-03, 2.2686e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([48.9308, 62.3478, 57.5890, 95.0036], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4439.9668, 4872.7612, 5616.5513, 5645.1431])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([133.,  96.,  35.,  26.])\n",
            "*************************************************\n",
            "t :  142\n",
            "ce:  tensor([49.6638, 62.0286, 57.6179, 94.3074], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7522e-04, 5.8920e-04, 1.9399e-03, 2.2952e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([49.6643, 62.0304, 57.6236, 94.9730], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5167.3188, 5108.7778, 3382.9592, 6046.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 97.,  28., 114.,  29.])\n",
            "*************************************************\n",
            "t :  143\n",
            "ce:  tensor([49.2350, 62.0233, 58.2178, 94.3309], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.0466e-04, 6.2744e-04, 1.7854e-03, 2.3115e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([49.2356, 62.0251, 58.2229, 94.9897], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5020.6230, 5468.6372, 6015.8486, 5644.8145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 36.,  34., 100.,  28.])\n",
            "*************************************************\n",
            "t :  144\n",
            "ce:  tensor([49.4204, 62.0664, 57.9221, 94.3042], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1396e-04, 6.3268e-04, 2.0156e-03, 2.3329e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([49.4210, 62.0682, 57.9278, 94.9574], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4243.8521, 6462.0654, 4961.8560, 6045.9492])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([122., 129.,  50.,  30.])\n",
            "*************************************************\n",
            "t :  145\n",
            "ce:  tensor([49.9731, 62.5185, 58.0257, 94.3315], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9596e-04, 6.5353e-04, 2.1092e-03, 2.3509e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([49.9736, 62.5203, 58.0315, 94.9780], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.8945, 4961.6191, 6359.4902, 5644.4512])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([108.,  67.,  92.,  28.])\n",
            "*************************************************\n",
            "t :  146\n",
            "ce:  tensor([49.6637, 62.5611, 58.1559, 94.3164], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.2743e-04, 6.9356e-04, 2.1028e-03, 2.3729e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([49.6643, 62.5630, 58.1616, 94.9571], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5099.2422, 4185.3364, 4961.8560, 6642.8340])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([138., 145.,  65.,  52.])\n",
            "*************************************************\n",
            "t :  147\n",
            "ce:  tensor([50.4252, 63.1818, 58.2524, 94.4399], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1145e-04, 6.5329e-04, 2.2052e-03, 2.3908e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([50.4258, 63.1835, 58.2582, 95.0735], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.8955, 5020.0532, 4639.6528, 5494.7451])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 96., 105., 143.,  46.])\n",
            "*************************************************\n",
            "t :  148\n",
            "ce:  tensor([50.0394, 62.8453, 58.8689, 94.5150], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0002, 0.0008, 0.0021, 0.2406], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([50.0400, 62.8472, 58.8743, 95.1406], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4912.5049, 5468.6450, 5108.9912, 4465.0850])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 42.,  34.,  93., 114.])\n",
            "*************************************************\n",
            "t :  149\n",
            "ce:  tensor([50.1135, 62.8587, 58.5301, 94.9214], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0002, 0.0008, 0.0024, 0.2357], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([50.1141, 62.8607, 58.5362, 95.5225], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3949.6870, 5108.7900, 4961.8711, 5643.3633])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109.,  30.,  26.,  79.])\n",
            "*************************************************\n",
            "t :  150\n",
            "ce:  tensor([50.6549, 62.8538, 58.6284, 94.7231], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3374e-04, 8.0148e-04, 2.3834e-03, 2.4738e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([50.6555, 62.8558, 58.6344, 95.3415], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5476.9785, 3890.8340, 4438.0225, 7048.9375])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([108., 124., 129., 130.])\n",
            "*************************************************\n",
            "t :  151\n",
            "ce:  tensor([50.3619, 63.5410, 59.1483, 95.1769], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0003, 0.0007, 0.0022, 0.2560], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([50.3626, 63.5427, 59.1537, 95.8040], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3697.7725, 5419.1616, 4872.9912, 5643.5400])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([125., 110., 101.,  48.])\n",
            "*************************************************\n",
            "t :  152\n",
            "ce:  tensor([51.1281, 63.1891, 58.8167, 95.0551], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0003, 0.0008, 0.0025, 0.2603], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([51.1287, 63.1911, 58.8226, 95.6798], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5476.9814, 5108.7910, 3276.5942, 4464.5703])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([112.,  30., 124., 118.])\n",
            "*************************************************\n",
            "t :  153\n",
            "ce:  tensor([50.6542, 63.1824, 59.4759, 95.5573], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0003, 0.0009, 0.0023, 0.2532], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([50.6549, 63.1844, 59.4813, 96.1524], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6012.6235, 5616.3340, 5419.3794, 5642.8491])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([49., 26., 98., 79.])\n",
            "*************************************************\n",
            "t :  154\n",
            "ce:  tensor([50.7178, 63.1927, 59.1450, 95.2571], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0003, 0.0009, 0.0026, 0.2649], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([50.7185, 63.1947, 59.1509, 95.8664], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3441.7913, 5108.7939, 5468.8755, 5493.6357])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([97., 27., 43., 27.])\n",
            "*************************************************\n",
            "t :  155\n",
            "ce:  tensor([51.2575, 63.2031, 59.1486, 95.2615], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0003, 0.0009, 0.0027, 0.2645], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([51.2582, 63.2051, 59.1547, 95.8567], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5476.9819, 6015.6499, 5359.6665, 5642.6362])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([107.,  50.,  38.,  20.])\n",
            "*************************************************\n",
            "t :  156\n",
            "ce:  tensor([50.9952, 63.2639, 59.1735, 95.2418], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0003, 0.0009, 0.0027, 0.2687], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([50.9960, 63.2659, 59.1795, 95.8330], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3697.7764, 4961.6265, 3981.5457, 5493.1592])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([125.,  52., 135.,  26.])\n",
            "*************************************************\n",
            "t :  157\n",
            "ce:  tensor([51.7596, 63.3381, 59.8948, 95.3080], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0003, 0.0009, 0.0025, 0.2686], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([51.7603, 63.3401, 59.9003, 95.8856], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6637.0767, 4437.7646, 5419.3794, 5065.9849])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([166., 133., 103., 139.])\n",
            "*************************************************\n",
            "t :  158\n",
            "ce:  tensor([51.5637, 63.8538, 59.6573, 96.1139], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0004, 0.0009, 0.0028, 0.2663], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([51.5645, 63.8556, 59.6632, 96.6731], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3839.3025, 5020.0547, 6424.0151, 5641.7861])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 90., 104., 126.,  77.])\n",
            "*************************************************\n",
            "t :  159\n",
            "ce:  tensor([51.9781, 63.4989, 59.9996, 95.8106], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0003, 0.0010, 0.0029, 0.2776], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([51.9788, 63.5009, 60.0056, 96.3797], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5020.6289, 5468.6440, 5109.0122, 5492.4897])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([101.,  34.,  59.,  27.])\n",
            "*************************************************\n",
            "t :  160\n",
            "ce:  tensor([51.8220, 63.5229, 59.8915, 95.8218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0004, 0.0010, 0.0031, 0.2773], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([51.8228, 63.5249, 59.8978, 96.3764], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4243.8638, 5108.7866, 6015.8945, 5641.5015])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([125.,  31.,  48.,  20.])\n",
            "*************************************************\n",
            "t :  161\n",
            "ce:  tensor([52.3094, 63.5526, 59.9355, 95.8001], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0004, 0.0010, 0.0031, 0.2817], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([52.3101, 63.5546, 59.9415, 96.3493], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5020.6294, 4037.4268, 4961.8516, 5641.3096])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([108., 116.,  50.,   2.])\n",
            "*************************************************\n",
            "t :  162\n",
            "ce:  tensor([52.0288, 64.0616, 59.9969, 95.7946], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0004, 0.0009, 0.0032, 0.2832], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([52.0296, 64.0634, 60.0029, 96.3326], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5099.2524, 5020.0498, 4438.0083, 5641.0400])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([141.,  99., 132.,   1.])\n",
            "*************************************************\n",
            "t :  163\n",
            "ce:  tensor([52.7553, 63.6929, 60.5233, 95.7925], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0004, 0.0011, 0.0030, 0.2839], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([52.7560, 63.6949, 60.5288, 96.3178], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.9053, 5468.6406, 5020.2583, 5640.7471])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 97.,  33., 103.,   1.])\n",
            "*************************************************\n",
            "t :  164\n",
            "ce:  tensor([52.3323, 63.7355, 60.1581, 95.7904], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0005, 0.0011, 0.0033, 0.2847], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([52.3332, 63.7375, 60.1640, 96.3029], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4765.5757, 5507.9399, 4961.8442, 5640.4521])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([38., 42., 19.,  1.])\n",
            "*************************************************\n",
            "t :  165\n",
            "ce:  tensor([52.5538, 63.7601, 60.1769, 95.7904], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0005, 0.0011, 0.0033, 0.2847], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([52.5546, 63.7620, 60.1827, 96.2887], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4496.0449, 4961.6191, 6015.8579, 5640.1304])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([122.,  43.,  58.,   1.])\n",
            "*************************************************\n",
            "t :  166\n",
            "ce:  tensor([52.9536, 63.8135, 60.2497, 95.7900], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0004, 0.0011, 0.0033, 0.2850], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([52.9544, 63.8153, 60.2552, 96.2744], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.9053, 5040.9927, 4961.8237, 5639.8125])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([101., 162.,  50.,   1.])\n",
            "*************************************************\n",
            "t :  167\n",
            "ce:  tensor([52.7153, 64.7271, 60.3145, 95.7896], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0005, 0.0010, 0.0034, 0.2852], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([52.7162, 64.7289, 60.3201, 96.2602], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4243.8647, 4872.7656, 4037.6416, 5639.4946])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([125., 100., 112.,   0.])\n",
            "*************************************************\n",
            "t :  168\n",
            "ce:  tensor([53.3256, 64.3773, 60.7612, 95.7896], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0005, 0.0012, 0.0031, 0.2852], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([53.3263, 64.3792, 60.7663, 96.2459], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.9053, 5108.7788, 5020.2295, 5639.1724])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109.,  19.,  98.,   0.])\n",
            "*************************************************\n",
            "t :  169\n",
            "ce:  tensor([52.9605, 64.3671, 60.3880, 95.7896], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0005, 0.0012, 0.0036, 0.2852], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([52.9614, 64.3689, 60.3936, 96.2316], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4550.1709, 4961.6172, 3891.0386, 5638.8506])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([142.,  22., 127.,   0.])\n",
            "*************************************************\n",
            "t :  170\n",
            "ce:  tensor([53.7807, 64.3808, 61.0923, 95.7896], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0005, 0.0012, 0.0033, 0.2852], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([53.7815, 64.3826, 61.0972, 96.2174], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5078.6299, 5108.7749, 5419.3330, 5638.5288])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([101.,  18., 109.,   0.])\n",
            "*************************************************\n",
            "t :  171\n",
            "ce:  tensor([53.3213, 64.3740, 60.7055, 95.7896], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0006, 0.0013, 0.0037, 0.2852], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([53.3222, 64.3758, 60.7108, 96.2031], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5417.2383, 5616.3135, 4961.8047, 5638.2075])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([34., 29., 44.,  2.])\n",
            "*************************************************\n",
            "t :  172\n",
            "ce:  tensor([53.3338, 64.4044, 60.7244, 95.7892], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0006, 0.0013, 0.0038, 0.2854], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([53.3346, 64.4061, 60.7296, 96.1889], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5167.3350, 4961.6089, 6613.4595, 5637.8906])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([38., 37., 82.,  0.])\n",
            "*************************************************\n",
            "t :  173\n",
            "ce:  tensor([53.3331, 64.4065, 60.9226, 95.7892], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0006, 0.0013, 0.0037, 0.2854], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([53.3339, 64.4082, 60.9276, 96.1746], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3734.8403, 5616.3052, 4961.7876, 5637.5693])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([116.,  35.,  60.,   0.])\n",
            "*************************************************\n",
            "t :  174\n",
            "ce:  tensor([54.0108, 64.4190, 60.8128, 95.7892], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0006, 0.0013, 0.0039, 0.2854], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.0115, 64.4207, 60.8179, 96.1603], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.9019, 5108.7651, 5616.4844, 5637.2485])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([112.,  28.,  31.,   1.])\n",
            "*************************************************\n",
            "t :  175\n",
            "ce:  tensor([53.5392, 64.3992, 60.8385, 95.7897], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0007, 0.0013, 0.0040, 0.2857], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([53.5400, 64.4008, 60.8435, 96.1468], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5675.6323, 5616.3018, 3529.2710, 5487.5781])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 40.,  30., 116.,  23.])\n",
            "*************************************************\n",
            "t :  176\n",
            "ce:  tensor([53.5752, 64.4294, 61.3504, 95.8036], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0007, 0.0013, 0.0036, 0.2855], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([53.5760, 64.4310, 61.3548, 96.1462], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5328.5737, 5108.7598, 5419.2954, 5636.6206])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([47., 28., 96., 14.])\n",
            "*************************************************\n",
            "t :  177\n",
            "ce:  tensor([53.7547, 64.4318, 61.0555, 95.7924], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0007, 0.0014, 0.0041, 0.2877], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([53.7555, 64.4333, 61.0602, 96.1232], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3190.1514, 3928.3347, 5380.0015, 5636.3306])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([125., 118.,  48.,   0.])\n",
            "*************************************************\n",
            "t :  178\n",
            "ce:  tensor([54.4690, 64.9473, 61.0381, 95.7924], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0006, 0.0012, 0.0042, 0.2877], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.4697, 64.9487, 61.0427, 96.1089], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5476.9814, 5020.0205, 4853.8857, 5636.0093])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111., 103.,  47.,   0.])\n",
            "*************************************************\n",
            "t :  179\n",
            "ce:  tensor([53.9851, 64.6092, 61.1289, 95.7924], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0007, 0.0014, 0.0042, 0.2877], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([53.9859, 64.6107, 61.1332, 96.0945], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5528.0850, 6423.7471, 4289.9111, 5635.6865])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 47., 122., 133.,   1.])\n",
            "*************************************************\n",
            "t :  180\n",
            "ce:  tensor([54.0132, 65.0558, 61.7751, 95.7922], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0008, 0.0014, 0.0039, 0.2879], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.0139, 65.0572, 61.7790, 96.0801], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5565.6001, 5020.0225, 5020.1592, 5635.3677])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 46.,  61., 111.,   2.])\n",
            "*************************************************\n",
            "t :  181\n",
            "ce:  tensor([54.0951, 64.8840, 61.3497, 95.7920], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0008, 0.0015, 0.0044, 0.2881], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.0958, 64.8854, 61.3539, 96.0657], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4550.1602, 4037.3813, 5379.9702, 5635.0488])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([138., 121.,  34.,   1.])\n",
            "*************************************************\n",
            "t :  182\n",
            "ce:  tensor([54.9010, 65.4495, 61.3783, 95.7918], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0008, 0.0013, 0.0044, 0.2883], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.9017, 65.4507, 61.3822, 96.0512], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5476.9790, 5020.0112, 5108.8799, 5634.7295])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([101., 102.,  29.,   2.])\n",
            "*************************************************\n",
            "t :  183\n",
            "ce:  tensor([54.4582, 65.0500, 61.3637, 95.7916], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0008, 0.0015, 0.0046, 0.2885], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.4589, 65.0513, 61.3676, 96.0368], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5020.6235, 5507.8975, 4961.7148, 5634.4111])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([42., 38., 21.,  1.])\n",
            "*************************************************\n",
            "t :  184\n",
            "ce:  tensor([54.4926, 65.0861, 61.3870, 95.7914], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0009, 0.0015, 0.0045, 0.2887], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.4933, 65.0873, 61.3906, 96.0224], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5565.5957, 4872.7305, 4437.8433, 5634.0923])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 46.,  47., 132.,   2.])\n",
            "*************************************************\n",
            "t :  185\n",
            "ce:  tensor([54.4726, 65.0933, 62.0239, 95.7912], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0009, 0.0016, 0.0043, 0.2890], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.4732, 65.0945, 62.0271, 96.0079], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5020.6206, 6015.5864, 4872.8350, 5633.7729])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 47.,  58., 107.,   1.])\n",
            "*************************************************\n",
            "t :  186\n",
            "ce:  tensor([54.6377, 65.1426, 61.6252, 95.7916], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0009, 0.0016, 0.0047, 0.2892], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.6384, 65.1437, 61.6285, 95.9940], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3986.8372, 5108.7280, 5870.0396, 6230.3340])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110.,  42.,  76.,  44.])\n",
            "*************************************************\n",
            "t :  187\n",
            "ce:  tensor([54.9821, 65.1460, 61.8057, 95.8958], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0008, 0.0016, 0.0047, 0.2895], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.9826, 65.1470, 61.8088, 96.0839], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5078.6118, 3529.0312, 4872.8237, 6034.2339])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105., 117.,  55.,  37.])\n",
            "*************************************************\n",
            "t :  188\n",
            "ce:  tensor([54.7313, 65.6247, 61.8067, 95.9571], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0010, 0.0015, 0.0048, 0.2907], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.7319, 65.6256, 61.8096, 96.1316], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3734.8191, 5419.0967, 5004.4229, 4051.0669])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([122., 104., 218., 111.])\n",
            "*************************************************\n",
            "t :  189\n",
            "ce:  tensor([55.2657, 65.2931, 63.3831, 96.3698], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0009, 0.0017, 0.0049, 0.2828], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([55.2661, 65.2940, 63.3858, 96.5254], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.8833, 5468.5708, 5419.1909, 6033.5239])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([112.,  47., 107.,  81.])\n",
            "*************************************************\n",
            "t :  190\n",
            "ce:  tensor([54.9046, 65.2914, 63.0022, 96.1206], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0010, 0.0017, 0.0052, 0.2969], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([54.9051, 65.2923, 63.0048, 96.2691], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5099.2266, 5507.8682, 4961.6396, 5632.2207])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([148.,  43.,  45.,  23.])\n",
            "*************************************************\n",
            "t :  191\n",
            "ce:  tensor([55.7226, 65.2986, 63.0514, 96.1091], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0010, 0.0017, 0.0053, 0.2993], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([55.7230, 65.2994, 63.0538, 96.2438], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.8804, 4872.7026, 6015.6455, 6586.9814])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([103.,  47.,  60., 109.])\n",
            "*************************************************\n",
            "t :  192\n",
            "ce:  tensor([55.2789, 65.4095, 63.0607, 96.4886], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0011, 0.0017, 0.0052, 0.3067], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([55.2793, 65.4102, 63.0628, 96.6113], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4912.4844, 4437.6714, 5108.7744, 5631.6206])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 43., 133.,  43.,  45.])\n",
            "*************************************************\n",
            "t :  193\n",
            "ce:  tensor([55.3138, 65.9274, 63.0240, 96.3648], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0011, 0.0016, 0.0055, 0.3099], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([55.3142, 65.9280, 63.0259, 96.4733], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.8765, 5019.9717, 5507.9219, 4451.3389])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 39., 107.,  32., 127.])\n",
            "*************************************************\n",
            "t :  194\n",
            "ce:  tensor([55.3173, 65.5315, 63.0439, 96.9155], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0011, 0.0018, 0.0054, 0.3025], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([55.3176, 65.5321, 63.0455, 97.0062], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4496.0059, 5272.0234, 4961.5874, 5630.9453])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([125.,  45.,  44.,  86.])\n",
            "*************************************************\n",
            "t :  195\n",
            "ce:  tensor([55.9257, 65.5946, 63.0897, 96.6064], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0010, 0.0017, 0.0055, 0.3164], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([55.9260, 65.5950, 63.0910, 96.6854], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4931.8696, 5019.9629, 6015.5894, 5630.6646])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102.,  39.,  60.,   4.])\n",
            "*************************************************\n",
            "t :  196\n",
            "ce:  tensor([55.4845, 65.5442, 63.0987, 96.6060], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0012, 0.0018, 0.0055, 0.3171], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([55.4848, 65.5445, 63.0998, 96.6694], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4912.4707, 5616.2212, 5108.7212, 5630.3345])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([44., 30., 43.,  4.])\n",
            "*************************************************\n",
            "t :  197\n",
            "ce:  tensor([55.5359, 65.5820, 63.0527, 96.6057], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0012, 0.0018, 0.0058, 0.3178], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([55.5361, 65.5823, 63.0536, 96.6533], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5020.5889, 4961.5146, 6015.5605, 5630.0034])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([39., 37., 52.,  4.])\n",
            "*************************************************\n",
            "t :  198\n",
            "ce:  tensor([55.5170, 65.5942, 63.1326, 96.6053], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0012, 0.0018, 0.0056, 0.3186], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([55.5171, 65.5943, 63.1331, 96.6372], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4096.3672, 3946.9634, 4961.5288, 5629.6719])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([119., 114.,  53.,   5.])\n",
            "*************************************************\n",
            "t :  199\n",
            "ce:  tensor([56.1245, 66.1110, 63.1296, 96.6050], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0011, 0.0017, 0.0058, 0.3195], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([56.1246, 66.1111, 63.1299, 96.6210], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5328.5229, 5019.9424, 6613.1650, 5629.3398])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 102.,  84.,   5.])\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([-0., -0., -0., -0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(mals.to(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec043d50-966e-4e79-8489-c8e01a8df6d2",
        "id": "uVr5sDdm9L5V"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-19.8462,  21.1819],\n",
              "        [-42.3733,  44.2564],\n",
              "        [-28.2794,  29.8791],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a1f908e-b0bc-4ebd-f862-bd3395a430bd",
        "id": "s6J19_LA9L5V"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-15.0439,  16.9277],\n",
              "        [-25.3470,  28.5899],\n",
              "        [-27.2132,  31.3625],\n",
              "        [-36.7231,  41.4289]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b601202-2024-4fcf-ed7f-6a1cdaee7095",
        "id": "QsXhhAxH9L5V"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-19.8213,  23.4770],\n",
              "        [-27.4885,  30.7869],\n",
              "        [-19.7688,  23.2969],\n",
              "        [-39.5807,  44.1316]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    }
  ]
}