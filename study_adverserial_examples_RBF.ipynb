{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv4/blob/main/study_adverserial_examples_RBF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RBF_models\n",
        "\n",
        "download_links = [\n",
        "                  'https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f',\n",
        "                  'https://drive.google.com/uc?id=1-OHACrNCt0yKBbdqQPVfNZcjKt5_jxKD',\n",
        "                  'https://drive.google.com/uc?id=1-KeXJXtU1_6m9JOhormeVwigy0myX3HL',\n",
        "                  'https://drive.google.com/uc?id=1-13RDdZqnrNkdHg3D8PC5KI0CZREwlsz',\n",
        "                  'https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP',\n",
        "\n",
        "]\n",
        "\n",
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM_3KjraHnkn",
        "outputId": "eaf498c6-d0c3-4c1c-c74b-e172ed9fccdb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f\n",
            "From (redirected): https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f&confirm=t&uuid=4e315a3c-a2a3-490b-9a73-d884804d3740\n",
            "To: /content/best_model_gaussian_400.pth\n",
            "100%|██████████| 32.0M/32.0M [00:00<00:00, 32.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-OHACrNCt0yKBbdqQPVfNZcjKt5_jxKD\n",
            "To: /content/best_model_gaussian_600_nonremoval.pth\n",
            "100%|██████████| 5.50M/5.50M [00:00<00:00, 75.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-KeXJXtU1_6m9JOhormeVwigy0myX3HL\n",
            "To: /content/best_model_gaussian_600.pth\n",
            "100%|██████████| 24.0M/24.0M [00:00<00:00, 200MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-13RDdZqnrNkdHg3D8PC5KI0CZREwlsz\n",
            "To: /content/best_model_gaussian_1000_nonremoval.pth\n",
            "100%|██████████| 9.16M/9.16M [00:00<00:00, 44.3MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP\n",
            "From (redirected): https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP&confirm=t&uuid=9d7091a5-10aa-4a86-a798-f970d5f7850b\n",
            "To: /content/best_model_gaussian_1000.pth\n",
            "100%|██████████| 40.0M/40.0M [00:00<00:00, 57.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "download_links = ['https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py'\n",
        "]"
      ],
      "metadata": {
        "id": "1IW4pHac9VLq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kzSbjaXGVeG",
        "outputId": "e26f1c42-7b25-4838-e583-f1821cdc3c97"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz\n",
            "To: /content/sparse_matrix_0.npz\n",
            "100%|██████████| 461k/461k [00:00<00:00, 4.24MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz\n",
            "To: /content/sparse_matrix_1.npz\n",
            "100%|██████████| 148k/148k [00:00<00:00, 2.13MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz\n",
            "To: /content/sparse_matrix_2.npz\n",
            "100%|██████████| 150k/150k [00:00<00:00, 2.51MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz\n",
            "To: /content/sparse_matrix_y0.npz\n",
            "100%|██████████| 5.79k/5.79k [00:00<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz\n",
            "To: /content/sparse_matrix_y1.npz\n",
            "100%|██████████| 2.64k/2.64k [00:00<00:00, 4.47MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz\n",
            "To: /content/sparse_matrix_y2.npz\n",
            "100%|██████████| 2.71k/2.71k [00:00<00:00, 493kB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth\n",
            "To: /content/model_DNN_drebin_best.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 16.4MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth\n",
            "To: /content/model_AT_rFGSM_weightedLoss.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 19.1MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth\n",
            "To: /content/model_AT_rFGSM.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 16.5MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl\n",
            "To: /content/insertion_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 2.14MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl\n",
            "To: /content/removal_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 1.46MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py\n",
            "To: /content/adverserial_attacks_functions.py\n",
            "67.1kB [00:00, 43.3MB/s]                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,balanced_accuracy_score\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "from adverserial_attacks_functions import *\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494f2768-0873-4a7c-c893-015219fe90d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a8e417e1e30>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    #os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX4ncRLLFDnN",
        "outputId": "41fe3822-dbf5-4eda-edcc-2a2607420aea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the .pkl file\n",
        "with open('/content/insertion_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    insertion_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "insertion_array = torch.tensor(insertion_array).to(device)\n",
        "print(len(insertion_array))\n",
        "\n",
        "# Open the .pkl file\n",
        "with open('/content/removal_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    removal_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "removal_array = torch.tensor(removal_array).to(device)\n",
        "print(len(removal_array))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXV0WIjsJG_F",
        "outputId": "e3ed5b4b-21bb-4cb8-9829-d0029734c228"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load dataset\n",
        "X_train = sparse.load_npz(\"/content/sparse_matrix_0.npz\").toarray()\n",
        "X_val = sparse.load_npz(\"/content/sparse_matrix_1.npz\").toarray()\n",
        "X_test = sparse.load_npz(\"/content/sparse_matrix_2.npz\").toarray()\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.int8)\n",
        "X_val = torch.tensor(X_val, dtype=torch.int8)\n",
        "X_test = torch.tensor(X_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "y_train = sparse.load_npz(\"/content/sparse_matrix_y0.npz\").toarray().reshape((-1, 1))\n",
        "y_val = sparse.load_npz(\"/content/sparse_matrix_y1.npz\").toarray().reshape((-1, 1))\n",
        "y_test = sparse.load_npz(\"/content/sparse_matrix_y2.npz\").toarray().reshape((-1, 1))\n",
        "\n",
        "y_train = torch.tensor(y_train, dtype=torch.int8)\n",
        "y_val = torch.tensor(y_val, dtype=torch.int8)\n",
        "y_test = torch.tensor(y_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"x_train:\", X_train.shape)\n",
        "print(\"x_val:\", X_val.shape)\n",
        "print(\"x_test:\", X_test.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"y_val:\", y_val.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5blmEg4h-GKy",
        "outputId": "6910fd22-d96b-4084-aee6-b5850fb34214"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:\n",
            "x_train: torch.Size([28683, 10000])\n",
            "x_val: torch.Size([9562, 10000])\n",
            "x_test: torch.Size([9562, 10000])\n",
            "y_train: torch.Size([28683, 1])\n",
            "y_val: torch.Size([9562, 1])\n",
            "y_test: torch.Size([9562, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of benigns and malicious sample in training dataset\n",
        "n_ben = (y_train.squeeze()== 0).sum().item()\n",
        "n_mal = (y_train.squeeze()== 1).sum().item()\n",
        "print('the proportion of malwares : ', n_mal/(n_mal+n_ben))\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del train_dataset, val_dataset, test_dataset, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81AZSXOV-HoW",
        "outputId": "391d1051-dabf-4dba-b154-3ef64b4216ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the proportion of malwares :  0.11386535578565701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM.load_state_dict(torch.load('model_AT_rFGSM.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE8WMAUgSCms",
        "outputId": "cc57afc8-a69d-4312-9ca4-12586b996516"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RBFModel(nn.Module):\n",
        "    def __init__(self, hidden_dim, output_dim, init_centers, init_sigmas, kernel):\n",
        "        super(RBFModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.centers = nn.Parameter(torch.Tensor(init_centers))\n",
        "        self.sigmas = nn.Parameter(torch.Tensor(init_sigmas))\n",
        "        self.kernel = kernel\n",
        "        # Linear layer for output\n",
        "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def gaussian(self, x, c, sigma):\n",
        "        return torch.exp(-torch.sum((x[:, None, :] - c) ** 2, dim=-1) / (2 * sigma ** 2))\n",
        "\n",
        "    def laplacian(self, x, c, sigma):\n",
        "        return torch.exp(-torch.sum(torch.abs(x[:, None, :] - c) , dim=-1) / sigma)\n",
        "\n",
        "    def forward(self, x):\n",
        "      if self.kernel == 'gaussian':\n",
        "        radial_out = self.gaussian(x, self.centers, self.sigmas)\n",
        "      elif self.kernel == 'laplacian':\n",
        "        radial_out = self.laplacian(x, self.centers, self.sigmas)\n",
        "      else:\n",
        "        raise ValueError(\"Invalid kernel type. Choose 'gaussian' or 'laplacian'.\")\n",
        "\n",
        "      output = self.linear(radial_out.to(torch.float32))\n",
        "      return output\n"
      ],
      "metadata": {
        "id": "WHAI-VGJSGa2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_removal_features = False\n",
        "non_removal_mask = torch.logical_not(removal_array).to('cpu')\n",
        "sigma = 4.15\n",
        "kernel = 'gaussian'\n",
        "all_centers = torch.rand((1000, 10000))\n",
        "model_gaussian_1000 = RBFModel(1000, 2, all_centers, [sigma], kernel)\n",
        "model_gaussian_1000 = model_gaussian_1000.to(device)\n",
        "\n",
        "# Load the model state dictionary\n",
        "model_gaussian_1000.load_state_dict(torch.load('/content/best_model_gaussian_1000.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "id": "W9qJYeK0bbnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab14fbc-eb5b-4710-a614-9c3a7eef345f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_removal_features = True\n",
        "non_removal_mask = torch.logical_not(removal_array).to('cpu')\n",
        "sigma = 4.15\n",
        "kernel = 'gaussian'\n",
        "all_centers = torch.rand((1000, 1144))\n",
        "model_gaussian_1000_nonremoval = RBFModel(1000, 2, all_centers, [sigma], kernel)\n",
        "model_gaussian_1000_nonremoval = model_gaussian_1000_nonremoval.to(device)\n",
        "\n",
        "# Load the model state dictionary\n",
        "model_gaussian_1000_nonremoval.load_state_dict(torch.load('/content/best_model_gaussian_1000_nonremoval.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMA7rzpTPhv7",
        "outputId": "dde0f888-d895-48ec-e4d9-42277f06d6fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in test_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break\n",
        "\n",
        "mals = x[:40][y[:40].squeeze()==1]\n",
        "mals_y = y[:40][y[:40].squeeze()==1]\n",
        "mals.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StL135L1JUiE",
        "outputId": "b319adab-7f3e-4b99-b284-3f4a965a8a8d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 10000])\n",
            "torch.Size([128, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_gaussian_1000(mals)\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "id": "N9WjCVDF5DFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0a4ba9-2905-4b4c-9edd-b2ce2efb016f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0256e-02, 9.8974e-01],\n",
              "        [6.4868e-04, 9.9935e-01],\n",
              "        [6.6529e-04, 9.9933e-01],\n",
              "        [2.0942e-02, 9.7906e-01]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_gaussian_1000_nonremoval(mals[:, non_removal_mask])\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa98a66-2c25-4113-dffe-c2ba04a31e17",
        "id": "dRMeJ6lXP187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0171, 0.9829],\n",
              "        [0.0048, 0.9952],\n",
              "        [0.0023, 0.9977],\n",
              "        [0.0156, 0.9844]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_AT_rFGSM(mals.to(torch.float32))\n",
        "torch.softmax(outputs, dim=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snm7-klbKI0k",
        "outputId": "3ea8820d-7610-45ab-c726-db179b21731d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5196e-18, 1.0000e+00],\n",
              "        [2.3834e-38, 1.0000e+00],\n",
              "        [5.5222e-26, 1.0000e+00],\n",
              "        [0.0000e+00, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_AT_rFGSM, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuzcco7SL2wA",
        "outputId": "0b4ae1de-ea25-4fe5-ce32-08000b63a80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 75.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgcmZjnlNucd",
        "outputId": "1e4b982c-8574-4eb6-85e3-cef2069e5236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_gaussian_1000(adv)\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmynJJVkNwI5",
        "outputId": "d0bd452e-6786-44ce-aa2a-6b219d30b29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0273, 0.9727],\n",
              "        [0.0608, 0.9392],\n",
              "        [0.0017, 0.9983],\n",
              "        [0.0209, 0.9791]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_gaussian_1000_nonremoval(adv[:, non_removal_mask])\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCQP_gWpQGpX",
        "outputId": "3f534972-ebb9-4c61-be68-1fdf561af51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4113, 0.5887],\n",
              "        [0.7621, 0.2379],\n",
              "        [0.3029, 0.6971],\n",
              "        [0.2166, 0.7834]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_AT_rFGSM(adv.to(torch.float32))\n",
        "torch.softmax(outputs, dim=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g336ciLVN6wp",
        "outputId": "766a84fc-f2b6-4152-c53d-e3d935219159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9997e-01, 3.3653e-05],\n",
              "        [9.7767e-01, 2.2329e-02],\n",
              "        [8.8007e-01, 1.1993e-01],\n",
              "        [0.0000e+00, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EK0_fBVRxCb",
        "outputId": "ba70a804-e2e5-4880-b05f-293d5eef921d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.8403,  -5.4591],\n",
              "        [  1.5538,  -2.2255],\n",
              "        [  0.8769,  -1.1162],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gkde(x, y, model, penalty_factor, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural, _ = get_loss_kde(x,y,model, penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        #y_model = model(x_var)\n",
        "        if t > 0:\n",
        "          decayed_penalty_factor = decayed_penalty_factor/2.\n",
        "          print('t : ',t)\n",
        "          print('decayed_penalty_factor : ',decayed_penalty_factor)\n",
        "        else:\n",
        "          decayed_penalty_factor = penalty_factor\n",
        "\n",
        "        # Compute loss\n",
        "        loss, _ = get_loss_kde(x_var,y,model, decayed_penalty_factor)\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            _, done = get_loss_kde(x_next,y,model, penalty_factor)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv, done = get_loss_kde(x_next,y,model, penalty_factor)\n",
        "    loss_adv = loss_adv.data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "rBy2t9Kc5DA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_AT_rFGSM(adv.to(torch.float32))\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeNH2OZiWusD",
        "outputId": "3982e4fb-b2dc-413a-94f6-5d0bcd8481fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9997e-01, 3.3653e-05],\n",
              "        [9.7767e-01, 2.2329e-02],\n",
              "        [8.8007e-01, 1.1993e-01],\n",
              "        [0.0000e+00, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "outputs = model_AT_rFGSM(adv.to(torch.float32))\n",
        "print(outputs)\n",
        "ce = criterion(outputs, mals_y.view(-1).long())\n",
        "print(ce)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlbNKoAoVHSp",
        "outputId": "a394e4aa-c750-4147-fd11-8c5929cd8970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  4.8403,  -5.4591],\n",
            "        [  1.5538,  -2.2255],\n",
            "        [  0.8769,  -1.1162],\n",
            "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)\n",
            "tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "outputs = model_gaussian_1000(adv.to(torch.float32))\n",
        "print(outputs)\n",
        "ce = criterion(outputs, mals_y.view(-1).long())\n",
        "print(ce)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VulPv7cMVec2",
        "outputId": "da71ca45-fd98-453d-e358-134528fac298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.6591,  1.9131],\n",
            "        [-1.2412,  1.4970],\n",
            "        [-3.0718,  3.3226],\n",
            "        [-1.9212,  1.9236]], grad_fn=<AddmmBackward0>)\n",
            "tensor([0.0277, 0.0627, 0.0017, 0.0212], grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_loss_kde(adv.to(torch.float32),mals_y,model_AT_rFGSM, 1.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFLQRmSNUgKJ",
        "outputId": "2d64c7a6-49af-461c-ccf2-af44f49d9767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  4.8403,  -5.4591],\n",
            "        [  1.5538,  -2.2255],\n",
            "        [  0.8769,  -1.1162],\n",
            "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)\n",
            "ce:  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0277, 0.0627, 0.0017, 0.0212], grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10.3271,  3.8646,  2.1225,  0.0212], grad_fn=<AddBackward0>),\n",
              " tensor([ True,  True,  True, False]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model, penalty_factor):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y.view(-1).long())\n",
        "    print('ce: ', ce)\n",
        "    outputs_rbf = model_gaussian_1000(adv_x)\n",
        "    kde = criterion(outputs_rbf, y.view(-1).long())\n",
        "    #kde=0.\n",
        "    print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "gAWNQW7u5LKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_gaussian_1000, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "id": "ntOql6cfTZBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 0.001, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpJNQCSkTQxy",
        "outputId": "297001bb-458f-4d2b-9083-9dbdad42b382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0103, 0.0006, 0.0007, 0.0212], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0103, 0.0006, 0.0007, 0.0212], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([0.0040, 0.0002, 0.0002, 0.0008])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0103, 0.0006, 0.0007, 0.0212], grad_fn=<NllLossBackward0>)\n",
            "t :  1\n",
            "decayed_penalty_factor :  0.0005\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2840, 0.0139, 0.0113, 0.0289], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([0.0473, 0.0023, 0.0018, 0.0005])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2840, 0.0139, 0.0113, 0.0289], grad_fn=<NllLossBackward0>)\n",
            "t :  2\n",
            "decayed_penalty_factor :  0.00025\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1649, 0.2077, 0.1473, 0.0387], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([0.0828, 0.0152, 0.0105, 0.0003])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1649, 0.2077, 0.1473, 0.0387], grad_fn=<NllLossBackward0>)\n",
            "t :  3\n",
            "decayed_penalty_factor :  0.000125\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.8952, 1.3642, 1.0102, 0.0510], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([0.0453, 0.0294, 0.0238, 0.0002])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.8952, 1.3642, 1.0102, 0.0510], grad_fn=<NllLossBackward0>)\n",
            "t :  4\n",
            "decayed_penalty_factor :  6.25e-05\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.2471, 3.2237, 2.7530, 0.0668], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([0.0222, 0.0185, 0.0178, 0.0002])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.2471, 3.2237, 2.7530, 0.0668], grad_fn=<NllLossBackward0>)\n",
            "t :  5\n",
            "decayed_penalty_factor :  3.125e-05\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.3487, 5.0775, 4.6796, 0.0847], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.0829e-02, 9.3228e-03, 9.1865e-03, 9.2622e-05])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.3487, 5.0775, 4.6796, 0.0847], grad_fn=<NllLossBackward0>)\n",
            "t :  6\n",
            "decayed_penalty_factor :  1.5625e-05\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([11.1857,  6.7189,  6.4336,  0.1043], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.3136e-03, 4.5976e-03, 4.5158e-03, 5.5363e-05])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([11.1857,  6.7189,  6.4336,  0.1043], grad_fn=<NllLossBackward0>)\n",
            "t :  7\n",
            "decayed_penalty_factor :  7.8125e-06\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([12.8181,  8.1919,  7.9327,  0.1276], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.5946e-03, 2.2475e-03, 2.2202e-03, 3.4520e-05])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([12.8181,  8.1919,  7.9327,  0.1276], grad_fn=<NllLossBackward0>)\n",
            "t :  8\n",
            "decayed_penalty_factor :  3.90625e-06\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([14.3279,  9.6636,  9.3169,  0.1523], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.2640e-03, 1.1464e-03, 1.0852e-03, 1.9981e-05])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([14.3279,  9.6636,  9.3169,  0.1523], grad_fn=<NllLossBackward0>)\n",
            "t :  9\n",
            "decayed_penalty_factor :  1.953125e-06\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([15.7883, 11.0292, 10.5902,  0.1781], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.4318e-04, 5.5861e-04, 5.2907e-04, 1.1353e-05])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([15.7883, 11.0292, 10.5902,  0.1781], grad_fn=<NllLossBackward0>)\n",
            "t :  10\n",
            "decayed_penalty_factor :  9.765625e-07\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([17.1759, 12.4387, 11.7611,  0.2057], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.1356e-04, 2.8536e-04, 2.5810e-04, 6.3418e-06])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([17.1759, 12.4387, 11.7611,  0.2057], grad_fn=<NllLossBackward0>)\n",
            "t :  11\n",
            "decayed_penalty_factor :  4.8828125e-07\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([18.6486, 13.6986, 12.8367,  0.2342], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.6107e-04, 1.3914e-04, 1.2580e-04, 3.4905e-06])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([18.6486, 13.6986, 12.8367,  0.2342], grad_fn=<NllLossBackward0>)\n",
            "t :  12\n",
            "decayed_penalty_factor :  2.44140625e-07\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([19.9301, 14.9896, 13.8545,  0.2663], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8458e-05, 7.1473e-05, 6.1659e-05, 1.9814e-06])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([19.9301, 14.9896, 13.8545,  0.2663], grad_fn=<NllLossBackward0>)\n",
            "t :  13\n",
            "decayed_penalty_factor :  1.220703125e-07\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([21.1310, 16.1552, 14.8188,  0.3036], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.8428e-05, 3.4820e-05, 3.1182e-05, 1.1432e-06])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([21.1310, 16.1552, 14.8188,  0.3036], grad_fn=<NllLossBackward0>)\n",
            "t :  14\n",
            "decayed_penalty_factor :  6.103515625e-08\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([22.3491, 17.2454, 15.7377,  0.3461], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.9439e-05, 1.7058e-05, 1.5221e-05, 6.5439e-07])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([22.3491, 17.2454, 15.7377,  0.3461], grad_fn=<NllLossBackward0>)\n",
            "t :  15\n",
            "decayed_penalty_factor :  3.0517578125e-08\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([23.5282, 18.3016, 16.5782,  0.3927], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.0687e-05, 8.6304e-06, 7.4469e-06, 3.6809e-07])\n",
            "ce:  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([23.5282, 18.3016, 16.5782,  0.3927], grad_fn=<NllLossBackward0>)\n",
            "t :  16\n",
            "decayed_penalty_factor :  1.52587890625e-08\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 19.3880, 17.3629,  0.4427], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 4.4313e-06, 3.6312e-06, 2.0530e-07])\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 19.3880, 17.3629,  0.4427], grad_fn=<NllLossBackward0>)\n",
            "t :  17\n",
            "decayed_penalty_factor :  7.62939453125e-09\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 20.5049, 18.1144,  0.4989], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 2.2752e-06, 1.8038e-06, 1.1547e-07])\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 20.5049, 18.1144,  0.4989], grad_fn=<NllLossBackward0>)\n",
            "t :  18\n",
            "decayed_penalty_factor :  3.814697265625e-09\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 21.6178, 18.8310,  0.5572], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 1.2156e-06, 8.9894e-07, 6.4370e-08])\n",
            "ce:  tensor([2.2319, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 21.6178, 18.8310,  0.5572], grad_fn=<NllLossBackward0>)\n",
            "t :  19\n",
            "decayed_penalty_factor :  1.9073486328125e-09\n",
            "ce:  tensor([2.2319e+00, 3.5763e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.7441, 19.4446,  0.6210], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 3.5608e-03, 4.3983e-07, 3.5543e-08])\n",
            "ce:  tensor([2.2319e+00, 3.5763e-07, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.7441, 19.4446,  0.6210], grad_fn=<NllLossBackward0>)\n",
            "t :  20\n",
            "decayed_penalty_factor :  9.5367431640625e-10\n",
            "ce:  tensor([2.2319, 0.0099, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 21.6747, 23.5219,  0.6851], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 9.1592e+01, 2.6040e-07, 1.8740e-08])\n",
            "ce:  tensor([2.2319, 0.0099, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 21.6747, 23.5219,  0.6851], grad_fn=<NllLossBackward0>)\n",
            "t :  21\n",
            "decayed_penalty_factor :  4.76837158203125e-10\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.1910,  0.7478], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 1.2767e-07, 9.7522e-09])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.1910,  0.7478], grad_fn=<NllLossBackward0>)\n",
            "t :  22\n",
            "decayed_penalty_factor :  2.384185791015625e-10\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.8489,  0.8140], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 6.7697e-08, 5.1992e-09])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.8489,  0.8140], grad_fn=<NllLossBackward0>)\n",
            "t :  23\n",
            "decayed_penalty_factor :  1.1920928955078125e-10\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.4476,  0.8851], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 3.3371e-08, 2.8167e-09])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.4476,  0.8851], grad_fn=<NllLossBackward0>)\n",
            "t :  24\n",
            "decayed_penalty_factor :  5.960464477539063e-11\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.9464,  1.1311], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 3.0244e-08, 1.7617e-09])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.9464,  1.1311], grad_fn=<NllLossBackward0>)\n",
            "t :  25\n",
            "decayed_penalty_factor :  2.980232238769531e-11\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 26.4169,  1.3205], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 3.9103e-08, 1.0039e-09])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 26.4169,  1.3205], grad_fn=<NllLossBackward0>)\n",
            "t :  26\n",
            "decayed_penalty_factor :  1.4901161193847657e-11\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 26.8470,  1.4240], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 5.3413e-08, 5.2946e-10])\n",
            "ce:  tensor([2.2319, 3.4978, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 26.8470,  1.4240], grad_fn=<NllLossBackward0>)\n",
            "t :  27\n",
            "decayed_penalty_factor :  7.450580596923828e-12\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 7.1526e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.7683,  1.5345], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 6.6710e-03, 2.8092e-10])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 7.1526e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 25.7683,  1.5345], grad_fn=<NllLossBackward0>)\n",
            "t :  28\n",
            "decayed_penalty_factor :  3.725290298461914e-12\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 23.2601,  1.6515], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 7.5758e-03, 1.4862e-10])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 23.2601,  1.6515], grad_fn=<NllLossBackward0>)\n",
            "t :  29\n",
            "decayed_penalty_factor :  1.862645149230957e-12\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  1.7732], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 7.7849e-11])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  1.7732], grad_fn=<NllLossBackward0>)\n",
            "t :  30\n",
            "decayed_penalty_factor :  9.313225746154785e-13\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  1.8868], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 4.0661e-11])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  1.8868], grad_fn=<NllLossBackward0>)\n",
            "t :  31\n",
            "decayed_penalty_factor :  4.656612873077393e-13\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  2.0043], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 2.1280e-11])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  2.0043], grad_fn=<NllLossBackward0>)\n",
            "t :  32\n",
            "decayed_penalty_factor :  2.3283064365386963e-13\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  2.1212], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 1.0619e-11])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  2.1212], grad_fn=<NllLossBackward0>)\n",
            "t :  33\n",
            "decayed_penalty_factor :  1.1641532182693482e-13\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  2.2483], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 5.5380e-12])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  2.2483], grad_fn=<NllLossBackward0>)\n",
            "t :  34\n",
            "decayed_penalty_factor :  5.820766091346741e-14\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  8.2252], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 6.4126e-12])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  8.2252], grad_fn=<NllLossBackward0>)\n",
            "t :  35\n",
            "decayed_penalty_factor :  2.9103830456733704e-14\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  8.5204], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 3.2810e-12])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  8.5204], grad_fn=<NllLossBackward0>)\n",
            "t :  36\n",
            "decayed_penalty_factor :  1.4551915228366852e-14\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  8.8227], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 1.6831e-12])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  8.8227], grad_fn=<NllLossBackward0>)\n",
            "t :  37\n",
            "decayed_penalty_factor :  7.275957614183426e-15\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  9.1211], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 8.6351e-13])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  9.1211], grad_fn=<NllLossBackward0>)\n",
            "t :  38\n",
            "decayed_penalty_factor :  3.637978807091713e-15\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  9.4085], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 4.2252e-13])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  9.4085], grad_fn=<NllLossBackward0>)\n",
            "t :  39\n",
            "decayed_penalty_factor :  1.8189894035458565e-15\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  9.6875], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 2.1577e-13])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798,  9.6875], grad_fn=<NllLossBackward0>)\n",
            "t :  40\n",
            "decayed_penalty_factor :  9.094947017729283e-16\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  9.9516], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 1.0592e-13])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145,  9.9516], grad_fn=<NllLossBackward0>)\n",
            "t :  41\n",
            "decayed_penalty_factor :  4.547473508864641e-16\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 10.2339], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 5.3943e-14])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 10.2339], grad_fn=<NllLossBackward0>)\n",
            "t :  42\n",
            "decayed_penalty_factor :  2.2737367544323206e-16\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 10.4943], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 2.7639e-14])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 10.4943], grad_fn=<NllLossBackward0>)\n",
            "t :  43\n",
            "decayed_penalty_factor :  1.1368683772161603e-16\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 10.7537], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 1.4145e-14])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 10.7537], grad_fn=<NllLossBackward0>)\n",
            "t :  44\n",
            "decayed_penalty_factor :  5.684341886080802e-17\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 11.0182], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 7.1362e-15])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 11.0182], grad_fn=<NllLossBackward0>)\n",
            "t :  45\n",
            "decayed_penalty_factor :  2.842170943040401e-17\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 11.2812], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 3.6562e-15])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 11.2812], grad_fn=<NllLossBackward0>)\n",
            "t :  46\n",
            "decayed_penalty_factor :  1.4210854715202004e-17\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 11.8195], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 1.9198e-15])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 11.8195], grad_fn=<NllLossBackward0>)\n",
            "t :  47\n",
            "decayed_penalty_factor :  7.105427357601002e-18\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 12.0901], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 9.4005e-16])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 12.0901], grad_fn=<NllLossBackward0>)\n",
            "t :  48\n",
            "decayed_penalty_factor :  3.552713678800501e-18\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 12.3681], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 9.3441e-03, 4.8164e-16])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 12.3681], grad_fn=<NllLossBackward0>)\n",
            "t :  49\n",
            "decayed_penalty_factor :  1.7763568394002505e-18\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 12.6247], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.8070e+03, 6.6000e+03, 2.4594e-02, 2.3593e-16])\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 4.0531e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 21.9798, 12.6247], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([2.2319e+00, 3.4978e+00, 1.0729e-06, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([24.6534, 22.5972, 24.4145, 12.8910], grad_fn=<NllLossBackward0>)\n",
            "PGD l1: Attack effectiveness 50.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_gaussian_1000(adv2.to(torch.float32))\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq4PoC1Sdo_e",
        "outputId": "8b406a09-3f11-49c3-8fd5-38c76ba3a6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 12.4715, -12.1819],\n",
            "        [ 11.4356, -11.1617],\n",
            "        [ 12.3292, -12.0853],\n",
            "        [  6.4998,  -6.3911]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_AT_rFGSM(adv2.to(torch.float32))\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS5zPGfId5AL",
        "outputId": "bdfde24b-9070-4e1b-e242-44a28fe294c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0.8798,  -1.2386],\n",
            "        [  1.5130,  -1.9541],\n",
            "        [ -6.5551,   7.1809],\n",
            "        [-29.9500,  31.9684]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model_AT_rFGSM(mals.to(torch.float32))\n",
        "torch.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "id": "Mj5rIgXvgY2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(mals_y.view(-1).long())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzEOZOp9li_p",
        "outputId": "aaedc836-d106-4a10-dad0-3b46910a55da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2, -2, -2, -2])"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "inputs = mals.to(torch.float32).clone().detach().requires_grad_(True)\n",
        "outputs = model_AT_rFGSM(inputs)\n",
        "loss = criterion(outputs, mals_y.view(-1).long())\n",
        "print(loss)\n",
        "\n",
        "\n",
        "grad_vars = torch.autograd.grad(loss.mean(), inputs)\n",
        "gradients = grad_vars[0].data\n",
        "print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH7t193OjDJD",
        "outputId": "9edd7891-8b6d-4bb1-f7a0-3ea36f33e684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.4870e-15, 1.1302e-34, 2.6278e-22, 0.0000e+00])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "inputs = mals.to(torch.float32).clone().detach().requires_grad_(True)\n",
        "outputs = model_AT_rFGSM(inputs)\n",
        "labels = (mals_y.view(-1).long() - 1)\n",
        "loss = criterion(outputs, labels)\n",
        "print(loss)\n",
        "\n",
        "\n",
        "grad_vars = torch.autograd.grad(loss.mean(), inputs)\n",
        "gradients = grad_vars[0].data\n",
        "print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yPLTp_YmKkh",
        "outputId": "20828f44-ea47-42ab-bd51-30ddfe9a1d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vj7PBARTodzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model, penalty_factor):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    print('ce: ', ce)\n",
        "    outputs_rbf = model_gaussian_1000(adv_x)\n",
        "    kde = criterion(outputs_rbf, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    #kde=0.\n",
        "    print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "i8wDOTsZnfFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWBOUPflotzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1UAKciYp9Qj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, torch.zeros_like(mals_y.view(-1).long()))\n",
        "        print('loss : ',loss)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            outputs = model(x_next)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            done = (predicted != y).squeeze()\n",
        "            print(done)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "XdQ-5RbP6oDu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_AT_rFGSM, insertion_array, removal_array, k=500, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlsAkPMhpc7S",
        "outputId": "600fa957-9145-4118-adec-d652bdc78e41"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n",
            "tensor([False, False, False, False])\n",
            "loss :  tensor([ 17.2574,  71.0176,  53.6272, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10475.5771,  8753.7480,  9374.5732,  9018.6055])\n",
            "tensor([False, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 5.5429e+01, 4.4622e+01, 1.5478e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1265e+03, 1.0463e+04, 9.0235e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 4.2018e+01, 3.5233e+01, 1.4863e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.5316e+03, 1.0955e+04, 8.8765e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 3.0319e+01, 2.5832e+01, 1.4469e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.3921e+03, 1.0962e+04, 8.4613e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 1.9540e+01, 1.7143e+01, 1.3839e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1422e+03, 1.1507e+04, 8.3465e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 1.2214e+01, 8.8525e+00, 1.3348e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 8.7310e+03, 1.1474e+04, 8.3465e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 4.0993e+00, 1.3330e+00, 1.2865e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 7.7917e+03, 9.0294e+03, 8.3465e+03])\n",
            "tensor([ True, False, False, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.2417e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3465e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1939e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1495e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1068e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0643e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0237e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.8351e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.4362e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.0639e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3357e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.7156e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.3935e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3143e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.0755e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.7752e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8621e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.4700e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.1965e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.9337e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3132e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.7578e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8157e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.4789e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8228e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2163e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2845e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2409e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7232e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.9668e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8201e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.7031e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7293e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.4995e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2633e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.2756e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5679e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.0393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.8147e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.7072e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0702e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.4889e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.2713e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.0543e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.8393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9781e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.6430e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.4583e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2908e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3707e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2531e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.4075e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2872e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.4608e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2053e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.8152e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1368e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8477e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "tensor([ True,  True,  True, False])\n",
            "PGD l1: Attack effectiveness 75.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "        print('loss : ',loss)\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            outputs = model(x_next)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            done = (predicted != y).squeeze()\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "DQicJeD3wLxA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_AT_rFGSM, insertion_array, removal_array, k=500, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a652596-a011-4a8a-f953-fb4a0f4e355b",
        "id": "BCWXhAJ8W46H"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.4870e-15, 1.1302e-34, 2.6278e-22, 0.0000e+00])\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5985e-04, 6.1378e-28, 2.3369e-20, 0.0000e+00])\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 3.7722e-21, 2.1269e-16, 0.0000e+00])\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 2.6399e-15, 2.6725e-12, 0.0000e+00])\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 3.1136e-10, 3.1988e-08, 0.0000e+00])\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 1.4353e-05, 1.9638e-04, 0.0000e+00])\n",
            "loss :  tensor([1.0299e+01, 5.0068e-06, 1.4304e-04, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 4.3532e-02, 1.6415e+00, 0.0000e+00])\n",
            "loss :  tensor([10.2994,  0.0167,  0.3061, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8880.3486,  131.3973, 3233.3621,    0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "PGD l1: Attack effectiveness 75.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gkde(x, y, model,bens, bandwidth, penalty_factor, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural, _ = get_loss_kde(x,y,model,bens, bandwidth, penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        #y_model = model(x_var)\n",
        "        if t > 20:\n",
        "          decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "        else:\n",
        "          decayed_penalty_factor = penalty_factor\n",
        "\n",
        "        # Compute loss\n",
        "        loss, _ = get_loss_kde(x_var,y,model,bens, bandwidth, decayed_penalty_factor)\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            _, done = get_loss_kde(x_next,y,model,bens, bandwidth, penalty_factor)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv, done = get_loss_kde(x_next,y,model,bens, bandwidth, penalty_factor)\n",
        "    loss_adv = loss_adv.data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "2GiSV8FEoleR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Create a range of values for logits\n",
        "logit_range = np.linspace(-10, 10, 100)\n",
        "logits = torch.tensor(logit_range, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Compute sigmoid probabilities\n",
        "probabilities = torch.sigmoid(logits).numpy()\n",
        "\n",
        "# Assume the true label is 1 (malware) for simplicity\n",
        "true_labels = torch.ones_like(logits)\n",
        "\n",
        "# Compute binary cross-entropy loss\n",
        "binary_cross_entropy_loss = F.binary_cross_entropy_with_logits(logits, true_labels, reduction='none').numpy()\n",
        "\n",
        "# Plot the binary cross-entropy loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(logit_range, binary_cross_entropy_loss, label='Binary Cross-Entropy Loss')\n",
        "plt.xlabel('Logit')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Binary Cross-Entropy Loss for Different Logits')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "2PrmiKsMz7ca",
        "outputId": "59fc00d1-1487-4202-ad9a-8fdfd651d31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RHYlmKaAXuDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-TwoMjmQXt_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gkde(x, y, model, penalty_factor, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        #y_model = model(x_var)\n",
        "        if t > 40:\n",
        "          decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "          print('t : ',t)\n",
        "          print('decayed_penalty_factor : ',decayed_penalty_factor)\n",
        "        else:\n",
        "          decayed_penalty_factor = penalty_factor\n",
        "\n",
        "        # Compute loss\n",
        "        loss, _ = get_loss_kde(x_var,y,model, decayed_penalty_factor)\n",
        "        print('loss : ',loss)\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            print('l2norm ; ',l2norm)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            print('un_mod',un_mod.sum(dim=-1))\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            print('max_grad', val)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            _, done = get_loss_kde(x_next,y,model, penalty_factor)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, y.view(-1).long()).data\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    print('loss_natural : ',loss_natural)\n",
        "    print('loss_adv : ',loss_adv)\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "PP1EIy_6XqWC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model, penalty_factor):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    print('ce: ', ce)\n",
        "    outputs_rbf = model_gaussian_1000(adv_x)\n",
        "    kde = criterion(outputs_rbf, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    #kde=0.\n",
        "    print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "Y1BJFkXPXr9a"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8V-HBitZxvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 50, insertion_array, removal_array, k=200, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ec2b1d3-c4bb-4554-ef03-4404ed1a6dc1",
        "id": "_KO-eZiwZyEz"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([270.0239, 453.6583, 423.9228, 380.1457], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([27473.8125, 24902.7988, 24146.7676, 10260.3184])\n",
            "un_mod tensor([10000, 10000, 10000, 10000])\n",
            "max_grad tensor([[43.0186],\n",
            "        [37.5190],\n",
            "        [34.5575],\n",
            "        [ 8.7332]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([ 41.4521,  87.1468,  58.7566, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3975, 4.2835, 4.4865, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([111.3284, 301.3212, 283.0825, 343.9585], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([22641.8633, 24454.8613, 23824.1016, 10288.9590])\n",
            "un_mod tensor([9999, 9999, 9999, 9999])\n",
            "max_grad tensor([[31.0305],\n",
            "        [35.1407],\n",
            "        [33.1568],\n",
            "        [ 4.3887]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.4521,  87.1468,  58.7566, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3975, 4.2835, 4.4865, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([ 41.0207,  86.5490,  57.6814, 162.1008], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1219, 1.6738, 1.9881, 3.2830], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 47.1157, 170.2408, 157.0856, 326.2496], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([11464.3242, 20178.1094, 21578.3535, 10243.5723])\n",
            "un_mod tensor([9998, 9998, 9998, 9998])\n",
            "max_grad tensor([[ 7.0760],\n",
            "        [26.4701],\n",
            "        [26.3823],\n",
            "        [ 3.6644]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.0207,  86.5490,  57.6814, 162.1008], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.1219, 1.6738, 1.9881, 3.2830], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([ 17.6691,  88.2370,  59.8087, 152.3671], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0622, 0.2952, 0.4528, 3.1783], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.7810, 102.9947,  82.4475, 311.2840], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([11207.5186, 12543.9766, 14275.4102, 10283.7197])\n",
            "un_mod tensor([9997, 9997, 9997, 9997])\n",
            "max_grad tensor([[6.7577],\n",
            "        [6.8699],\n",
            "        [9.8279],\n",
            "        [3.7309]], dtype=torch.float64)\n",
            "ce:  tensor([ 17.6691,  88.2370,  59.8087, 152.3671], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0622, 0.2952, 0.4528, 3.1783], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 9.0022e+01, 6.0618e+01, 1.4773e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0406, 0.0659, 2.9807], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  92.0529,  63.9109, 296.7697], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129, 10076.5664, 10651.4541, 10199.9395])\n",
            "un_mod tensor([9996, 9996, 9996, 9996])\n",
            "max_grad tensor([[1.3526],\n",
            "        [4.9291],\n",
            "        [2.5060],\n",
            "        [3.3921]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 9.0022e+01, 6.0618e+01, 1.4773e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0406, 0.0659, 2.9807], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 7.3856e+01, 5.1751e+01, 1.4841e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0212, 0.0556, 2.6996], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  74.9180,  54.5334, 283.3917], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  8698.0186, 10243.8311, 10186.6553])\n",
            "un_mod tensor([9996, 9995, 9995, 9995])\n",
            "max_grad tensor([[1.3526],\n",
            "        [3.6905],\n",
            "        [2.4005],\n",
            "        [3.3169]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 7.3856e+01, 5.1751e+01, 1.4841e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0212, 0.0556, 2.6996], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.9019e+01, 4.2614e+01, 1.5007e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0100, 0.0468, 2.4235], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  59.5218,  44.9515, 271.2455], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  8749.8428, 10771.7529, 10139.8213])\n",
            "un_mod tensor([9996, 9994, 9994, 9994])\n",
            "max_grad tensor([[1.3526],\n",
            "        [3.0322],\n",
            "        [2.3544],\n",
            "        [3.0680]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.9019e+01, 4.2614e+01, 1.5007e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0100, 0.0468, 2.4235], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 4.5852e+01, 3.4015e+01, 1.4864e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0208, 0.0391, 2.2296], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  46.8924,  35.9686, 260.1192], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  9895.3486, 10728.3408, 10076.2744])\n",
            "un_mod tensor([9996, 9993, 9993, 9993])\n",
            "max_grad tensor([[1.3526],\n",
            "        [3.1433],\n",
            "        [2.1360],\n",
            "        [2.5996]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 4.5852e+01, 3.4015e+01, 1.4864e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0208, 0.0391, 2.2296], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 3.4178e+01, 2.6019e+01, 1.4795e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0108, 0.0325, 2.0660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  34.7172,  27.6423, 251.2510], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  9272.0625, 11518.7363, 10020.2051])\n",
            "un_mod tensor([9996, 9992, 9992, 9992])\n",
            "max_grad tensor([[1.3526],\n",
            "        [2.7762],\n",
            "        [2.1603],\n",
            "        [2.4595]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 3.4178e+01, 2.6019e+01, 1.4795e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0108, 0.0325, 2.0660], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 2.3364e+01, 1.8244e+01, 1.4765e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0050, 0.0268, 1.9082], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  23.6129,  19.5851, 243.0597], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  8682.0938, 10834.2998,  9946.8027])\n",
            "un_mod tensor([9996, 9991, 9991, 9991])\n",
            "max_grad tensor([[1.3526],\n",
            "        [2.3819],\n",
            "        [1.9677],\n",
            "        [2.4791]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 2.3364e+01, 1.8244e+01, 1.4765e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0050, 0.0268, 1.9082], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 1.4976e+01, 1.1861e+01, 1.4537e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 9.8907e-04, 2.2040e-02, 1.7862e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,  15.0258,  12.9626, 234.6768], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 8452.8936, 9542.7852, 9948.5527])\n",
            "un_mod tensor([9996, 9990, 9990, 9990])\n",
            "max_grad tensor([[1.3526],\n",
            "        [2.0726],\n",
            "        [1.6772],\n",
            "        [2.4560]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 1.4976e+01, 1.1861e+01, 1.4537e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 9.8907e-04, 2.2040e-02, 1.7862e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 6.8049e+00, 5.4601e+00, 1.4339e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 5.7359e-04, 5.1326e-02, 1.6648e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   6.8336,   8.0264, 226.6242], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  8224.9141, 12004.9111,  9931.3633])\n",
            "un_mod tensor([9996, 9989, 9989, 9989])\n",
            "max_grad tensor([[1.3526],\n",
            "        [1.9644],\n",
            "        [1.9553],\n",
            "        [2.4457]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 6.8049e+00, 5.4601e+00, 1.4339e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 5.7359e-04, 5.1326e-02, 1.6648e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 2.6747e+00, 1.3862e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 7.6197e-03, 1.6004e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   3.0557, 218.6424], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557, 11454.2559,  9945.8008])\n",
            "un_mod tensor([9996, 9988, 9988, 9988])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.7466],\n",
            "        [2.4387]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 2.6747e+00, 1.3862e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 7.6197e-03, 1.6004e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 1.6629e+00, 1.3269e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 3.2911e-03, 1.5615e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   1.8275, 210.7626], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  9520.9414, 10009.8223])\n",
            "un_mod tensor([9996, 9988, 9987, 9987])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.5928],\n",
            "        [2.3008]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 1.6629e+00, 1.3269e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 3.2911e-03, 1.5615e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.3047e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.4600e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 203.4710], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10004.5342])\n",
            "un_mod tensor([9996, 9988, 9986, 9986])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3216]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.3047e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.4600e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.2524e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.4188e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 196.1797], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10022.0625])\n",
            "un_mod tensor([9996, 9988, 9986, 9985])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3152]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.2524e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.4188e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.2099e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.3590e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 188.9390], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10031.0859])\n",
            "un_mod tensor([9996, 9988, 9986, 9984])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3346]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.2099e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.3590e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.1945e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.2455e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 181.7310], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10007.4678])\n",
            "un_mod tensor([9996, 9988, 9986, 9983])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3148]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.1945e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.2455e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.1453e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.2017e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 174.6136], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10014.1357])\n",
            "un_mod tensor([9996, 9988, 9986, 9982])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3248]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.1453e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.2017e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0960e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.1575e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 167.4736], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10022.9961])\n",
            "un_mod tensor([9996, 9988, 9986, 9981])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.3376]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0960e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.1575e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0928e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.0223e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 160.3994], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10098.9688])\n",
            "un_mod tensor([9996, 9988, 9986, 9980])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.2300]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0928e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 1.0223e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0483e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 9.7730e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 153.6976], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10099.2432])\n",
            "un_mod tensor([9996, 9988, 9986, 9979])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.2149]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0483e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 9.7730e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0064e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 9.3223e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 147.2490], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9551.9482])\n",
            "un_mod tensor([9996, 9988, 9986, 9978])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.5102]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0064e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 9.3223e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0021e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 8.1230e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 140.8286], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([  662.7129,  3067.5557,  3399.8079, 10016.7324])\n",
            "un_mod tensor([9996, 9988, 9986, 9977])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.0417]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.0021e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 8.1230e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 9.7503e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 7.4768e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 134.8872], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9986.7695])\n",
            "un_mod tensor([9996, 9988, 9986, 9976])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [2.0099]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 9.7503e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 7.4768e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 9.2468e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 7.3054e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 128.9951], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9851.0068])\n",
            "un_mod tensor([9996, 9988, 9986, 9975])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.9568]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 9.2468e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 7.3054e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.9963e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 6.6738e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 123.3323], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9959.9229])\n",
            "un_mod tensor([9996, 9988, 9986, 9974])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.9009]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.9963e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 6.6738e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.7584e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 6.0606e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 117.8871], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9913.5791])\n",
            "un_mod tensor([9996, 9988, 9986, 9973])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.8469]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.7584e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 6.0606e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.4324e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 5.6511e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 112.5797], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9896.8877])\n",
            "un_mod tensor([9996, 9988, 9986, 9972])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.8243]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.4324e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 5.6511e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.1053e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 5.2519e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 107.3126], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9865.8389])\n",
            "un_mod tensor([9996, 9988, 9986, 9971])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.7821]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 8.1053e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 5.2519e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.7883e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 4.8643e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  1.7016,   0.5267,   0.4869, 102.2047], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9289.5322])\n",
            "un_mod tensor([9996, 9988, 9986, 9970])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.9366]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.7883e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 4.8643e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.5592e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 4.3494e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 97.3389], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9778.2109])\n",
            "un_mod tensor([9996, 9988, 9986, 9969])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.6709]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.5592e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 4.3494e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.3225e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.8947e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 92.6987], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9116.6719])\n",
            "un_mod tensor([9996, 9988, 9986, 9968])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.5165]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.3225e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.8947e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.0579e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.5589e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 88.3732], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 9082.0840])\n",
            "un_mod tensor([9996, 9988, 9986, 9967])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.4859]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 7.0579e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.5589e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.6893e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.4185e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 83.9854], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8934.3125])\n",
            "un_mod tensor([9996, 9988, 9986, 9966])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.4456]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.6893e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4024e-02, 3.2551e-04, 1.7913e-03, 3.4185e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.4816e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.3010], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 79.8673], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8880.5293])\n",
            "un_mod tensor([9996, 9988, 9986, 9965])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.3980]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.4816e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.3010], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.1276e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2898], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 75.7670], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8875.3467])\n",
            "un_mod tensor([9996, 9988, 9986, 9964])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.2806]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 6.1276e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2898], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.7290e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2969], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 72.1329], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8898.9033])\n",
            "un_mod tensor([9996, 9988, 9986, 9963])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.2918]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.7290e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2969], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.6723e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2414], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 68.7945], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8679.2461])\n",
            "un_mod tensor([9996, 9988, 9986, 9962])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.1641]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.6723e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2414], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.5325e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2079], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 65.7201], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8467.1582])\n",
            "un_mod tensor([9996, 9988, 9986, 9961])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.6766]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.5325e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2079], grad_fn=<NllLossBackward0>)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.0726e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2431], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.7016,  0.5267,  0.4869, 62.8791], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 662.7129, 3067.5557, 3399.8079, 8669.4102])\n",
            "un_mod tensor([9996, 9988, 9986, 9960])\n",
            "max_grad tensor([[1.3526],\n",
            "        [0.6967],\n",
            "        [0.1340],\n",
            "        [1.1642]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 5.0726e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2431], grad_fn=<NllLossBackward0>)\n",
            "t :  41\n",
            "decayed_penalty_factor :  39.75\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.8682e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2177], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3528,  0.5234,  0.4685, 57.3358], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 527.3314, 3066.9644, 3396.8303, 8535.8613])\n",
            "un_mod tensor([9996, 9988, 9986, 9959])\n",
            "max_grad tensor([[1.0753],\n",
            "        [0.6951],\n",
            "        [0.1387],\n",
            "        [1.0046]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.8682e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2177], grad_fn=<NllLossBackward0>)\n",
            "t :  42\n",
            "decayed_penalty_factor :  39.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.4966e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2375], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3443,  0.5233,  0.4681, 54.3462], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 524.0295, 3066.9500, 3396.7578, 8614.0801])\n",
            "un_mod tensor([9996, 9988, 9986, 9958])\n",
            "max_grad tensor([[1.0685],\n",
            "        [0.6951],\n",
            "        [0.1388],\n",
            "        [0.9965]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.4966e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2375], grad_fn=<NllLossBackward0>)\n",
            "t :  43\n",
            "decayed_penalty_factor :  39.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.3404e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2125], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3358,  0.5232,  0.4676, 51.7453], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 520.7275, 3066.9355, 3396.6853, 7897.1206])\n",
            "un_mod tensor([9996, 9988, 9986, 9957])\n",
            "max_grad tensor([[1.0618],\n",
            "        [0.6950],\n",
            "        [0.1389],\n",
            "        [0.8296]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.3404e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.2125], grad_fn=<NllLossBackward0>)\n",
            "t :  44\n",
            "decayed_penalty_factor :  39.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.1768e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1965], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3273,  0.5231,  0.4672, 49.4326], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 517.4257, 3066.9211, 3396.6130, 7653.0098])\n",
            "un_mod tensor([9996, 9988, 9986, 9956])\n",
            "max_grad tensor([[1.0550],\n",
            "        [0.6950],\n",
            "        [0.1390],\n",
            "        [0.7928]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 4.1768e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1965], grad_fn=<NllLossBackward0>)\n",
            "t :  45\n",
            "decayed_penalty_factor :  38.75\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.9929e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1853], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3188,  0.5230,  0.4667, 47.1091], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 514.1237, 3066.9067, 3396.5405, 7641.3755])\n",
            "un_mod tensor([9996, 9988, 9986, 9955])\n",
            "max_grad tensor([[1.0482],\n",
            "        [0.6950],\n",
            "        [0.1391],\n",
            "        [0.7616]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.9929e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1853], grad_fn=<NllLossBackward0>)\n",
            "t :  46\n",
            "decayed_penalty_factor :  38.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.8578e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1642], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3103,  0.5230,  0.4663, 44.8999], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 510.8217, 3066.8921, 3396.4683, 7613.5889])\n",
            "un_mod tensor([9996, 9988, 9986, 9954])\n",
            "max_grad tensor([[1.0415],\n",
            "        [0.6949],\n",
            "        [0.1392],\n",
            "        [0.7117]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.8578e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1642], grad_fn=<NllLossBackward0>)\n",
            "t :  47\n",
            "decayed_penalty_factor :  38.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.7307e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1444], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.3018,  0.5229,  0.4658, 42.8288], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 507.5199, 3066.8779, 3396.3960, 7471.3442])\n",
            "un_mod tensor([9996, 9988, 9986, 9953])\n",
            "max_grad tensor([[1.0347],\n",
            "        [0.6949],\n",
            "        [0.1394],\n",
            "        [0.6751]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.7307e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1444], grad_fn=<NllLossBackward0>)\n",
            "t :  48\n",
            "decayed_penalty_factor :  38.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.5617e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1365], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2933,  0.5228,  0.4654, 40.8025], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 504.2180, 3066.8635, 3396.3232, 7462.6655])\n",
            "un_mod tensor([9996, 9988, 9986, 9952])\n",
            "max_grad tensor([[1.0279],\n",
            "        [0.6948],\n",
            "        [0.1395],\n",
            "        [0.6281]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.5617e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1365], grad_fn=<NllLossBackward0>)\n",
            "t :  49\n",
            "decayed_penalty_factor :  37.75\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.3738e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1423], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2848,  0.5227,  0.4649, 39.1098], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 500.9161, 3066.8491, 3396.2507, 7476.2236])\n",
            "un_mod tensor([9996, 9988, 9986, 9951])\n",
            "max_grad tensor([[1.0212],\n",
            "        [0.6948],\n",
            "        [0.1396],\n",
            "        [0.6352]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.3738e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1423], grad_fn=<NllLossBackward0>)\n",
            "t :  50\n",
            "decayed_penalty_factor :  37.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.2579e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1247], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2763,  0.5226,  0.4645, 37.2543], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 497.6142, 3066.8347, 3396.1787, 7451.8208])\n",
            "un_mod tensor([9996, 9988, 9986, 9950])\n",
            "max_grad tensor([[1.0144],\n",
            "        [0.6948],\n",
            "        [0.1397],\n",
            "        [0.5819]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.2579e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1247], grad_fn=<NllLossBackward0>)\n",
            "t :  51\n",
            "decayed_penalty_factor :  37.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.1297e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1165], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2678,  0.5226,  0.4640, 35.6355], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 494.3123, 3066.8198, 3396.1064, 7263.6318])\n",
            "un_mod tensor([9996, 9988, 9986, 9949])\n",
            "max_grad tensor([[1.0076],\n",
            "        [0.6947],\n",
            "        [0.1398],\n",
            "        [0.5607]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.1297e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1165], grad_fn=<NllLossBackward0>)\n",
            "t :  52\n",
            "decayed_penalty_factor :  37.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.0226e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1015], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2592,  0.5225,  0.4636, 33.9799], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 491.0104, 3066.8057, 3396.0342, 7241.5757])\n",
            "un_mod tensor([9996, 9988, 9986, 9948])\n",
            "max_grad tensor([[1.0009],\n",
            "        [0.6947],\n",
            "        [0.1399],\n",
            "        [0.5594]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 3.0226e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1015], grad_fn=<NllLossBackward0>)\n",
            "t :  53\n",
            "decayed_penalty_factor :  36.75\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.7966e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1198], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2507,  0.5224,  0.4631, 32.3684], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 487.7086, 3066.7915, 3395.9614, 7189.1138])\n",
            "un_mod tensor([9996, 9988, 9986, 9947])\n",
            "max_grad tensor([[0.9941],\n",
            "        [0.6946],\n",
            "        [0.1400],\n",
            "        [0.5351]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.7966e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1198], grad_fn=<NllLossBackward0>)\n",
            "t :  54\n",
            "decayed_penalty_factor :  36.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.7006e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1045], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2422,  0.5223,  0.4627, 30.8188], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 484.4067, 3066.7769, 3395.8889, 7165.6396])\n",
            "un_mod tensor([9996, 9988, 9986, 9946])\n",
            "max_grad tensor([[0.9874],\n",
            "        [0.6946],\n",
            "        [0.1402],\n",
            "        [0.5155]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.7006e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1045], grad_fn=<NllLossBackward0>)\n",
            "t :  55\n",
            "decayed_penalty_factor :  36.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.4920e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1293], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2337,  0.5222,  0.4623, 29.6067], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 481.1049, 3066.7625, 3395.8167, 6956.0889])\n",
            "un_mod tensor([9996, 9988, 9986, 9945])\n",
            "max_grad tensor([[0.9806],\n",
            "        [0.6946],\n",
            "        [0.1403],\n",
            "        [0.5438]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.4920e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1293], grad_fn=<NllLossBackward0>)\n",
            "t :  56\n",
            "decayed_penalty_factor :  36.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.3979e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1131], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2252,  0.5221,  0.4618, 28.0489], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 477.8030, 3066.7480, 3395.7441, 6765.8354])\n",
            "un_mod tensor([9996, 9988, 9986, 9944])\n",
            "max_grad tensor([[0.9738],\n",
            "        [0.6945],\n",
            "        [0.1404],\n",
            "        [0.5204]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.3979e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1131], grad_fn=<NllLossBackward0>)\n",
            "t :  57\n",
            "decayed_penalty_factor :  35.75000000000001\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.2465e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1146], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2167,  0.5221,  0.4614, 26.5623], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 474.5012, 3066.7336, 3395.6719, 7302.1660])\n",
            "un_mod tensor([9996, 9988, 9986, 9943])\n",
            "max_grad tensor([[0.9671],\n",
            "        [0.6945],\n",
            "        [0.1405],\n",
            "        [0.5132]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.2465e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.1146], grad_fn=<NllLossBackward0>)\n",
            "t :  58\n",
            "decayed_penalty_factor :  35.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.2011e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0904], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.2082,  0.5220,  0.4609, 25.2216], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 471.1993, 3066.7192, 3395.5994, 7139.5796])\n",
            "un_mod tensor([9996, 9988, 9986, 9942])\n",
            "max_grad tensor([[0.9603],\n",
            "        [0.6944],\n",
            "        [0.1406],\n",
            "        [0.4599]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.2011e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0904], grad_fn=<NllLossBackward0>)\n",
            "t :  59\n",
            "decayed_penalty_factor :  35.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.1113e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0781], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.1997,  0.5219,  0.4605, 23.8658], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 467.8976, 3066.7046, 3395.5269, 6704.0073])\n",
            "un_mod tensor([9996, 9988, 9986, 9941])\n",
            "max_grad tensor([[0.9535],\n",
            "        [0.6944],\n",
            "        [0.1407],\n",
            "        [0.4140]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.1113e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0781], grad_fn=<NllLossBackward0>)\n",
            "t :  60\n",
            "decayed_penalty_factor :  35.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.0279e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0671], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.1912,  0.5218,  0.4600, 22.6283], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 464.5958, 3066.6904, 3395.4543, 6623.7344])\n",
            "un_mod tensor([9996, 9988, 9986, 9940])\n",
            "max_grad tensor([[0.9468],\n",
            "        [0.6944],\n",
            "        [0.1408],\n",
            "        [0.3690]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.0279e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0671], grad_fn=<NllLossBackward0>)\n",
            "t :  61\n",
            "decayed_penalty_factor :  34.75\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.1524e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0773], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.1827,  0.5217,  0.4596, 24.2097], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 461.2940, 3066.6758, 3395.3821, 5229.0879])\n",
            "un_mod tensor([9996, 9988, 9986, 9939])\n",
            "max_grad tensor([[0.9400],\n",
            "        [0.6943],\n",
            "        [0.1410],\n",
            "        [0.9860]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 2.1524e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0773], grad_fn=<NllLossBackward0>)\n",
            "t :  62\n",
            "decayed_penalty_factor :  34.5\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.9415e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0565], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.1742,  0.5217,  0.4591, 21.3645], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 457.9922, 3066.6616, 3395.3098, 6725.0146])\n",
            "un_mod tensor([9996, 9988, 9986, 9938])\n",
            "max_grad tensor([[0.9333],\n",
            "        [0.6943],\n",
            "        [0.1411],\n",
            "        [0.3293]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.9415e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0565], grad_fn=<NllLossBackward0>)\n",
            "t :  63\n",
            "decayed_penalty_factor :  34.25\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.8417e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0571], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 1.1657,  0.5216,  0.4587, 20.3717], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 454.6905, 3066.6470, 3395.2373, 5702.9175])\n",
            "un_mod tensor([9996, 9988, 9986, 9937])\n",
            "max_grad tensor([[0.9265],\n",
            "        [0.6943],\n",
            "        [0.1412],\n",
            "        [0.3155]], dtype=torch.float64)\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.8417e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0340, 0.0003, 0.0018, 0.0571], grad_fn=<NllLossBackward0>)\n",
            "t :  64\n",
            "decayed_penalty_factor :  34.0\n",
            "ce:  tensor([3.7449e-04, 5.1043e-01, 3.9732e-01, 1.9438e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-baac1bb428c9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmals_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_AT_rFGSM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsertion_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoval_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_rounding_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_report_loss_diff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-36e820d98cd0>\u001b[0m in \u001b[0;36mgkde\u001b[0;34m(x, y, model, penalty_factor, insertion_array, removal_array, k, step_length, norm, initial_rounding_threshold, round_threshold, random, is_report_loss_diff, is_sample)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecayed_penalty_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-33344a7622d3>\u001b[0m in \u001b[0;36mget_loss_kde\u001b[0;34m(adv_x, y, model, penalty_factor)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmals_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ce: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutputs_rbf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_gaussian_1000\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_rbf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmals_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#kde=0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-a6e13bf31657>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mradial_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'laplacian'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mradial_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaplacian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-a6e13bf31657>\u001b[0m in \u001b[0;36mgaussian\u001b[0;34m(self, x, c, sigma)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlaplacian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# See https://github.com/pytorch/pytorch/issues/75462\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 150, insertion_array, removal_array, k=150, step_length=0.1, norm='l2', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGqpNQTZgM_N",
        "outputId": "935e61fb-4ba7-49a0-c563-6bdd9226d7ad"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 728.0156, 1187.7156, 1155.4517,  766.7467], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([65625.9688, 58235.7500, 55779.8438, 13472.1680])\n",
            "l2norm ;  tensor([[682.7472],\n",
            "        [596.8692],\n",
            "        [560.4139],\n",
            "        [ 57.0439]], dtype=torch.float64)\n",
            "ce:  tensor([ 46.0083,  90.9380,  62.7585, 188.0305], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.7538, 5.7141, 5.7855, 3.7050], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([459.0752, 948.0568, 930.5891, 743.7858], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([62477.9766, 58402.9805, 55649.1953, 13476.3564])\n",
            "l2norm ;  tensor([[650.8463],\n",
            "        [600.9231],\n",
            "        [563.4948],\n",
            "        [ 57.7570]], dtype=torch.float64)\n",
            "ce:  tensor([ 50.9619,  95.0748,  67.3104, 189.1739], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1665, 4.0847, 4.2546, 3.5425], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([225.9418, 707.7725, 705.4983, 720.5509], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([48905.2656, 57829.3008, 55270.8359, 13480.7910])\n",
            "l2norm ;  tensor([[478.5675],\n",
            "        [598.0340],\n",
            "        [560.3563],\n",
            "        [ 58.4165]], dtype=torch.float64)\n",
            "ce:  tensor([ 55.6005,  99.0350,  71.8393, 190.2644], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.2847, 2.4976, 2.7559, 3.3787], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 98.3048, 473.6791, 485.2194, 697.0621], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([23344.3984, 54450.2617, 53022.3906, 13486.2656])\n",
            "l2norm ;  tensor([[166.9071],\n",
            "        [562.4973],\n",
            "        [534.2544],\n",
            "        [ 59.0307]], dtype=torch.float64)\n",
            "ce:  tensor([ 58.9488, 102.8552,  76.3616, 191.2925], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0483, 1.1332, 1.4130, 3.2136], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 66.2010, 272.8354, 288.3165, 673.3350], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12194.1484, 42634.5117, 44573.0625, 13495.0391])\n",
            "l2norm ;  tensor([[ 29.5001],\n",
            "        [415.7833],\n",
            "        [430.9827],\n",
            "        [ 59.6136]], dtype=torch.float64)\n",
            "ce:  tensor([ 58.7504, 106.4169,  80.7105, 192.2183], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0094, 0.3323, 0.5028, 3.0475], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 60.1658, 156.2594, 156.1273, 649.3464], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10445.8477, 22623.1113, 27206.6152, 13363.2383])\n",
            "l2norm ;  tensor([[ 11.1979],\n",
            "        [170.1166],\n",
            "        [221.2186],\n",
            "        [ 60.3349]], dtype=torch.float64)\n",
            "ce:  tensor([ 55.1947, 108.9750,  84.3588, 193.0621], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0049, 0.0715, 0.1291, 2.8801], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 55.9265, 119.7070, 103.7191, 625.0810], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10261.3008, 12300.3271, 14304.4688, 13332.7080])\n",
            "l2norm ;  tensor([[10.3284],\n",
            "        [40.0602],\n",
            "        [63.4671],\n",
            "        [61.0015]], dtype=torch.float64)\n",
            "ce:  tensor([ 51.3652, 108.7732,  86.2083, 193.8207], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.0033, 0.0158, 0.0302, 2.7117], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 51.8573, 111.1480,  90.7355, 600.5699], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 9112.4219, 10112.1982, 10418.0459, 13344.4961])\n",
            "l2norm ;  tensor([[ 9.5118],\n",
            "        [13.9123],\n",
            "        [15.4624],\n",
            "        [61.5670]], dtype=torch.float64)\n",
            "ce:  tensor([ 47.7041, 105.2175,  85.1783, 194.4948], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.4137e-03, 6.7249e-03, 9.5486e-03, 2.5423e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 48.0662, 106.2262,  86.6106, 575.8392], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 9089.5352,  9816.3135,  9717.9775, 13350.8770])\n",
            "l2norm ;  tensor([[ 9.4402],\n",
            "        [11.6389],\n",
            "        [ 8.6915],\n",
            "        [62.0941]], dtype=torch.float64)\n",
            "ce:  tensor([ 44.6479, 101.0328,  82.4411, 195.0831], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8771e-03, 4.0244e-03, 5.5802e-03, 2.3722e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 44.9295, 101.6365,  83.2781, 550.9117], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8631.8867,  9532.1152,  9485.7559, 13347.9062])\n",
            "l2norm ;  tensor([[ 8.1954],\n",
            "        [11.4106],\n",
            "        [ 8.2168],\n",
            "        [62.5416]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.4498,  96.7106,  79.3930, 195.5844], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4058e-03, 2.6943e-03, 4.0017e-03, 2.2016e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 41.6607,  97.1148,  79.9932, 525.8292], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8614.5566,  9472.8369,  9373.2852, 13332.6875])\n",
            "l2norm ;  tensor([[ 8.1494],\n",
            "        [11.2418],\n",
            "        [ 8.2000],\n",
            "        [62.8590]], dtype=torch.float64)\n",
            "ce:  tensor([ 38.2483,  92.3544,  76.2724, 195.9964], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0860e-03, 1.8929e-03, 3.0907e-03, 2.0311e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 38.4112,  92.6383,  76.7360, 500.6553], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8595.5547,  9442.8984,  9347.3145, 13301.9209])\n",
            "l2norm ;  tensor([[ 8.1046],\n",
            "        [11.1487],\n",
            "        [ 8.1414],\n",
            "        [62.9891]], dtype=torch.float64)\n",
            "ce:  tensor([ 35.0196,  88.3072,  73.7623, 196.3145], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.5794e-04, 1.3695e-03, 2.4998e-03, 1.8611e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 35.1483,  88.5126,  74.1373, 475.4769], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8739.9229,  8349.5557,  8882.9922, 13250.8086])\n",
            "l2norm ;  tensor([[ 8.1916],\n",
            "        [10.4168],\n",
            "        [ 6.8713],\n",
            "        [62.8694]], dtype=torch.float64)\n",
            "ce:  tensor([ 31.7721,  84.1969,  71.1171, 196.5343], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.8498e-04, 1.0222e-03, 1.8984e-03, 1.6925e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 31.8749,  84.3503,  71.4019, 450.4080], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8734.5361,  8327.4414,  8866.6738, 13174.8281])\n",
            "l2norm ;  tensor([[ 3.7600],\n",
            "        [10.4247],\n",
            "        [ 6.8117],\n",
            "        [62.4296]], dtype=torch.float64)\n",
            "ce:  tensor([ 30.3214,  80.0662,  68.5226, 196.6524], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.3999e-04, 7.8028e-04, 1.4856e-03, 1.5263e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 30.4024,  80.1833,  68.7455, 425.5930], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8643.1699,  8193.4365,  8828.9297, 13067.5322])\n",
            "l2norm ;  tensor([[ 3.6424],\n",
            "        [10.5124],\n",
            "        [ 6.5590],\n",
            "        [61.5482]], dtype=torch.float64)\n",
            "ce:  tensor([ 28.9139,  75.9526,  65.9732, 196.6693], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.3562e-04, 6.0147e-04, 1.1820e-03, 1.3637e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 28.9793,  76.0428,  66.1505, 401.2185], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8301.5117,  8168.5454,  8833.0332, 12926.8115])\n",
            "l2norm ;  tensor([[ 3.4827],\n",
            "        [10.3114],\n",
            "        [ 6.3538],\n",
            "        [60.2539]], dtype=torch.float64)\n",
            "ce:  tensor([ 27.5188,  71.8421,  63.4900, 196.5640], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5899e-04, 4.7053e-04, 9.5334e-04, 1.2060e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 27.5726,  71.9127,  63.6330, 377.4649], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8323.8857,  8152.8975,  8848.0459, 12747.3730])\n",
            "l2norm ;  tensor([[ 3.5258],\n",
            "        [10.3429],\n",
            "        [ 6.2771],\n",
            "        [58.4354]], dtype=torch.float64)\n",
            "ce:  tensor([ 26.2214,  67.7638,  61.0109, 196.3399], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.0251e-04, 3.7127e-04, 7.8004e-04, 1.0548e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.2668,  67.8195,  61.1279, 354.5670], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 9258.2852,  8159.5859,  8848.8359, 12915.6787])\n",
            "l2norm ;  tensor([[ 2.7456],\n",
            "        [10.1608],\n",
            "        [ 6.2637],\n",
            "        [56.0085]], dtype=torch.float64)\n",
            "ce:  tensor([ 25.4354,  63.7123,  58.5315, 195.8435], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3291e-04, 2.9560e-04, 6.4519e-04, 9.1276e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.4703,  63.7566,  58.6283, 332.7579], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8149.9707,  8157.3311,  8883.2666, 12270.4160])\n",
            "l2norm ;  tensor([[ 2.7019],\n",
            "        [10.1539],\n",
            "        [ 6.2394],\n",
            "        [53.1299]], dtype=torch.float64)\n",
            "ce:  tensor([ 24.6088,  59.6535,  56.0566, 195.3448], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1598e-04, 2.3720e-04, 5.3809e-04, 7.7924e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.6412,  59.6891,  56.1373, 312.2312], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 7525.3779,  8146.0156,  8878.6475, 12371.7480])\n",
            "l2norm ;  tensor([[ 2.1460],\n",
            "        [10.1746],\n",
            "        [ 6.2409],\n",
            "        [47.4480]], dtype=torch.float64)\n",
            "ce:  tensor([ 23.8909,  55.5894,  53.5749, 195.1350], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.8321e-04, 1.9191e-04, 4.5313e-04, 6.5905e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.9184,  55.6182,  53.6428, 293.9920], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8529.1387,  8149.1367,  8867.3232, 11666.8516])\n",
            "l2norm ;  tensor([[ 2.4754],\n",
            "        [ 9.4710],\n",
            "        [ 6.2385],\n",
            "        [43.7501]], dtype=torch.float64)\n",
            "ce:  tensor([ 23.2159,  51.8368,  51.1315, 194.9447], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.2612e-04, 1.5961e-04, 3.8473e-04, 5.4964e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.2349,  51.8607,  51.1892, 277.3908], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 7475.5923,  8173.4580,  8720.0762, 11735.1455])\n",
            "l2norm ;  tensor([[ 2.1733],\n",
            "        [ 8.3759],\n",
            "        [ 6.0681],\n",
            "        [39.6708]], dtype=torch.float64)\n",
            "ce:  tensor([ 22.4058,  49.0460,  48.7134, 194.3187], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1086e-04, 1.3577e-04, 3.2396e-04, 4.5359e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.4224,  49.0663,  48.7620, 262.3572], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 6734.4419,  7734.5308,  8714.3887, 11005.6787])\n",
            "l2norm ;  tensor([[ 1.7305],\n",
            "        [ 5.7788],\n",
            "        [ 6.0707],\n",
            "        [35.4576]], dtype=torch.float64)\n",
            "ce:  tensor([ 21.8547,  46.8161,  46.5244, 193.6927], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0442e-04, 1.0800e-04, 2.7498e-04, 3.6925e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.8704,  46.8323,  46.5657, 249.0797], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 7615.6758,  8709.6279,  8162.8911, 11081.3691])\n",
            "l2norm ;  tensor([[ 2.1113],\n",
            "        [ 6.0332],\n",
            "        [ 5.3797],\n",
            "        [31.3737]], dtype=torch.float64)\n",
            "ce:  tensor([ 21.4402,  44.7965,  44.3856, 192.6543], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.0225e-05, 8.3443e-05, 2.1646e-04, 2.9836e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.4522,  44.8090,  44.4180, 237.4089], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 6439.3281,  7674.0054,  8153.8057, 10375.4502])\n",
            "l2norm ;  tensor([[ 1.4056],\n",
            "        [ 5.6124],\n",
            "        [ 4.7394],\n",
            "        [27.3015]], dtype=torch.float64)\n",
            "ce:  tensor([ 20.8750,  42.5543,  42.5106, 191.4973], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.3192e-05, 6.6993e-05, 1.7045e-04, 2.3827e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.8860,  42.5644,  42.5362, 227.2375], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 6408.6104,  7673.4902,  8136.5400, 10096.6504])\n",
            "l2norm ;  tensor([[ 1.4258],\n",
            "        [ 5.6109],\n",
            "        [ 4.3840],\n",
            "        [23.6442]], dtype=torch.float64)\n",
            "ce:  tensor([ 20.3234,  40.3139,  41.0209, 190.0878], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([6.7828e-05, 5.4239e-05, 1.3470e-04, 1.8903e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.3335,  40.3220,  41.0411, 218.4419], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7336.5786, 7665.9160, 7064.8311, 9853.9258])\n",
            "l2norm ;  tensor([[ 1.8827],\n",
            "        [ 4.9939],\n",
            "        [ 3.1338],\n",
            "        [20.4325]], dtype=torch.float64)\n",
            "ce:  tensor([ 20.1007,  38.3708,  39.7648, 188.4376], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.1378e-05, 4.7802e-05, 1.1467e-04, 1.4931e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.1084,  38.3779,  39.7820, 210.8344], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6364.3755, 7093.6533, 7001.0117, 9648.4854])\n",
            "l2norm ;  tensor([[ 1.3429],\n",
            "        [ 2.9919],\n",
            "        [ 2.5366],\n",
            "        [17.7054]], dtype=torch.float64)\n",
            "ce:  tensor([ 19.5391,  37.2718,  38.7528, 186.5664], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7206e-05, 4.1961e-05, 9.8581e-05, 1.1770e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.5462,  37.2781,  38.7676, 204.2213], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6328.9702, 8113.1587, 7000.5503, 9479.5195])\n",
            "l2norm ;  tensor([[ 1.4167],\n",
            "        [ 3.5886],\n",
            "        [ 2.5354],\n",
            "        [15.4511]], dtype=torch.float64)\n",
            "ce:  tensor([ 18.9887,  36.3458,  37.7268, 184.5074], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.3510e-05, 3.3855e-05, 8.5589e-05, 9.2752e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.9953,  36.3509,  37.7396, 198.4201], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6336.6138, 7001.3281, 6961.8125, 9343.6807])\n",
            "l2norm ;  tensor([[ 1.3792],\n",
            "        [ 2.7386],\n",
            "        [ 2.6646],\n",
            "        [13.6372]], dtype=torch.float64)\n",
            "ce:  tensor([ 18.4346,  35.3684,  36.6783, 182.2861], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.0292e-05, 2.8967e-05, 7.4622e-05, 7.3217e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.4407,  35.3727,  36.6895, 193.2686], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6278.8330, 6865.3228, 6916.9131, 9233.1777])\n",
            "l2norm ;  tensor([[ 1.4138],\n",
            "        [ 2.5134],\n",
            "        [ 2.5917],\n",
            "        [11.8436]], dtype=torch.float64)\n",
            "ce:  tensor([ 17.8695,  34.4290,  35.6431, 179.9812], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.7312e-05, 2.4318e-05, 6.5682e-05, 5.8479e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.8751,  34.4327,  35.6529, 188.7531], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6278.7417, 6220.5420, 6916.6528, 9149.2021])\n",
            "l2norm ;  tensor([[ 1.4136],\n",
            "        [ 2.2265],\n",
            "        [ 2.5911],\n",
            "        [10.7453]], dtype=torch.float64)\n",
            "ce:  tensor([ 17.3299,  33.5389,  34.6609, 177.5503], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4928e-05, 2.1338e-05, 5.8292e-05, 4.7145e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.3351,  33.5421,  34.6696, 184.6220], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5880.3994, 6220.4487, 7780.8398, 9084.1279])\n",
            "l2norm ;  tensor([[1.3833],\n",
            "        [2.2263],\n",
            "        [3.2862],\n",
            "        [9.4780]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.8412,  32.6636,  34.0572, 175.2263], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.3378e-05, 1.8835e-05, 4.8755e-05, 3.8229e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.8462,  32.6665,  34.0645, 180.9608], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7170.6968, 6160.9185, 6678.1362, 9031.7412])\n",
            "l2norm ;  tensor([[2.1489],\n",
            "        [2.1791],\n",
            "        [2.3401],\n",
            "        [8.8583]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.6130,  31.7923,  33.1431, 172.8400], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.7656e-05, 1.6689e-05, 4.4583e-05, 3.1192e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.6171,  31.7948,  33.1498, 177.5187], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4243.6382, 6160.8535, 6628.2749, 8989.5303])\n",
            "l2norm ;  tensor([[0.7687],\n",
            "        [2.1789],\n",
            "        [2.2783],\n",
            "        [8.3754]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.6936,  30.9386,  32.2805, 170.4041], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3484e-05, 1.5020e-05, 4.1126e-05, 2.5622e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.6971,  30.9409,  32.2867, 174.2474], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5671.5430, 6092.0142, 6166.3623, 8955.5947])\n",
            "l2norm ;  tensor([[1.5131],\n",
            "        [2.0810],\n",
            "        [1.9949],\n",
            "        [7.9991]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.5433,  30.1404,  31.4828, 168.1270], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.4438e-05, 1.3471e-05, 3.9934e-05, 2.1188e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.5469,  30.1424,  31.4888, 171.3052], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4095.6650, 5830.0698, 6166.3252, 8374.9512])\n",
            "l2norm ;  tensor([[0.6831],\n",
            "        [1.8692],\n",
            "        [1.9352],\n",
            "        [7.2096]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.3299,  29.3950,  30.7091, 165.8633], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1100e-05, 1.1802e-05, 3.7669e-05, 1.7416e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.3331,  29.3968,  30.7147, 168.4757], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5671.4673, 5796.8003, 6166.2598, 8351.2266])\n",
            "l2norm ;  tensor([[1.4853],\n",
            "        [1.8422],\n",
            "        [1.9350],\n",
            "        [6.9498]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.5442,  28.6647,  29.9355, 163.5787], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.1934e-05, 1.0490e-05, 3.5762e-05, 1.4399e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.5475,  28.6662,  29.9409, 165.7386], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5458.5708, 5770.4233, 6127.0669, 8332.1064])\n",
            "l2norm ;  tensor([[1.8880],\n",
            "        [1.8181],\n",
            "        [1.9011],\n",
            "        [6.7446]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.6186,  27.9376,  29.3004, 161.3160], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7643e-05, 9.2983e-06, 3.4332e-05, 1.1966e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.6212,  27.9390,  29.3055, 163.1109], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4095.4492, 5770.3887, 5527.6768, 8175.7246])\n",
            "l2norm ;  tensor([[0.5945],\n",
            "        [1.7437],\n",
            "        [2.5681],\n",
            "        [6.4522]], dtype=torch.float64)\n",
            "ce:  tensor([ 16.7937,  27.3259,  29.6349, 159.0679], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7047e-05, 8.8214e-06, 2.7656e-05, 9.9468e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.7962,  27.3272,  29.6390, 160.5599], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5671.3418, 6727.1670, 6072.5059, 8156.3774])\n",
            "l2norm ;  tensor([[1.4210],\n",
            "        [2.4363],\n",
            "        [1.8578],\n",
            "        [6.2948]], dtype=torch.float64)\n",
            "t :  41\n",
            "decayed_penalty_factor :  109.0\n",
            "ce:  tensor([ 16.6799,  26.9034,  29.0633, 156.8197], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.9073e-05, 7.7486e-06, 2.6822e-05, 8.3020e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.6819,  26.9043,  29.0662, 157.7246], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4495.2588, 5368.6777, 3894.6514, 8128.3652])\n",
            "l2norm ;  tensor([[1.0273],\n",
            "        [1.6753],\n",
            "        [0.9625],\n",
            "        [6.0371]], dtype=torch.float64)\n",
            "t :  42\n",
            "decayed_penalty_factor :  108.0\n",
            "ce:  tensor([ 16.5967,  26.3762,  29.0159, 154.5583], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4305e-05, 7.8678e-06, 2.0981e-05, 7.0098e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.5982,  26.3770,  29.0181, 155.3154], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5671.1333, 3788.8467, 5475.5293, 8121.6846])\n",
            "l2norm ;  tensor([[1.3774],\n",
            "        [0.9327],\n",
            "        [1.6523],\n",
            "        [5.9734]], dtype=torch.float64)\n",
            "t :  43\n",
            "decayed_penalty_factor :  107.0\n",
            "ce:  tensor([ 16.5895,  26.3344,  28.7622, 152.2948], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6212e-05, 6.6757e-06, 1.9908e-05, 5.9412e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.5913,  26.3351,  28.7643, 152.9305], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4495.1836, 5368.6519, 3894.5081, 8114.6592])\n",
            "l2norm ;  tensor([[0.7997],\n",
            "        [1.7376],\n",
            "        [0.9304],\n",
            "        [5.6716]], dtype=torch.float64)\n",
            "t :  44\n",
            "decayed_penalty_factor :  106.0\n",
            "ce:  tensor([ 16.4194,  26.1756,  28.5120, 150.1265], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4186e-05, 6.3181e-06, 1.6212e-05, 5.0776e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.4209,  26.1763,  28.5137, 150.6647], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6132.3779, 3788.8101, 5475.4346, 8110.1743])\n",
            "l2norm ;  tensor([[2.2604],\n",
            "        [0.9327],\n",
            "        [1.5872],\n",
            "        [5.5020]], dtype=torch.float64)\n",
            "t :  45\n",
            "decayed_penalty_factor :  105.0\n",
            "ce:  tensor([ 16.8341,  25.8027,  28.5039, 148.0054], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7762e-05, 5.4836e-06, 1.5616e-05, 4.3826e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.8360,  25.8032,  28.5055, 148.4656], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4495.2109, 3788.7910, 3894.4194, 8106.5469])\n",
            "l2norm ;  tensor([[1.0271],\n",
            "        [0.8175],\n",
            "        [0.9279],\n",
            "        [5.3329]], dtype=torch.float64)\n",
            "t :  46\n",
            "decayed_penalty_factor :  104.0\n",
            "ce:  tensor([ 16.5312,  25.7765,  28.1331, 145.9379], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3471e-05, 4.5299e-06, 1.2994e-05, 3.8044e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.5326,  25.7769,  28.1344, 146.3336], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4087.3296, 6325.1167, 3894.3677, 8103.5059])\n",
            "l2norm ;  tensor([[0.5824],\n",
            "        [2.3405],\n",
            "        [0.8990],\n",
            "        [4.9452]], dtype=torch.float64)\n",
            "t :  47\n",
            "decayed_penalty_factor :  103.0\n",
            "ce:  tensor([ 16.6639,  25.8267,  28.2706, 144.0120], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3232e-05, 3.8147e-06, 1.0610e-05, 3.3390e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.6652,  25.8271,  28.2717, 144.3559], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6132.3472, 3788.7534, 5219.2178, 8101.0278])\n",
            "l2norm ;  tensor([[2.2480],\n",
            "        [0.9745],\n",
            "        [1.2956],\n",
            "        [4.8199]], dtype=torch.float64)\n",
            "t :  48\n",
            "decayed_penalty_factor :  101.99999999999999\n",
            "ce:  tensor([ 16.9803,  25.4369,  28.0210, 142.1271], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6332e-05, 3.2186e-06, 1.0490e-05, 2.9505e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.9819,  25.4373,  28.0220, 142.4281], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5592.1177, 3788.7412, 3641.0273, 8098.9429])\n",
            "l2norm ;  tensor([[2.2347],\n",
            "        [0.7765],\n",
            "        [0.8187],\n",
            "        [4.5447]], dtype=torch.float64)\n",
            "t :  49\n",
            "decayed_penalty_factor :  101.0\n",
            "ce:  tensor([ 16.9877,  25.3529,  28.2585, 140.3449], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1086e-05, 2.7418e-06, 9.0599e-06, 2.6254e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.9888,  25.3531,  28.2594, 140.6101], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5806.7671, 5317.7939, 5698.2539, 8097.1855])\n",
            "l2norm ;  tensor([[1.3756],\n",
            "        [1.5675],\n",
            "        [2.1066],\n",
            "        [4.5319]], dtype=torch.float64)\n",
            "t :  50\n",
            "decayed_penalty_factor :  100.00000000000001\n",
            "ce:  tensor([ 17.0390,  25.5225,  28.2433, 138.5623], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3113e-05, 2.7418e-06, 9.6559e-06, 2.3472e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.0403,  25.5228,  28.2443, 138.7970], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4087.3091, 4709.6294, 3641.0078, 8095.6758])\n",
            "l2norm ;  tensor([[0.8213],\n",
            "        [2.0459],\n",
            "        [0.8923],\n",
            "        [4.4413]], dtype=torch.float64)\n",
            "t :  51\n",
            "decayed_penalty_factor :  98.99999999999999\n",
            "ce:  tensor([ 16.8791,  25.5500,  28.3688, 136.8105], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0729e-05, 2.3842e-06, 8.3446e-06, 2.1168e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.8802,  25.5503,  28.3696, 137.0201], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6132.2852, 3788.7222, 5219.1714, 8094.4131])\n",
            "l2norm ;  tensor([[2.2412],\n",
            "        [0.7699],\n",
            "        [1.2508],\n",
            "        [4.3321]], dtype=torch.float64)\n",
            "t :  52\n",
            "decayed_penalty_factor :  98.0\n",
            "ce:  tensor([ 17.2593,  25.6295,  28.1371, 135.0985], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3709e-05, 2.2650e-06, 8.2254e-06, 1.9204e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.2607,  25.6297,  28.1379, 135.2867], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4632.5107, 5317.7817, 3640.9800, 8093.3276])\n",
            "l2norm ;  tensor([[1.0124],\n",
            "        [1.5675],\n",
            "        [0.8922],\n",
            "        [4.2481]], dtype=torch.float64)\n",
            "t :  53\n",
            "decayed_penalty_factor :  97.00000000000001\n",
            "ce:  tensor([ 16.9353,  25.5194,  28.3339, 133.4454], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.7751e-06, 2.1458e-06, 7.2717e-06, 1.7566e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 16.9362,  25.5196,  28.3346, 133.6158], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3981.1533, 4140.1411, 5219.1499, 8006.0068])\n",
            "l2norm ;  tensor([[0.6526],\n",
            "        [1.0955],\n",
            "        [1.3315],\n",
            "        [3.8436]], dtype=torch.float64)\n",
            "t :  54\n",
            "decayed_penalty_factor :  96.0\n",
            "ce:  tensor([ 17.1185,  25.3256,  28.2122, 131.9222], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0133e-05, 1.7881e-06, 7.8678e-06, 1.6197e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.1195,  25.3257,  28.2130, 132.0777], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5427.8135, 5317.7720, 5014.1792, 8005.2358])\n",
            "l2norm ;  tensor([[1.3618],\n",
            "        [1.5373],\n",
            "        [2.4130],\n",
            "        [3.4647]], dtype=torch.float64)\n",
            "t :  55\n",
            "decayed_penalty_factor :  95.0\n",
            "ce:  tensor([ 17.1632,  25.4944,  28.6199, 130.5493], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1325e-05, 1.6689e-06, 6.4373e-06, 1.4934e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.1643,  25.4946,  28.6205, 130.6911], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5307.6943, 3737.7517, 5219.1338, 8004.5220])\n",
            "l2norm ;  tensor([[1.9738],\n",
            "        [0.8853],\n",
            "        [1.2986],\n",
            "        [3.4120]], dtype=torch.float64)\n",
            "t :  56\n",
            "decayed_penalty_factor :  94.0\n",
            "ce:  tensor([ 17.5465,  25.1412,  28.4445, 129.1949], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.1791e-06, 1.5497e-06, 7.2717e-06, 1.3906e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.5473,  25.1413,  28.4452, 129.3256], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6136.5176, 3729.2654, 3640.9570, 8003.9297])\n",
            "l2norm ;  tensor([[2.2008],\n",
            "        [0.6596],\n",
            "        [0.8282],\n",
            "        [3.3245]], dtype=torch.float64)\n",
            "t :  57\n",
            "decayed_penalty_factor :  93.0\n",
            "ce:  tensor([ 17.7601,  25.2149,  28.5748, 127.8727], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1325e-05, 1.3113e-06, 7.0333e-06, 1.3154e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.7612,  25.2150,  28.5755, 127.9950], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4399.3369, 5158.2080, 5875.6357, 8003.4814])\n",
            "l2norm ;  tensor([[1.1046],\n",
            "        [1.4163],\n",
            "        [1.3183],\n",
            "        [3.2637]], dtype=torch.float64)\n",
            "t :  58\n",
            "decayed_penalty_factor :  92.0\n",
            "ce:  tensor([ 17.5377,  25.3984,  28.5668, 126.5726], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.5102e-06, 1.3113e-06, 8.1062e-06, 1.2622e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.5384,  25.3985,  28.5676, 126.6887], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5574.9883, 4954.1548, 3640.9663, 8003.1426])\n",
            "l2norm ;  tensor([[1.3580],\n",
            "        [2.1626],\n",
            "        [0.8779],\n",
            "        [3.1497]], dtype=torch.float64)\n",
            "t :  59\n",
            "decayed_penalty_factor :  91.0\n",
            "ce:  tensor([ 17.6797,  25.4910,  28.6760, 125.3186], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-06, 1.1921e-06, 7.2717e-06, 1.2141e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.6804,  25.4911,  28.6766, 125.4291], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4399.2739, 5158.2051, 5219.1406, 7973.1152])\n",
            "l2norm ;  tensor([[1.1000],\n",
            "        [1.4470],\n",
            "        [1.1857],\n",
            "        [3.0654]], dtype=torch.float64)\n",
            "t :  60\n",
            "decayed_penalty_factor :  90.0\n",
            "ce:  tensor([ 17.4107,  25.6278,  28.5636, 124.0962], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.6028e-06, 1.3113e-06, 8.5830e-06, 1.1771e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.4112,  25.6279,  28.5643, 124.2021], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5902.1113, 3583.1428, 4042.0750, 7972.8560])\n",
            "l2norm ;  tensor([[2.2029],\n",
            "        [0.7609],\n",
            "        [1.0637],\n",
            "        [3.0289]], dtype=torch.float64)\n",
            "t :  61\n",
            "decayed_penalty_factor :  88.99999999999999\n",
            "ce:  tensor([ 17.9282,  25.3641,  28.7933, 122.8871], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.0333e-06, 1.3113e-06, 6.9141e-06, 1.1529e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.9288,  25.3642,  28.7939, 122.9897], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4399.2441, 4129.9473, 5698.1953, 7972.6597])\n",
            "l2norm ;  tensor([[1.0555],\n",
            "        [0.7997],\n",
            "        [2.2360],\n",
            "        [2.9316]], dtype=torch.float64)\n",
            "t :  62\n",
            "decayed_penalty_factor :  88.0\n",
            "ce:  tensor([ 17.6804,  25.6241,  28.9220, 121.7152], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.4107e-06, 1.1921e-06, 8.7022e-06, 1.1488e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.6808,  25.6242,  28.9228, 121.8163], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3853.2986, 5413.2734, 4614.8223, 7972.5537])\n",
            "l2norm ;  tensor([[0.4310],\n",
            "        [1.4693],\n",
            "        [2.2724],\n",
            "        [2.8916]], dtype=torch.float64)\n",
            "t :  63\n",
            "decayed_penalty_factor :  87.00000000000001\n",
            "ce:  tensor([ 17.7933,  25.6830,  29.3206, 120.5636], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.4571e-06, 1.1921e-06, 7.5102e-06, 1.1532e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.7936,  25.6831,  29.3213, 120.6639], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5574.9097, 4556.3008, 5475.2490, 7922.8687])\n",
            "l2norm ;  tensor([[1.3554],\n",
            "        [2.1152],\n",
            "        [1.1681],\n",
            "        [2.7425]], dtype=torch.float64)\n",
            "t :  64\n",
            "decayed_penalty_factor :  85.99999999999999\n",
            "ce:  tensor([ 17.8951,  26.0210,  29.1909, 119.4647], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.0531e-06, 1.1921e-06, 8.8214e-06, 1.1700e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.8954,  26.0211,  29.1917, 119.5654], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4820.0469, 5862.9316, 4042.0710, 7937.8452])\n",
            "l2norm ;  tensor([[2.0052],\n",
            "        [1.6365],\n",
            "        [1.3058],\n",
            "        [2.7596]], dtype=torch.float64)\n",
            "t :  65\n",
            "decayed_penalty_factor :  85.0\n",
            "ce:  tensor([ 18.2827,  26.0599,  29.3843, 118.3591], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5763e-06, 1.3113e-06, 7.0333e-06, 1.1944e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.2830,  26.0600,  29.3849, 118.4606], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5973.0723, 3634.1526, 5953.6567, 7937.8604])\n",
            "l2norm ;  tensor([[1.2103],\n",
            "        [0.8836],\n",
            "        [2.3065],\n",
            "        [2.6868]], dtype=torch.float64)\n",
            "t :  66\n",
            "decayed_penalty_factor :  84.00000000000001\n",
            "ce:  tensor([ 18.3434,  25.9821,  29.3942, 117.2818], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.1723e-06, 1.1921e-06, 9.1791e-06, 1.2279e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.3438,  25.9822,  29.3950, 117.3850], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4000.0298, 5413.2725, 3640.9673, 7937.9111])\n",
            "l2norm ;  tensor([[0.5512],\n",
            "        [1.3885],\n",
            "        [0.8931],\n",
            "        [2.6386]], dtype=torch.float64)\n",
            "t :  67\n",
            "decayed_penalty_factor :  83.0\n",
            "ce:  tensor([ 18.1551,  26.1163,  29.5280, 116.2237], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.2186e-06, 1.3113e-06, 8.3446e-06, 1.2637e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.1554,  26.1164,  29.5287, 116.3286], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4252.2559, 3583.1406, 5219.1426, 7937.9648])\n",
            "l2norm ;  tensor([[0.5573],\n",
            "        [0.7480],\n",
            "        [1.1728],\n",
            "        [2.5155]], dtype=torch.float64)\n",
            "t :  68\n",
            "decayed_penalty_factor :  82.0\n",
            "ce:  tensor([ 18.5312,  25.9330,  29.4921, 115.2567], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-06, 1.3113e-06, 9.8943e-06, 1.3053e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.5314,  25.9331,  29.4929, 115.3637], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5902.0474, 5413.2744, 5014.1812, 7823.3516])\n",
            "l2norm ;  tensor([[2.2712],\n",
            "        [1.3597],\n",
            "        [2.3946],\n",
            "        [2.3008]], dtype=torch.float64)\n",
            "t :  69\n",
            "decayed_penalty_factor :  81.0\n",
            "ce:  tensor([ 18.6400,  26.3097,  29.9381, 114.3336], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.9802e-06, 1.4305e-06, 8.3446e-06, 1.3427e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.6402,  26.3099,  29.9388, 114.4424], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4000.0061, 3982.4644, 5475.2500, 7823.4004])\n",
            "l2norm ;  tensor([[0.6848],\n",
            "        [1.0990],\n",
            "        [1.2591],\n",
            "        [2.2279]], dtype=torch.float64)\n",
            "t :  70\n",
            "decayed_penalty_factor :  80.0\n",
            "ce:  tensor([ 18.4677,  25.9400,  29.8654, 113.4390], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.0266e-06, 1.1921e-06, 9.8943e-06, 1.3894e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.4678,  25.9401,  29.8662, 113.5502], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5427.6489, 3583.1379, 4033.7041, 7823.4829])\n",
            "l2norm ;  tensor([[1.2853],\n",
            "        [0.6789],\n",
            "        [1.0997],\n",
            "        [2.2262]], dtype=torch.float64)\n",
            "t :  71\n",
            "decayed_penalty_factor :  78.99999999999999\n",
            "ce:  tensor([ 18.6916,  26.4394,  30.0136, 112.5445], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([2.3842e-06, 1.3113e-06, 8.1062e-06, 1.4450e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.6918,  26.4395,  30.0142, 112.6586], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4252.2383, 6426.3667, 4613.4868, 7823.5908])\n",
            "l2norm ;  tensor([[0.9538],\n",
            "        [2.1707],\n",
            "        [1.2461],\n",
            "        [2.0797]], dtype=torch.float64)\n",
            "t :  72\n",
            "decayed_penalty_factor :  78.0\n",
            "ce:  tensor([ 18.4425,  26.2729,  30.0850, 111.7085], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6689e-06, 1.3113e-06, 1.0252e-05, 1.5020e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.4426,  26.2730,  30.0858, 111.8257], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4323.7754, 5523.1216, 3886.5701, 7823.6929])\n",
            "l2norm ;  tensor([[1.0989],\n",
            "        [1.2427],\n",
            "        [0.9073],\n",
            "        [1.9869]], dtype=torch.float64)\n",
            "t :  73\n",
            "decayed_penalty_factor :  77.0\n",
            "ce:  tensor([ 18.7722,  26.6725,  30.1067, 110.9488], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.4305e-06, 1.5497e-06, 9.0599e-06, 1.5741e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 18.7723,  26.6726,  30.1074, 111.0700], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5574.8706, 3434.1343, 4760.8037, 7182.5723])\n",
            "l2norm ;  tensor([[1.2338],\n",
            "        [0.9195],\n",
            "        [1.4709],\n",
            "        [1.7022]], dtype=torch.float64)\n",
            "t :  74\n",
            "decayed_penalty_factor :  75.99999999999999\n",
            "ce:  tensor([ 19.0865,  26.4615,  30.3223, 110.2623], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.7881e-06, 1.1921e-06, 1.0133e-05, 1.6528e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.0866,  26.4616,  30.3231, 110.3879], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5217.9629, 3511.3333, 3942.9595, 7182.7466])\n",
            "l2norm ;  tensor([[2.2946],\n",
            "        [1.2772],\n",
            "        [1.0258],\n",
            "        [1.6282]], dtype=torch.float64)\n",
            "t :  75\n",
            "decayed_penalty_factor :  75.0\n",
            "ce:  tensor([ 19.2217,  26.7817,  30.1096, 109.6504], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3113e-06, 1.1921e-06, 7.9870e-06, 1.7335e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.2218,  26.7817,  30.1102, 109.7804], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5574.8672, 5922.6431, 4613.4795, 7754.5503])\n",
            "l2norm ;  tensor([[1.0894],\n",
            "        [1.5737],\n",
            "        [1.4598],\n",
            "        [1.6065]], dtype=torch.float64)\n",
            "t :  76\n",
            "decayed_penalty_factor :  74.0\n",
            "ce:  tensor([ 19.2604,  26.9416,  30.6185, 109.1035], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5497e-06, 1.3113e-06, 9.0599e-06, 1.8391e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.2605,  26.9417,  30.6192, 109.2396], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3853.2405, 3036.4370, 5000.1167, 7123.2490])\n",
            "l2norm ;  tensor([[0.6468],\n",
            "        [1.3624],\n",
            "        [1.9175],\n",
            "        [1.4231]], dtype=torch.float64)\n",
            "t :  77\n",
            "decayed_penalty_factor :  73.0\n",
            "ce:  tensor([ 19.2108,  26.7150,  30.7103, 108.5267], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3113e-06, 9.5367e-07, 8.8214e-06, 1.9480e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.2109,  26.7151,  30.7109, 108.6689], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5574.8672, 4817.8896, 4342.7979, 7123.4893])\n",
            "l2norm ;  tensor([[1.1665],\n",
            "        [1.3330],\n",
            "        [1.1021],\n",
            "        [1.4206]], dtype=torch.float64)\n",
            "t :  78\n",
            "decayed_penalty_factor :  72.0\n",
            "ce:  tensor([ 19.4153,  27.0722,  30.6460, 107.9500], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5497e-06, 1.3113e-06, 7.8678e-06, 2.0722e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.4154,  27.0723,  30.6466, 108.0992], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5217.9580, 4914.9805, 5346.6123, 7123.7632])\n",
            "l2norm ;  tensor([[2.1199],\n",
            "        [2.4042],\n",
            "        [2.6750],\n",
            "        [1.3737]], dtype=torch.float64)\n",
            "t :  79\n",
            "decayed_penalty_factor :  71.00000000000001\n",
            "ce:  tensor([ 19.7220,  27.1757,  31.1421, 107.4050], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-06, 1.0729e-06, 9.7751e-06, 2.2048e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.7221,  27.1758,  31.1428, 107.5615], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6047.4849, 5015.8516, 3780.3665, 7749.7622])\n",
            "l2norm ;  tensor([[2.1347],\n",
            "        [1.3005],\n",
            "        [0.8990],\n",
            "        [1.5076]], dtype=torch.float64)\n",
            "t :  80\n",
            "decayed_penalty_factor :  70.0\n",
            "ce:  tensor([ 20.1866,  27.6224,  30.8817, 106.9493], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5497e-06, 1.4305e-06, 8.7022e-06, 2.3429e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.1867,  27.6225,  30.8823, 107.1133], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4399.1333, 4033.5925, 3288.1675, 7124.3213])\n",
            "l2norm ;  tensor([[1.0403],\n",
            "        [1.1145],\n",
            "        [0.6033],\n",
            "        [1.3286]], dtype=torch.float64)\n",
            "t :  81\n",
            "decayed_penalty_factor :  69.0\n",
            "ce:  tensor([ 19.8463,  27.3815,  31.1657, 106.4071], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0729e-06, 1.1921e-06, 7.9870e-06, 2.5075e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 19.8464,  27.3816,  31.1662, 106.5801], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3999.9707, 3036.4336, 4760.7778, 7124.6685])\n",
            "l2norm ;  tensor([[0.3789],\n",
            "        [0.5067],\n",
            "        [1.5321],\n",
            "        [1.3116]], dtype=torch.float64)\n",
            "t :  82\n",
            "decayed_penalty_factor :  68.0\n",
            "ce:  tensor([ 20.1067,  27.8932,  31.1742, 105.8886], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 1.1921e-06, 9.1791e-06, 2.7056e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.1068,  27.8933,  31.1749, 106.0726], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5427.6279, 5523.1172, 3543.6360, 6133.7373])\n",
            "l2norm ;  tensor([[1.2328],\n",
            "        [1.4901],\n",
            "        [0.8225],\n",
            "        [1.5337]], dtype=torch.float64)\n",
            "t :  83\n",
            "decayed_penalty_factor :  67.0\n",
            "ce:  tensor([ 20.0529,  27.6191,  31.1729, 105.8290], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 1.3113e-06, 8.3446e-06, 2.6736e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.0530,  27.6192,  31.1734, 106.0082], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4399.1245, 4342.7070, 4760.7788, 7124.8564])\n",
            "l2norm ;  tensor([[0.7905],\n",
            "        [1.1123],\n",
            "        [1.4686],\n",
            "        [1.7418]], dtype=torch.float64)\n",
            "t :  84\n",
            "decayed_penalty_factor :  65.99999999999999\n",
            "ce:  tensor([ 20.0713,  27.9009,  31.6651, 105.2953], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.0729e-06, 9.4175e-06, 2.8292e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.0714,  27.9010,  31.6657, 105.4821], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5427.6260, 5092.2480, 5518.7065, 6755.5923])\n",
            "l2norm ;  tensor([[1.2081],\n",
            "        [2.5991],\n",
            "        [2.5868],\n",
            "        [1.1187]], dtype=torch.float64)\n",
            "t :  85\n",
            "decayed_penalty_factor :  65.0\n",
            "ce:  tensor([ 20.1962,  28.0881,  31.6450, 105.1709], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 1.3113e-06, 8.2254e-06, 2.9025e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.1962,  28.0882,  31.6455, 105.3596], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4226.1460, 3689.7241, 5015.9170, 7125.1655])\n",
            "l2norm ;  tensor([[0.8508],\n",
            "        [1.6558],\n",
            "        [1.3306],\n",
            "        [1.2575]], dtype=torch.float64)\n",
            "t :  86\n",
            "decayed_penalty_factor :  63.99999999999999\n",
            "ce:  tensor([ 20.0568,  27.6451,  32.1226, 104.8057], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 9.5367e-07, 1.0371e-05, 3.1424e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.0568,  27.6452,  32.1233, 105.0068], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5427.6245, 4868.6553, 3543.6401, 6134.3389])\n",
            "l2norm ;  tensor([[1.0515],\n",
            "        [1.3223],\n",
            "        [1.5975],\n",
            "        [1.0760]], dtype=torch.float64)\n",
            "t :  87\n",
            "decayed_penalty_factor :  63.00000000000001\n",
            "ce:  tensor([ 20.3456,  28.1076,  31.6009, 104.7397], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 1.1921e-06, 7.7486e-06, 3.2036e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.3457,  28.1077,  31.6014, 104.9416], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4819.9844, 4914.9756, 4159.1797, 7751.3281])\n",
            "l2norm ;  tensor([[2.0114],\n",
            "        [2.4565],\n",
            "        [1.1587],\n",
            "        [1.2681]], dtype=torch.float64)\n",
            "t :  88\n",
            "decayed_penalty_factor :  62.0\n",
            "ce:  tensor([ 20.6958,  28.2216,  31.8684, 104.4708], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 9.5367e-07, 7.0333e-06, 3.4452e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.6959,  28.2217,  31.8688, 104.6844], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6445.5332, 3434.2529, 4613.4512, 6134.7837])\n",
            "l2norm ;  tensor([[1.8659],\n",
            "        [0.7067],\n",
            "        [0.9615],\n",
            "        [0.9966]], dtype=torch.float64)\n",
            "t :  89\n",
            "decayed_penalty_factor :  60.99999999999999\n",
            "ce:  tensor([ 21.1818,  28.1107,  32.1106, 104.3604], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 8.3446e-07, 8.1062e-06, 3.5194e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.1818,  28.1107,  32.1111, 104.5751], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3993.9961, 4613.3950, 4915.0405, 7751.7363])\n",
            "l2norm ;  tensor([[0.7246],\n",
            "        [1.4775],\n",
            "        [2.4149],\n",
            "        [1.6832]], dtype=torch.float64)\n",
            "t :  90\n",
            "decayed_penalty_factor :  60.0\n",
            "ce:  tensor([ 20.8920,  28.4270,  32.4981, 104.2596], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 9.5367e-07, 6.9141e-06, 3.7166e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 20.8920,  28.4271,  32.4985, 104.4826], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3993.9932, 3942.8435, 5015.8984, 6637.5391])\n",
            "l2norm ;  tensor([[0.3391],\n",
            "        [0.9729],\n",
            "        [1.3121],\n",
            "        [0.8986]], dtype=torch.float64)\n",
            "t :  91\n",
            "decayed_penalty_factor :  59.0\n",
            "ce:  tensor([ 21.1323,  28.2591,  32.8429, 103.9899], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 7.1526e-07, 8.7022e-06, 3.7555e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.1324,  28.2591,  32.8434, 104.2115], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5569.1958, 3288.0784, 4291.9707, 6040.3618])\n",
            "l2norm ;  tensor([[1.2306],\n",
            "        [0.4852],\n",
            "        [1.1552],\n",
            "        [0.9072]], dtype=torch.float64)\n",
            "t :  92\n",
            "decayed_penalty_factor :  58.00000000000001\n",
            "ce:  tensor([ 21.1488,  28.3518,  32.6652, 104.0188], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 8.3446e-07, 8.4638e-06, 3.8001e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.1489,  28.3519,  32.6657, 104.2392], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4393.3003, 4760.7021, 3288.1453, 7596.8672])\n",
            "l2norm ;  tensor([[0.9464],\n",
            "        [1.5072],\n",
            "        [0.4827],\n",
            "        [1.4214]], dtype=torch.float64)\n",
            "t :  93\n",
            "decayed_penalty_factor :  57.0\n",
            "ce:  tensor([ 21.1718,  28.5862,  32.8202, 103.8130], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 9.5367e-07, 7.8678e-06, 4.1350e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.1718,  28.5863,  32.8207, 104.0487], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5664.7632, 3543.5479, 5267.7534, 6040.8696])\n",
            "l2norm ;  tensor([[2.5795],\n",
            "        [0.8287],\n",
            "        [1.3730],\n",
            "        [0.8783]], dtype=torch.float64)\n",
            "t :  94\n",
            "decayed_penalty_factor :  55.99999999999999\n",
            "ce:  tensor([ 21.6033,  28.3223,  32.9976, 103.6732], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 8.3446e-07, 8.4638e-06, 4.2145e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.6033,  28.3223,  32.9981, 103.9092], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3993.9934, 4760.7021, 4546.4067, 7597.3828])\n",
            "l2norm ;  tensor([[0.7319],\n",
            "        [1.2593],\n",
            "        [1.4770],\n",
            "        [1.2420]], dtype=torch.float64)\n",
            "t :  95\n",
            "decayed_penalty_factor :  55.00000000000001\n",
            "ce:  tensor([ 21.3141,  28.8634,  33.0311, 103.6576], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.0729e-06, 7.1525e-06, 4.3826e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.3141,  28.8635,  33.0315, 103.8986], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5569.1948, 5060.3472, 4613.4429, 6040.9722])\n",
            "l2norm ;  tensor([[1.1561],\n",
            "        [2.4255],\n",
            "        [1.3577],\n",
            "        [0.8590]], dtype=torch.float64)\n",
            "t :  96\n",
            "decayed_penalty_factor :  54.0\n",
            "ce:  tensor([ 21.6672,  28.9068,  33.2713, 103.4394], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 8.3446e-07, 8.1062e-06, 4.4739e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.6672,  28.9069,  33.2717, 103.6810], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4483.1533, 4415.6509, 3942.8992, 7597.4683])\n",
            "l2norm ;  tensor([[0.8091],\n",
            "        [1.1674],\n",
            "        [1.0247],\n",
            "        [1.3570]], dtype=torch.float64)\n",
            "t :  97\n",
            "decayed_penalty_factor :  53.00000000000001\n",
            "ce:  tensor([ 21.5073,  29.0158,  33.0944, 103.5369], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 8.3446e-07, 6.4373e-06, 4.8503e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.5073,  29.0158,  33.0948, 103.7939], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3340.8047, 5015.8452, 4868.6934, 6041.5430])\n",
            "l2norm ;  tensor([[0.4918],\n",
            "        [1.4243],\n",
            "        [1.5046],\n",
            "        [0.8500]], dtype=torch.float64)\n",
            "t :  98\n",
            "decayed_penalty_factor :  52.0\n",
            "ce:  tensor([ 21.8168,  29.5358,  33.5674, 103.2652], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 9.5367e-07, 7.5102e-06, 4.9429e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.8168,  29.5359,  33.5678, 103.5222], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5569.1943, 4636.8311, 4382.5464, 6638.5244])\n",
            "l2norm ;  tensor([[1.1261],\n",
            "        [1.5025],\n",
            "        [2.2733],\n",
            "        [0.7796]], dtype=torch.float64)\n",
            "t :  99\n",
            "decayed_penalty_factor :  50.99999999999999\n",
            "ce:  tensor([ 21.8443,  29.3710,  33.0824, 103.3833], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 8.3446e-07, 5.8412e-06, 5.0363e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 21.8443,  29.3710,  33.0827, 103.6401], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5301.9238, 3288.0776, 3288.1155, 6996.6699])\n",
            "l2norm ;  tensor([[2.1906],\n",
            "        [0.5498],\n",
            "        [0.5715],\n",
            "        [1.2817]], dtype=torch.float64)\n",
            "t :  100\n",
            "decayed_penalty_factor :  50.00000000000001\n",
            "ce:  tensor([ 22.4620,  29.6178,  33.3697, 103.1550], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 8.3446e-07, 5.3644e-06, 5.3950e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.4620,  29.6178,  33.3699, 103.4247], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6170.9604, 4760.7007, 4613.4248, 6638.9160])\n",
            "l2norm ;  tensor([[2.5244],\n",
            "        [1.4533],\n",
            "        [1.4706],\n",
            "        [0.7502]], dtype=torch.float64)\n",
            "t :  101\n",
            "decayed_penalty_factor :  49.0\n",
            "ce:  tensor([ 22.5695,  29.7081,  33.5215, 103.1857], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 9.5367e-07, 6.4373e-06, 5.4620e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.5695,  29.7081,  33.5218, 103.4533], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4483.1528, 4144.4360, 4915.0103, 6996.9712])\n",
            "l2norm ;  tensor([[1.0544],\n",
            "        [2.0558],\n",
            "        [2.4720],\n",
            "        [0.7873]], dtype=torch.float64)\n",
            "t :  102\n",
            "decayed_penalty_factor :  47.99999999999999\n",
            "ce:  tensor([ 22.5030,  29.5220,  33.8269, 103.0155], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 7.1526e-07, 5.6028e-06, 5.9005e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.5030,  29.5220,  33.8271, 103.2987], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5569.1938, 4868.6509, 5492.3726, 6639.3203])\n",
            "l2norm ;  tensor([[1.0972],\n",
            "        [1.3853],\n",
            "        [2.2349],\n",
            "        [0.7529]], dtype=torch.float64)\n",
            "t :  103\n",
            "decayed_penalty_factor :  47.0\n",
            "ce:  tensor([ 22.5843,  29.7286,  34.1886, 103.1956], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 8.3446e-07, 7.5102e-06, 5.9760e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.5844,  29.7286,  34.1889, 103.4765], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4456.5049, 4033.5811, 4090.4097, 6997.3428])\n",
            "l2norm ;  tensor([[0.8907],\n",
            "        [1.1967],\n",
            "        [1.5040],\n",
            "        [1.3564]], dtype=torch.float64)\n",
            "t :  104\n",
            "decayed_penalty_factor :  46.0\n",
            "ce:  tensor([ 22.5199,  29.5883,  33.9097, 102.9121], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 7.1526e-07, 5.9604e-06, 6.2292e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.5199,  29.5884,  33.9099, 103.1987], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4855.6821, 5015.8433, 4868.6836, 6639.3184])\n",
            "l2norm ;  tensor([[1.2907],\n",
            "        [1.2347],\n",
            "        [1.2776],\n",
            "        [0.7441]], dtype=torch.float64)\n",
            "t :  105\n",
            "decayed_penalty_factor :  45.00000000000001\n",
            "ce:  tensor([ 22.7364,  29.9991,  34.3032, 103.0002], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 9.5367e-07, 7.9870e-06, 6.3148e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.7365,  29.9991,  34.3036, 103.2844], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3940.6426, 4517.4297, 3634.1841, 6997.3389])\n",
            "l2norm ;  tensor([[0.7230],\n",
            "        [2.3802],\n",
            "        [1.6977],\n",
            "        [1.2595]], dtype=torch.float64)\n",
            "t :  106\n",
            "decayed_penalty_factor :  44.0\n",
            "ce:  tensor([ 22.4603,  30.1890,  33.8828, 102.8307], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 8.3446e-07, 6.1989e-06, 6.7832e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.4603,  30.1890,  33.8831, 103.1292], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3787.0408, 6011.2119, 5266.4897, 6042.7075])\n",
            "l2norm ;  tensor([[0.4517],\n",
            "        [1.5137],\n",
            "        [1.1990],\n",
            "        [0.7901]], dtype=torch.float64)\n",
            "t :  107\n",
            "decayed_penalty_factor :  42.99999999999999\n",
            "ce:  tensor([ 22.7661,  30.5779,  34.3074, 102.8344], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 1.0729e-06, 6.7949e-06, 6.9016e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.7661,  30.5780,  34.3077, 103.1312], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5401.4692, 3641.4915, 4235.2480, 7598.9321])\n",
            "l2norm ;  tensor([[1.3424],\n",
            "        [0.7688],\n",
            "        [1.2731],\n",
            "        [0.9845]], dtype=torch.float64)\n",
            "t :  108\n",
            "decayed_penalty_factor :  42.00000000000001\n",
            "ce:  tensor([ 22.8043,  30.4055,  34.2503, 102.7778], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.1921e-06, 6.4373e-06, 7.4566e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 22.8043,  30.4056,  34.2506, 103.0910], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4762.8892, 5015.8457, 4613.4243, 6043.1489])\n",
            "l2norm ;  tensor([[2.2711],\n",
            "        [1.4671],\n",
            "        [1.4046],\n",
            "        [0.7879]], dtype=torch.float64)\n",
            "t :  109\n",
            "decayed_penalty_factor :  41.0\n",
            "ce:  tensor([ 23.3955,  30.9703,  34.6768, 102.7869], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.4305e-06, 7.6294e-06, 7.5981e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.3956,  30.9703,  34.6771, 103.0984], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6145.5796, 4792.0078, 5004.5508, 7599.3130])\n",
            "l2norm ;  tensor([[2.4554],\n",
            "        [1.6922],\n",
            "        [2.5371],\n",
            "        [1.2016]], dtype=torch.float64)\n",
            "t :  110\n",
            "decayed_penalty_factor :  40.00000000000001\n",
            "ce:  tensor([ 23.5861,  30.7634,  34.7091, 102.7169], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 1.3113e-06, 6.7949e-06, 7.8918e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.5861,  30.7635,  34.7094, 103.0326], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4366.1509, 3295.4082, 5104.6460, 6043.0991])\n",
            "l2norm ;  tensor([[0.9655],\n",
            "        [0.5099],\n",
            "        [1.2351],\n",
            "        [0.8417]], dtype=torch.float64)\n",
            "t :  111\n",
            "decayed_penalty_factor :  39.0\n",
            "ce:  tensor([ 23.5527,  30.9404,  35.1469, 102.6683], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.1921e-06, 9.1791e-06, 8.1199e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.5528,  30.9404,  35.1472, 102.9850], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5516.5566, 5238.0493, 4382.5396, 7599.3521])\n",
            "l2norm ;  tensor([[1.2999],\n",
            "        [2.5074],\n",
            "        [1.3875],\n",
            "        [1.2105]], dtype=torch.float64)\n",
            "t :  112\n",
            "decayed_penalty_factor :  37.99999999999999\n",
            "ce:  tensor([ 23.5605,  31.3245,  34.9678, 102.6327], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.5497e-06, 8.5830e-06, 8.7458e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.5605,  31.3246,  34.9681, 102.9651], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4339.9292, 4389.7593, 3288.1174, 6043.6133])\n",
            "l2norm ;  tensor([[0.7770],\n",
            "        [2.1519],\n",
            "        [0.5962],\n",
            "        [0.7457]], dtype=torch.float64)\n",
            "t :  113\n",
            "decayed_penalty_factor :  37.00000000000001\n",
            "ce:  tensor([ 23.4993,  30.8942,  35.1934, 102.5532], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.1921e-06, 7.8678e-06, 8.9075e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.4993,  30.8942,  35.1937, 102.8828], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4862.8818, 5273.6689, 5238.0820, 7599.6753])\n",
            "l2norm ;  tensor([[1.2548],\n",
            "        [1.3382],\n",
            "        [2.4982],\n",
            "        [0.8901]], dtype=torch.float64)\n",
            "t :  114\n",
            "decayed_penalty_factor :  36.0\n",
            "ce:  tensor([ 23.7663,  31.3960,  35.4817, 102.6388], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.4305e-06, 9.6559e-06, 9.4748e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.7663,  31.3960,  35.4820, 102.9799], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4192.9585, 3641.4917, 4382.5376, 6043.7832])\n",
            "l2norm ;  tensor([[1.5708],\n",
            "        [1.1286],\n",
            "        [2.2522],\n",
            "        [0.7388]], dtype=torch.float64)\n",
            "t :  115\n",
            "decayed_penalty_factor :  34.99999999999999\n",
            "ce:  tensor([ 23.3888,  31.0229,  35.2276, 102.5997], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 1.3113e-06, 7.7486e-06, 9.5459e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.3888,  31.0229,  35.2279, 102.9338], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5387.1313, 3441.5774, 4868.6816, 7599.6660])\n",
            "l2norm ;  tensor([[1.4284],\n",
            "        [0.4613],\n",
            "        [1.1014],\n",
            "        [1.3871]], dtype=torch.float64)\n",
            "t :  116\n",
            "decayed_penalty_factor :  34.0\n",
            "ce:  tensor([ 23.7453,  31.3089,  35.5335, 102.6306], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.3113e-06, 9.7751e-06, 9.8843e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.7453,  31.3090,  35.5338, 102.9666], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3794.3489, 5274.8857, 3942.8804, 6043.4507])\n",
            "l2norm ;  tensor([[0.7298],\n",
            "        [1.3227],\n",
            "        [1.1818],\n",
            "        [0.6660]], dtype=torch.float64)\n",
            "t :  117\n",
            "decayed_penalty_factor :  32.99999999999999\n",
            "ce:  tensor([ 23.5274,  31.3394,  35.3982, 102.5189], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 1.5497e-06, 7.9870e-06, 9.7727e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.5275,  31.3394,  35.3984, 102.8414], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4862.8809, 3950.1292, 4613.4219, 7599.1514])\n",
            "l2norm ;  tensor([[1.2100],\n",
            "        [1.0124],\n",
            "        [1.2439],\n",
            "        [0.8675]], dtype=torch.float64)\n",
            "t :  118\n",
            "decayed_penalty_factor :  32.00000000000001\n",
            "ce:  tensor([ 23.9883,  31.3590,  35.6853, 102.7062], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.1921e-06, 9.2983e-06, 1.0393e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 23.9883,  31.3590,  35.6856, 103.0388], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5249.8633, 5023.0327, 3942.5972, 6043.1841])\n",
            "l2norm ;  tensor([[2.3732],\n",
            "        [1.4682],\n",
            "        [0.8839],\n",
            "        [0.7691]], dtype=torch.float64)\n",
            "t :  119\n",
            "decayed_penalty_factor :  31.0\n",
            "ce:  tensor([ 24.1010,  31.6641,  35.3772, 102.6010], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.5497e-06, 8.2254e-06, 1.0558e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.1010,  31.6641,  35.3774, 102.9283], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6234.3789, 4151.7041, 3036.4548, 7599.1812])\n",
            "l2norm ;  tensor([[2.7129],\n",
            "        [1.2511],\n",
            "        [0.4686],\n",
            "        [1.2560]], dtype=torch.float64)\n",
            "t :  120\n",
            "decayed_penalty_factor :  29.999999999999993\n",
            "ce:  tensor([ 24.5825,  31.5502,  36.0705, 102.6838], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.4305e-06, 9.0599e-06, 1.1352e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.5825,  31.5503,  36.0708, 103.0244], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4456.5029, 4875.8379, 5922.6636, 6043.3516])\n",
            "l2norm ;  tensor([[1.6886],\n",
            "        [1.4103],\n",
            "        [1.4691],\n",
            "        [0.6268]], dtype=torch.float64)\n",
            "t :  121\n",
            "decayed_penalty_factor :  29.000000000000004\n",
            "ce:  tensor([ 24.0295,  31.9007,  35.8211, 102.5800], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.7684e-07, 1.7881e-06, 1.0610e-05, 1.1255e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.0295,  31.9007,  35.8214, 102.9063], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5260.3398, 4553.6094, 5513.3545, 7599.0303])\n",
            "l2norm ;  tensor([[0.9149],\n",
            "        [2.1228],\n",
            "        [2.0181],\n",
            "        [1.0568]], dtype=torch.float64)\n",
            "t :  122\n",
            "decayed_penalty_factor :  27.999999999999996\n",
            "ce:  tensor([ 24.4422,  31.6440,  36.3680, 102.7635], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.3113e-06, 1.1325e-05, 1.1482e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.4422,  31.6440,  36.3683, 103.0850], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3884.7786, 4875.8374, 5015.8784, 6042.5171])\n",
            "l2norm ;  tensor([[0.8157],\n",
            "        [1.1780],\n",
            "        [1.4472],\n",
            "        [0.6915]], dtype=torch.float64)\n",
            "t :  123\n",
            "decayed_penalty_factor :  27.000000000000007\n",
            "ce:  tensor([ 24.2747,  32.1881,  36.5263, 102.6308], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.9073e-06, 1.3590e-05, 1.1619e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.2747,  32.1882,  36.5267, 102.9445], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5644.0000, 4922.2246, 3942.8835, 7598.4746])\n",
            "l2norm ;  tensor([[1.4796],\n",
            "        [2.5534],\n",
            "        [1.6751],\n",
            "        [1.2108]], dtype=torch.float64)\n",
            "t :  124\n",
            "decayed_penalty_factor :  26.0\n",
            "ce:  tensor([ 24.6007,  32.2165,  36.2940, 102.7975], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.6689e-06, 1.0252e-05, 1.2427e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.6008,  32.2165,  36.2943, 103.1206], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4192.9570, 5023.0337, 4868.6797, 6639.4121])\n",
            "l2norm ;  tensor([[0.8738],\n",
            "        [1.2165],\n",
            "        [1.1056],\n",
            "        [0.7087]], dtype=torch.float64)\n",
            "t :  125\n",
            "decayed_penalty_factor :  24.999999999999993\n",
            "ce:  tensor([ 24.4459,  32.4576,  36.5348, 102.6181], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 1.9073e-06, 1.3590e-05, 1.2266e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.4459,  32.4577,  36.5352, 102.9247], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5338.3896, 3043.7729, 4194.9473, 6041.7993])\n",
            "l2norm ;  tensor([[2.5389],\n",
            "        [1.0069],\n",
            "        [1.3553],\n",
            "        [0.5473]], dtype=torch.float64)\n",
            "t :  126\n",
            "decayed_penalty_factor :  24.000000000000004\n",
            "ce:  tensor([ 25.0012,  32.3500,  36.3222, 102.9846], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.6689e-06, 1.1086e-05, 1.2509e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.0013,  32.3501,  36.3224, 103.2848], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4339.9272, 5023.0327, 4613.4204, 7597.8877])\n",
            "l2norm ;  tensor([[0.7860],\n",
            "        [1.3652],\n",
            "        [0.8200],\n",
            "        [1.3942]], dtype=torch.float64)\n",
            "t :  127\n",
            "decayed_penalty_factor :  23.0\n",
            "ce:  tensor([ 24.8061,  32.6485,  36.7018, 102.6911], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 2.0266e-06, 1.3351e-05, 1.3072e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.8061,  32.6486,  36.7021, 102.9918], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3794.3484, 4299.1738, 4144.4702, 6041.4570])\n",
            "l2norm ;  tensor([[0.3566],\n",
            "        [1.1853],\n",
            "        [1.2547],\n",
            "        [0.5478]], dtype=torch.float64)\n",
            "t :  128\n",
            "decayed_penalty_factor :  21.999999999999993\n",
            "ce:  tensor([ 24.9467,  32.5105,  36.7435, 102.9389], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 2.0266e-06, 1.2636e-05, 1.3163e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 24.9467,  32.5105,  36.7437, 103.2285], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5643.9995, 4875.8384, 4868.6807, 7597.4321])\n",
            "l2norm ;  tensor([[1.5788],\n",
            "        [1.4640],\n",
            "        [1.2830],\n",
            "        [1.2601]], dtype=torch.float64)\n",
            "t :  129\n",
            "decayed_penalty_factor :  21.000000000000004\n",
            "ce:  tensor([ 25.2207,  33.0294,  36.9789, 102.7735], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 2.3842e-06, 1.4782e-05, 1.4083e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.2207,  33.0294,  36.9792, 103.0692], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5304.9443, 3950.1287, 3543.5796, 6041.1562])\n",
            "l2norm ;  tensor([[2.3329],\n",
            "        [1.6858],\n",
            "        [1.7403],\n",
            "        [0.6412]], dtype=torch.float64)\n",
            "t :  130\n",
            "decayed_penalty_factor :  19.999999999999996\n",
            "ce:  tensor([ 25.3667,  32.4766,  36.6835, 102.9182], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 1.7881e-06, 1.1563e-05, 1.3898e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.3667,  32.4766,  36.6837, 103.1962], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5542.9229, 3295.4048, 5744.0303, 7596.9492])\n",
            "l2norm ;  tensor([[1.2477],\n",
            "        [0.5914],\n",
            "        [2.3200],\n",
            "        [1.0515]], dtype=torch.float64)\n",
            "t :  131\n",
            "decayed_penalty_factor :  19.000000000000007\n",
            "ce:  tensor([ 25.4386,  32.8237,  37.1867, 102.8777], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 1.7881e-06, 1.5259e-05, 1.4246e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.4386,  32.8237,  37.1870, 103.1484], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4366.1479, 5167.7739, 5513.3511, 5639.0469])\n",
            "l2norm ;  tensor([[0.9439],\n",
            "        [1.4281],\n",
            "        [2.4534],\n",
            "        [0.7829]], dtype=torch.float64)\n",
            "t :  132\n",
            "decayed_penalty_factor :  18.0\n",
            "ce:  tensor([ 25.4233,  32.8434,  37.2890, 103.0389], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 2.2650e-06, 1.4305e-05, 1.4324e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.4233,  32.8435,  37.2893, 103.2967], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5016.1416, 4776.3140, 5015.8696, 7596.1909])\n",
            "l2norm ;  tensor([[1.6464],\n",
            "        [2.1915],\n",
            "        [1.3879],\n",
            "        [1.0459]], dtype=torch.float64)\n",
            "t :  133\n",
            "decayed_penalty_factor :  16.999999999999993\n",
            "ce:  tensor([ 25.7377,  33.2732,  37.7573, 102.9913], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 2.0266e-06, 1.7047e-05, 1.4745e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.7377,  33.2732,  37.7576, 103.2419], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3820.3811, 6003.4722, 4180.9858, 6039.3384])\n",
            "l2norm ;  tensor([[1.6292],\n",
            "        [2.1186],\n",
            "        [1.7823],\n",
            "        [0.6603]], dtype=torch.float64)\n",
            "t :  134\n",
            "decayed_penalty_factor :  16.000000000000004\n",
            "ce:  tensor([ 25.2240,  33.6560,  37.2492, 103.0975], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([5.9605e-07, 2.7418e-06, 1.2994e-05, 1.5099e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.2240,  33.6560,  37.2494, 103.3391], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5260.3394, 4094.5435, 4868.6709, 7595.5410])\n",
            "l2norm ;  tensor([[0.8801],\n",
            "        [1.1903],\n",
            "        [1.0651],\n",
            "        [1.2394]], dtype=torch.float64)\n",
            "t :  135\n",
            "decayed_penalty_factor :  14.999999999999996\n",
            "ce:  tensor([ 25.7188,  33.4621,  37.7716, 103.0280], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 2.3842e-06, 1.7047e-05, 1.6201e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.7189,  33.4622,  37.7719, 103.2710], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3823.3354, 5019.9414, 4033.6079, 5637.8418])\n",
            "l2norm ;  tensor([[0.7488],\n",
            "        [1.2611],\n",
            "        [1.2769],\n",
            "        [0.9283]], dtype=torch.float64)\n",
            "t :  136\n",
            "decayed_penalty_factor :  14.000000000000007\n",
            "ce:  tensor([ 25.4257,  33.9127,  37.4511, 103.0676], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 3.0994e-06, 1.5020e-05, 1.6562e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.4257,  33.9127,  37.4513, 103.2995], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3794.3469, 3694.0784, 5015.8633, 7595.1240])\n",
            "l2norm ;  tensor([[0.3603],\n",
            "        [1.7448],\n",
            "        [1.2518],\n",
            "        [1.1387]], dtype=torch.float64)\n",
            "t :  137\n",
            "decayed_penalty_factor :  13.0\n",
            "ce:  tensor([ 25.8553,  33.3266,  38.0113, 103.0845], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 2.3842e-06, 1.6689e-05, 1.6972e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.8553,  33.3266,  38.0115, 103.3051], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5416.2695, 4872.6602, 4235.2329, 6038.0518])\n",
            "l2norm ;  tensor([[1.5475],\n",
            "        [1.1658],\n",
            "        [1.2260],\n",
            "        [0.6674]], dtype=torch.float64)\n",
            "t :  138\n",
            "decayed_penalty_factor :  11.999999999999995\n",
            "ce:  tensor([ 25.9101,  33.9184,  37.7999, 103.1235], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 2.7418e-06, 1.6212e-05, 1.6650e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.9101,  33.9184,  37.8001, 103.3233], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3695.1826, 4640.9683, 4613.4106, 7594.0229])\n",
            "l2norm ;  tensor([[1.5737],\n",
            "        [1.7221],\n",
            "        [1.4234],\n",
            "        [1.2820]], dtype=torch.float64)\n",
            "t :  139\n",
            "decayed_penalty_factor :  11.000000000000004\n",
            "ce:  tensor([ 25.7449,  33.6808,  38.2120, 103.1287], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([7.1526e-07, 2.3842e-06, 1.8954e-05, 1.7890e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 25.7449,  33.6809,  38.2122, 103.3255], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5162.1953, 3292.2087, 3886.4653, 6037.1196])\n",
            "l2norm ;  tensor([[1.1008],\n",
            "        [0.5751],\n",
            "        [0.9614],\n",
            "        [0.5648]], dtype=torch.float64)\n",
            "t :  140\n",
            "decayed_penalty_factor :  9.999999999999998\n",
            "ce:  tensor([ 26.0009,  33.9723,  37.9106, 103.1523], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 2.3842e-06, 1.7166e-05, 1.7973e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.0009,  33.9723,  37.9108, 103.3320], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4635.5425, 5271.9937, 3036.4412, 7593.2847])\n",
            "l2norm ;  tensor([[2.3675],\n",
            "        [1.3870],\n",
            "        [0.4687],\n",
            "        [1.0483]], dtype=torch.float64)\n",
            "t :  141\n",
            "decayed_penalty_factor :  9.000000000000007\n",
            "ce:  tensor([ 26.4461,  33.8750,  38.4805, 103.2756], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([8.3446e-07, 2.8610e-06, 1.9073e-05, 1.8446e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.4462,  33.8750,  38.4807, 103.4417], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6199.0264, 3585.4197, 5922.6484, 5634.8975])\n",
            "l2norm ;  tensor([[1.5554],\n",
            "        [0.9182],\n",
            "        [1.3741],\n",
            "        [0.6854]], dtype=torch.float64)\n",
            "t :  142\n",
            "decayed_penalty_factor :  8.000000000000002\n",
            "ce:  tensor([ 26.5183,  33.9841,  38.3600, 103.3256], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.0729e-06, 2.5034e-06, 2.1696e-05, 1.8683e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.5183,  33.9841,  38.3602, 103.4750], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3695.1824, 5350.6528, 4544.2061, 7592.2485])\n",
            "l2norm ;  tensor([[0.8171],\n",
            "        [2.5989],\n",
            "        [2.0547],\n",
            "        [1.0361]], dtype=torch.float64)\n",
            "t :  143\n",
            "decayed_penalty_factor :  6.999999999999995\n",
            "ce:  tensor([ 26.5633,  34.4026,  38.4013, 103.4129], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([9.5367e-07, 3.0994e-06, 1.8239e-05, 1.9440e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.5633,  34.4026,  38.4015, 103.5490], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5417.5527, 3694.0752, 5266.4668, 5633.7900])\n",
            "l2norm ;  tensor([[1.1603],\n",
            "        [1.2241],\n",
            "        [1.2367],\n",
            "        [0.9471]], dtype=torch.float64)\n",
            "t :  144\n",
            "decayed_penalty_factor :  6.000000000000005\n",
            "ce:  tensor([ 26.5614,  33.9713,  38.3349, 103.4252], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-06, 2.7418e-06, 2.1338e-05, 1.9481e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.5614,  33.9714,  38.3350, 103.5421], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4295.3354, 3292.2075, 3795.9429, 7591.1387])\n",
            "l2norm ;  tensor([[1.1146],\n",
            "        [0.3958],\n",
            "        [0.9536],\n",
            "        [1.2478]], dtype=torch.float64)\n",
            "t :  145\n",
            "decayed_penalty_factor :  4.999999999999999\n",
            "ce:  tensor([ 26.8161,  34.1270,  38.4122, 103.4194], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.1921e-06, 2.6226e-06, 1.9312e-05, 2.0953e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.8161,  34.1270,  38.4123, 103.5242], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4890.6367, 5271.9922, 5862.0234, 6033.6841])\n",
            "l2norm ;  tensor([[1.7189],\n",
            "        [1.2854],\n",
            "        [1.2178],\n",
            "        [0.7101]], dtype=torch.float64)\n",
            "t :  146\n",
            "decayed_penalty_factor :  3.9999999999999925\n",
            "ce:  tensor([ 26.8522,  34.6269,  38.5188, 103.3960], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.5497e-06, 3.0994e-06, 2.2411e-05, 2.1556e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.8522,  34.6269,  38.5189, 103.4822], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3695.1821, 5612.3701, 3036.4302, 7590.1055])\n",
            "l2norm ;  tensor([[0.7675],\n",
            "        [2.8693],\n",
            "        [0.8648],\n",
            "        [1.1902]], dtype=torch.float64)\n",
            "t :  147\n",
            "decayed_penalty_factor :  3.0000000000000027\n",
            "ce:  tensor([ 26.8241,  34.5790,  38.7481, 103.4471], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3113e-06, 2.7418e-06, 2.1696e-05, 2.2510e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.8241,  34.5790,  38.7482, 103.5147], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5417.5522, 5527.3765, 5523.1113, 6032.3301])\n",
            "l2norm ;  tensor([[1.1850],\n",
            "        [1.0295],\n",
            "        [1.3206],\n",
            "        [0.7450]], dtype=torch.float64)\n",
            "t :  148\n",
            "decayed_penalty_factor :  1.9999999999999962\n",
            "ce:  tensor([ 26.9329,  34.8717,  38.7045, 103.4071], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.6689e-06, 3.5763e-06, 2.4914e-05, 2.2292e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.9329,  34.8717,  38.7045, 103.4517], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4093.6987, 3946.9512, 4798.0435, 7588.7432])\n",
            "l2norm ;  tensor([[0.9432],\n",
            "        [1.1796],\n",
            "        [1.4827],\n",
            "        [1.1754]], dtype=torch.float64)\n",
            "t :  149\n",
            "decayed_penalty_factor :  1.0000000000000064\n",
            "ce:  tensor([ 26.8579,  34.7897,  38.9720, 103.4738], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3113e-06, 2.9802e-06, 2.2411e-05, 2.3823e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 26.8579,  34.7897,  38.9720, 103.4976], grad_fn=<AddBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5394.3652, 5019.9375, 4613.3892, 5629.8135])\n",
            "l2norm ;  tensor([[1.3842],\n",
            "        [1.4240],\n",
            "        [1.1329],\n",
            "        [0.8204]], dtype=torch.float64)\n",
            "PGD l2: Attack effectiveness 0.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([0.0006, 0.0078, -0.0000, -0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to9tOIafa0tD",
        "outputId": "a7225f66-aa82-4059-dd58-478ddcd3f72f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.0159,  -4.5420],\n",
              "        [  0.7008,  -1.1086],\n",
              "        [  0.8464,  -1.0425],\n",
              "        [-14.8106,  16.5576]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(mals.to(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga0MyFVia-nJ",
        "outputId": "bf0fc8ab-2a6e-4944-a440-c5855531acb2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-19.8462,  21.1819],\n",
              "        [-42.3733,  44.2564],\n",
              "        [-28.2794,  29.8791],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hpRfjZlVS-fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cEG-feOGS-cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zo93PmRES-u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        print('*********************************************************')\n",
        "        print('t : ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "        print('loss : ',loss)\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "            print('torch.abs(perturbation).sum(dim=-1) : ',torch.abs(perturbation).sum(dim=-1))\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            print('l2norm ; ',l2norm)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            print('max(grad) : ',val)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            outputs = model(x_next)\n",
        "            _, predicted = torch.topk(outputs, k=1)\n",
        "            done = (predicted != y).squeeze()\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "VAGvgkIzS_DW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gkde(x, y, model, penalty_factor, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        print('*************************************************')\n",
        "        print('t : ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        #y_model = model(x_var)\n",
        "        if t > 60:\n",
        "          decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "          #print('t : ',t)\n",
        "          #print('decayed_penalty_factor : ',decayed_penalty_factor)\n",
        "        else:\n",
        "          decayed_penalty_factor = penalty_factor\n",
        "\n",
        "        # Compute loss\n",
        "        loss, _ = get_loss_kde(x_var,y,model, decayed_penalty_factor)\n",
        "        print('loss : ',loss)\n",
        "        print('loss_natural : ' ,criterion(model(x_var), y.view(-1).long()))\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "            print('torch.abs(perturbation).sum(dim=-1) : ',torch.abs(perturbation).sum(dim=-1))\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            print('l2norm ; ',l2norm)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            #print('un_mod',un_mod.sum(dim=-1))\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            print('max_grad', val)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            _, done = get_loss_kde(x_next,y,model, penalty_factor)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, y.view(-1).long()).data\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    print('loss_natural : ',loss_natural)\n",
        "    print('loss_adv : ',loss_adv)\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "QN1EByvZTjAk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model, penalty_factor):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    print('ce: ', ce)\n",
        "    outputs_rbf = model_gaussian_1000(adv_x)\n",
        "    kde = criterion(outputs_rbf, torch.zeros_like(mals_y.view(-1).long()))\n",
        "    #kde=0.\n",
        "    print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "_76-fZbLTjAl"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#comparing two approaches:\n",
        "\n",
        " 1: loss based on its class and maximize the loss\n",
        "\n",
        " 2: loss based on the goal's class and minimize the loss\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qYzL-xKWhTD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `l1 attack`"
      ],
      "metadata": {
        "id": "vl7nVQXTaAhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_AT_rFGSM, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgQwFdzgS3kz",
        "outputId": "6548758e-52f1-4e97-88a9-ea29105c0653"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*********************************************************\n",
            "t :  0\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.4870e-15, 1.1302e-34, 2.6278e-22, 0.0000e+00])\n",
            "max(grad) :  tensor([[4.3781e-18],\n",
            "        [5.2451e-38],\n",
            "        [6.5250e-26],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  1\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5985e-04, 6.1378e-28, 2.3369e-20, 0.0000e+00])\n",
            "max(grad) :  tensor([[9.3436e-08],\n",
            "        [2.5265e-31],\n",
            "        [5.4686e-24],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  2\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 3.7722e-21, 2.1269e-16, 0.0000e+00])\n",
            "max(grad) :  tensor([[1.6631e+00],\n",
            "        [1.2673e-24],\n",
            "        [4.7833e-20],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  3\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 2.6399e-15, 2.6725e-12, 0.0000e+00])\n",
            "max(grad) :  tensor([[1.6631e+00],\n",
            "        [7.9984e-19],\n",
            "        [5.7116e-16],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  4\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 3.1136e-10, 3.1988e-08, 0.0000e+00])\n",
            "max(grad) :  tensor([[1.6631e+00],\n",
            "        [8.9839e-14],\n",
            "        [6.1582e-12],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  5\n",
            "loss :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 1.4353e-05, 1.9638e-04, 0.0000e+00])\n",
            "max(grad) :  tensor([[1.6631e+00],\n",
            "        [3.8651e-09],\n",
            "        [3.5020e-08],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  6\n",
            "loss :  tensor([1.0299e+01, 5.0068e-06, 1.4304e-04, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.8803e+03, 4.3532e-02, 1.6415e+00, 0.0000e+00])\n",
            "max(grad) :  tensor([[1.6631e+00],\n",
            "        [1.0837e-05],\n",
            "        [2.7402e-04],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  7\n",
            "loss :  tensor([10.2994,  0.0167,  0.3061, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8880.3486,  131.3973, 3233.3621,    0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [0.0367],\n",
            "        [0.1887],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  8\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  9\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  10\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  11\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  12\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  13\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  14\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  15\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  16\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  17\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  18\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  19\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  20\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  21\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  22\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  23\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  24\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  25\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  26\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  27\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  28\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  29\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  30\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  31\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  32\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  33\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  34\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  35\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  36\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  37\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  38\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  39\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  40\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  41\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  42\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  43\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  44\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  45\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  46\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  47\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  48\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "*********************************************************\n",
            "t :  49\n",
            "loss :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 8880.3486,  6764.0625, 11089.5908,     0.0000])\n",
            "max(grad) :  tensor([[1.6631],\n",
            "        [1.4348],\n",
            "        [0.5274],\n",
            "        [0.0000]], dtype=torch.float64)\n",
            "PGD l1: Attack effectiveness 75.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Myu2JdDPTiyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 0, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAqEfIhESwd_",
        "outputId": "03fb7d20-1eef-4f27-b4df-1883a2cf865f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t :  0\n",
            "loss :  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n",
            "max_grad tensor([[5.9220],\n",
            "        [4.4970],\n",
            "        [2.4442],\n",
            "        [5.5750]], dtype=torch.float64)\n",
            "t :  1\n",
            "loss :  tensor([ 17.2574,  71.0176,  53.6272, 164.5218], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10475.5771,  8753.7480,  9374.5732,  9018.6055])\n",
            "max_grad tensor([[6.1256],\n",
            "        [3.5946],\n",
            "        [2.1932],\n",
            "        [2.4330]], dtype=torch.float64)\n",
            "t :  2\n",
            "loss :  tensor([3.3616e-05, 5.5429e+01, 4.4622e+01, 1.5478e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1265e+03, 1.0463e+04, 9.0235e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.0219e+00],\n",
            "        [2.3581e+00],\n",
            "        [1.5561e+00]], dtype=torch.float64)\n",
            "t :  3\n",
            "loss :  tensor([3.3616e-05, 4.2018e+01, 3.5233e+01, 1.4863e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.5316e+03, 1.0955e+04, 8.8765e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.9064e+00],\n",
            "        [2.3421e+00],\n",
            "        [1.6096e+00]], dtype=torch.float64)\n",
            "t :  4\n",
            "loss :  tensor([3.3616e-05, 3.0319e+01, 2.5832e+01, 1.4469e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.3921e+03, 1.0962e+04, 8.4613e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.7028e+00],\n",
            "        [2.1177e+00],\n",
            "        [1.6392e+00]], dtype=torch.float64)\n",
            "t :  5\n",
            "loss :  tensor([3.3616e-05, 1.9540e+01, 1.7143e+01, 1.3839e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1422e+03, 1.1507e+04, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.4242e+00],\n",
            "        [2.0476e+00],\n",
            "        [1.2280e+00]], dtype=torch.float64)\n",
            "t :  6\n",
            "loss :  tensor([3.3616e-05, 1.2214e+01, 8.8525e+00, 1.3348e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0299e+01, 5.0068e-06, 1.4304e-04, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 8.7310e+03, 1.1474e+04, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.1735e+00],\n",
            "        [1.9154e+00],\n",
            "        [1.2060e+00]], dtype=torch.float64)\n",
            "t :  7\n",
            "loss :  tensor([3.3616e-05, 4.0993e+00, 1.3330e+00, 1.2865e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  0.0167,  0.3061, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 7.7917e+03, 9.0294e+03, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.1753e+00],\n",
            "        [5.2700e-01],\n",
            "        [1.1217e+00]], dtype=torch.float64)\n",
            "t :  8\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.2417e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.1173e+00]], dtype=torch.float64)\n",
            "t :  9\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1939e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.1097e+00]], dtype=torch.float64)\n",
            "t :  10\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1495e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0670e+00]], dtype=torch.float64)\n",
            "t :  11\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1068e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0610e+00]], dtype=torch.float64)\n",
            "t :  12\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0643e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0143e+00]], dtype=torch.float64)\n",
            "t :  13\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0237e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0043e+00]], dtype=torch.float64)\n",
            "t :  14\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.8351e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [9.9714e-01]], dtype=torch.float64)\n",
            "t :  15\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.4362e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [9.3243e-01]], dtype=torch.float64)\n",
            "t :  16\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.0639e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3357e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.5881e-01]], dtype=torch.float64)\n",
            "t :  17\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.7156e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.0538e-01]], dtype=torch.float64)\n",
            "t :  18\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.3935e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3143e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.9628e-01]], dtype=torch.float64)\n",
            "t :  19\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.0755e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.9117e-01]], dtype=torch.float64)\n",
            "t :  20\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.7752e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8621e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.1519e-01]], dtype=torch.float64)\n",
            "t :  21\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.4700e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.8368e-01]], dtype=torch.float64)\n",
            "t :  22\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.1965e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5682e-01]], dtype=torch.float64)\n",
            "t :  23\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.9337e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3132e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5225e-01]], dtype=torch.float64)\n",
            "t :  24\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.7578e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8157e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.9891e-01]], dtype=torch.float64)\n",
            "t :  25\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.4789e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8228e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.8515e-01]], dtype=torch.float64)\n",
            "t :  26\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2163e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2845e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5524e-01]], dtype=torch.float64)\n",
            "t :  27\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2409e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7232e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.0716e-01]], dtype=torch.float64)\n",
            "t :  28\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.9668e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8201e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.7152e-01]], dtype=torch.float64)\n",
            "t :  29\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.7031e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7293e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.2330e-01]], dtype=torch.float64)\n",
            "t :  30\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.4995e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2633e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.1782e-01]], dtype=torch.float64)\n",
            "t :  31\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.2756e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5679e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.9095e-01]], dtype=torch.float64)\n",
            "t :  32\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.0393e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.6147e-01]], dtype=torch.float64)\n",
            "t :  33\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.8147e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.5578e-01]], dtype=torch.float64)\n",
            "t :  34\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.7072e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0702e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4725e-01]], dtype=torch.float64)\n",
            "t :  35\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.4889e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4381e-01]], dtype=torch.float64)\n",
            "t :  36\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.2713e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4263e-01]], dtype=torch.float64)\n",
            "t :  37\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.0543e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4237e-01]], dtype=torch.float64)\n",
            "t :  38\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.8393e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9781e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.9568e-01]], dtype=torch.float64)\n",
            "t :  39\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.6430e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.6170e-01]], dtype=torch.float64)\n",
            "t :  40\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.4583e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.3553e-01]], dtype=torch.float64)\n",
            "t :  41\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2908e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3707e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.3911e-01]], dtype=torch.float64)\n",
            "t :  42\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2531e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.4075e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.3935e-01]], dtype=torch.float64)\n",
            "t :  43\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2872e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.4608e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.5223e+00]], dtype=torch.float64)\n",
            "t :  44\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2053e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.8152e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.3077e-01]], dtype=torch.float64)\n",
            "t :  45\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.0705e-01]], dtype=torch.float64)\n",
            "t :  46\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.5631e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.9829e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.6541e-01]], dtype=torch.float64)\n",
            "t :  47\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.3381e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8933e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.8362e-01]], dtype=torch.float64)\n",
            "t :  48\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1606e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 4.9637e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.9100e-01]], dtype=torch.float64)\n",
            "t :  49\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2428e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.7787e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.0003e-01]], dtype=torch.float64)\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([10.2994,  3.8019,  2.1209, -0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(mals.to(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQdsaaSDkJGt",
        "outputId": "b19fc239-43a7-4fc4-d1ba-9a840614dd19"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-19.8462,  21.1819],\n",
              "        [-42.3733,  44.2564],\n",
              "        [-28.2794,  29.8791],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY9WI2agXaPm",
        "outputId": "4e573d18-f462-49f9-93a7-dc731c13a005"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.8403,  -5.4591],\n",
              "        [  1.5538,  -2.2255],\n",
              "        [  0.8769,  -1.1162],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpbw4NJOXW8e",
        "outputId": "e287d641-9569-42cd-b623-59b58e323558"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.8403,  -5.4591],\n",
              "        [  1.5538,  -2.2255],\n",
              "        [  0.8769,  -1.1162],\n",
              "        [-14.3782,  16.4776]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pWJIcjGoaLxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `linf attack`"
      ],
      "metadata": {
        "id": "7kiaFrgiaMBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adv = pgd(mals.to(torch.float32), mals_y, model_AT_rFGSM, insertion_array, removal_array, k=100, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd722d5-0744-4c66-85cf-5f77cf14b419",
        "id": "MucmaxrCaMBo"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*********************************************************\n",
            "t :  0\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.4870e-15, 1.1302e-34, 2.6278e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([121., 225., 247.,   0.])\n",
            "*********************************************************\n",
            "t :  1\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.6104e-14, 2.6541e-32, 9.4535e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([114., 269., 199.,   0.])\n",
            "*********************************************************\n",
            "t :  2\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.9466e-13, 3.1007e-29, 5.3306e-19, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105., 316., 209.,   0.])\n",
            "*********************************************************\n",
            "t :  3\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.1073e-12, 3.0971e-26, 2.5778e-17, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([121., 327., 219.,   0.])\n",
            "*********************************************************\n",
            "t :  4\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.7257e-11, 8.3830e-23, 1.3431e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111., 337., 228.,   0.])\n",
            "*********************************************************\n",
            "t :  5\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.7650e-10, 3.0536e-21, 8.0913e-14, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([131., 259., 225.,   0.])\n",
            "*********************************************************\n",
            "t :  6\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.1742e-09, 1.6437e-19, 1.6523e-12, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([136., 246., 219.,   0.])\n",
            "*********************************************************\n",
            "t :  7\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.1507e-09, 9.5543e-18, 4.5661e-12, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([100., 243., 159.,   0.])\n",
            "*********************************************************\n",
            "t :  8\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.5897e-08, 1.0583e-16, 3.1140e-11, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([123., 155., 155.,   0.])\n",
            "*********************************************************\n",
            "t :  9\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.3366e-08, 1.2247e-15, 1.1673e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([103., 153., 122.,   0.])\n",
            "*********************************************************\n",
            "t :  10\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.4573e-07, 1.3879e-14, 5.2028e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 99., 153., 128.,   0.])\n",
            "*********************************************************\n",
            "t :  11\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.0291e-06, 1.6619e-13, 1.7374e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([106., 201., 120.,   0.])\n",
            "*********************************************************\n",
            "t :  12\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.2036e-06, 3.6093e-13, 1.3230e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 98., 141.,  87.,   0.])\n",
            "*********************************************************\n",
            "t :  13\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.6678e-06, 7.8356e-13, 2.7389e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 84., 108.,  96.,   0.])\n",
            "*********************************************************\n",
            "t :  14\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.4771e-06, 1.7149e-12, 3.9581e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([208., 108.,  87.,   0.])\n",
            "*********************************************************\n",
            "t :  15\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.0192e-06, 3.7534e-12, 6.4940e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109., 108., 119.,   0.])\n",
            "*********************************************************\n",
            "t :  16\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.7281e-06, 9.9066e-12, 2.7813e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 84., 142., 100.,   0.])\n",
            "*********************************************************\n",
            "t :  17\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.2480e-06, 3.8477e-12, 5.6265e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109., 129., 118.,   0.])\n",
            "*********************************************************\n",
            "t :  18\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.3089e-06, 8.0272e-12, 5.2267e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92., 129., 119.,   0.])\n",
            "*********************************************************\n",
            "t :  19\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.3284e-06, 1.8641e-11, 2.5452e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 84., 129., 100.,   0.])\n",
            "*********************************************************\n",
            "t :  20\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.4652e-06, 3.5751e-11, 4.4896e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 90., 130., 100.,   0.])\n",
            "*********************************************************\n",
            "t :  21\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.2551e-05, 1.5410e-11, 7.3787e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([105., 129., 117.,   0.])\n",
            "*********************************************************\n",
            "t :  22\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.4426e-06, 3.2149e-11, 3.7648e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 88., 129., 110.,   0.])\n",
            "*********************************************************\n",
            "t :  23\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.0505e-05, 6.4371e-11, 4.9495e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87., 122.,  97.,   0.])\n",
            "*********************************************************\n",
            "t :  24\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.8071e-05, 1.7253e-10, 7.1295e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111., 185., 155.,   0.])\n",
            "*********************************************************\n",
            "t :  25\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5796e-05, 4.2677e-11, 2.5773e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([201., 112.,  85.,   0.])\n",
            "*********************************************************\n",
            "t :  26\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.5562e-06, 7.7367e-11, 3.0913e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 100.,  82.,   0.])\n",
            "*********************************************************\n",
            "t :  27\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.9581e-06, 7.2462e-11, 2.6442e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87., 123., 104.,   0.])\n",
            "*********************************************************\n",
            "t :  28\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.9243e-06, 3.4022e-11, 1.5375e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75., 100.,  82.,   0.])\n",
            "*********************************************************\n",
            "t :  29\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.0502e-06, 4.6957e-11, 1.4441e-09, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([110., 122., 111.,   0.])\n",
            "*********************************************************\n",
            "t :  30\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.4065e-07, 1.4101e-11, 6.1150e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([77., 95., 78.,  0.])\n",
            "*********************************************************\n",
            "t :  31\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.3122e-06, 2.2286e-11, 5.2846e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102., 121., 137.,   0.])\n",
            "*********************************************************\n",
            "t :  32\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.0846e-07, 6.3224e-12, 1.6260e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 76., 228.,  97.,   0.])\n",
            "*********************************************************\n",
            "t :  33\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.4732e-07, 7.9178e-13, 1.0777e-10, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 67., 124., 102.,   0.])\n",
            "*********************************************************\n",
            "t :  34\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.4253e-07, 3.7322e-13, 4.7847e-11, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([146.,  68., 239.,   0.])\n",
            "*********************************************************\n",
            "t :  35\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.0982e-07, 3.8144e-13, 1.1913e-12, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75.,  88., 111.,   0.])\n",
            "*********************************************************\n",
            "t :  36\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.6743e-08, 2.0733e-13, 2.1224e-12, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([117., 117.,  85.,   0.])\n",
            "*********************************************************\n",
            "t :  37\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.0280e-08, 1.5712e-13, 8.6320e-13, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([97., 82., 87.,  0.])\n",
            "*********************************************************\n",
            "t :  38\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.1979e-08, 1.5707e-13, 8.3293e-13, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 71., 114., 139.,   0.])\n",
            "*********************************************************\n",
            "t :  39\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.6723e-08, 4.0591e-14, 1.5517e-13, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([74., 90., 78.,  0.])\n",
            "*********************************************************\n",
            "t :  40\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.1117e-08, 4.6377e-14, 1.9136e-13, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([97., 76., 55.,  0.])\n",
            "*********************************************************\n",
            "t :  41\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.3204e-09, 3.1243e-14, 1.5697e-13, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([188.,  84.,  93.,   0.])\n",
            "*********************************************************\n",
            "t :  42\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.0539e-10, 1.5208e-14, 7.4041e-14, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 94., 110.,  94.,   0.])\n",
            "*********************************************************\n",
            "t :  43\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.2089e-10, 1.0292e-14, 5.9167e-14, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([90., 88., 99.,  0.])\n",
            "*********************************************************\n",
            "t :  44\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.9714e-10, 5.9103e-15, 1.7089e-14, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 70., 116.,  91.,   0.])\n",
            "*********************************************************\n",
            "t :  45\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.7368e-10, 3.7699e-15, 2.7952e-14, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([101.,  77., 150.,   0.])\n",
            "*********************************************************\n",
            "t :  46\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.7646e-11, 6.9744e-15, 3.8062e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 65., 161.,  93.,   0.])\n",
            "*********************************************************\n",
            "t :  47\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.6085e-10, 7.0478e-16, 7.0350e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 99.,  92., 109.,   0.])\n",
            "*********************************************************\n",
            "t :  48\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.7801e-11, 1.5403e-15, 1.7172e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 109.,  95.,   0.])\n",
            "*********************************************************\n",
            "t :  49\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.4431e-11, 3.7060e-16, 2.4987e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([106., 111., 106.,   0.])\n",
            "*********************************************************\n",
            "t :  50\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.9539e-11, 4.5064e-16, 9.0057e-16, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([104.,  79.,  78.,   0.])\n",
            "*********************************************************\n",
            "t :  51\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.1047e-12, 3.3778e-16, 1.2846e-15, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75., 110., 159.,   0.])\n",
            "*********************************************************\n",
            "t :  52\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.2810e-11, 1.4980e-16, 2.0522e-16, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 99., 143., 102.,   0.])\n",
            "*********************************************************\n",
            "t :  53\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.0188e-12, 1.0055e-16, 1.9296e-16, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 80., 104., 100.,   0.])\n",
            "*********************************************************\n",
            "t :  54\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.4522e-12, 4.7703e-17, 1.1903e-16, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([152., 225., 135.,   0.])\n",
            "*********************************************************\n",
            "t :  55\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.4224e-13, 4.1080e-18, 3.6852e-17, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 106., 138.,   0.])\n",
            "*********************************************************\n",
            "t :  56\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5087e-12, 6.7759e-18, 2.0690e-17, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([127., 111., 106.,   0.])\n",
            "*********************************************************\n",
            "t :  57\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.4455e-13, 3.1157e-18, 1.4269e-17, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([116., 119., 151.,   0.])\n",
            "*********************************************************\n",
            "t :  58\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.7156e-13, 2.6044e-18, 9.6755e-18, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 49., 134.,  65.,   0.])\n",
            "*********************************************************\n",
            "t :  59\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.7363e-13, 8.4409e-19, 4.8078e-18, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92., 127., 124.,   0.])\n",
            "*********************************************************\n",
            "t :  60\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.0508e-14, 1.8195e-18, 2.1180e-18, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 82.,  47., 137.,   0.])\n",
            "*********************************************************\n",
            "t :  61\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.6895e-14, 1.2836e-18, 1.1077e-18, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 93., 152.,  94.,   0.])\n",
            "*********************************************************\n",
            "t :  62\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.3913e-14, 2.5402e-19, 7.9855e-19, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([117., 100., 101.,   0.])\n",
            "*********************************************************\n",
            "t :  63\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.7289e-14, 5.5416e-19, 6.3977e-19, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92.,  48., 131.,   0.])\n",
            "*********************************************************\n",
            "t :  64\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.1366e-14, 3.0632e-19, 2.1672e-19, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 65., 132., 100.,   0.])\n",
            "*********************************************************\n",
            "t :  65\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5011e-14, 1.3088e-19, 3.4705e-19, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 37., 121., 213.,   0.])\n",
            "*********************************************************\n",
            "t :  66\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.4301e-14, 1.5219e-19, 5.9434e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([119., 122., 139.,   0.])\n",
            "*********************************************************\n",
            "t :  67\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.1214e-15, 9.4347e-20, 7.2861e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 97., 122.,  84.,   0.])\n",
            "*********************************************************\n",
            "t :  68\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.1734e-15, 8.7815e-20, 5.1372e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109., 112.,  51.,   0.])\n",
            "*********************************************************\n",
            "t :  69\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.7193e-15, 6.2737e-20, 7.4920e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 96., 117.,  63.,   0.])\n",
            "*********************************************************\n",
            "t :  70\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.3103e-15, 6.0999e-20, 5.0186e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([138., 149.,  46.,   0.])\n",
            "*********************************************************\n",
            "t :  71\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.1290e-16, 1.7765e-20, 5.4369e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([120., 140.,  35.,   0.])\n",
            "*********************************************************\n",
            "t :  72\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.4030e-16, 2.8274e-20, 4.6507e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 97.,  58., 145.,   0.])\n",
            "*********************************************************\n",
            "t :  73\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.2744e-16, 3.7434e-20, 7.8186e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 91., 140.,  97.,   0.])\n",
            "*********************************************************\n",
            "t :  74\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.9127e-16, 1.0557e-20, 1.6894e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([101.,  68.,  24.,   0.])\n",
            "*********************************************************\n",
            "t :  75\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.1814e-16, 1.0732e-20, 1.7972e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([119., 124.,  32.,   0.])\n",
            "*********************************************************\n",
            "t :  76\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.8538e-16, 4.2419e-21, 1.8289e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([100., 108.,  45.,   0.])\n",
            "*********************************************************\n",
            "t :  77\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8.4346e-17, 6.6933e-21, 1.4695e-21, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 76., 112.,  34.,   0.])\n",
            "*********************************************************\n",
            "t :  78\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.9673e-16, 3.0489e-21, 9.5550e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 90., 110., 109.,   0.])\n",
            "*********************************************************\n",
            "t :  79\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6.2495e-17, 5.3769e-21, 5.0500e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([106.,  49., 111.,   0.])\n",
            "*********************************************************\n",
            "t :  80\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.2412e-17, 3.6719e-21, 7.4751e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102., 158.,  52.,   0.])\n",
            "*********************************************************\n",
            "t :  81\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4.2692e-17, 7.1015e-22, 4.8686e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([151., 114., 150.,   0.])\n",
            "*********************************************************\n",
            "t :  82\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.3192e-17, 1.7553e-21, 1.2620e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 99.,  26., 144.,   0.])\n",
            "*********************************************************\n",
            "t :  83\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.6515e-17, 1.9228e-21, 1.3254e-22, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87.,  39., 229.,   0.])\n",
            "*********************************************************\n",
            "t :  84\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.3621e-17, 1.0203e-21, 2.8593e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 97., 127.,  86.,   0.])\n",
            "*********************************************************\n",
            "t :  85\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.2115e-17, 5.3453e-22, 6.7982e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([104., 119.,  25.,   0.])\n",
            "*********************************************************\n",
            "t :  86\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.1460e-17, 8.4763e-22, 5.9915e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([129., 137.,  23.,   0.])\n",
            "*********************************************************\n",
            "t :  87\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.8994e-18, 2.7827e-22, 6.8695e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([114., 123.,  23.,   0.])\n",
            "*********************************************************\n",
            "t :  88\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.6506e-18, 7.3985e-22, 5.9447e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([118.,  24.,  21.,   0.])\n",
            "*********************************************************\n",
            "t :  89\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.1935e-18, 5.2345e-22, 6.7557e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 90., 136.,  24.,   0.])\n",
            "*********************************************************\n",
            "t :  90\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.3738e-18, 1.8587e-22, 5.8023e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([149., 114.,  21.,   0.])\n",
            "*********************************************************\n",
            "t :  91\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9.7866e-19, 4.8751e-22, 6.6963e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([92., 49., 45.,  0.])\n",
            "*********************************************************\n",
            "t :  92\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.5926e-18, 2.4685e-22, 4.7137e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([117., 123.,  42.,   0.])\n",
            "*********************************************************\n",
            "t :  93\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.2921e-19, 1.2642e-22, 5.7823e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([118., 112.,  58.,   0.])\n",
            "*********************************************************\n",
            "t :  94\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7.1816e-19, 2.8247e-22, 4.2319e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([136., 167.,  44.,   0.])\n",
            "*********************************************************\n",
            "t :  95\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3.1828e-19, 4.1906e-23, 5.6204e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([101., 116.,  68.,   0.])\n",
            "*********************************************************\n",
            "t :  96\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5.7399e-19, 1.2198e-22, 3.2500e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([115., 131.,  49.,   0.])\n",
            "*********************************************************\n",
            "t :  97\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.7571e-19, 3.2483e-23, 4.7561e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([107.,  61.,  58.,   0.])\n",
            "*********************************************************\n",
            "t :  98\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9833e-19, 5.5510e-23, 3.1224e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([90., 32., 46.,  0.])\n",
            "*********************************************************\n",
            "t :  99\n",
            "loss :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1.6262e-19, 4.7636e-23, 3.7931e-24, 0.0000e+00])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([121.,  28.,  17.,   0.])\n",
            "PGD linf: Attack effectiveness 0.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 0, insertion_array, removal_array, k=100, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b483c45-7801-4d97-d9d6-1303142b812f",
        "id": "n8EdiEvfaMBq"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "t :  0\n",
            "loss :  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([119., 224., 242., 269.])\n",
            "*************************************************\n",
            "t :  1\n",
            "loss :  tensor([ 38.9261,  81.0620,  54.4818, 180.4803], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10320.1094,  8620.9150,  9300.6074,  9011.1484])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102., 261., 197., 269.])\n",
            "*************************************************\n",
            "t :  2\n",
            "loss :  tensor([ 36.9672,  74.1730,  50.4399, 174.7070], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9165.1289, 9202.2500, 9227.6904, 8399.1846])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 92., 308., 220., 262.])\n",
            "*************************************************\n",
            "t :  3\n",
            "loss :  tensor([ 34.5991,  67.0495,  46.4729, 168.9660], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8735.9189, 8263.8496, 8915.4727, 8258.7188])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([111., 309., 203., 248.])\n",
            "*************************************************\n",
            "t :  4\n",
            "loss :  tensor([ 32.2973,  59.1113,  42.5275, 163.4096], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8493.3340, 7385.1299, 8754.5732, 8258.7188])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([103., 319., 216., 248.])\n",
            "*************************************************\n",
            "t :  5\n",
            "loss :  tensor([ 30.2587,  55.1975,  38.4088, 157.8634], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([9281.1836, 7970.1445, 8738.1250, 8252.8262])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([122., 247., 217., 247.])\n",
            "*************************************************\n",
            "t :  6\n",
            "loss :  tensor([ 28.2272,  50.9528,  35.2546, 152.3443], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([8219.1064, 6950.1992, 7885.7285, 8250.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([116., 243., 201., 247.])\n",
            "*************************************************\n",
            "t :  7\n",
            "loss :  tensor([ 26.1662,  46.8429,  33.8714, 146.8350], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6868.9570, 6875.8882, 6755.9170, 8250.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 91., 226., 147., 247.])\n",
            "*************************************************\n",
            "t :  8\n",
            "loss :  tensor([ 24.5901,  43.7140,  31.8959, 141.3257], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6750.8560, 6098.1050, 6719.6836, 8250.3145])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 87., 150., 145., 247.])\n",
            "*************************************************\n",
            "t :  9\n",
            "loss :  tensor([ 23.1277,  41.2342,  29.9907, 135.8538], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([7547.0591, 6098.1050, 6676.7642, 8161.2568])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 94., 150., 143., 238.])\n",
            "*************************************************\n",
            "t :  10\n",
            "loss :  tensor([ 22.4542,  38.9035,  28.9155, 130.6019], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6336.0449, 7014.7983, 5607.2778, 8161.2568])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 81., 193., 117., 238.])\n",
            "*************************************************\n",
            "t :  11\n",
            "loss :  tensor([ 21.2590,  37.2616,  27.4847, 125.3665], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5902.6260, 6059.2842, 5569.2759, 8126.8125])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 78., 146., 114., 240.])\n",
            "*************************************************\n",
            "t :  12\n",
            "loss :  tensor([ 19.9286,  35.1469,  27.3365, 120.1605], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5871.0557, 5120.8809, 3988.7178, 8094.7358])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 82., 136.,  82., 236.])\n",
            "*************************************************\n",
            "t :  13\n",
            "loss :  tensor([ 18.6790,  33.7603,  26.7909, 115.2130], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5722.6396, 3284.2192, 3421.1265, 7974.3389])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 77., 112.,  85., 231.])\n",
            "*************************************************\n",
            "t :  14\n",
            "loss :  tensor([ 18.9175,  32.9630,  26.1729, 110.2807], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5107.4839, 3279.4324, 3477.6370, 7974.3389])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([134., 110.,  83., 231.])\n",
            "*************************************************\n",
            "t :  15\n",
            "loss :  tensor([ 19.2570,  32.1819,  25.8127, 106.1112], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4442.6294, 4856.6699, 4802.6626, 7280.1831])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 73., 131., 116., 211.])\n",
            "*************************************************\n",
            "t :  16\n",
            "loss :  tensor([ 19.0701,  32.5674,  26.3655, 102.5519], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5605.9072, 3787.5869, 4136.5845, 6288.3242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 83., 115., 103., 156.])\n",
            "*************************************************\n",
            "t :  17\n",
            "loss :  tensor([18.9791, 31.9369, 26.0897, 99.3398], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4034.7456, 3134.3682, 3165.9988, 6288.3242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 117.,  97., 156.])\n",
            "*************************************************\n",
            "t :  18\n",
            "loss :  tensor([18.2817, 31.1933, 25.7029, 96.1278], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4034.7456, 3134.3682, 5051.0332, 6288.3242])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 117., 123., 156.])\n",
            "*************************************************\n",
            "t :  19\n",
            "loss :  tensor([17.5843, 30.4497, 26.3557, 92.9893], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4034.7456, 3134.3682, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 117.,  94., 150.])\n",
            "*************************************************\n",
            "t :  20\n",
            "loss :  tensor([16.8869, 29.8929, 25.7846, 89.8805], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4034.7454, 4709.4390, 3729.3491, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 122., 101., 150.])\n",
            "*************************************************\n",
            "t :  21\n",
            "loss :  tensor([16.5455, 30.5232, 25.5007, 86.7717], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5100.2427, 4614.0112, 5192.3447, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75., 237., 102., 150.])\n",
            "*************************************************\n",
            "t :  22\n",
            "loss :  tensor([16.4930, 31.0354, 26.0035, 83.6629], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4034.7454, 3134.3682, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 117.,  94., 150.])\n",
            "*************************************************\n",
            "t :  23\n",
            "loss :  tensor([15.8910, 30.5713, 25.4269, 80.5541], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3428.3442, 4709.4390, 3222.1963, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59., 122.,  94., 150.])\n",
            "*************************************************\n",
            "t :  24\n",
            "loss :  tensor([15.2549, 30.8426, 25.3847, 78.1801], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3428.3438, 3134.3682, 6175.7275, 4611.9790])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59., 117., 149., 161.])\n",
            "*************************************************\n",
            "t :  25\n",
            "loss :  tensor([14.6676, 30.1644, 26.1598, 75.9270], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.7684e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5341.5239, 3550.8931, 3222.1963, 4462.4604])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 80.,  99.,  87., 136.])\n",
            "*************************************************\n",
            "t :  26\n",
            "loss :  tensor([15.0635, 29.6926, 25.6648, 73.9886], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3428.3433, 3036.4189, 4099.5752, 4062.1274])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([51., 91., 89., 86.])\n",
            "*************************************************\n",
            "t :  27\n",
            "loss :  tensor([14.8631, 29.8506, 26.2489, 74.5140], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([3.5763e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3653.8372, 4613.3867, 4768.4033, 6039.4648])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 49., 107.,  99.,  63.])\n",
            "*************************************************\n",
            "t :  28\n",
            "loss :  tensor([14.6755, 30.4484, 26.7233, 74.3617], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([4.7684e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3119.2571, 3550.8931, 3222.1963, 4062.1274])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59.,  86.,  77., 100.])\n",
            "*************************************************\n",
            "t :  29\n",
            "loss :  tensor([15.2084, 30.4031, 26.6611, 75.1037], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5722.4585, 3686.2048, 5954.7959, 6189.5356])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 81.,  77., 100.,  61.])\n",
            "*************************************************\n",
            "t :  30\n",
            "loss :  tensor([15.3051, 30.5219, 27.5171, 74.7511], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3824.5381, 4868.6455, 3222.1963, 6039.4648])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 51., 112.,  73.,  35.])\n",
            "*************************************************\n",
            "t :  31\n",
            "loss :  tensor([15.1216, 31.4953, 27.4732, 74.9265], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5289.9375, 3550.8931, 5923.0322, 4462.4604])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 72.,  84., 130., 100.])\n",
            "*************************************************\n",
            "t :  32\n",
            "loss :  tensor([16.2197, 31.3611, 28.8655, 75.5406], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5127.4370, 4153.0273, 3729.3491, 5789.2070])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([149., 217.,  82.,  74.])\n",
            "*************************************************\n",
            "t :  33\n",
            "loss :  tensor([17.4013, 34.6743, 28.6891, 75.2225], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4933.9775, 5414.8091, 3618.8379, 6033.4912])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 62., 111.,  55.,  38.])\n",
            "*************************************************\n",
            "t :  34\n",
            "loss :  tensor([17.6353, 33.9646, 29.3002, 75.4099], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3911.3672, 3803.2217, 5051.0332, 4605.9878])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 44.,  77., 103., 101.])\n",
            "*************************************************\n",
            "t :  35\n",
            "loss :  tensor([17.5465, 34.4389, 29.7016, 76.0355], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3541.6221, 4875.8320, 4127.7192, 5634.1650])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 59., 109.,  79.,  76.])\n",
            "*************************************************\n",
            "t :  36\n",
            "loss :  tensor([18.1478, 35.0887, 29.9151, 75.7448], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5160.7344, 3950.1208, 5051.0332, 6183.5649])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 68.,  92., 100.,  45.])\n",
            "*************************************************\n",
            "t :  37\n",
            "loss :  tensor([18.3078, 35.1338, 31.1448, 75.7992], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 3441.5703, 4192.1514, 4456.4258])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 47.,  57., 212., 104.])\n",
            "*************************************************\n",
            "t :  38\n",
            "loss :  tensor([18.2437, 35.1553, 34.5713, 76.5162], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3648.2214, 4767.8999, 6429.8174, 5783.4253])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 41., 113., 131.,  74.])\n",
            "*************************************************\n",
            "t :  39\n",
            "loss :  tensor([18.7624, 36.2596, 34.0355, 76.2071], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4672.6055, 3043.7659, 4379.0483, 6033.4912])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([71., 82., 72., 37.])\n",
            "*************************************************\n",
            "t :  40\n",
            "loss :  tensor([19.2109, 36.4460, 34.6355, 76.2051], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 4349.9844, 4795.8843, 4456.4258])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 47.,  91.,  91., 102.])\n",
            "*************************************************\n",
            "t :  41\n",
            "loss :  tensor([19.0794, 36.3411, 35.0546, 77.0117], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3911.3672, 3043.7659, 4134.9858, 5783.4253])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([42., 73., 77., 73.])\n",
            "*************************************************\n",
            "t :  42\n",
            "loss :  tensor([19.5648, 37.7912, 35.4185, 76.6674], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5616.8936, 5929.8252, 5058.1914, 6033.4912])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 99., 106.,  94.,  34.])\n",
            "*************************************************\n",
            "t :  43\n",
            "loss :  tensor([20.8563, 37.3917, 36.0776, 76.8565], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5213.0430, 3840.9678, 3626.1331, 5571.6934])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([145.,  68.,  61., 175.])\n",
            "*************************************************\n",
            "t :  44\n",
            "loss :  tensor([22.1939, 37.5848, 35.9757, 79.4907], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4758.4883, 4620.6113, 3950.5518, 5783.4253])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 62.,  94., 116.,  71.])\n",
            "*************************************************\n",
            "t :  45\n",
            "loss :  tensor([22.4232, 38.7595, 37.3291, 79.0914], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 4299.1665, 5855.1001, 6183.5649])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 46., 116.,  98.,  37.])\n",
            "*************************************************\n",
            "t :  46\n",
            "loss :  tensor([22.3561, 38.9738, 37.6031, 78.9088], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5422.3169, 3295.3997, 3883.0549, 5876.9805])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([59., 65., 82., 55.])\n",
            "*************************************************\n",
            "t :  47\n",
            "loss :  tensor([23.0926, 39.1467, 37.9628, 78.6741], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 6122.5845, 5448.5859, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 49., 154.,  85.,  51.])\n",
            "*************************************************\n",
            "t :  48\n",
            "loss :  tensor([22.9721, 40.4137, 38.2646, 78.9021], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3911.3672, 3288.9519, 4330.9453, 4296.1665])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 39.,  72., 115., 118.])\n",
            "*************************************************\n",
            "t :  49\n",
            "loss :  tensor([23.1417, 40.3063, 39.5162, 79.7308], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4672.6055, 4344.1343, 5596.6099, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([69., 85., 81., 87.])\n",
            "*************************************************\n",
            "t :  50\n",
            "loss :  tensor([23.9780, 40.7384, 39.2600, 79.3028], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 4617.5840, 3474.1106, 6833.7549])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 54.,  96.,  81., 108.])\n",
            "*************************************************\n",
            "t :  51\n",
            "loss :  tensor([23.7258, 41.4948, 40.1157, 79.9747], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3981.4170, 3547.6951, 5982.5942, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 32.,  91., 134.,  61.])\n",
            "*************************************************\n",
            "t :  52\n",
            "loss :  tensor([23.6885, 41.3669, 40.6419, 80.4517], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5422.3169, 5419.0410, 4879.6724, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 64., 112., 117., 117.])\n",
            "*************************************************\n",
            "t :  53\n",
            "loss :  tensor([24.5850, 42.2957, 42.0219, 80.7347], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5213.0430, 3040.1052, 5052.7095, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([149.,  96.,  87.,  94.])\n",
            "*************************************************\n",
            "t :  54\n",
            "loss :  tensor([26.5811, 42.4402, 41.8534, 80.7044], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5462.4043, 7482.7437, 4193.7007, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([102., 174., 228., 119.])\n",
            "*************************************************\n",
            "t :  55\n",
            "loss :  tensor([27.0096, 43.6059, 47.1931, 81.3132], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4053.9656, 3837.8774, 7175.5098, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 56.,  88., 146.,  95.])\n",
            "*************************************************\n",
            "t :  56\n",
            "loss :  tensor([26.7271, 43.2892, 46.7588, 80.9192], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5670.7041, 3438.4768, 5596.6099, 4296.1665])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 73.,  42.,  53., 126.])\n",
            "*************************************************\n",
            "t :  57\n",
            "loss :  tensor([27.6096, 43.4300, 46.6079, 82.0546], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4294.2368, 5019.9370, 6104.4409, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 56., 103.,  55.,  92.])\n",
            "*************************************************\n",
            "t :  58\n",
            "loss :  tensor([27.2663, 44.4803, 46.4691, 81.7333], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3668.4836, 3946.9497, 5596.6099, 6581.1318])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 35., 119.,  42., 104.])\n",
            "*************************************************\n",
            "t :  59\n",
            "loss :  tensor([27.3590, 44.3622, 46.4287, 82.1789], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5803.0342, 5019.9370, 6553.4619, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 80., 112.,  64.,  63.])\n",
            "*************************************************\n",
            "t :  60\n",
            "loss :  tensor([28.1253, 45.1623, 46.6692, 82.2566], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3911.3672, 3800.1702, 5052.7095, 3895.4583])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 51., 100.,  54., 131.])\n",
            "*************************************************\n",
            "t :  61\n",
            "loss :  tensor([27.7749, 44.6970, 47.2206, 83.2882], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4437.9097, 3837.8774, 4380.3838, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 37.,  54., 102.,  92.])\n",
            "*************************************************\n",
            "t :  62\n",
            "loss :  tensor([27.8489, 44.8085, 47.8151, 82.6485], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4609.7915, 4872.6562, 5674.1445, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 68.,  99., 137.,  37.])\n",
            "*************************************************\n",
            "t :  63\n",
            "loss :  tensor([28.3224, 46.0295, 48.4111, 82.9330], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3807.4080, 4919.0776, 4620.0420, 5413.7148])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 46., 228., 114., 195.])\n",
            "*************************************************\n",
            "t :  64\n",
            "loss :  tensor([28.9293, 48.5752, 48.9117, 85.6939], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5647.8379, 5019.9370, 5052.7095, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 84., 104.,  87.,  85.])\n",
            "*************************************************\n",
            "t :  65\n",
            "loss :  tensor([29.1909, 47.8287, 48.7843, 85.0598], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4271.6348, 4639.2568, 4527.8179, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 54., 133., 105.,  33.])\n",
            "*************************************************\n",
            "t :  66\n",
            "loss :  tensor([29.0043, 49.2853, 49.5457, 85.0367], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5159.1011, 5019.9370, 5052.7095, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 82., 102.,  90.,  32.])\n",
            "*************************************************\n",
            "t :  67\n",
            "loss :  tensor([29.9156, 48.5424, 49.3420, 84.9836], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4271.6348, 5507.8164, 4367.9287, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 55.,  45., 124.,  33.])\n",
            "*************************************************\n",
            "t :  68\n",
            "loss :  tensor([29.4900, 48.8184, 50.7292, 85.0016], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4135.1279, 3382.5669, 5052.7095, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 25., 104.,  90.,  37.])\n",
            "*************************************************\n",
            "t :  69\n",
            "loss :  tensor([29.4953, 49.7679, 49.9877, 84.9960], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4271.6348, 5926.8262, 5448.5859, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 30., 113.,  27.,  34.])\n",
            "*************************************************\n",
            "t :  70\n",
            "loss :  tensor([29.5515, 49.1805, 50.0387, 84.9885], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3645.8015, 3130.8225, 4440.8359, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 35., 130., 204.,  37.])\n",
            "*************************************************\n",
            "t :  71\n",
            "loss :  tensor([29.8559, 51.0193, 54.4898, 85.1415], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5924.2217, 6524.4004, 6666.7964, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 82., 134., 145., 127.])\n",
            "*************************************************\n",
            "t :  72\n",
            "loss :  tensor([30.6592, 50.3045, 54.1612, 86.1305], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4808.5840, 5108.6631, 6104.4409, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([148.,  44.,  50.,  94.])\n",
            "*************************************************\n",
            "t :  73\n",
            "loss :  tensor([32.9352, 50.3456, 54.1037, 85.5583], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([6822.7754, 4437.6265, 5596.6099, 6027.0879])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([116., 117.,  29.,  31.])\n",
            "*************************************************\n",
            "t :  74\n",
            "loss :  tensor([32.9740, 51.3901, 54.0394, 85.5870], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4642.6738, 5019.9370, 5596.6099, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 49., 104.,  18.,  35.])\n",
            "*************************************************\n",
            "t :  75\n",
            "loss :  tensor([32.8534, 50.6782, 54.0304, 85.6780], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5281.8242, 5867.0674, 6104.4409, 6982.9194])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 78.,  45.,  35., 106.])\n",
            "*************************************************\n",
            "t :  76\n",
            "loss :  tensor([33.6236, 50.8088, 54.1365, 86.4323], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4127.5903, 3528.9597, 5646.6909, 5476.8105])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 58., 105.,  48.,  63.])\n",
            "*************************************************\n",
            "t :  77\n",
            "loss :  tensor([33.0695, 51.7259, 54.3228, 86.3662], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5524.6982, 5419.0410, 5599.4731, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 67., 104.,  36., 124.])\n",
            "*************************************************\n",
            "t :  78\n",
            "loss :  tensor([33.8371, 51.2876, 54.2341, 87.2162], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 4491.8130, 5052.7095, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 60., 154.,  35.,  90.])\n",
            "*************************************************\n",
            "t :  79\n",
            "loss :  tensor([33.4252, 52.9387, 54.6651, 86.6691], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5284.3442, 5019.9370, 5134.5366, 5876.9805])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 83., 112., 142.,  31.])\n",
            "*************************************************\n",
            "t :  80\n",
            "loss :  tensor([34.4931, 52.1520, 56.0316, 86.6731], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 6225.5488, 5055.3926, 5626.0986])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 66., 130.,  90.,  29.])\n",
            "*************************************************\n",
            "t :  81\n",
            "loss :  tensor([33.9372, 53.0547, 55.3392, 86.6666], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3971.2996, 5108.6631, 5599.4731, 6029.9590])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([63., 67., 32., 29.])\n",
            "*************************************************\n",
            "t :  82\n",
            "loss :  tensor([34.4887, 52.9526, 55.4154, 86.7209], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5381.4346, 4437.6265, 5055.3926, 6432.9019])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 74., 125.,  31., 114.])\n",
            "*************************************************\n",
            "t :  83\n",
            "loss :  tensor([35.1901, 53.8903, 55.3727, 87.5753], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5048.4453, 5019.9370, 5599.4731, 6029.9590])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 61., 111.,  32.,  63.])\n",
            "*************************************************\n",
            "t :  84\n",
            "loss :  tensor([35.3772, 53.1988, 55.4557, 87.5155], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4528.5103, 4346.9844, 5055.3926, 4445.8726])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 65., 124.,  31., 116.])\n",
            "*************************************************\n",
            "t :  85\n",
            "loss :  tensor([35.5458, 54.2649, 55.6155, 88.3857], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5302.8442, 5019.9370, 5134.5366, 5629.0073])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 75., 109., 145.,  91.])\n",
            "*************************************************\n",
            "t :  86\n",
            "loss :  tensor([35.7740, 53.4785, 57.2753, 87.8068], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3982.8694, 5213.5254, 5055.3926, 6029.9590])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([64., 56., 89., 29.])\n",
            "*************************************************\n",
            "t :  87\n",
            "loss :  tensor([35.7753, 53.6980, 56.5361, 87.8274], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5195.4038, 5419.0410, 5055.3926, 5468.5156])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([74., 52.,  8., 33.])\n",
            "*************************************************\n",
            "t :  88\n",
            "loss :  tensor([36.0220, 53.9955, 56.5262, 87.9705], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3982.8694, 3382.5669, 5202.0801, 5040.8652])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 63., 116.,  16., 142.])\n",
            "*************************************************\n",
            "t :  89\n",
            "loss :  tensor([35.9490, 54.8054, 56.5290, 89.4564], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5449.8081, 5419.0410, 5055.3926, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 84., 108.,  11.,  86.])\n",
            "*************************************************\n",
            "t :  90\n",
            "loss :  tensor([36.4710, 54.2273, 56.5202, 88.8896], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4379.1719, 3890.6902, 5202.0801, 6423.6553])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 68., 134.,  13., 106.])\n",
            "*************************************************\n",
            "t :  91\n",
            "loss :  tensor([36.2715, 55.3411, 56.5248, 89.7259], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5523.0210, 5419.0410, 5055.3926, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([106., 115.,  10.,  64.])\n",
            "*************************************************\n",
            "t :  92\n",
            "loss :  tensor([37.6637, 54.4431, 56.5529, 89.4049], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5449.2227, 5108.6631, 5599.4731, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([161.,  31.,  37.,  29.])\n",
            "*************************************************\n",
            "t :  93\n",
            "loss :  tensor([39.1612, 54.4256, 56.6786, 89.4335], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5411.7764, 4346.9844, 6007.9644, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 86., 127., 106.,  35.])\n",
            "*************************************************\n",
            "t :  94\n",
            "loss :  tensor([39.0137, 55.6142, 57.4950, 89.4127], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([4089.9229, 5019.9370, 5202.0801, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 66., 110.,  50.,  26.])\n",
            "*************************************************\n",
            "t :  95\n",
            "loss :  tensor([39.1404, 54.7779, 57.2326, 89.4210], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5411.7764, 5108.6631, 5599.4731, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([84., 10., 31., 33.])\n",
            "*************************************************\n",
            "t :  96\n",
            "loss :  tensor([39.3585, 54.7737, 57.3370, 89.4396], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3943.1123, 5019.9370, 3477.0913, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 72.,  11., 103.,  27.])\n",
            "*************************************************\n",
            "t :  97\n",
            "loss :  tensor([39.3682, 54.7773, 58.5872, 89.4160], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5157.5010, 5108.6631, 6580.7925, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 77.,   9., 146.,  33.])\n",
            "*************************************************\n",
            "t :  98\n",
            "loss :  tensor([39.5434, 54.7722, 58.1241, 89.4638], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([3944.8264, 5108.6631, 3477.0913, 5616.1987])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([ 64.,   3., 109.,  27.])\n",
            "*************************************************\n",
            "t :  99\n",
            "loss :  tensor([39.5305, 54.7976, 59.0839, 89.4109], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([5459.3418, 6015.5127, 6705.0693, 6015.5127])\n",
            "torch.abs(perturbation).sum(dim=-1) :  tensor([109.,  54., 122.,  34.])\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([-0., -0., -0., -0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(mals.to(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEoslyYCgMGz",
        "outputId": "d04ed703-35d1-44fa-bb55-49938c576154"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-19.8462,  21.1819],\n",
              "        [-42.3733,  44.2564],\n",
              "        [-28.2794,  29.8791],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae5b959-4e97-4951-b33a-61273d8abefb",
        "id": "dWT1KrbOaMBq"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-11.4985,  13.8264],\n",
              "        [-21.6522,  25.6011],\n",
              "        [-25.6268,  30.0696],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db86cec1-1e40-4af0-bedf-da009aefd427",
        "id": "klQwgaJnaMBr"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-15.0647,  16.9694],\n",
              "        [-21.0841,  23.9766],\n",
              "        [-19.3803,  23.2305],\n",
              "        [-35.6905,  40.3540]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#comparing two attacks:\n",
        "loss based on the goal's class and minimize the loss\n",
        "\n",
        " 1: without loss of rbf\n",
        "\n",
        " 2: with loss of rbf"
      ],
      "metadata": {
        "id": "geawDEM_iAMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yKLI-D28imiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `l1 attack`"
      ],
      "metadata": {
        "id": "oLk4eeuvkfUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adv = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 0, insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766de510-fcb0-44ef-c425-75cf660f96b2",
        "id": "StYrbgUgkduu"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "t :  0\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10107.7500,  9719.9551,  9792.7520,  9011.1484])\n",
            "max_grad tensor([[5.9220],\n",
            "        [4.4970],\n",
            "        [2.4442],\n",
            "        [5.5750]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  1\n",
            "ce:  tensor([ 17.2574,  71.0176,  53.6272, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.1610, 6.9179, 7.9014, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 17.2574,  71.0176,  53.6272, 164.5218], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([10475.5771,  8753.7480,  9374.5732,  9018.6055])\n",
            "max_grad tensor([[6.1256],\n",
            "        [3.5946],\n",
            "        [2.1932],\n",
            "        [2.4330]], dtype=torch.float64)\n",
            "ce:  tensor([ 17.2574,  71.0176,  53.6272, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.1610, 6.9179, 7.9014, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  2\n",
            "ce:  tensor([3.3616e-05, 5.5429e+01, 4.4622e+01, 1.5478e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.3994, 8.0200, 3.4887], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 5.5429e+01, 4.4622e+01, 1.5478e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1265e+03, 1.0463e+04, 9.0235e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.0219e+00],\n",
            "        [2.3581e+00],\n",
            "        [1.5561e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 5.5429e+01, 4.4622e+01, 1.5478e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.3994, 8.0200, 3.4887], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  3\n",
            "ce:  tensor([3.3616e-05, 4.2018e+01, 3.5233e+01, 1.4863e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.9749, 8.1421, 3.4971], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 4.2018e+01, 3.5233e+01, 1.4863e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.5316e+03, 1.0955e+04, 8.8765e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.9064e+00],\n",
            "        [2.3421e+00],\n",
            "        [1.6096e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 4.2018e+01, 3.5233e+01, 1.4863e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.9749, 8.1421, 3.4971], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  4\n",
            "ce:  tensor([3.3616e-05, 3.0319e+01, 2.5832e+01, 1.4469e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.5596, 8.2675, 3.5144], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 3.0319e+01, 2.5832e+01, 1.4469e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.3921e+03, 1.0962e+04, 8.4613e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.7028e+00],\n",
            "        [2.1177e+00],\n",
            "        [1.6392e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 3.0319e+01, 2.5832e+01, 1.4469e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.5596, 8.2675, 3.5144], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  5\n",
            "ce:  tensor([3.3616e-05, 1.9540e+01, 1.7143e+01, 1.3839e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.0290, 8.3965, 3.3179], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 1.9540e+01, 1.7143e+01, 1.3839e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 9.1422e+03, 1.1507e+04, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.4242e+00],\n",
            "        [2.0476e+00],\n",
            "        [1.2280e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 1.9540e+01, 1.7143e+01, 1.3839e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 6.0290, 8.3965, 3.3179], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  6\n",
            "ce:  tensor([3.3616e-05, 1.2214e+01, 8.8525e+00, 1.3348e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 4.4829, 8.5291, 3.3215], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 1.2214e+01, 8.8525e+00, 1.3348e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([1.0299e+01, 5.0068e-06, 1.4304e-04, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 8.7310e+03, 1.1474e+04, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.1735e+00],\n",
            "        [1.9154e+00],\n",
            "        [1.2060e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 1.2214e+01, 8.8525e+00, 1.3348e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 4.4829, 8.5291, 3.3215], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  7\n",
            "ce:  tensor([3.3616e-05, 4.0993e+00, 1.3330e+00, 1.2865e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 4.2261, 8.6654, 3.3252], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 4.0993e+00, 1.3330e+00, 1.2865e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  0.0167,  0.3061, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 7.7917e+03, 9.0294e+03, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [2.1753e+00],\n",
            "        [5.2700e-01],\n",
            "        [1.1217e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 4.0993e+00, 1.3330e+00, 1.2865e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 4.2261, 8.6654, 3.3252], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  8\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.2417e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3290], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.2417e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3465e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.1173e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.2417e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3290], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  9\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1939e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3727], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1939e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.1097e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1939e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3727], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  10\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1495e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3381], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1495e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0670e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1495e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3381], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  11\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1068e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3422], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1068e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3130e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0610e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.1068e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3422], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  12\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0643e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3187], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0643e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0143e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0643e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3187], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  13\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0237e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3662], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0237e+02],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.0043e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 1.0237e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.3662], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  14\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.8351e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4699], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.8351e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [9.9714e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.8351e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4699], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  15\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.4362e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4776], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.4362e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3388e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [9.3243e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.4362e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4776], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  16\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.0639e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6308], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.0639e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3357e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.5881e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 9.0639e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6308], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  17\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.7156e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6984], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.7156e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.0538e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.7156e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6984], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  18\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.3935e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.7126], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.3935e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3143e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.9628e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.3935e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.7126], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  19\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.0755e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6848], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.0755e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.9117e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 8.0755e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6848], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  20\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.7752e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4857], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.7752e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8621e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.1519e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.7752e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4857], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  21\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.4700e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4939], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.4700e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.8368e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.4700e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4939], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  22\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.1965e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.5023], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.1965e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3092e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5682e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 7.1965e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.5023], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  23\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.9337e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4632], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.9337e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.3132e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5225e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.9337e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4632], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  24\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.7578e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6252], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.7578e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8157e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.9891e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.7578e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.6252], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  25\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.4789e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.8672], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.4789e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8228e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.8515e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.4789e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.8672], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  26\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2163e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.8861], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2163e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2845e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.5524e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2163e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.8861], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  27\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2409e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4148], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2409e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7232e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [7.0716e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 6.2409e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4148], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  28\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.9668e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4012], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.9668e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.8201e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.7152e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.9668e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.4012], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  29\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.7031e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.2164], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.7031e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.7293e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.2330e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.7031e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.2164], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  30\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.4995e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0216], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.4995e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.2633e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.1782e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.4995e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0216], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  31\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.2756e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.9558], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.2756e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5679e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.9095e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.2756e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.9558], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  32\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.0393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.9026], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.0393e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.6147e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 5.0393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.9026], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  33\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.8147e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.8468], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.8147e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.5643e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.5578e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.8147e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.8468], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  34\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.7072e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0203], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.7072e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0702e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4725e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.7072e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0203], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  35\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.4889e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0155], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.4889e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4381e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.4889e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0155], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  36\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.2713e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0723], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.2713e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4263e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.2713e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.0723], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  37\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.0543e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.1250], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.0543e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 8.0619e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.4237e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 4.0543e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 3.1250], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  38\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.8393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5892], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.8393e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9781e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.9568e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.8393e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5892], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  39\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.6430e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5361], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.6430e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.6170e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.6430e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5361], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  40\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.4583e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5183], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.4583e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.9231e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.3553e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.4583e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5183], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  41\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2908e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5225], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2908e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3707e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.3911e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2908e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5225], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  42\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2531e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.6161], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2531e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.4075e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [8.3935e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2531e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.6161], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  43\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2872e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4479], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2872e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.4608e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [1.5223e+00]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2872e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4479], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  44\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2053e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.2608], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2053e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.8152e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.3077e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2053e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.2608], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  45\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.0267], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 7.3166e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [6.0705e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.0925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.0267], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  46\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.5631e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5051], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.5631e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.9829e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [5.6541e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.5631e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.5051], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  47\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.3381e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4828], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.3381e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 5.8933e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.8362e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.3381e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4828], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  48\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1606e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4941], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1606e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 4.9637e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.9100e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.1606e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.4941], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  49\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2428e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.6191], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2428e+01],\n",
            "       grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([10.2994,  3.8019,  2.1209, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([2.9870e-01, 1.5448e+02, 1.5112e+03, 6.7787e+03])\n",
            "max_grad tensor([[5.5941e-05],\n",
            "        [3.2769e-02],\n",
            "        [7.1873e-02],\n",
            "        [4.0003e-01]], dtype=torch.float64)\n",
            "ce:  tensor([3.3616e-05, 2.2582e-02, 1.2775e-01, 3.2428e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([3.5999, 2.8008, 6.3960, 2.6191], grad_fn=<NllLossBackward0>)\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([10.2994,  3.8019,  2.1209, -0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv2 = gkde(mals.to(torch.float32), mals_y, model_AT_rFGSM, 10., insertion_array, removal_array, k=50, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFusQbf2knJA",
        "outputId": "8b054b13-4290-44f3-feba-b236547e35f9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "t :  0\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 86.8272, 160.0354, 131.3113, 225.5053], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12908.3301, 12200.0391, 12128.9160,  9213.8662])\n",
            "max_grad tensor([[8.5023],\n",
            "        [7.3571],\n",
            "        [7.0327],\n",
            "        [6.2066]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.0281,  86.6297,  58.1584, 186.8452], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([4.5799, 7.3406, 7.3153, 3.8660], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  1\n",
            "ce:  tensor([ 41.4521,  87.1468,  56.9110, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3975, 4.2835, 4.5723, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 55.4273, 129.9817, 102.6341, 200.4092], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([12014.8213, 12182.2734, 12070.9980,  9225.7969])\n",
            "max_grad tensor([[7.1064],\n",
            "        [7.1157],\n",
            "        [6.5516],\n",
            "        [2.6466]], dtype=torch.float64)\n",
            "ce:  tensor([ 41.4521,  87.1468,  56.9110, 164.5218], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([1.3975, 4.2835, 4.5723, 3.5887], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  2\n",
            "ce:  tensor([ 17.9860,  86.5490,  57.6814, 154.7815], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.9643, 1.6738, 1.9881, 3.4887], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 27.6292, 103.2873,  77.5623, 189.6684], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([11407.0674, 10388.8174, 11772.3848,  9236.5176])\n",
            "max_grad tensor([[6.7228],\n",
            "        [5.4520],\n",
            "        [4.8363],\n",
            "        [1.7776]], dtype=torch.float64)\n",
            "ce:  tensor([ 17.9860,  86.5490,  57.6814, 154.7815], grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.9643, 1.6738, 1.9881, 3.4887], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  3\n",
            "ce:  tensor([1.9203e-04, 7.9864e+01, 5.9809e+01, 1.5008e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.7019, 0.4528, 3.2918], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  86.8821,  64.3365, 183.0031], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739, 10865.0176, 10639.5020,  9121.3682])\n",
            "max_grad tensor([[4.2258],\n",
            "        [5.3384],\n",
            "        [2.4349],\n",
            "        [1.5102]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.9864e+01, 5.9809e+01, 1.5008e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.7019, 0.4528, 3.2918], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  4\n",
            "ce:  tensor([1.9203e-04, 6.2046e+01, 5.0805e+01, 1.4397e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.4414, 0.4125, 3.3144], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  66.4602,  54.9296, 177.1118], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739, 10118.6143, 10764.6777,  8560.1807])\n",
            "max_grad tensor([[4.2258],\n",
            "        [4.1851],\n",
            "        [2.4314],\n",
            "        [1.3745]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 6.2046e+01, 5.0805e+01, 1.4397e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.4414, 0.4125, 3.3144], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  5\n",
            "ce:  tensor([1.9203e-04, 4.8027e+01, 4.1444e+01, 1.3839e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.2649, 0.3742, 3.3179], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  50.6758,  45.1854, 171.5689], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739,  8729.1289, 11453.9707,  8566.5918])\n",
            "max_grad tensor([[4.2258],\n",
            "        [3.6175],\n",
            "        [2.4504],\n",
            "        [1.3673]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 4.8027e+01, 4.1444e+01, 1.3839e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.2649, 0.3742, 3.3179], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  6\n",
            "ce:  tensor([1.9203e-04, 3.4261e+01, 3.2356e+01, 1.3609e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.1354, 0.3379, 3.0051], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  35.6157,  35.7354, 166.1406], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739,  8880.4951, 11617.9658,  8547.9941])\n",
            "max_grad tensor([[4.2258],\n",
            "        [2.6689],\n",
            "        [2.1945],\n",
            "        [1.3411]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 3.4261e+01, 3.2356e+01, 1.3609e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.1354, 0.3379, 3.0051], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  7\n",
            "ce:  tensor([1.9203e-04, 2.1081e+01, 2.4095e+01, 1.3618e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.2683, 0.3038, 2.7243], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  23.7635,  27.1331, 163.4186], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, -0.0000, -0.0000, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739,  8800.2656, 12710.7617,  9223.3057])\n",
            "max_grad tensor([[4.2258],\n",
            "        [3.1691],\n",
            "        [2.2486],\n",
            "        [1.3826]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 2.1081e+01, 2.4095e+01, 1.3618e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.2683, 0.3038, 2.7243], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  8\n",
            "ce:  tensor([1.9203e-04, 1.4233e+01, 1.6045e+01, 1.3089e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0697, 0.2718, 2.7116], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,  14.9304,  18.7637, 158.0015], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580e+00, 7.1526e-07, 1.1921e-07, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739, 10373.1660, 12401.0254,  9229.3447])\n",
            "max_grad tensor([[4.2258],\n",
            "        [2.3994],\n",
            "        [2.1282],\n",
            "        [1.3747]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 1.4233e+01, 1.6045e+01, 1.3089e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0697, 0.2718, 2.7116], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  9\n",
            "ce:  tensor([1.9203e-04, 4.6814e+00, 1.0333e+01, 1.2546e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0454, 0.5256, 2.7353], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   5.1358,  15.5891, 152.8183], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580e+00, 9.3090e-03, 3.2544e-05, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739, 10979.6123, 12873.6641,  9091.2939])\n",
            "max_grad tensor([[4.2258],\n",
            "        [2.3688],\n",
            "        [2.6915],\n",
            "        [1.3345]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 4.6814e+00, 1.0333e+01, 1.2546e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0454, 0.5256, 2.7353], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  10\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 7.6136e+00, 1.2071e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0991, 2.6874], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   8.6045, 147.5829], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580e+00, 2.6260e+00, 4.9388e-04, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([ 1965.8739,   661.5317, 12247.4385,  9097.2891])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [2.1425],\n",
            "        [1.2964]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 7.6136e+00, 1.2071e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0991, 2.6874], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  11\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.1578e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6737], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 142.5204], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9103.9688])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.2958]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.1578e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6737], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  12\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.1087e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6597], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 137.4640], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9110.8145])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.1863]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.1087e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6597], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  13\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.0665e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6198], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 132.8436], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9117.3154])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.1831]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.0665e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6198], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  14\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.0221e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6043], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 128.2520], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9124.4805])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.1707]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 1.0221e+02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6043], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  15\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.7830e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.5884], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 123.7139], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9131.8252])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.0918]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.7830e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.5884], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  16\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.3521e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6157], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 119.6780], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8588.1836])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.2655]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.3521e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.6157], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  17\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.1365e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.4424], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 115.7887], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9135.9082])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.0871]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 9.1365e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.4424], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  18\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.9925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.1811], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 111.7360], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9121.8750])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.0303]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.9925e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.1811], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  19\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.8814e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.0203], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 109.0167], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8563.9902])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.0201]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.8814e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 2.0203], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  20\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.5636e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9583], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 105.2195], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8568.7129])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9569]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.5636e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9583], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  21\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.2430e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9264], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([  6.6569,   0.3645,   1.5372, 101.6943], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8575.0547])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9320]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 8.2430e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9264], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  22\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.8871e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9900], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 98.7701], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9131.4150])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.0242]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.8871e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9900], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  23\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.6566e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.8849], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 95.4143], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8572.6279])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9235]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.6566e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.8849], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  24\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.3045e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9006], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 92.0508], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8581.0137])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9134]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.3045e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.9006], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  25\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.2464e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.7219], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 89.6827], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9119.9883])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9981]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 7.2464e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.7219], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  26\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.9192e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.6850], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 86.0426], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 9125.4658])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9705]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.9192e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.6850], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  27\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.7232e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.5767], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 82.9992], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8569.7734])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.9360]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.7232e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.5767], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  28\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.4604e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.5027], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 79.6307], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8571.8086])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8958]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.4604e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.5027], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  29\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.2166e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.4273], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 76.4389], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8556.7588])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8916]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 6.2166e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.4273], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  30\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.9423e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.3855], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 73.2773], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8577.0488])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8791]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.9423e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.3855], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  31\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.7096e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.3079], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 70.1752], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8560.6260])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8608]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.7096e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.3079], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  32\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.4513e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.2645], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 67.1589], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8527.3770])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8200]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.4513e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.2645], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  33\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.3965e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0531], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 64.4957], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8416.9258])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.8108]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.3965e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0531], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  34\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.0362e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.1371], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 61.7334], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8450.8652])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.7912]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 5.0362e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.1371], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  35\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.8327e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0679], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 59.0064], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8448.2432])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.7668]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.8327e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0679], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  36\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.6152e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0229], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 56.3809], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8448.8584])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.7456]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.6152e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 1.0229], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  37\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.4948e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8923], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 53.8713], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8432.8682])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.7037]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.4948e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8923], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  38\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.2691e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8890], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 51.5804], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8299.4023])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.6915]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.2691e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8890], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  39\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.0818e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8441], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 49.2588], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8297.8564])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.6774]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 4.0818e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8441], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  40\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.8648e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8345], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 46.9931], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 8302.4336])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.6734]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.8648e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.8345], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  41\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.7644e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.7642], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 45.2861], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7642.4419])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.7589]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.7644e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.7642], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  42\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.6973e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5917], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 42.8901], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7598.0254])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.5627]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.6973e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5917], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  43\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.5412e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5827], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 41.2390], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 6500.8940])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [1.3753]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.5412e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5827], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  44\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.5958e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4696], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 40.6546], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7486.9814])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.5302]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.5958e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4696], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  45\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.4653e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4313], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 38.9664], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7339.8442])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.5103]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.4653e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4313], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  46\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.3331e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.3959], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 37.2902], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7332.8423])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.5061]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.3331e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.3959], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  47\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.1061e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4593], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 35.6540], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7461.6235])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.4935]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 3.1061e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4593], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  48\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 2.8772e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5376], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 34.1481], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7453.0757])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.5048]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 2.8772e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.5376], grad_fn=<NllLossBackward0>)\n",
            "*************************************************\n",
            "t :  49\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 2.8271e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4409], grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([ 6.6569,  0.3645,  1.5372, 32.6800], grad_fn=<AddBackward0>)\n",
            "loss_natural :  tensor([8.5580, 2.6260, 0.6986, -0.0000], grad_fn=<NllLossBackward0>)\n",
            "torch.abs(gradients).sum() :  tensor([1965.8739,  661.5317, 5917.1641, 7262.8149])\n",
            "max_grad tensor([[4.2258],\n",
            "        [0.2255],\n",
            "        [0.6505],\n",
            "        [0.4678]], dtype=torch.float64)\n",
            "ce:  tensor([1.9203e-04, 7.5117e-02, 6.8769e-01, 2.8271e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde :  tensor([0.6657, 0.0289, 0.0850, 0.4409], grad_fn=<NllLossBackward0>)\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "loss_natural :  tensor([-0., -0., -0., -0.], grad_fn=<NllLossBackward0>)\n",
            "loss_adv :  tensor([8.5580, 2.6260, 0.6986, -0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(mals.to(torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eddd6c51-a5dd-4ae9-e2fe-9a94b3cde0f1",
        "id": "gkdO0Dcakduv"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-19.8462,  21.1819],\n",
              "        [-42.3733,  44.2564],\n",
              "        [-28.2794,  29.8791],\n",
              "        [-90.6743,  96.1709]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2709d5-9c2b-4f2b-d0de-3c0f44d9bbe7",
        "id": "Np2bbEr6kduv"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.8403,  -5.4591],\n",
              "        [  1.5538,  -2.2255],\n",
              "        [  0.8769,  -1.1162],\n",
              "        [-14.3782,  16.4776]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_AT_rFGSM(adv2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0b0ae3-b889-4a42-f741-237c5f8f9c2c",
        "id": "5CyX9TnQkduv"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  4.0159,  -4.5420],\n",
              "        [  1.0198,  -1.5311],\n",
              "        [ -0.0686,  -0.0795],\n",
              "        [-12.8020,  14.3310]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}