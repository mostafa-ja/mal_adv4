{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYlxaZ9F0J4dxsjGPrs1Hw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv4/blob/main/RBF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "download_links = ['https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py'\n",
        "]"
      ],
      "metadata": {
        "id": "1IW4pHac9VLq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kzSbjaXGVeG",
        "outputId": "830deb0e-544d-4b3b-cabd-a76583a06298"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz\n",
            "To: /content/sparse_matrix_0.npz\n",
            "100%|██████████| 461k/461k [00:00<00:00, 8.43MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz\n",
            "To: /content/sparse_matrix_1.npz\n",
            "100%|██████████| 148k/148k [00:00<00:00, 5.32MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz\n",
            "To: /content/sparse_matrix_2.npz\n",
            "100%|██████████| 150k/150k [00:00<00:00, 5.40MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz\n",
            "To: /content/sparse_matrix_y0.npz\n",
            "100%|██████████| 5.79k/5.79k [00:00<00:00, 7.49MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz\n",
            "To: /content/sparse_matrix_y1.npz\n",
            "100%|██████████| 2.64k/2.64k [00:00<00:00, 3.92MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz\n",
            "To: /content/sparse_matrix_y2.npz\n",
            "100%|██████████| 2.71k/2.71k [00:00<00:00, 10.0MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth\n",
            "To: /content/model_DNN_drebin_best.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 23.5MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth\n",
            "To: /content/model_AT_rFGSM_weightedLoss.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 28.5MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth\n",
            "To: /content/model_AT_rFGSM.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 23.1MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl\n",
            "To: /content/insertion_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 3.56MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl\n",
            "To: /content/removal_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 3.75MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py\n",
            "To: /content/adverserial_attacks_functions.py\n",
            "67.1kB [00:00, 49.7MB/s]                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,balanced_accuracy_score\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "from adverserial_attacks_functions import *\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19fd5e6-272b-44af-e029-ea3755e264c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7dcf090cff10>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the .pkl file\n",
        "with open('/content/insertion_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    insertion_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "insertion_array = torch.tensor(insertion_array).to(device)\n",
        "print(len(insertion_array))\n",
        "\n",
        "# Open the .pkl file\n",
        "with open('/content/removal_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    removal_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "removal_array = torch.tensor(removal_array).to(device)\n",
        "print(len(removal_array))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXV0WIjsJG_F",
        "outputId": "bc60c057-007f-4412-af59-69aee8fa9331"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load dataset\n",
        "X_train = sparse.load_npz(\"/content/sparse_matrix_0.npz\").toarray()\n",
        "X_val = sparse.load_npz(\"/content/sparse_matrix_1.npz\").toarray()\n",
        "X_test = sparse.load_npz(\"/content/sparse_matrix_2.npz\").toarray()\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.int8)\n",
        "X_val = torch.tensor(X_val, dtype=torch.int8)\n",
        "X_test = torch.tensor(X_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "y_train = sparse.load_npz(\"/content/sparse_matrix_y0.npz\").toarray().reshape((-1, 1))\n",
        "y_val = sparse.load_npz(\"/content/sparse_matrix_y1.npz\").toarray().reshape((-1, 1))\n",
        "y_test = sparse.load_npz(\"/content/sparse_matrix_y2.npz\").toarray().reshape((-1, 1))\n",
        "\n",
        "y_train = torch.tensor(y_train, dtype=torch.int8)\n",
        "y_val = torch.tensor(y_val, dtype=torch.int8)\n",
        "y_test = torch.tensor(y_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"x_train:\", X_train.shape)\n",
        "print(\"x_val:\", X_val.shape)\n",
        "print(\"x_test:\", X_test.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"y_val:\", y_val.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5blmEg4h-GKy",
        "outputId": "8edcec9f-8b53-4c0a-becf-07361eebbfaf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:\n",
            "x_train: torch.Size([28683, 10000])\n",
            "x_val: torch.Size([9562, 10000])\n",
            "x_test: torch.Size([9562, 10000])\n",
            "y_train: torch.Size([28683, 1])\n",
            "y_val: torch.Size([9562, 1])\n",
            "y_test: torch.Size([9562, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of benigns and malicious sample in training dataset\n",
        "n_ben = (y_train.squeeze()== 0).sum().item()\n",
        "n_mal = (y_train.squeeze()== 1).sum().item()\n",
        "print('the proportion of malwares : ', n_mal/(n_mal+n_ben))\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del train_dataset, val_dataset, test_dataset, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81AZSXOV-HoW",
        "outputId": "47abcb85-bf8b-4d99-86a2-7b83d6873610"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the proportion of malwares :  0.11386535578565701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN = MalwareDetectionModel().to(device)\n",
        "# Load model parameters\n",
        "model_DNN.load_state_dict(torch.load('model_DNN_drebin_best.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "id": "0MavlKAt6mb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0016e836-6f3c-4fe2-8b79-a1c60d817165"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM.load_state_dict(torch.load('model_AT_rFGSM.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE8WMAUgSCms",
        "outputId": "18d02ae3-b6ba-4709-8646-b2cc00d8a60e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM_weightedLoss = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM_weightedLoss.load_state_dict(torch.load('model_AT_rFGSM_weightedLoss.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGs5E9_2SDbJ",
        "outputId": "709b949a-a4e0-4fb6-d525-a9e9e46c0035"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Function to initialize centers and sigmas separately for benign and malware samples using KMeans clustering\n",
        "def initialize_centers_sigmas_separate(data_loader, num_centers_per_class, removal_array = removal_array, non_removal_features = False):\n",
        "    centers_benign = []\n",
        "    centers_malware = []\n",
        "    non_removal_mask = torch.logical_not(removal_array).to('cpu')\n",
        "\n",
        "    # Collect data into a single tensor\n",
        "    all_data = torch.cat([batch for batch, _ in data_loader], dim=0)\n",
        "    if non_removal_features:\n",
        "        all_data = all_data[:,non_removal_mask]\n",
        "\n",
        "    all_data = all_data.numpy()\n",
        "    # Collect labels into a single tensor\n",
        "    all_labels = torch.cat([labels for _, labels in data_loader], dim=0)\n",
        "    all_labels = all_labels.numpy()\n",
        "\n",
        "    # Separate benign and malware samples\n",
        "    benign_indices = np.where(all_labels == 0)[0]\n",
        "    malware_indices = np.where(all_labels == 1)[0]\n",
        "\n",
        "    # Clustering for benign samples\n",
        "    benigns = all_data[benign_indices]\n",
        "    if non_removal_features:\n",
        "        subset_benigns = benigns\n",
        "    else:\n",
        "        subset_benigns = benigns[:20000]\n",
        "\n",
        "    kmeans_benign = KMeans(n_clusters=num_centers_per_class, init='k-means++', n_init='auto')\n",
        "    kmeans_benign.fit(subset_benigns)\n",
        "    centers_selected_benign = kmeans_benign.cluster_centers_\n",
        "\n",
        "    # Clustering for malware samples\n",
        "    kmeans_malware = KMeans(n_clusters=num_centers_per_class, init='k-means++', n_init='auto')\n",
        "    kmeans_malware.fit(all_data[malware_indices])\n",
        "    centers_selected_malware = kmeans_malware.cluster_centers_\n",
        "\n",
        "    # Combine selected centers\n",
        "    all_centers = np.concatenate([centers_selected_benign, centers_selected_malware], axis=0)\n",
        "\n",
        "    # Calculate sigma based on the average distance between centers\n",
        "    total_distance = 0.0\n",
        "    num_pairs = 0\n",
        "\n",
        "    # Calculate pairwise distances between centers for benign samples\n",
        "    for i in range(len(centers_selected_benign)):\n",
        "        for j in range(i + 1, len(centers_selected_benign)):\n",
        "            distance_ij = np.sqrt(((centers_selected_benign[i] - centers_selected_benign[j]) ** 2).sum())\n",
        "            total_distance += distance_ij\n",
        "            num_pairs += 1\n",
        "\n",
        "    # Calculate pairwise distances between centers for malware samples\n",
        "    for i in range(len(centers_selected_malware)):\n",
        "        for j in range(i + 1, len(centers_selected_malware)):\n",
        "            distance_ij = np.sqrt(((centers_selected_malware[i] - centers_selected_malware[j]) ** 2).sum())\n",
        "            total_distance += distance_ij\n",
        "            num_pairs += 1\n",
        "\n",
        "    # Calculate mean sigma\n",
        "\n",
        "    sigma = total_distance / num_pairs\n",
        "\n",
        "    return all_centers, sigma\n"
      ],
      "metadata": {
        "id": "vh2VQ93Od2vL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_centers, sigma = initialize_centers_sigmas_separate(train_loader, 500)"
      ],
      "metadata": {
        "id": "AQEr5VdJ4Upt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAHioaOp6rIS",
        "outputId": "fad54326-e63f-4e88-ee07-cd9284e98d77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.325346210357184"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_centers.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Uz_cJ926sv2",
        "outputId": "9bad2139-fe62-432a-dd6f-fcfd54d9a1cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the array to a file\n",
        "np.save('all_centers.npy', all_centers)"
      ],
      "metadata": {
        "id": "oSnXMB926oVh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_centers_non_removal_features, sigma_non_removal_features = initialize_centers_sigmas_separate(train_loader, 500, removal_array = removal_array, non_removal_features = True)"
      ],
      "metadata": {
        "id": "V6p9knzUXngT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_centers_non_removal_features.shape)\n",
        "print(sigma_non_removal_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eshb64sLZ7nr",
        "outputId": "8dd03ae3-36ee-4d41-a08e-6bb6802d5bb5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 1144)\n",
            "3.967844595954441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_centers_non_removal_features[0][:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_zhMZhOaAyZ",
        "outputId": "4023e63d-70f9-4ac5-b67e-e4c1d89cede1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.76190476e-02, -5.55111512e-17,  4.76190476e-02, -4.16333634e-17,\n",
              "        4.76190476e-02,  0.00000000e+00, -1.38777878e-17, -6.93889390e-18,\n",
              "        9.52380952e-02, -5.55111512e-17,  4.76190476e-02, -2.77555756e-17,\n",
              "       -1.38777878e-17,  8.09523810e-01, -6.93889390e-18,  0.00000000e+00,\n",
              "        0.00000000e+00,  2.08166817e-17,  1.42857143e-01,  1.04083409e-17])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the array to a file\n",
        "np.save('all_centers_non_removal_features.npy', all_centers_non_removal_features)"
      ],
      "metadata": {
        "id": "4p_gIe72abKJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the array from the file\n",
        "all_centers = np.load('all_centers.npy')\n",
        "\n",
        "sigma = 6.281732838681898"
      ],
      "metadata": {
        "id": "Ss6Qdd-H6otO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move all_centers back to GPU\n",
        "all_centers = torch.tensor(all_centers, device=device)"
      ],
      "metadata": {
        "id": "5llZpwJP3ZsP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_centers_non_removal_features = torch.tensor(all_centers_non_removal_features, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0ozBK-hajKm",
        "outputId": "d517c2e3-0085-47b3-f835-2308ba26fcee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-b585ae409818>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  all_centers_non_removal_features = torch.tensor(all_centers_non_removal_features, device=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Define the RBF model\n",
        "class RBFModel(nn.Module):\n",
        "    def __init__(self, hidden_dim, output_dim, init_centers, init_sigmas):\n",
        "        super(RBFModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.centers = nn.Parameter(torch.Tensor(init_centers))\n",
        "        self.sigmas = nn.Parameter(torch.Tensor(init_sigmas))\n",
        "\n",
        "        # Linear layer for output\n",
        "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def gaussian(self, x, c, sigma):\n",
        "        return torch.exp(-torch.sum((x[:, None, :] - c) ** 2, dim=-1) / (2 * sigma ** 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        radial_out = self.gaussian(x, self.centers, self.sigmas)\n",
        "        output = self.linear(radial_out.to(torch.float32))\n",
        "        return output\n",
        "\n",
        "# Function to evaluate the model on a dataset\n",
        "def evaluate_model(model, data_loader, criterion, removal_array = removal_array, non_removal_features = False):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    non_removal_mask = torch.logical_not(removal_array).to('cpu')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in data_loader:\n",
        "            if non_removal_features:\n",
        "                batch_x, batch_y = batch_x[:,non_removal_mask].to(torch.float32).to(device), batch_y.to(device)  # Move data to GPU\n",
        "            else:\n",
        "                batch_x, batch_y = batch_x.to(torch.float32).to(device), batch_y.to(device)  # Move data to GPU\n",
        "            output = model(batch_x)\n",
        "            loss = criterion(output, batch_y.squeeze().to(torch.long))\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            correct_predictions += (predicted == batch_y.squeeze()).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    accuracy = correct_predictions / len(data_loader.dataset)\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "WHAI-VGJSGa2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this to release GPU memory\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "e1cutWXY3eza"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_removal_features = True\n",
        "non_removal_mask = torch.logical_not(removal_array).to('cpu')\n",
        "\n",
        "model = RBFModel(1000, 2, all_centers_non_removal_features, [sigma_non_removal_features])\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)  # Decrease lr by a factor of 0.95 every 1 epoch\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 30\n",
        "best_val_accuracy = 0.0\n",
        "best_model_state_dict = None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    # Print the current learning rate\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print('************************************')\n",
        "    print(f'Current Learning Rate: {current_lr}')\n",
        "\n",
        "    for i, (batch_x, batch_y) in enumerate(train_loader):\n",
        "        # Remove features based on removal_array\n",
        "        if non_removal_features:\n",
        "            batch_x = batch_x[:, non_removal_mask].to(torch.float32).to(device)  # Select features\n",
        "        else:\n",
        "            batch_x = batch_x.to(torch.float32).to(device)  # Move all features to GPU\n",
        "        batch_y = batch_y.to(device)  # Move labels to GPU\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch_x)\n",
        "        loss = criterion(output, batch_y.squeeze().to(torch.long))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        correct_predictions += (predicted == batch_y.squeeze()).sum().item()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item()}')\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = correct_predictions / len(train_loader.dataset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss}, Train Accuracy: {accuracy}')\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_loss, val_accuracy = evaluate_model(model, val_loader, criterion, removal_array = removal_array, non_removal_features=non_removal_features)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "    # Check if the current model has the best validation accuracy\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        print(f\"New best validation accuracy: {best_val_accuracy}\")\n",
        "        # Save the current best model state dict\n",
        "        best_model_state_dict = model.state_dict()\n",
        "\n",
        "# Save the best model\n",
        "if best_model_state_dict is not None:\n",
        "    torch.save(best_model_state_dict, 'best_model.pth')\n",
        "    print(\"Best model saved with validation accuracy:\", best_val_accuracy)\n",
        "else:\n",
        "    print(\"No improvement in validation accuracy.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbyx6gEWdmyq",
        "outputId": "81994a76-c94c-4281-b1ac-29cc195725c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************************\n",
            "Current Learning Rate: 0.001\n",
            "Epoch [1/30], Step [10/113], Loss: 0.48220548033714294\n",
            "Epoch [1/30], Step [20/113], Loss: 0.2858605682849884\n",
            "Epoch [1/30], Step [30/113], Loss: 0.2665095031261444\n",
            "Epoch [1/30], Step [40/113], Loss: 0.21803133189678192\n",
            "Epoch [1/30], Step [50/113], Loss: 0.22780616581439972\n",
            "Epoch [1/30], Step [60/113], Loss: 0.16350334882736206\n",
            "Epoch [1/30], Step [70/113], Loss: 0.31015217304229736\n",
            "Epoch [1/30], Step [80/113], Loss: 0.20080940425395966\n",
            "Epoch [1/30], Step [90/113], Loss: 0.1882152557373047\n",
            "Epoch [1/30], Step [100/113], Loss: 0.19890359044075012\n",
            "Epoch [1/30], Step [110/113], Loss: 0.17353910207748413\n",
            "Epoch [1/30], Train Loss: 0.2583295907330724, Train Accuracy: 0.8975699891922044\n",
            "Epoch [1/30], Validation Loss: 0.16741640140351496, Validation Accuracy: 0.9479188454298264\n",
            "New best validation accuracy: 0.9479188454298264\n",
            "************************************\n",
            "Current Learning Rate: 0.00095\n",
            "Epoch [2/30], Step [10/113], Loss: 0.18119323253631592\n",
            "Epoch [2/30], Step [20/113], Loss: 0.1694667488336563\n",
            "Epoch [2/30], Step [30/113], Loss: 0.12798863649368286\n",
            "Epoch [2/30], Step [40/113], Loss: 0.1384599655866623\n",
            "Epoch [2/30], Step [50/113], Loss: 0.12476768344640732\n",
            "Epoch [2/30], Step [60/113], Loss: 0.16820280253887177\n",
            "Epoch [2/30], Step [70/113], Loss: 0.08598599582910538\n",
            "Epoch [2/30], Step [80/113], Loss: 0.15037018060684204\n",
            "Epoch [2/30], Step [90/113], Loss: 0.1798665076494217\n",
            "Epoch [2/30], Step [100/113], Loss: 0.1415785700082779\n",
            "Epoch [2/30], Step [110/113], Loss: 0.11319629848003387\n",
            "Epoch [2/30], Train Loss: 0.15069621221154136, Train Accuracy: 0.9522016525468048\n",
            "Epoch [2/30], Validation Loss: 0.13166025182918498, Validation Accuracy: 0.9546120058565154\n",
            "New best validation accuracy: 0.9546120058565154\n",
            "************************************\n",
            "Current Learning Rate: 0.0009025\n",
            "Epoch [3/30], Step [10/113], Loss: 0.09142100811004639\n",
            "Epoch [3/30], Step [20/113], Loss: 0.12230983376502991\n",
            "Epoch [3/30], Step [30/113], Loss: 0.09993524849414825\n",
            "Epoch [3/30], Step [40/113], Loss: 0.1252291351556778\n",
            "Epoch [3/30], Step [50/113], Loss: 0.08828909695148468\n",
            "Epoch [3/30], Step [60/113], Loss: 0.13873280584812164\n",
            "Epoch [3/30], Step [70/113], Loss: 0.12876926362514496\n",
            "Epoch [3/30], Step [80/113], Loss: 0.15336771309375763\n",
            "Epoch [3/30], Step [90/113], Loss: 0.17587339878082275\n",
            "Epoch [3/30], Step [100/113], Loss: 0.11004829406738281\n",
            "Epoch [3/30], Step [110/113], Loss: 0.12796787917613983\n",
            "Epoch [3/30], Train Loss: 0.1264542176066774, Train Accuracy: 0.9572569117595788\n",
            "Epoch [3/30], Validation Loss: 0.11920776218175888, Validation Accuracy: 0.9583769085965279\n",
            "New best validation accuracy: 0.9583769085965279\n",
            "************************************\n",
            "Current Learning Rate: 0.000857375\n",
            "Epoch [4/30], Step [10/113], Loss: 0.11204266548156738\n",
            "Epoch [4/30], Step [20/113], Loss: 0.1455632597208023\n",
            "Epoch [4/30], Step [30/113], Loss: 0.12836971879005432\n",
            "Epoch [4/30], Step [40/113], Loss: 0.11143244057893753\n",
            "Epoch [4/30], Step [50/113], Loss: 0.11080098897218704\n",
            "Epoch [4/30], Step [60/113], Loss: 0.11708809435367584\n",
            "Epoch [4/30], Step [70/113], Loss: 0.10047168284654617\n",
            "Epoch [4/30], Step [80/113], Loss: 0.1558847427368164\n",
            "Epoch [4/30], Step [90/113], Loss: 0.11660102754831314\n",
            "Epoch [4/30], Step [100/113], Loss: 0.07624153047800064\n",
            "Epoch [4/30], Step [110/113], Loss: 0.09557731449604034\n",
            "Epoch [4/30], Train Loss: 0.11805627356588314, Train Accuracy: 0.9603597950005229\n",
            "Epoch [4/30], Validation Loss: 0.11044711835290257, Validation Accuracy: 0.9610960050198704\n",
            "New best validation accuracy: 0.9610960050198704\n",
            "************************************\n",
            "Current Learning Rate: 0.0008145062499999999\n",
            "Epoch [5/30], Step [10/113], Loss: 0.08911950886249542\n",
            "Epoch [5/30], Step [20/113], Loss: 0.08571287244558334\n",
            "Epoch [5/30], Step [30/113], Loss: 0.0661659836769104\n",
            "Epoch [5/30], Step [40/113], Loss: 0.11321710050106049\n",
            "Epoch [5/30], Step [50/113], Loss: 0.13038504123687744\n",
            "Epoch [5/30], Step [60/113], Loss: 0.13455943763256073\n",
            "Epoch [5/30], Step [70/113], Loss: 0.09769242256879807\n",
            "Epoch [5/30], Step [80/113], Loss: 0.11116190254688263\n",
            "Epoch [5/30], Step [90/113], Loss: 0.09532267600297928\n",
            "Epoch [5/30], Step [100/113], Loss: 0.1104007437825203\n",
            "Epoch [5/30], Step [110/113], Loss: 0.0677119567990303\n",
            "Epoch [5/30], Train Loss: 0.11030285096669619, Train Accuracy: 0.9609524805633999\n",
            "Epoch [5/30], Validation Loss: 0.10477662508032824, Validation Accuracy: 0.9621418113365404\n",
            "New best validation accuracy: 0.9621418113365404\n",
            "************************************\n",
            "Current Learning Rate: 0.0007737809374999998\n",
            "Epoch [6/30], Step [10/113], Loss: 0.11241939663887024\n",
            "Epoch [6/30], Step [20/113], Loss: 0.06705718487501144\n",
            "Epoch [6/30], Step [30/113], Loss: 0.09647898375988007\n",
            "Epoch [6/30], Step [40/113], Loss: 0.1289810985326767\n",
            "Epoch [6/30], Step [50/113], Loss: 0.10389838367700577\n",
            "Epoch [6/30], Step [60/113], Loss: 0.10918302834033966\n",
            "Epoch [6/30], Step [70/113], Loss: 0.13200247287750244\n",
            "Epoch [6/30], Step [80/113], Loss: 0.09233031421899796\n",
            "Epoch [6/30], Step [90/113], Loss: 0.16431240737438202\n",
            "Epoch [6/30], Step [100/113], Loss: 0.09701179713010788\n",
            "Epoch [6/30], Step [110/113], Loss: 0.09511277824640274\n",
            "Epoch [6/30], Train Loss: 0.10849294379617261, Train Accuracy: 0.9609524805633999\n",
            "Epoch [6/30], Validation Loss: 0.1007119451502436, Validation Accuracy: 0.9624555532315415\n",
            "New best validation accuracy: 0.9624555532315415\n",
            "************************************\n",
            "Current Learning Rate: 0.0007350918906249997\n",
            "Epoch [7/30], Step [10/113], Loss: 0.1316673904657364\n",
            "Epoch [7/30], Step [20/113], Loss: 0.08861248195171356\n",
            "Epoch [7/30], Step [30/113], Loss: 0.08976727724075317\n",
            "Epoch [7/30], Step [40/113], Loss: 0.09276574105024338\n",
            "Epoch [7/30], Step [50/113], Loss: 0.17374254763126373\n",
            "Epoch [7/30], Step [60/113], Loss: 0.05492174252867699\n",
            "Epoch [7/30], Step [70/113], Loss: 0.10466883331537247\n",
            "Epoch [7/30], Step [80/113], Loss: 0.08709225803613663\n",
            "Epoch [7/30], Step [90/113], Loss: 0.11238014698028564\n",
            "Epoch [7/30], Step [100/113], Loss: 0.10385925322771072\n",
            "Epoch [7/30], Step [110/113], Loss: 0.12745535373687744\n",
            "Epoch [7/30], Train Loss: 0.10239142311357818, Train Accuracy: 0.9629745842485096\n",
            "Epoch [7/30], Validation Loss: 0.09757033078686188, Validation Accuracy: 0.965906714076553\n",
            "New best validation accuracy: 0.965906714076553\n",
            "************************************\n",
            "Current Learning Rate: 0.0006983372960937497\n",
            "Epoch [8/30], Step [10/113], Loss: 0.09904990345239639\n",
            "Epoch [8/30], Step [20/113], Loss: 0.11671759188175201\n",
            "Epoch [8/30], Step [30/113], Loss: 0.09907601773738861\n",
            "Epoch [8/30], Step [40/113], Loss: 0.08194399625062943\n",
            "Epoch [8/30], Step [50/113], Loss: 0.07543788105249405\n",
            "Epoch [8/30], Step [60/113], Loss: 0.10370033234357834\n",
            "Epoch [8/30], Step [70/113], Loss: 0.04737744852900505\n",
            "Epoch [8/30], Step [80/113], Loss: 0.09189651161432266\n",
            "Epoch [8/30], Step [90/113], Loss: 0.14722616970539093\n",
            "Epoch [8/30], Step [100/113], Loss: 0.09421730786561966\n",
            "Epoch [8/30], Step [110/113], Loss: 0.12037791311740875\n",
            "Epoch [8/30], Train Loss: 0.09948134819556655, Train Accuracy: 0.9644040023707422\n",
            "Epoch [8/30], Validation Loss: 0.09912228143136752, Validation Accuracy: 0.9637105208115457\n",
            "************************************\n",
            "Current Learning Rate: 0.0006634204312890621\n",
            "Epoch [9/30], Step [10/113], Loss: 0.12223280221223831\n",
            "Epoch [9/30], Step [20/113], Loss: 0.06497108191251755\n",
            "Epoch [9/30], Step [30/113], Loss: 0.07788371294736862\n",
            "Epoch [9/30], Step [40/113], Loss: 0.09388524293899536\n",
            "Epoch [9/30], Step [50/113], Loss: 0.09318850189447403\n",
            "Epoch [9/30], Step [60/113], Loss: 0.102025605738163\n",
            "Epoch [9/30], Step [70/113], Loss: 0.06590685993432999\n",
            "Epoch [9/30], Step [80/113], Loss: 0.09331908822059631\n",
            "Epoch [9/30], Step [90/113], Loss: 0.12919026613235474\n",
            "Epoch [9/30], Step [100/113], Loss: 0.066592738032341\n",
            "Epoch [9/30], Step [110/113], Loss: 0.07482987642288208\n",
            "Epoch [9/30], Train Loss: 0.09848820942297445, Train Accuracy: 0.9658334204929749\n",
            "Epoch [9/30], Validation Loss: 0.09335187891204107, Validation Accuracy: 0.9663250366032211\n",
            "New best validation accuracy: 0.9663250366032211\n",
            "************************************\n",
            "Current Learning Rate: 0.000630249409724609\n",
            "Epoch [10/30], Step [10/113], Loss: 0.0771777331829071\n",
            "Epoch [10/30], Step [20/113], Loss: 0.11179687082767487\n",
            "Epoch [10/30], Step [30/113], Loss: 0.0593130923807621\n",
            "Epoch [10/30], Step [40/113], Loss: 0.1198761910200119\n",
            "Epoch [10/30], Step [50/113], Loss: 0.060265135020017624\n",
            "Epoch [10/30], Step [60/113], Loss: 0.09648901969194412\n",
            "Epoch [10/30], Step [70/113], Loss: 0.14072185754776\n",
            "Epoch [10/30], Step [80/113], Loss: 0.08826713263988495\n",
            "Epoch [10/30], Step [90/113], Loss: 0.1176973432302475\n",
            "Epoch [10/30], Step [100/113], Loss: 0.09712260961532593\n",
            "Epoch [10/30], Step [110/113], Loss: 0.08431997150182724\n",
            "Epoch [10/30], Train Loss: 0.09493128521845931, Train Accuracy: 0.9661123313460935\n",
            "Epoch [10/30], Validation Loss: 0.09962921648433334, Validation Accuracy: 0.9642334239698808\n",
            "************************************\n",
            "Current Learning Rate: 0.0005987369392383785\n",
            "Epoch [11/30], Step [10/113], Loss: 0.11436457931995392\n",
            "Epoch [11/30], Step [20/113], Loss: 0.14172114431858063\n",
            "Epoch [11/30], Step [30/113], Loss: 0.10087192803621292\n",
            "Epoch [11/30], Step [40/113], Loss: 0.07725314795970917\n",
            "Epoch [11/30], Step [50/113], Loss: 0.09070272743701935\n",
            "Epoch [11/30], Step [60/113], Loss: 0.1000753864645958\n",
            "Epoch [11/30], Step [70/113], Loss: 0.07935971021652222\n",
            "Epoch [11/30], Step [80/113], Loss: 0.08724092692136765\n",
            "Epoch [11/30], Step [90/113], Loss: 0.1137915626168251\n",
            "Epoch [11/30], Step [100/113], Loss: 0.09675866365432739\n",
            "Epoch [11/30], Step [110/113], Loss: 0.08124478161334991\n",
            "Epoch [11/30], Train Loss: 0.09385543540779469, Train Accuracy: 0.967367430185127\n",
            "Epoch [11/30], Validation Loss: 0.09073257093366824, Validation Accuracy: 0.9714494875549048\n",
            "New best validation accuracy: 0.9714494875549048\n",
            "************************************\n",
            "Current Learning Rate: 0.0005688000922764595\n",
            "Epoch [12/30], Step [10/113], Loss: 0.042353253811597824\n",
            "Epoch [12/30], Step [20/113], Loss: 0.10174600780010223\n",
            "Epoch [12/30], Step [30/113], Loss: 0.07981032133102417\n",
            "Epoch [12/30], Step [40/113], Loss: 0.07213923335075378\n",
            "Epoch [12/30], Step [50/113], Loss: 0.0833970382809639\n",
            "Epoch [12/30], Step [60/113], Loss: 0.11520044505596161\n",
            "Epoch [12/30], Step [70/113], Loss: 0.10267622023820877\n",
            "Epoch [12/30], Step [80/113], Loss: 0.08700013905763626\n",
            "Epoch [12/30], Step [90/113], Loss: 0.05955614522099495\n",
            "Epoch [12/30], Step [100/113], Loss: 0.10429079830646515\n",
            "Epoch [12/30], Step [110/113], Loss: 0.07555496692657471\n",
            "Epoch [12/30], Train Loss: 0.09444499388337135, Train Accuracy: 0.9677857964648049\n",
            "Epoch [12/30], Validation Loss: 0.08860712851348676, Validation Accuracy: 0.9692532942898975\n",
            "************************************\n",
            "Current Learning Rate: 0.0005403600876626365\n",
            "Epoch [13/30], Step [10/113], Loss: 0.14675520360469818\n",
            "Epoch [13/30], Step [20/113], Loss: 0.09743056446313858\n",
            "Epoch [13/30], Step [30/113], Loss: 0.09839655458927155\n",
            "Epoch [13/30], Step [40/113], Loss: 0.10216408967971802\n",
            "Epoch [13/30], Step [50/113], Loss: 0.13654163479804993\n",
            "Epoch [13/30], Step [60/113], Loss: 0.07095181196928024\n",
            "Epoch [13/30], Step [70/113], Loss: 0.1259724497795105\n",
            "Epoch [13/30], Step [80/113], Loss: 0.07561389356851578\n",
            "Epoch [13/30], Step [90/113], Loss: 0.12571090459823608\n",
            "Epoch [13/30], Step [100/113], Loss: 0.0960431843996048\n",
            "Epoch [13/30], Step [110/113], Loss: 0.14897745847702026\n",
            "Epoch [13/30], Train Loss: 0.09105461826795234, Train Accuracy: 0.9689711675905589\n",
            "Epoch [13/30], Validation Loss: 0.08793960952837217, Validation Accuracy: 0.9695670361848986\n",
            "************************************\n",
            "Current Learning Rate: 0.0005133420832795047\n",
            "Epoch [14/30], Step [10/113], Loss: 0.1166563481092453\n",
            "Epoch [14/30], Step [20/113], Loss: 0.0988764762878418\n",
            "Epoch [14/30], Step [30/113], Loss: 0.08052283525466919\n",
            "Epoch [14/30], Step [40/113], Loss: 0.08781375735998154\n",
            "Epoch [14/30], Step [50/113], Loss: 0.07607507705688477\n",
            "Epoch [14/30], Step [60/113], Loss: 0.1204448938369751\n",
            "Epoch [14/30], Step [70/113], Loss: 0.06542889773845673\n",
            "Epoch [14/30], Step [80/113], Loss: 0.0753553956747055\n",
            "Epoch [14/30], Step [90/113], Loss: 0.1220937967300415\n",
            "Epoch [14/30], Step [100/113], Loss: 0.07838134467601776\n",
            "Epoch [14/30], Step [110/113], Loss: 0.03836488723754883\n",
            "Epoch [14/30], Train Loss: 0.09013446368507844, Train Accuracy: 0.9691803507303978\n",
            "Epoch [14/30], Validation Loss: 0.08757369024188895, Validation Accuracy: 0.9702991006065677\n",
            "************************************\n",
            "Current Learning Rate: 0.00048767497911552944\n",
            "Epoch [15/30], Step [10/113], Loss: 0.09254200011491776\n",
            "Epoch [15/30], Step [20/113], Loss: 0.07764289528131485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-instantiate the model\n",
        "model = RBFModel(10000, 1000, 2, all_centers, [sigma])\n",
        "\n",
        "# Load the saved model state dictionary\n",
        "model_state_dict = torch.load('best_model.pth')\n",
        "\n",
        "# Load the model state dictionary into the model\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-rclGF3LlSh",
        "outputId": "cede9801-cb25-4c07-e82a-23f455423c29"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RBFModel(\n",
              "  (linear): Linear(in_features=1000, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (batch_x, batch_y) in enumerate(train_loader):\n",
        "        batch_x, batch_y = batch_x.to(torch.float32).to(device), batch_y.to(device)\n",
        "        output = model(batch_x)\n",
        "        break"
      ],
      "metadata": {
        "id": "UxJgq6lJK_Gi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31lEhP2pMDiO",
        "outputId": "1b1b9353-b281-47d9-cabe-45a5e025f0a0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]], device='cuda:0', dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZePCnjZLFBE",
        "outputId": "f4de6f35-9e8b-45a0-c666-34e85bd79a09"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.5949, -3.7890],\n",
              "        [ 2.3963, -2.5447],\n",
              "        [ 4.7550, -4.9008],\n",
              "        [-2.0959,  1.8883],\n",
              "        [ 1.0827, -1.2903],\n",
              "        [ 4.2781, -4.4563],\n",
              "        [ 1.8530, -2.1296],\n",
              "        [ 2.4713, -2.7093],\n",
              "        [ 3.5167, -3.6290],\n",
              "        [ 3.1558, -3.3632],\n",
              "        [ 2.7086, -2.9140],\n",
              "        [ 4.2223, -4.3793],\n",
              "        [ 2.4756, -2.7242],\n",
              "        [ 5.2013, -5.3457],\n",
              "        [ 3.3582, -3.5315],\n",
              "        [ 4.8625, -5.0373],\n",
              "        [ 2.8663, -3.1130],\n",
              "        [ 2.2492, -2.4581],\n",
              "        [ 2.9067, -3.1698],\n",
              "        [ 3.5118, -3.6695],\n",
              "        [ 3.2226, -3.4617],\n",
              "        [ 1.3615, -1.5182],\n",
              "        [ 2.4652, -2.7245],\n",
              "        [ 3.8473, -4.0772],\n",
              "        [ 2.7479, -2.9086],\n",
              "        [ 4.8274, -4.9394],\n",
              "        [ 4.1073, -4.3304],\n",
              "        [ 2.5318, -2.7993],\n",
              "        [ 3.7883, -4.0139],\n",
              "        [ 3.2683, -3.5091],\n",
              "        [ 2.5497, -2.8065],\n",
              "        [ 3.9403, -4.1609]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, you can extract the trained parameters\n",
        "trained_centers = model.centers.detach().cpu().numpy()\n",
        "trained_sigmas = model.sigmas.detach().cpu().numpy()\n",
        "\n",
        "# Print or use the trained parameters\n",
        "print(\"Trained Centers:\", trained_centers)\n",
        "print(\"Trained Sigmas:\", trained_sigmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cvj498VR87gn",
        "outputId": "93c8d761-f1e9-4604-a72d-61b49eb99ce9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Centers: [[ 6.82626901e-01 -1.57842796e-01 -9.10633264e-01 ... -1.35908069e-03\n",
            "  -7.18771835e-06 -3.75721239e-07]\n",
            " [-6.69717064e-02 -1.14904760e-01 -9.74693168e-01 ... -7.95601256e-04\n",
            "  -1.61720848e-06  5.57291111e-08]\n",
            " [ 1.13970780e-01  1.01621359e-02 -8.41641331e-01 ... -1.29463659e-03\n",
            "  -5.19032333e-06 -9.45904902e-07]\n",
            " ...\n",
            " [ 3.28155071e-02 -8.84417520e-02  1.41652337e+00 ...  8.22687592e-04\n",
            "  -1.71252737e-04  1.12640569e-07]\n",
            " [-5.62768074e-02 -8.98881165e-02 -9.67118275e-01 ... -7.32456894e-04\n",
            "  -8.73512269e-06 -3.86629888e-08]\n",
            " [ 1.01287085e+00  2.35785213e-01  1.07589317e+00 ...  1.32226698e-03\n",
            "  -1.63619668e-04  2.84134646e-07]]\n",
            "Trained Sigmas: [4.9973483]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_centers.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJGskhNEM-UM",
        "outputId": "38c69ba7-7763-48c5-f050-e32ddbbd06f0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_centers[0][:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHc5HGHRMSQi",
        "outputId": "2ce1d659-c206-442f-8c6d-14c01c07a070"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6.82626901e-01, -1.57842796e-01, -9.10633264e-01,  2.37577198e-01,\n",
              "       -6.26838652e-02,  6.70036206e-01, -1.60009342e-01, -2.23739003e-01,\n",
              "        1.18476455e-01, -3.87529193e-01,  2.73201868e-02, -4.53082282e-01,\n",
              "       -4.94938135e-01,  9.96039044e-01,  4.91933296e-02,  8.45646006e-02,\n",
              "       -3.00290185e-01, -6.18974304e-02,  8.16441501e-01,  7.67651765e-01,\n",
              "        4.17308083e-01,  3.52254245e-02,  1.71979274e-01,  1.04967470e-01,\n",
              "        1.13975330e-01,  1.22958523e+00, -6.97449781e-02, -3.97829565e-01,\n",
              "        2.14242215e-01,  4.87425539e-01, -2.96133903e-01, -3.67946295e-02,\n",
              "        7.64374631e-02, -1.10759236e-01,  9.25623384e-02, -2.34933596e-01,\n",
              "        4.64434705e-01,  1.00638761e+00, -5.27856739e-01,  8.17454471e-02,\n",
              "       -2.76793184e-02,  1.77565128e-01, -3.23893320e-01, -5.36100208e-01,\n",
              "       -2.74831020e-01, -2.64936380e-01, -2.19044896e-01, -2.59677026e-01,\n",
              "       -3.90212805e-01,  2.23359263e-01,  2.52186492e-01, -2.46078962e-01,\n",
              "        7.84815601e-01, -2.45909099e-01, -4.76057581e-01, -2.29403669e-01,\n",
              "       -2.43877811e-01, -2.07786805e-01, -2.93487542e-01, -2.92132099e-01,\n",
              "       -2.92132099e-01, -2.92132099e-01, -2.92132099e-01, -1.75710201e-01,\n",
              "       -6.37137946e-02,  1.16532086e-01,  4.10407359e-01,  1.61695316e-01,\n",
              "       -2.36734832e-01, -2.76807038e-01, -1.00817390e-03, -2.35789674e-01,\n",
              "        9.22065593e-01,  1.10533786e-01,  1.43627853e-01, -7.00624959e-02,\n",
              "       -2.70299651e-01,  2.67549966e-01,  1.02795251e+00,  2.15815789e-01,\n",
              "       -1.79046458e-01, -2.65419197e-01,  8.99715689e-02,  1.05557532e+00,\n",
              "        2.60867759e-02,  3.55341875e-01, -3.18106643e-02,  4.81192107e-02,\n",
              "       -1.24726429e-01, -1.24726429e-01, -1.24726429e-01, -1.49117785e-01,\n",
              "       -7.27853148e-02, -7.21400559e-02, -4.95310067e-02,  1.89280473e-01,\n",
              "       -1.78665013e-01,  6.84531162e-01, -5.56174291e-01, -1.39422240e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9JL7fSGAMiO",
        "outputId": "ab339fb3-9a2c-4fa9-a947-21be5661a531"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}