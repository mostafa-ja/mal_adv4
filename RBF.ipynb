{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMwqC/Kd1JK2AKUXBtwN8Qz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv4/blob/main/RBF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "download_links = ['https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py'\n",
        "]"
      ],
      "metadata": {
        "id": "1IW4pHac9VLq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kzSbjaXGVeG",
        "outputId": "167c633a-013b-491a-ea98-46266861a628"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz\n",
            "To: /content/sparse_matrix_0.npz\n",
            "100%|██████████| 461k/461k [00:00<00:00, 4.35MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz\n",
            "To: /content/sparse_matrix_1.npz\n",
            "100%|██████████| 148k/148k [00:00<00:00, 2.61MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz\n",
            "To: /content/sparse_matrix_2.npz\n",
            "100%|██████████| 150k/150k [00:00<00:00, 2.27MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz\n",
            "To: /content/sparse_matrix_y0.npz\n",
            "100%|██████████| 5.79k/5.79k [00:00<00:00, 13.5MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz\n",
            "To: /content/sparse_matrix_y1.npz\n",
            "100%|██████████| 2.64k/2.64k [00:00<00:00, 8.47MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz\n",
            "To: /content/sparse_matrix_y2.npz\n",
            "100%|██████████| 2.71k/2.71k [00:00<00:00, 8.63MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth\n",
            "To: /content/model_DNN_drebin_best.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 17.5MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth\n",
            "To: /content/model_AT_rFGSM_weightedLoss.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 57.6MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth\n",
            "To: /content/model_AT_rFGSM.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 79.0MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl\n",
            "To: /content/insertion_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 4.12MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl\n",
            "To: /content/removal_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 3.76MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py\n",
            "To: /content/adverserial_attacks_functions.py\n",
            "67.1kB [00:00, 47.3MB/s]                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,balanced_accuracy_score\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "from adverserial_attacks_functions import *\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f84686d-d4a9-48f3-e8c3-59228dc8e5b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7db9157504d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the .pkl file\n",
        "with open('/content/insertion_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    insertion_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "insertion_array = torch.tensor(insertion_array).to(device)\n",
        "print(len(insertion_array))\n",
        "\n",
        "# Open the .pkl file\n",
        "with open('/content/removal_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    removal_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "removal_array = torch.tensor(removal_array).to(device)\n",
        "print(len(removal_array))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXV0WIjsJG_F",
        "outputId": "1f965468-9628-4531-87f4-09e6cdb4d672"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load dataset\n",
        "X_train = sparse.load_npz(\"/content/sparse_matrix_0.npz\").toarray()\n",
        "X_val = sparse.load_npz(\"/content/sparse_matrix_1.npz\").toarray()\n",
        "X_test = sparse.load_npz(\"/content/sparse_matrix_2.npz\").toarray()\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.int8)\n",
        "X_val = torch.tensor(X_val, dtype=torch.int8)\n",
        "X_test = torch.tensor(X_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "y_train = sparse.load_npz(\"/content/sparse_matrix_y0.npz\").toarray().reshape((-1, 1))\n",
        "y_val = sparse.load_npz(\"/content/sparse_matrix_y1.npz\").toarray().reshape((-1, 1))\n",
        "y_test = sparse.load_npz(\"/content/sparse_matrix_y2.npz\").toarray().reshape((-1, 1))\n",
        "\n",
        "y_train = torch.tensor(y_train, dtype=torch.int8)\n",
        "y_val = torch.tensor(y_val, dtype=torch.int8)\n",
        "y_test = torch.tensor(y_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"x_train:\", X_train.shape)\n",
        "print(\"x_val:\", X_val.shape)\n",
        "print(\"x_test:\", X_test.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"y_val:\", y_val.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5blmEg4h-GKy",
        "outputId": "a6892267-ce91-40da-c4c7-70f85ff1cc6e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:\n",
            "x_train: torch.Size([28683, 10000])\n",
            "x_val: torch.Size([9562, 10000])\n",
            "x_test: torch.Size([9562, 10000])\n",
            "y_train: torch.Size([28683, 1])\n",
            "y_val: torch.Size([9562, 1])\n",
            "y_test: torch.Size([9562, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of benigns and malicious sample in training dataset\n",
        "n_ben = (y_train.squeeze()== 0).sum().item()\n",
        "n_mal = (y_train.squeeze()== 1).sum().item()\n",
        "print('the proportion of malwares : ', n_mal/(n_mal+n_ben))\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del train_dataset, val_dataset, test_dataset, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81AZSXOV-HoW",
        "outputId": "c9e931b1-30a6-4389-ca18-2c57ee754b86"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the proportion of malwares :  0.11386535578565701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN = MalwareDetectionModel().to(device)\n",
        "# Load model parameters\n",
        "model_DNN.load_state_dict(torch.load('model_DNN_drebin_best.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "id": "0MavlKAt6mb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6225056-a5ee-4cac-b3bb-2e71413f6b52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM.load_state_dict(torch.load('model_AT_rFGSM.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE8WMAUgSCms",
        "outputId": "a5f1f7a0-6c99-4d4d-b6eb-3f3379b40f60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM_weightedLoss = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM_weightedLoss.load_state_dict(torch.load('model_AT_rFGSM_weightedLoss.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGs5E9_2SDbJ",
        "outputId": "bdaa06d8-9737-4cf3-a8f0-722da5253524"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Function to initialize centers and sigmas separately for benign and malware samples using KMeans clustering\n",
        "def initialize_centers_sigmas_separate(data_loader, num_centers_per_class):\n",
        "    centers_benign = []\n",
        "    centers_malware = []\n",
        "\n",
        "    # Collect data into a single tensor\n",
        "    all_data = torch.cat([batch for batch, _ in data_loader], dim=0)\n",
        "    all_data = all_data.numpy()\n",
        "\n",
        "    # Collect labels into a single tensor\n",
        "    all_labels = torch.cat([labels for _, labels in data_loader], dim=0)\n",
        "    all_labels = all_labels.numpy()\n",
        "\n",
        "    # Separate benign and malware samples\n",
        "    benign_indices = np.where(all_labels == 0)[0]\n",
        "    malware_indices = np.where(all_labels == 1)[0]\n",
        "\n",
        "    # Clustering for benign samples\n",
        "    benigns = all_data[benign_indices]\n",
        "    subset_benigns = benigns[:20000]\n",
        "    kmeans_benign = KMeans(n_clusters=num_centers_per_class, init='k-means++', n_init='auto')\n",
        "    kmeans_benign.fit(subset_benigns)\n",
        "    centers_selected_benign = kmeans_benign.cluster_centers_\n",
        "\n",
        "    # Clustering for malware samples\n",
        "    kmeans_malware = KMeans(n_clusters=num_centers_per_class, init='k-means++', n_init='auto')\n",
        "    kmeans_malware.fit(all_data[malware_indices])\n",
        "    centers_selected_malware = kmeans_malware.cluster_centers_\n",
        "\n",
        "    # Combine selected centers\n",
        "    all_centers = np.concatenate([centers_selected_benign, centers_selected_malware], axis=0)\n",
        "\n",
        "    # Calculate sigma based on the average distance between centers\n",
        "    total_distance = 0.0\n",
        "    num_pairs = 0\n",
        "\n",
        "    # Calculate pairwise distances between centers for benign samples\n",
        "    for i in range(len(centers_selected_benign)):\n",
        "        for j in range(i + 1, len(centers_selected_benign)):\n",
        "            distance_ij = np.sqrt(((centers_selected_benign[i] - centers_selected_benign[j]) ** 2).sum())\n",
        "            total_distance += distance_ij\n",
        "            num_pairs += 1\n",
        "\n",
        "    # Calculate pairwise distances between centers for malware samples\n",
        "    for i in range(len(centers_selected_malware)):\n",
        "        for j in range(i + 1, len(centers_selected_malware)):\n",
        "            distance_ij = np.sqrt(((centers_selected_malware[i] - centers_selected_malware[j]) ** 2).sum())\n",
        "            total_distance += distance_ij\n",
        "            num_pairs += 1\n",
        "\n",
        "    # Calculate mean sigma\n",
        "\n",
        "    sigma = total_distance / num_pairs\n",
        "\n",
        "    return all_centers, sigma\n"
      ],
      "metadata": {
        "id": "vh2VQ93Od2vL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_centers, sigma = initialize_centers_sigmas_separate(train_loader, 500)"
      ],
      "metadata": {
        "id": "AQEr5VdJ4Upt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAHioaOp6rIS",
        "outputId": "fad54326-e63f-4e88-ee07-cd9284e98d77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.325346210357184"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_centers.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Uz_cJ926sv2",
        "outputId": "9bad2139-fe62-432a-dd6f-fcfd54d9a1cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the array to a file\n",
        "np.save('all_centers.npy', all_centers)"
      ],
      "metadata": {
        "id": "oSnXMB926oVh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the array from the file\n",
        "all_centers = np.load('all_centers.npy')\n",
        "\n",
        "sigma = 6.281732838681898"
      ],
      "metadata": {
        "id": "Ss6Qdd-H6otO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move all_centers back to GPU\n",
        "all_centers = torch.tensor(all_centers, device=device)"
      ],
      "metadata": {
        "id": "5llZpwJP3ZsP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Define the RBF model\n",
        "class RBFModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, init_centers, init_sigmas):\n",
        "        super(RBFModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.centers = nn.Parameter(torch.Tensor(init_centers))\n",
        "        self.sigmas = nn.Parameter(torch.Tensor(init_sigmas))\n",
        "\n",
        "        # Linear layer for output\n",
        "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def gaussian(self, x, c, sigma):\n",
        "        return torch.exp(-torch.sum((x[:, None, :] - c) ** 2, dim=-1) / (2 * sigma ** 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        radial_out = self.gaussian(x, self.centers, self.sigmas)\n",
        "        output = self.linear(radial_out.to(torch.float32))\n",
        "        return output\n",
        "\n",
        "# Function to evaluate the model on a dataset\n",
        "def evaluate_model(model, data_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in data_loader:\n",
        "            batch_x, batch_y = batch_x.to(torch.float32).to(device), batch_y.to(device)  # Move data to GPU\n",
        "            output = model(batch_x)\n",
        "            loss = criterion(output, batch_y.squeeze().to(torch.long))\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            correct_predictions += (predicted == batch_y.squeeze()).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    accuracy = correct_predictions / len(data_loader.dataset)\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "WHAI-VGJSGa2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this to release GPU memory\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "e1cutWXY3eza"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the RBF model with initialized centers and sigmas\n",
        "model = RBFModel(10000, 1000, 2, all_centers, [sigma])\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for i, (batch_x, batch_y) in enumerate(train_loader):\n",
        "        batch_x, batch_y = batch_x.to(torch.float32).to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch_x)\n",
        "        loss = criterion(output, batch_y.squeeze().to(torch.long))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        correct_predictions += (predicted == batch_y.squeeze()).sum().item()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item()}')\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = correct_predictions / len(train_loader.dataset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss}, Train Accuracy: {accuracy}')\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZesZJEGxD09",
        "outputId": "b71111c9-bc90-4e97-ce87-73991d94246b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [10/897], Loss: 0.0172998309135437\n",
            "Epoch [1/10], Step [20/897], Loss: 0.032817691564559937\n",
            "Epoch [1/10], Step [30/897], Loss: 0.05968206748366356\n",
            "Epoch [1/10], Step [40/897], Loss: 0.1018967255949974\n",
            "Epoch [1/10], Step [50/897], Loss: 0.11222320050001144\n",
            "Epoch [1/10], Step [60/897], Loss: 0.04457662254571915\n",
            "Epoch [1/10], Step [70/897], Loss: 0.033884137868881226\n",
            "Epoch [1/10], Step [80/897], Loss: 0.17707860469818115\n",
            "Epoch [1/10], Step [90/897], Loss: 0.018819378688931465\n",
            "Epoch [1/10], Step [100/897], Loss: 0.05857442319393158\n",
            "Epoch [1/10], Step [110/897], Loss: 0.008322658017277718\n",
            "Epoch [1/10], Step [120/897], Loss: 0.0827416181564331\n",
            "Epoch [1/10], Step [130/897], Loss: 0.21955044567584991\n",
            "Epoch [1/10], Step [140/897], Loss: 0.08162592351436615\n",
            "Epoch [1/10], Step [150/897], Loss: 0.04201076924800873\n",
            "Epoch [1/10], Step [160/897], Loss: 0.012118374928832054\n",
            "Epoch [1/10], Step [170/897], Loss: 0.05060906335711479\n",
            "Epoch [1/10], Step [180/897], Loss: 0.05158982798457146\n",
            "Epoch [1/10], Step [190/897], Loss: 0.0396631620824337\n",
            "Epoch [1/10], Step [200/897], Loss: 0.03682459145784378\n",
            "Epoch [1/10], Step [210/897], Loss: 0.0202835351228714\n",
            "Epoch [1/10], Step [220/897], Loss: 0.11783022433519363\n",
            "Epoch [1/10], Step [230/897], Loss: 0.047487422823905945\n",
            "Epoch [1/10], Step [240/897], Loss: 0.0077865272760391235\n",
            "Epoch [1/10], Step [250/897], Loss: 0.02382413111627102\n",
            "Epoch [1/10], Step [260/897], Loss: 0.004144906997680664\n",
            "Epoch [1/10], Step [270/897], Loss: 0.09004415571689606\n",
            "Epoch [1/10], Step [280/897], Loss: 0.022889001294970512\n",
            "Epoch [1/10], Step [290/897], Loss: 0.08283652365207672\n",
            "Epoch [1/10], Step [300/897], Loss: 0.04067430645227432\n",
            "Epoch [1/10], Step [310/897], Loss: 0.10013846307992935\n",
            "Epoch [1/10], Step [320/897], Loss: 0.02121582441031933\n",
            "Epoch [1/10], Step [330/897], Loss: 0.026210449635982513\n",
            "Epoch [1/10], Step [340/897], Loss: 0.17528997361660004\n",
            "Epoch [1/10], Step [350/897], Loss: 0.2374746948480606\n",
            "Epoch [1/10], Step [360/897], Loss: 0.06421441584825516\n",
            "Epoch [1/10], Step [370/897], Loss: 0.02705688774585724\n",
            "Epoch [1/10], Step [380/897], Loss: 0.013756124302744865\n",
            "Epoch [1/10], Step [390/897], Loss: 0.0499810166656971\n",
            "Epoch [1/10], Step [400/897], Loss: 0.02633685991168022\n",
            "Epoch [1/10], Step [410/897], Loss: 0.005928258411586285\n",
            "Epoch [1/10], Step [420/897], Loss: 0.14504821598529816\n",
            "Epoch [1/10], Step [430/897], Loss: 0.019646475091576576\n",
            "Epoch [1/10], Step [440/897], Loss: 0.103722482919693\n",
            "Epoch [1/10], Step [450/897], Loss: 0.040736209601163864\n",
            "Epoch [1/10], Step [460/897], Loss: 0.0359342135488987\n",
            "Epoch [1/10], Step [470/897], Loss: 0.17353175580501556\n",
            "Epoch [1/10], Step [480/897], Loss: 0.017251281067728996\n",
            "Epoch [1/10], Step [490/897], Loss: 0.0468558669090271\n",
            "Epoch [1/10], Step [500/897], Loss: 0.06174331530928612\n",
            "Epoch [1/10], Step [510/897], Loss: 0.008531146682798862\n",
            "Epoch [1/10], Step [520/897], Loss: 0.058013465255498886\n",
            "Epoch [1/10], Step [530/897], Loss: 0.011901096440851688\n",
            "Epoch [1/10], Step [540/897], Loss: 0.023583518341183662\n",
            "Epoch [1/10], Step [550/897], Loss: 0.08865416795015335\n",
            "Epoch [1/10], Step [560/897], Loss: 0.0342487171292305\n",
            "Epoch [1/10], Step [570/897], Loss: 0.09579937160015106\n",
            "Epoch [1/10], Step [580/897], Loss: 0.12033991515636444\n",
            "Epoch [1/10], Step [590/897], Loss: 0.009527410380542278\n",
            "Epoch [1/10], Step [600/897], Loss: 0.00777784176170826\n",
            "Epoch [1/10], Step [610/897], Loss: 0.01833079755306244\n",
            "Epoch [1/10], Step [620/897], Loss: 0.03545314073562622\n",
            "Epoch [1/10], Step [630/897], Loss: 0.08049192279577255\n",
            "Epoch [1/10], Step [640/897], Loss: 0.010248158127069473\n",
            "Epoch [1/10], Step [650/897], Loss: 0.04432675614953041\n",
            "Epoch [1/10], Step [660/897], Loss: 0.021949946880340576\n",
            "Epoch [1/10], Step [670/897], Loss: 0.015775227919220924\n",
            "Epoch [1/10], Step [680/897], Loss: 0.17962317168712616\n",
            "Epoch [1/10], Step [690/897], Loss: 0.024799762293696404\n",
            "Epoch [1/10], Step [700/897], Loss: 0.005249750334769487\n",
            "Epoch [1/10], Step [710/897], Loss: 0.1261080652475357\n",
            "Epoch [1/10], Step [720/897], Loss: 0.046214550733566284\n",
            "Epoch [1/10], Step [730/897], Loss: 0.05663180723786354\n",
            "Epoch [1/10], Step [740/897], Loss: 0.06494242697954178\n",
            "Epoch [1/10], Step [750/897], Loss: 0.21661965548992157\n",
            "Epoch [1/10], Step [760/897], Loss: 0.04014447331428528\n",
            "Epoch [1/10], Step [770/897], Loss: 0.09956666082143784\n",
            "Epoch [1/10], Step [780/897], Loss: 0.14317671954631805\n",
            "Epoch [1/10], Step [790/897], Loss: 0.01949899271130562\n",
            "Epoch [1/10], Step [800/897], Loss: 0.07123851776123047\n",
            "Epoch [1/10], Step [810/897], Loss: 0.022457033395767212\n",
            "Epoch [1/10], Step [820/897], Loss: 0.016367517411708832\n",
            "Epoch [1/10], Step [830/897], Loss: 0.0067733959294855595\n",
            "Epoch [1/10], Step [840/897], Loss: 0.09975296258926392\n",
            "Epoch [1/10], Step [850/897], Loss: 0.2036389857530594\n",
            "Epoch [1/10], Step [860/897], Loss: 0.011422192677855492\n",
            "Epoch [1/10], Step [870/897], Loss: 0.12583932280540466\n",
            "Epoch [1/10], Step [880/897], Loss: 0.0699787586927414\n",
            "Epoch [1/10], Step [890/897], Loss: 0.04015975072979927\n",
            "Epoch [1/10], Train Loss: 0.0657955295031988, Train Accuracy: 0.9769898546177178\n",
            "Epoch [1/10], Validation Loss: 0.0638318183609163, Validation Accuracy: 0.9786655511399289\n",
            "Epoch [2/10], Step [10/897], Loss: 0.02065727859735489\n",
            "Epoch [2/10], Step [20/897], Loss: 0.005432089790701866\n",
            "Epoch [2/10], Step [30/897], Loss: 0.06773380935192108\n",
            "Epoch [2/10], Step [40/897], Loss: 0.024961210787296295\n",
            "Epoch [2/10], Step [50/897], Loss: 0.012811752036213875\n",
            "Epoch [2/10], Step [60/897], Loss: 0.018390124663710594\n",
            "Epoch [2/10], Step [70/897], Loss: 0.259723961353302\n",
            "Epoch [2/10], Step [80/897], Loss: 0.213558167219162\n",
            "Epoch [2/10], Step [90/897], Loss: 0.029518887400627136\n",
            "Epoch [2/10], Step [100/897], Loss: 0.0355253703892231\n",
            "Epoch [2/10], Step [110/897], Loss: 0.012657479383051395\n",
            "Epoch [2/10], Step [120/897], Loss: 0.01126452349126339\n",
            "Epoch [2/10], Step [130/897], Loss: 0.025202585384249687\n",
            "Epoch [2/10], Step [140/897], Loss: 0.07335410267114639\n",
            "Epoch [2/10], Step [150/897], Loss: 0.033669427037239075\n",
            "Epoch [2/10], Step [160/897], Loss: 0.07313495129346848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Evaluate on validation set\n",
        "    val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzIR6bFR9jVn",
        "outputId": "71576405-504d-4ab6-f256-fb8febc438ac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Validation Loss: 0.08652751230683828, Validation Accuracy: 0.9742731646099142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, you can extract the trained parameters\n",
        "trained_centers = model.centers.detach().cpu().numpy()\n",
        "trained_sigmas = model.sigmas.detach().cpu().numpy()\n",
        "\n",
        "# Print or use the trained parameters\n",
        "print(\"Trained Centers:\", trained_centers)\n",
        "print(\"Trained Sigmas:\", trained_sigmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cvj498VR87gn",
        "outputId": "8e7968be-8b75-488e-fab8-5445665fb084"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Centers: [[ 5.72939974e-02 -4.31551280e-01 -9.85139705e-01 ... -1.22846259e-03\n",
            "   1.63294273e-06  1.01501844e-09]\n",
            " [-4.38452198e-01 -4.18462970e-01 -9.89346378e-01 ... -1.01941469e-04\n",
            "  -2.80480012e-03  1.43014868e-12]\n",
            " [-3.59904254e-01 -3.00404876e-01 -9.32873314e-01 ... -9.18345210e-05\n",
            "  -8.13778867e-04  1.97773827e-18]\n",
            " ...\n",
            " [ 5.68983011e-01  3.89639550e-01  1.41794207e+00 ...  1.18695540e-03\n",
            "   6.26176883e-07  5.45631881e-20]\n",
            " [-4.58739444e-01 -4.25028808e-01 -1.01310583e+00 ... -1.00712603e-04\n",
            "   3.03886764e-06  2.57006704e-11]\n",
            " [ 1.52572886e+00  6.01671322e-01  1.31605251e+00 ...  4.33774665e-03\n",
            "  -3.32060611e-04  6.05219894e-04]]\n",
            "Trained Sigmas: [4.879355]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the array to a file\n",
        "np.save('trained_centers.npy', trained_centers)"
      ],
      "metadata": {
        "id": "fm3-ri-E9A4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}