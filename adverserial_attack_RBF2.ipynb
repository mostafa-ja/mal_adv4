{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv4/blob/main/adverserial_attack_RBF2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RBF_models\n",
        "\n",
        "download_links = [\n",
        "                  'https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f',\n",
        "                  'https://drive.google.com/uc?id=1-OHACrNCt0yKBbdqQPVfNZcjKt5_jxKD',\n",
        "                  'https://drive.google.com/uc?id=1-KeXJXtU1_6m9JOhormeVwigy0myX3HL',\n",
        "                  'https://drive.google.com/uc?id=1-13RDdZqnrNkdHg3D8PC5KI0CZREwlsz',\n",
        "                  'https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP',\n",
        "\n",
        "]\n",
        "\n",
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM_3KjraHnkn",
        "outputId": "076438c0-8df9-42a3-883c-a3bde41f554d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f\n",
            "From (redirected): https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f&confirm=t&uuid=1e830f5c-034e-42e9-8079-d4405b25d8ba\n",
            "To: /content/best_model_gaussian_400.pth\n",
            "100%|██████████| 32.0M/32.0M [00:00<00:00, 34.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-OHACrNCt0yKBbdqQPVfNZcjKt5_jxKD\n",
            "To: /content/best_model_gaussian_600_nonremoval.pth\n",
            "100%|██████████| 5.50M/5.50M [00:00<00:00, 80.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-KeXJXtU1_6m9JOhormeVwigy0myX3HL\n",
            "To: /content/best_model_gaussian_600.pth\n",
            "100%|██████████| 24.0M/24.0M [00:00<00:00, 98.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-13RDdZqnrNkdHg3D8PC5KI0CZREwlsz\n",
            "To: /content/best_model_gaussian_1000_nonremoval.pth\n",
            "100%|██████████| 9.16M/9.16M [00:00<00:00, 104MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP\n",
            "From (redirected): https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP&confirm=t&uuid=52265b62-cfc3-4856-9e55-8f6f54495cd4\n",
            "To: /content/best_model_gaussian_1000.pth\n",
            "100%|██████████| 40.0M/40.0M [00:00<00:00, 136MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "download_links = ['https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py'\n",
        "]"
      ],
      "metadata": {
        "id": "1IW4pHac9VLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kzSbjaXGVeG",
        "outputId": "eb960f9e-2337-4b13-b747-5caa1995adc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz\n",
            "To: /content/sparse_matrix_0.npz\n",
            "100%|██████████| 461k/461k [00:00<00:00, 7.81MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz\n",
            "To: /content/sparse_matrix_1.npz\n",
            "100%|██████████| 148k/148k [00:00<00:00, 5.45MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz\n",
            "To: /content/sparse_matrix_2.npz\n",
            "100%|██████████| 150k/150k [00:00<00:00, 6.63MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz\n",
            "To: /content/sparse_matrix_y0.npz\n",
            "100%|██████████| 5.79k/5.79k [00:00<00:00, 15.9MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz\n",
            "To: /content/sparse_matrix_y1.npz\n",
            "100%|██████████| 2.64k/2.64k [00:00<00:00, 4.06MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz\n",
            "To: /content/sparse_matrix_y2.npz\n",
            "100%|██████████| 2.71k/2.71k [00:00<00:00, 4.24MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth\n",
            "To: /content/model_DNN_drebin_best.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 26.2MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth\n",
            "To: /content/model_AT_rFGSM_weightedLoss.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 23.0MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth\n",
            "To: /content/model_AT_rFGSM.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 24.5MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl\n",
            "To: /content/insertion_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 6.21MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl\n",
            "To: /content/removal_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 4.88MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py\n",
            "To: /content/adverserial_attacks_functions.py\n",
            "67.1kB [00:00, 39.2MB/s]                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,balanced_accuracy_score\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "from adverserial_attacks_functions import *\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96a405e-8d8b-4149-e23c-2f718a4eed65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fedd313d0f0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    #os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX4ncRLLFDnN",
        "outputId": "33a4565c-74da-4dfc-959e-e6598a90b87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the .pkl file\n",
        "with open('/content/insertion_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    insertion_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "insertion_array = torch.tensor(insertion_array, dtype=torch.uint8).to(device)\n",
        "print(len(insertion_array))\n",
        "\n",
        "# Open the .pkl file\n",
        "with open('/content/removal_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    removal_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "removal_array = torch.tensor(removal_array, dtype=torch.uint8).to(device)\n",
        "print(len(removal_array))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXV0WIjsJG_F",
        "outputId": "4d9ee2b8-4ffc-4fc5-ce80-8fd241c39080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load dataset\n",
        "X_train = sparse.load_npz(\"/content/sparse_matrix_0.npz\").toarray()\n",
        "X_val = sparse.load_npz(\"/content/sparse_matrix_1.npz\").toarray()\n",
        "X_test = sparse.load_npz(\"/content/sparse_matrix_2.npz\").toarray()\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.int8)\n",
        "X_val = torch.tensor(X_val, dtype=torch.int8)\n",
        "X_test = torch.tensor(X_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "y_train = sparse.load_npz(\"/content/sparse_matrix_y0.npz\").toarray().reshape((-1, 1))\n",
        "y_val = sparse.load_npz(\"/content/sparse_matrix_y1.npz\").toarray().reshape((-1, 1))\n",
        "y_test = sparse.load_npz(\"/content/sparse_matrix_y2.npz\").toarray().reshape((-1, 1))\n",
        "\n",
        "y_train = torch.tensor(y_train, dtype=torch.int8)\n",
        "y_val = torch.tensor(y_val, dtype=torch.int8)\n",
        "y_test = torch.tensor(y_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"x_train:\", X_train.shape)\n",
        "print(\"x_val:\", X_val.shape)\n",
        "print(\"x_test:\", X_test.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"y_val:\", y_val.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5blmEg4h-GKy",
        "outputId": "84671002-9bc3-4248-94e6-065f26ca0f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:\n",
            "x_train: torch.Size([28683, 10000])\n",
            "x_val: torch.Size([9562, 10000])\n",
            "x_test: torch.Size([9562, 10000])\n",
            "y_train: torch.Size([28683, 1])\n",
            "y_val: torch.Size([9562, 1])\n",
            "y_test: torch.Size([9562, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of benigns and malicious sample in training dataset\n",
        "n_ben = (y_train.squeeze()== 0).sum().item()\n",
        "n_mal = (y_train.squeeze()== 1).sum().item()\n",
        "print('the proportion of malwares : ', n_mal/(n_mal+n_ben))\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 1024\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del train_dataset, val_dataset, test_dataset, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81AZSXOV-HoW",
        "outputId": "026541e0-68b1-450c-b35c-297138e6721b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the proportion of malwares :  0.11386535578565701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM.load_state_dict(torch.load('model_AT_rFGSM.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE8WMAUgSCms",
        "outputId": "f8261531-f501-48e5-994d-9e45cc820113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RBFModel(nn.Module):\n",
        "    def __init__(self, hidden_dim, output_dim, init_centers, init_sigmas, kernel):\n",
        "        super(RBFModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.centers = nn.Parameter(torch.Tensor(init_centers))\n",
        "        self.sigmas = nn.Parameter(torch.Tensor(init_sigmas))\n",
        "        self.kernel = kernel\n",
        "        # Linear layer for output\n",
        "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def gaussian(self, x, c, sigma):\n",
        "        return torch.exp(-torch.sum((x[:, None, :] - c) ** 2, dim=-1) / (2 * sigma ** 2))\n",
        "\n",
        "    def laplacian(self, x, c, sigma):\n",
        "        return torch.exp(-torch.sum(torch.abs(x[:, None, :] - c) , dim=-1) / sigma)\n",
        "\n",
        "    def forward(self, x):\n",
        "      if self.kernel == 'gaussian':\n",
        "        radial_out = self.gaussian(x, self.centers, self.sigmas)\n",
        "      elif self.kernel == 'laplacian':\n",
        "        radial_out = self.laplacian(x, self.centers, self.sigmas)\n",
        "      else:\n",
        "        raise ValueError(\"Invalid kernel type. Choose 'gaussian' or 'laplacian'.\")\n",
        "\n",
        "      output = self.linear(radial_out.to(torch.float32))\n",
        "      return output\n"
      ],
      "metadata": {
        "id": "WHAI-VGJSGa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_removal_features = False\n",
        "non_removal_mask = torch.logical_not(removal_array).to('cpu')\n",
        "sigma = 4.15\n",
        "kernel = 'gaussian'\n",
        "all_centers = torch.rand((1000, 10000))\n",
        "model_gaussian_1000 = RBFModel(1000, 2, all_centers, [sigma], kernel)\n",
        "model_gaussian_1000 = model_gaussian_1000.to(device)\n",
        "\n",
        "# Load the model state dictionary\n",
        "model_gaussian_1000.load_state_dict(torch.load('/content/best_model_gaussian_1000.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "id": "W9qJYeK0bbnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1fd0b3-4da3-4aee-f6e7-4661220bc60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_removal_features = True\n",
        "non_removal_mask = torch.logical_not(removal_array).to('cpu')\n",
        "sigma = 4.15\n",
        "kernel = 'gaussian'\n",
        "all_centers = torch.rand((1000, 1144))\n",
        "model_gaussian_1000_nonremoval = RBFModel(1000, 2, all_centers, [sigma], kernel)\n",
        "model_gaussian_1000_nonremoval = model_gaussian_1000_nonremoval.to(device)\n",
        "\n",
        "# Load the model state dictionary\n",
        "model_gaussian_1000_nonremoval.load_state_dict(torch.load('/content/best_model_gaussian_1000_nonremoval.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMA7rzpTPhv7",
        "outputId": "477a649f-223b-4a8e-fdb3-efe660468482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QcyXy3kSd6QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in test_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break\n",
        "\n",
        "bens = x[y.squeeze()==0]\n",
        "bens_y = y[y.squeeze()==0]\n",
        "print(bens.shape)\n",
        "\n",
        "mals = x[y.squeeze()==1]\n",
        "mals_y = y[y.squeeze()==1]\n",
        "print(mals.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StL135L1JUiE",
        "outputId": "ba46ea83-29af-41dc-95c1-d70cfe7fc194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1024, 10000])\n",
            "torch.Size([1024, 1])\n",
            "torch.Size([909, 10000])\n",
            "torch.Size([115, 10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`analysis`**"
      ],
      "metadata": {
        "id": "lR06hA6gn_by"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PGD VS PGD2"
      ],
      "metadata": {
        "id": "lBVu5_O4xF4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = mals.to(device)\n",
        "\n",
        "# Expand insertion_array and removal_array to match the batch size\n",
        "expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "# Update insertion and removal arrays based on input x\n",
        "insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))"
      ],
      "metadata": {
        "id": "5Ybdj5iAOo_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(insertion_array.sum())\n",
        "print(insertion_array_updated.sum(dim=-1))\n",
        "\n",
        "print(removal_array.sum())\n",
        "print(removal_array_updated.sum(dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk3PeXfviDL7",
        "outputId": "197ac01e-11d2-4654-8570-7f1d13aa1736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9943, device='cuda:0')\n",
            "tensor([9943, 9944, 9943, 9949, 9944, 9944, 9944, 9945, 9946, 9947, 9943, 9945,\n",
            "        9944, 9943, 9943, 9944, 9946, 9945, 9947, 9945, 9945, 9946, 9944, 9945,\n",
            "        9945, 9945, 9943, 9944, 9944], device='cuda:0')\n",
            "tensor(8856, device='cuda:0')\n",
            "tensor([9996, 9993, 9986, 9962, 9993, 9986, 9973, 9989, 9967, 9980, 9996, 9989,\n",
            "        9993, 9992, 9985, 9989, 9977, 9968, 9984, 9968, 9976, 9989, 9993, 9965,\n",
            "        9984, 9989, 9994, 9989, 9997], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((x.to(torch.uint8)[0]).sum())\n",
        "print((removal_array_updated[0]*x.to(torch.uint8)[0]).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGD5H7qPqL3s",
        "outputId": "e223f1fc-6408-4e8e-c810-0d2cbb0c60aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10, device='cuda:0')\n",
            "tensor(6, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((x.to(torch.uint8)[1]).sum())\n",
        "print((removal_array_updated[1]*x.to(torch.uint8)[1]).sum())"
      ],
      "metadata": {
        "id": "2uCejvFCpYLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c42626-3ec1-44f2-e0c4-1bc4d2638ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18, device='cuda:0')\n",
            "tensor(11, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "        #print('loss : ',criterion(y_model, y.view(-1).long()))\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "gCxNx4sfOr-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd2(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "\n",
        "    #insertion_array_updated = torch.bitwise_or(insertion_array.to(torch.uint8), x.squeeze().to(torch.uint8) )\n",
        "    #removal_array_updated = torch.bitwise_or(removal_array.to(torch.uint8), (1 - x.squeeze().to(torch.uint8)) )\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "        #print('loss : ',criterion(y_model, y.view(-1).long()))\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "ljfazeC6MOcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=13\n",
        "adv3 = pgd(mals[i:i+1].to(torch.float32).to(device), mals_y[i:i+1].to(device), model_AT_rFGSM, insertion_array, removal_array, k=200, step_length=.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dfb42f2-39b7-4d36-d6f3-851143bc691e",
        "id": "wno-FScyQc7r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***********  0\n",
            "loss_mal :  tensor([38.1857], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  1\n",
            "loss_mal :  tensor([34.2699], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  2\n",
            "loss_mal :  tensor([29.9703], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  3\n",
            "loss_mal :  tensor([25.4033], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  4\n",
            "loss_mal :  tensor([21.0827], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  5\n",
            "loss_mal :  tensor([18.6158], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  6\n",
            "loss_mal :  tensor([19.1730], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  7\n",
            "loss_mal :  tensor([18.5722], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  8\n",
            "loss_mal :  tensor([17.9622], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  9\n",
            "loss_mal :  tensor([18.2092], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  10\n",
            "loss_mal :  tensor([17.6264], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  11\n",
            "loss_mal :  tensor([17.2231], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  12\n",
            "loss_mal :  tensor([17.6461], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  13\n",
            "loss_mal :  tensor([17.0438], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  14\n",
            "loss_mal :  tensor([16.5450], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  15\n",
            "loss_mal :  tensor([16.6668], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  16\n",
            "loss_mal :  tensor([16.7365], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  17\n",
            "loss_mal :  tensor([16.2144], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  18\n",
            "loss_mal :  tensor([15.8460], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  19\n",
            "loss_mal :  tensor([16.2541], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  20\n",
            "loss_mal :  tensor([15.6365], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  21\n",
            "loss_mal :  tensor([15.1847], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  22\n",
            "loss_mal :  tensor([15.2408], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  23\n",
            "loss_mal :  tensor([15.3970], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  24\n",
            "loss_mal :  tensor([14.9240], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.5763e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  25\n",
            "loss_mal :  tensor([14.4805], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([4.7684e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  26\n",
            "loss_mal :  tensor([15.1770], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  27\n",
            "loss_mal :  tensor([15.3370], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  28\n",
            "loss_mal :  tensor([18.0399], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  29\n",
            "loss_mal :  tensor([17.5291], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  30\n",
            "loss_mal :  tensor([18.5759], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  31\n",
            "loss_mal :  tensor([18.5073], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  32\n",
            "loss_mal :  tensor([19.3361], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  33\n",
            "loss_mal :  tensor([19.5283], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  34\n",
            "loss_mal :  tensor([19.8090], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  35\n",
            "loss_mal :  tensor([20.6668], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  36\n",
            "loss_mal :  tensor([20.5820], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  37\n",
            "loss_mal :  tensor([21.0349], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  38\n",
            "loss_mal :  tensor([22.0950], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  39\n",
            "loss_mal :  tensor([25.7003], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  40\n",
            "loss_mal :  tensor([25.0341], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  41\n",
            "loss_mal :  tensor([25.9631], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  42\n",
            "loss_mal :  tensor([26.0358], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  43\n",
            "loss_mal :  tensor([26.2545], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  44\n",
            "loss_mal :  tensor([27.0234], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  45\n",
            "loss_mal :  tensor([27.2249], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  46\n",
            "loss_mal :  tensor([27.8303], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  47\n",
            "loss_mal :  tensor([28.4456], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  48\n",
            "loss_mal :  tensor([28.5112], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  49\n",
            "loss_mal :  tensor([28.7157], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  50\n",
            "loss_mal :  tensor([29.7865], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  51\n",
            "loss_mal :  tensor([29.8639], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  52\n",
            "loss_mal :  tensor([30.0937], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  53\n",
            "loss_mal :  tensor([30.4724], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  54\n",
            "loss_mal :  tensor([31.2638], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  55\n",
            "loss_mal :  tensor([31.3466], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  56\n",
            "loss_mal :  tensor([31.4016], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  57\n",
            "loss_mal :  tensor([32.3835], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  58\n",
            "loss_mal :  tensor([32.7490], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  59\n",
            "loss_mal :  tensor([32.6407], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  60\n",
            "loss_mal :  tensor([32.9704], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  61\n",
            "loss_mal :  tensor([34.3624], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  62\n",
            "loss_mal :  tensor([36.8631], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  63\n",
            "loss_mal :  tensor([37.2833], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  64\n",
            "loss_mal :  tensor([37.5473], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  65\n",
            "loss_mal :  tensor([38.0170], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  66\n",
            "loss_mal :  tensor([38.4765], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  67\n",
            "loss_mal :  tensor([38.8761], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  68\n",
            "loss_mal :  tensor([39.2470], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  69\n",
            "loss_mal :  tensor([39.7409], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  70\n",
            "loss_mal :  tensor([39.2557], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  71\n",
            "loss_mal :  tensor([39.6956], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  72\n",
            "loss_mal :  tensor([40.5667], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  73\n",
            "loss_mal :  tensor([40.7395], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  74\n",
            "loss_mal :  tensor([41.2648], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  75\n",
            "loss_mal :  tensor([40.6510], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  76\n",
            "loss_mal :  tensor([41.3032], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  77\n",
            "loss_mal :  tensor([42.1344], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  78\n",
            "loss_mal :  tensor([42.0639], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  79\n",
            "loss_mal :  tensor([42.6217], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  80\n",
            "loss_mal :  tensor([42.4742], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  81\n",
            "loss_mal :  tensor([43.2104], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  82\n",
            "loss_mal :  tensor([42.8373], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  83\n",
            "loss_mal :  tensor([43.8001], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  84\n",
            "loss_mal :  tensor([43.6212], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  85\n",
            "loss_mal :  tensor([44.2113], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  86\n",
            "loss_mal :  tensor([44.4069], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  87\n",
            "loss_mal :  tensor([44.8563], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  88\n",
            "loss_mal :  tensor([44.4067], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  89\n",
            "loss_mal :  tensor([45.6805], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  90\n",
            "loss_mal :  tensor([45.2139], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  91\n",
            "loss_mal :  tensor([46.1938], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  92\n",
            "loss_mal :  tensor([46.2202], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  93\n",
            "loss_mal :  tensor([46.6961], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  94\n",
            "loss_mal :  tensor([46.2663], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  95\n",
            "loss_mal :  tensor([47.0882], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  96\n",
            "loss_mal :  tensor([47.0736], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  97\n",
            "loss_mal :  tensor([47.5637], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  98\n",
            "loss_mal :  tensor([46.9779], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  99\n",
            "loss_mal :  tensor([47.8359], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  100\n",
            "loss_mal :  tensor([47.7958], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  101\n",
            "loss_mal :  tensor([48.2153], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  102\n",
            "loss_mal :  tensor([48.4137], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  103\n",
            "loss_mal :  tensor([48.6403], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  104\n",
            "loss_mal :  tensor([48.9003], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  105\n",
            "loss_mal :  tensor([48.8218], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  106\n",
            "loss_mal :  tensor([49.4160], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  107\n",
            "loss_mal :  tensor([49.1052], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  108\n",
            "loss_mal :  tensor([49.3387], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  109\n",
            "loss_mal :  tensor([49.3371], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  110\n",
            "loss_mal :  tensor([50.3853], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  111\n",
            "loss_mal :  tensor([49.5553], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  112\n",
            "loss_mal :  tensor([50.2185], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  113\n",
            "loss_mal :  tensor([49.6733], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  114\n",
            "loss_mal :  tensor([50.8431], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  115\n",
            "loss_mal :  tensor([50.0224], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  116\n",
            "loss_mal :  tensor([50.2238], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  117\n",
            "loss_mal :  tensor([51.2280], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  118\n",
            "loss_mal :  tensor([50.3908], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  119\n",
            "loss_mal :  tensor([51.5084], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  120\n",
            "loss_mal :  tensor([50.5488], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  121\n",
            "loss_mal :  tensor([50.7055], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  122\n",
            "loss_mal :  tensor([51.7984], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  123\n",
            "loss_mal :  tensor([50.8001], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  124\n",
            "loss_mal :  tensor([52.6957], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  125\n",
            "loss_mal :  tensor([51.2729], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  126\n",
            "loss_mal :  tensor([52.1815], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  127\n",
            "loss_mal :  tensor([51.9248], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  128\n",
            "loss_mal :  tensor([51.9660], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  129\n",
            "loss_mal :  tensor([53.9478], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  130\n",
            "loss_mal :  tensor([52.9872], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  131\n",
            "loss_mal :  tensor([52.9911], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  132\n",
            "loss_mal :  tensor([53.0953], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  133\n",
            "loss_mal :  tensor([53.1235], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  134\n",
            "loss_mal :  tensor([53.1636], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  135\n",
            "loss_mal :  tensor([53.1505], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  136\n",
            "loss_mal :  tensor([53.2048], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  137\n",
            "loss_mal :  tensor([53.1772], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  138\n",
            "loss_mal :  tensor([53.2403], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  139\n",
            "loss_mal :  tensor([53.2744], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  140\n",
            "loss_mal :  tensor([53.2884], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  141\n",
            "loss_mal :  tensor([53.2570], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  142\n",
            "loss_mal :  tensor([53.2793], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  143\n",
            "loss_mal :  tensor([53.2307], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  144\n",
            "loss_mal :  tensor([53.3362], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  145\n",
            "loss_mal :  tensor([54.3056], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  146\n",
            "loss_mal :  tensor([53.5258], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  147\n",
            "loss_mal :  tensor([54.6378], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  148\n",
            "loss_mal :  tensor([53.6328], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  149\n",
            "loss_mal :  tensor([53.7278], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  150\n",
            "loss_mal :  tensor([54.0571], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  151\n",
            "loss_mal :  tensor([54.0202], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  152\n",
            "loss_mal :  tensor([55.1657], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  153\n",
            "loss_mal :  tensor([54.2403], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  154\n",
            "loss_mal :  tensor([55.3521], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  155\n",
            "loss_mal :  tensor([54.3920], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  156\n",
            "loss_mal :  tensor([54.3931], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  157\n",
            "loss_mal :  tensor([54.5385], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  158\n",
            "loss_mal :  tensor([54.5983], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  159\n",
            "loss_mal :  tensor([54.6775], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  160\n",
            "loss_mal :  tensor([55.6373], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  161\n",
            "loss_mal :  tensor([54.7709], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  162\n",
            "loss_mal :  tensor([55.8183], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  163\n",
            "loss_mal :  tensor([54.8311], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  164\n",
            "loss_mal :  tensor([56.0166], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  165\n",
            "loss_mal :  tensor([54.8923], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  166\n",
            "loss_mal :  tensor([55.0505], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  167\n",
            "loss_mal :  tensor([54.9815], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  168\n",
            "loss_mal :  tensor([56.0288], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  169\n",
            "loss_mal :  tensor([55.0874], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  170\n",
            "loss_mal :  tensor([56.0652], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  171\n",
            "loss_mal :  tensor([55.1147], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  172\n",
            "loss_mal :  tensor([55.2418], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  173\n",
            "loss_mal :  tensor([56.3768], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  174\n",
            "loss_mal :  tensor([55.3652], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  175\n",
            "loss_mal :  tensor([55.3756], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  176\n",
            "loss_mal :  tensor([55.4923], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  177\n",
            "loss_mal :  tensor([55.5233], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  178\n",
            "loss_mal :  tensor([56.4636], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  179\n",
            "loss_mal :  tensor([55.5444], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  180\n",
            "loss_mal :  tensor([56.5000], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  181\n",
            "loss_mal :  tensor([55.5681], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  182\n",
            "loss_mal :  tensor([57.3156], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  183\n",
            "loss_mal :  tensor([55.7465], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  184\n",
            "loss_mal :  tensor([55.8201], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  185\n",
            "loss_mal :  tensor([56.1730], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  186\n",
            "loss_mal :  tensor([55.9438], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  187\n",
            "loss_mal :  tensor([59.8039], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  188\n",
            "loss_mal :  tensor([58.7559], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  189\n",
            "loss_mal :  tensor([58.7960], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  190\n",
            "loss_mal :  tensor([58.7328], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  191\n",
            "loss_mal :  tensor([58.7429], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  192\n",
            "loss_mal :  tensor([58.8203], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  193\n",
            "loss_mal :  tensor([58.7509], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  194\n",
            "loss_mal :  tensor([58.7509], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  195\n",
            "loss_mal :  tensor([58.7509], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  196\n",
            "loss_mal :  tensor([58.7509], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  197\n",
            "loss_mal :  tensor([58.7509], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  198\n",
            "loss_mal :  tensor([58.7509], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  199\n",
            "loss_mal :  tensor([58.7509], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "PGD linf: Attack effectiveness 0.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=13\n",
        "adv3 = pgd2(mals[i:i+1].to(torch.float32).to(device), mals_y[i:i+1].to(device), model_AT_rFGSM, insertion_array, removal_array, k=200, step_length=.01, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6ffcbd-df80-4a08-c94c-d2ee834981fb",
        "id": "VA7I64WAQlzh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_mal :  tensor([38.1857], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([36.2778], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([34.1459], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([32.0459], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([29.7434], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([27.4553], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([25.1175], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([22.7606], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([20.7420], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([18.7855], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([17.7333], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([17.0531], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([16.1223], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([15.3524], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([14.7656], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.5763e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([13.8007], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.0729e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([13.0112], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.2650e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([12.5444], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.5763e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([11.6671], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([8.5830e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([11.3863], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.1325e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([10.2367], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.5881e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([9.2161], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([9.9416e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([9.4727], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([7.6887e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([8.7340], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0002], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([7.7916], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0004], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([7.4897], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0006], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([9.3333], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([8.8449e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([7.3538], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0006], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([5.9726], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0026], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([6.3044], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0018], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([7.2304], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0007], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([6.0834], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0023], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([4.7234], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0089], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([4.3221], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0134], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([5.8951], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0028], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([4.3293], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0133], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([3.2786], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0384], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([4.0669], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0173], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([3.9127], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0202], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.9162], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0557], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([3.9034], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0204], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([3.6429], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0265], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.9277], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0550], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.9581], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.1521], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.9436], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.1545], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.6260], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0751], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.8590], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0590], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.4482], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0904], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.2558], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.3352], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.9197], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.5085], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.7572], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.6330], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.9694], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.4769], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.3177], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.3116], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.5444], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.8679], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.5643], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.8410], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.3931], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0958], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.8096], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.5888], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.3027], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.3425], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.7227], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.6645], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.3755], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.1613], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0892], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.4609], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0557], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.9151], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0451], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.1222], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0605], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.8352], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0731], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.6521], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0147], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([4.2298], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.1553], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.9392], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0211], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.8668], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0074], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([4.9123], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0599], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.8451], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0096], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([4.6477], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0040], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([5.5347], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0038], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([5.5780], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0036], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([5.6367], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0025], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([6.0047], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0015], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([6.4953], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0008], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([7.1494], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0004], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([7.7841], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0004], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([7.8195], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0002], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([8.4549], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0002], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([8.6143], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([9.7866e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([9.2318], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([0.0005], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([7.5747], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([7.3669e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([9.5154], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([3.3736e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.2967], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.5868e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.5637], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([3.7789e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.1824], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.7404e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.9576], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.6451e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.0120], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.1086e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.4133], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.0371e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.4801], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([5.9604e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.0398], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([6.0797e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.0062], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([4.2915e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.3569], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([3.6955e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.4986], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.2650e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.9914], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.1458e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.0478], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.4305e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.4899], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.5497e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.3926], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([9.5367e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.9123], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([9.5367e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.8642], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([5.9605e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.2797], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([8.3446e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.9929], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([4.7684e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.4852], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([7.1526e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.1059], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([3.5763e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.7666], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([3.5763e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.8205], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.2218], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.1785], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.5289], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.0717], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.6906], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([3.5763e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.8573], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.8415], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.0516], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.9979], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.1779], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.2113], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.1807], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.5920], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.8915], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.7072], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.9245], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.1821], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.9369], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.8058], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.1525], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.2827], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.3518], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.3100], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.4926], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.9303], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.5889], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.6794], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.7684], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.8297], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.5572], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.3395], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.0459], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.0215], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.0777], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.2277], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.2953], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.2866], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.4161], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.6764], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.5151], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.5406], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.6368], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.4993], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.6868], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.8509], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.6713], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.8222], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.3812], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.8683], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.5569], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.9306], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.8948], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.1698], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.0208], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.5820], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.1567], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.9064], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.2704], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.6482], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.3006], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.3837], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.7682], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.7323], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.7673], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.4611], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.9545], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.9501], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([20.1487], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([20.1800], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([20.3351], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([20.5411], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([20.6605], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([20.2835], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([20.6128], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([20.8182], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.0505], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.3736], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.3705], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.3748], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.5194], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.6121], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([21.6836], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.0233], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.2959], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.2906], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.0599], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.3548], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.6085], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.4280], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.2590], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.6373], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.5472], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([22.7872], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "PGD linf: Attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zc-0yhEwDPT",
        "outputId": "b372804d-2ebb-43d6-aa4f-74e7dbeaa5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 6.897%.\n",
            "PGD linf: Attack effectiveness 8.000%.\n",
            "PGD linf: Attack effectiveness 7.692%.\n",
            "PGD linf: Attack effectiveness 2.857%.\n",
            "PGD linf: Attack effectiveness 8.000%.\n",
            "PGD linf: Attack effectiveness 8.000%.\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "PGD linf: Attack effectiveness 6.061%.\n",
            "PGD linf: Attack effectiveness 9.524%.\n",
            "PGD linf: Attack effectiveness 10.345%.\n",
            "PGD linf: Attack effectiveness 10.000%.\n",
            "PGD linf: Attack effectiveness 11.765%.\n",
            "PGD linf: Attack effectiveness 10.000%.\n",
            "PGD linf: Attack effectiveness 14.815%.\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "PGD linf: Attack effectiveness 3.226%.\n",
            "PGD linf: Attack effectiveness 3.333%.\n",
            "PGD linf: Attack effectiveness 8.000%.\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "PGD linf: Attack effectiveness 14.815%.\n",
            "PGD linf: Attack effectiveness 16.667%.\n",
            "PGD linf: Attack effectiveness 10.000%.\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "PGD linf: Attack effectiveness 17.241%.\n",
            "PGD linf: Attack effectiveness 18.182%.\n",
            "PGD linf: Attack effectiveness 3.846%.\n",
            "PGD linf: Attack effectiveness 10.714%.\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "PGD linf: Attack effectiveness 3.125%.\n",
            "PGD linf: Attack effectiveness 6.250%.\n",
            "PGD linf: Attack effectiveness 8.333%.\n",
            "PGD linf: Attack effectiveness 8.108%.\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "PGD linf: Attack effectiveness 3.226%.\n",
            "PGD linf: Attack effectiveness 7.143%.\n",
            "PGD linf: Attack effectiveness 3.571%.\n",
            "PGD linf: Attack effectiveness 2.941%.\n",
            "PGD linf: Attack effectiveness 6.667%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7TiMkblwKWx",
        "outputId": "af65e2b9-876f-4810-eb13-f219664addf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 72.414%.\n",
            "PGD linf: Attack effectiveness 60.000%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 80.000%.\n",
            "PGD linf: Attack effectiveness 64.000%.\n",
            "PGD linf: Attack effectiveness 52.000%.\n",
            "PGD linf: Attack effectiveness 52.941%.\n",
            "PGD linf: Attack effectiveness 48.485%.\n",
            "PGD linf: Attack effectiveness 73.810%.\n",
            "PGD linf: Attack effectiveness 55.172%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 55.882%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 70.370%.\n",
            "PGD linf: Attack effectiveness 56.000%.\n",
            "PGD linf: Attack effectiveness 64.516%.\n",
            "PGD linf: Attack effectiveness 70.000%.\n",
            "PGD linf: Attack effectiveness 72.000%.\n",
            "PGD linf: Attack effectiveness 58.065%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 63.333%.\n",
            "PGD linf: Attack effectiveness 73.333%.\n",
            "PGD linf: Attack effectiveness 45.455%.\n",
            "PGD linf: Attack effectiveness 65.517%.\n",
            "PGD linf: Attack effectiveness 61.364%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 70.270%.\n",
            "PGD linf: Attack effectiveness 43.750%.\n",
            "PGD linf: Attack effectiveness 46.875%.\n",
            "PGD linf: Attack effectiveness 61.111%.\n",
            "PGD linf: Attack effectiveness 64.865%.\n",
            "PGD linf: Attack effectiveness 68.421%.\n",
            "PGD linf: Attack effectiveness 61.290%.\n",
            "PGD linf: Attack effectiveness 78.571%.\n",
            "PGD linf: Attack effectiveness 64.286%.\n",
            "PGD linf: Attack effectiveness 76.471%.\n",
            "PGD linf: Attack effectiveness 46.667%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.26%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PG2 VS PGD_min"
      ],
      "metadata": {
        "id": "ZPY-dkCCw36O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_done(x, y, model):\n",
        "    # Get the model's predictions\n",
        "    outputs = model(x)\n",
        "\n",
        "    # Use argmax to get the predicted class indices\n",
        "    predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    # Ensure y is in the same shape as predicted for comparison\n",
        "    y = y.view_as(predicted)\n",
        "\n",
        "    # Determine if the predictions are incorrect\n",
        "    done = (predicted != y).bool()\n",
        "\n",
        "    return done\n",
        "\n",
        "\n",
        "def pgd_min(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack (loss based on goal's class, which we have to minimize the loss).\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), torch.zeros_like(y.view(-1).long()))\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, torch.zeros_like(y.view(-1).long()))\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "        #print('loss : ',criterion(y_model, y.view(-1).long()))\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "            #print(torch.abs(perturbation).sum())\n",
        "            #print('torch.abs(perturbation).sum(dim=-1) : ',torch.abs(perturbation).sum(dim=-1))\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            #print('l2norm ; ',l2norm)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        #print(torch.abs(x_next - torch.clamp(x_next + perturbation * step_length, min=0., max=1.)).sum())\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), torch.zeros_like(y.view(-1).long())).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        done = get_done(x_next, y, model)\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "bbCZIZiQlS30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mkFFSOXLuzWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=13\n",
        "adv3 = pgd2(mals[i:i+1].to(torch.float32).to(device), mals_y[i:i+1].to(device), model_AT_rFGSM, insertion_array, removal_array, k=100, step_length=.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55e6e04-edac-48fb-c943-d3704baebed4",
        "id": "p4HK-RBquzoT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***********  0\n",
            "loss_mal :  tensor([38.1857], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  1\n",
            "loss_mal :  tensor([34.2699], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  2\n",
            "loss_mal :  tensor([29.9657], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  3\n",
            "loss_mal :  tensor([25.3872], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  4\n",
            "loss_mal :  tensor([20.8934], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  5\n",
            "loss_mal :  tensor([17.8123], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  6\n",
            "loss_mal :  tensor([18.1594], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  7\n",
            "loss_mal :  tensor([15.2948], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  8\n",
            "loss_mal :  tensor([15.7294], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  9\n",
            "loss_mal :  tensor([12.9326], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.3842e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  10\n",
            "loss_mal :  tensor([12.9426], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.3842e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  11\n",
            "loss_mal :  tensor([10.3893], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.0756e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  12\n",
            "loss_mal :  tensor([8.0923], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0003], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  13\n",
            "loss_mal :  tensor([9.6567], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([6.4013e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  14\n",
            "loss_mal :  tensor([7.6484], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0005], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  15\n",
            "loss_mal :  tensor([6.4177], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0016], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  16\n",
            "loss_mal :  tensor([7.7147], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0004], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  17\n",
            "loss_mal :  tensor([6.7666], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0012], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  18\n",
            "loss_mal :  tensor([5.8183], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0030], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  19\n",
            "loss_mal :  tensor([3.7913], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0228], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  20\n",
            "loss_mal :  tensor([3.6471], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0264], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  21\n",
            "loss_mal :  tensor([6.5451], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0014], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  22\n",
            "loss_mal :  tensor([3.4312], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0329], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  23\n",
            "loss_mal :  tensor([1.7684], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.1871], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  24\n",
            "loss_mal :  tensor([2.7752], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0644], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  25\n",
            "loss_mal :  tensor([3.6827], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0255], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  26\n",
            "loss_mal :  tensor([0.7988], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.5976], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  27\n",
            "loss_mal :  tensor([4.7537], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0087], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  28\n",
            "loss_mal :  tensor([3.3431], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0360], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  29\n",
            "loss_mal :  tensor([1.8469], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.1717], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  30\n",
            "loss_mal :  tensor([0.3787], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.1545], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  31\n",
            "loss_mal :  tensor([1.0695], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.4204], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  32\n",
            "loss_mal :  tensor([1.9833], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.1481], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  33\n",
            "loss_mal :  tensor([1.8189], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.1770], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  34\n",
            "loss_mal :  tensor([1.7494], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.1910], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  35\n",
            "loss_mal :  tensor([0.1565], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.9320], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  36\n",
            "loss_mal :  tensor([0.2397], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.5459], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  37\n",
            "loss_mal :  tensor([0.9653], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.4794], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  38\n",
            "loss_mal :  tensor([0.0746], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.6333], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  39\n",
            "loss_mal :  tensor([0.3412], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.2410], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  40\n",
            "loss_mal :  tensor([0.3077], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.3284], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  41\n",
            "loss_mal :  tensor([0.0294], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.5420], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  42\n",
            "loss_mal :  tensor([0.3282], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.2736], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  43\n",
            "loss_mal :  tensor([0.0365], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.3295], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  44\n",
            "loss_mal :  tensor([0.8298], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.5729], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  45\n",
            "loss_mal :  tensor([0.0195], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.9491], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  46\n",
            "loss_mal :  tensor([0.0035], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([5.6541], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  47\n",
            "loss_mal :  tensor([0.0026], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([5.9476], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  48\n",
            "loss_mal :  tensor([0.0009], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([6.9745], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  49\n",
            "loss_mal :  tensor([0.0007], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([7.2607], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  50\n",
            "loss_mal :  tensor([0.0006], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([7.3728], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  51\n",
            "loss_mal :  tensor([0.0005], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([7.5356], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  52\n",
            "loss_mal :  tensor([5.0543e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([9.8933], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  53\n",
            "loss_mal :  tensor([2.6703e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.5321], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  54\n",
            "loss_mal :  tensor([3.8742e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.1599], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  55\n",
            "loss_mal :  tensor([1.2278e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.3117], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  56\n",
            "loss_mal :  tensor([2.7179e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.5147], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  57\n",
            "loss_mal :  tensor([9.2983e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.5798], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  58\n",
            "loss_mal :  tensor([2.0027e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.8165], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  59\n",
            "loss_mal :  tensor([5.0068e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.2088], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  60\n",
            "loss_mal :  tensor([3.5047e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.2593], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  61\n",
            "loss_mal :  tensor([3.2186e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.6607], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  62\n",
            "loss_mal :  tensor([1.3113e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.5381], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  63\n",
            "loss_mal :  tensor([9.5367e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.8148], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  64\n",
            "loss_mal :  tensor([1.3113e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.5161], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  65\n",
            "loss_mal :  tensor([1.6689e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.3080], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  66\n",
            "loss_mal :  tensor([1.3113e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.5208], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  67\n",
            "loss_mal :  tensor([7.1526e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.2034], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  68\n",
            "loss_mal :  tensor([2.7418e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.8268], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  69\n",
            "loss_mal :  tensor([4.7684e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.6124], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  70\n",
            "loss_mal :  tensor([1.7881e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.2622], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  71\n",
            "loss_mal :  tensor([3.5763e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.0045], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  72\n",
            "loss_mal :  tensor([8.3446e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.9858], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  73\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.3753], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  74\n",
            "loss_mal :  tensor([7.1526e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.2143], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  75\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.7451], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  76\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.0896], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  77\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.0098], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  78\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.4239], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  79\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.0536], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  80\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.5323], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  81\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.1801], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  82\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.4030], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  83\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.2882], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  84\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.0552], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  85\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.1186], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  86\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.5041], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  87\n",
            "loss_mal :  tensor([3.5763e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.9173], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  88\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.2590], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  89\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.7290], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  90\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.7429], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  91\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.4080], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  92\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.2161], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  93\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.2731], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  94\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.4290], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  95\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.0085], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  96\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.4040], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  97\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.8233], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  98\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.7385], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  99\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.1252], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "PGD linf: Attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=13\n",
        "adv3 = pgd_min(mals[i:i+1].to(torch.float32).to(device), mals_y[i:i+1].to(device), model_AT_rFGSM, insertion_array, removal_array, k=100, step_length=.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ad855a-1a8e-416f-d870-1889cb1de5d1",
        "id": "LVWC9nF7aZia"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***********  0\n",
            "loss_mal :  tensor([38.1857], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  1\n",
            "loss_mal :  tensor([34.2345], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  2\n",
            "loss_mal :  tensor([29.9309], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  3\n",
            "loss_mal :  tensor([25.2920], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  4\n",
            "loss_mal :  tensor([20.6400], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  5\n",
            "loss_mal :  tensor([17.5564], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  6\n",
            "loss_mal :  tensor([17.9629], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  7\n",
            "loss_mal :  tensor([15.0592], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  8\n",
            "loss_mal :  tensor([15.8962], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  9\n",
            "loss_mal :  tensor([12.6979], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([3.0994e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  10\n",
            "loss_mal :  tensor([12.9943], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.2650e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  11\n",
            "loss_mal :  tensor([11.0808], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.5378e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  12\n",
            "loss_mal :  tensor([8.7707], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0002], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  13\n",
            "loss_mal :  tensor([9.1304], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0001], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  14\n",
            "loss_mal :  tensor([8.6260], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0002], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  15\n",
            "loss_mal :  tensor([8.2149], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0003], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  16\n",
            "loss_mal :  tensor([6.0652], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0023], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  17\n",
            "loss_mal :  tensor([4.6464], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0096], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  18\n",
            "loss_mal :  tensor([7.6485], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0005], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  19\n",
            "loss_mal :  tensor([5.5824], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0038], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  20\n",
            "loss_mal :  tensor([3.1646], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0432], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  21\n",
            "loss_mal :  tensor([3.1386], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0443], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  22\n",
            "loss_mal :  tensor([5.6555], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0035], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  23\n",
            "loss_mal :  tensor([3.6233], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0271], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  24\n",
            "loss_mal :  tensor([3.2767], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0385], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  25\n",
            "loss_mal :  tensor([1.4218], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.2761], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  26\n",
            "loss_mal :  tensor([0.9565], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.4849], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  27\n",
            "loss_mal :  tensor([4.6454], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.0097], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  28\n",
            "loss_mal :  tensor([1.7336], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.1944], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  29\n",
            "loss_mal :  tensor([2.0485], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.1380], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  30\n",
            "loss_mal :  tensor([0.4938], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.9424], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  31\n",
            "loss_mal :  tensor([0.2037], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.6913], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  32\n",
            "loss_mal :  tensor([0.1557], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([1.9365], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  33\n",
            "loss_mal :  tensor([0.0924], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.4275], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  34\n",
            "loss_mal :  tensor([1.2486], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([0.3382], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  35\n",
            "loss_mal :  tensor([0.1078], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([2.2809], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  36\n",
            "loss_mal :  tensor([0.0104], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([4.5724], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  37\n",
            "loss_mal :  tensor([0.0039], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([5.5394], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  38\n",
            "loss_mal :  tensor([0.0020], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([6.1924], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  39\n",
            "loss_mal :  tensor([0.0006], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([7.4991], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  40\n",
            "loss_mal :  tensor([0.0007], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([7.2758], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  41\n",
            "loss_mal :  tensor([0.0002], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([8.4886], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  42\n",
            "loss_mal :  tensor([0.0001], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([9.0697], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  43\n",
            "loss_mal :  tensor([4.1365e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.0920], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  44\n",
            "loss_mal :  tensor([2.1457e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.7516], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  45\n",
            "loss_mal :  tensor([1.5378e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.0796], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  46\n",
            "loss_mal :  tensor([6.6757e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.9121], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  47\n",
            "loss_mal :  tensor([4.1723e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.3956], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  48\n",
            "loss_mal :  tensor([2.9802e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.7136], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  49\n",
            "loss_mal :  tensor([3.2186e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.6321], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  50\n",
            "loss_mal :  tensor([1.3113e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.5583], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  51\n",
            "loss_mal :  tensor([2.7895e-05], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([10.4868], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  52\n",
            "loss_mal :  tensor([9.5367e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.8692], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  53\n",
            "loss_mal :  tensor([0.0009], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([7.0662], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  54\n",
            "loss_mal :  tensor([8.3446e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.0070], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  55\n",
            "loss_mal :  tensor([3.4571e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([12.5824], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  56\n",
            "loss_mal :  tensor([5.9605e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.3068], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  57\n",
            "loss_mal :  tensor([3.5763e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.7389], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  58\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.0653], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  59\n",
            "loss_mal :  tensor([7.3909e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.8143], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  60\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.1435], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  61\n",
            "loss_mal :  tensor([3.5763e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([14.9123], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  62\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.5133], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  63\n",
            "loss_mal :  tensor([9.5367e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([11.5583], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  64\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.7569], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  65\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.4895], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  66\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.2097], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  67\n",
            "loss_mal :  tensor([1.1921e-06], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([13.6698], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  68\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.2498], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  69\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.6732], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  70\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.7017], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  71\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.6343], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  72\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.6715], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  73\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.2091], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  74\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.8232], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  75\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.5095], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  76\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.5486], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  77\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.6970], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  78\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.7999], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  79\n",
            "loss_mal :  tensor([1.1921e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([16.0975], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  80\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.7299], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  81\n",
            "loss_mal :  tensor([2.3842e-07], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([15.4905], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  82\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.8879], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  83\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.2015], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  84\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.0201], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  85\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.2666], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  86\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.9117], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  87\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.2953], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  88\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.0091], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  89\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.7422], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  90\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([17.6773], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  91\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.6948], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  92\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.1372], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  93\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.4145], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  94\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.9832], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  95\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.4932], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  96\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.3465], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  97\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.7350], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  98\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([18.3766], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "***********  99\n",
            "loss_mal :  tensor([-0.], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor([19.5599], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "PGD linf: Attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6yI8cjxbARk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYqfSitVY0z6",
        "outputId": "52fb3a24-204b-4ea4-be27-267a8085f9f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 72.414%.\n",
            "PGD linf: Attack effectiveness 60.000%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 80.000%.\n",
            "PGD linf: Attack effectiveness 64.000%.\n",
            "PGD linf: Attack effectiveness 52.000%.\n",
            "PGD linf: Attack effectiveness 52.941%.\n",
            "PGD linf: Attack effectiveness 48.485%.\n",
            "PGD linf: Attack effectiveness 73.810%.\n",
            "PGD linf: Attack effectiveness 55.172%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 55.882%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 70.370%.\n",
            "PGD linf: Attack effectiveness 56.000%.\n",
            "PGD linf: Attack effectiveness 64.516%.\n",
            "PGD linf: Attack effectiveness 70.000%.\n",
            "PGD linf: Attack effectiveness 72.000%.\n",
            "PGD linf: Attack effectiveness 58.065%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 63.333%.\n",
            "PGD linf: Attack effectiveness 73.333%.\n",
            "PGD linf: Attack effectiveness 45.455%.\n",
            "PGD linf: Attack effectiveness 65.517%.\n",
            "PGD linf: Attack effectiveness 61.364%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 70.270%.\n",
            "PGD linf: Attack effectiveness 43.750%.\n",
            "PGD linf: Attack effectiveness 46.875%.\n",
            "PGD linf: Attack effectiveness 61.111%.\n",
            "PGD linf: Attack effectiveness 64.865%.\n",
            "PGD linf: Attack effectiveness 68.421%.\n",
            "PGD linf: Attack effectiveness 61.290%.\n",
            "PGD linf: Attack effectiveness 78.571%.\n",
            "PGD linf: Attack effectiveness 64.286%.\n",
            "PGD linf: Attack effectiveness 76.471%.\n",
            "PGD linf: Attack effectiveness 46.667%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.26%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weBpa3AzZt0B",
        "outputId": "01b53b9a-24c5-4539-da24-13ffeff109ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 72.414%.\n",
            "PGD linf: Attack effectiveness 68.000%.\n",
            "PGD linf: Attack effectiveness 46.154%.\n",
            "PGD linf: Attack effectiveness 82.857%.\n",
            "PGD linf: Attack effectiveness 68.000%.\n",
            "PGD linf: Attack effectiveness 60.000%.\n",
            "PGD linf: Attack effectiveness 70.588%.\n",
            "PGD linf: Attack effectiveness 63.636%.\n",
            "PGD linf: Attack effectiveness 71.429%.\n",
            "PGD linf: Attack effectiveness 62.069%.\n",
            "PGD linf: Attack effectiveness 85.000%.\n",
            "PGD linf: Attack effectiveness 61.765%.\n",
            "PGD linf: Attack effectiveness 55.000%.\n",
            "PGD linf: Attack effectiveness 74.074%.\n",
            "PGD linf: Attack effectiveness 64.000%.\n",
            "PGD linf: Attack effectiveness 70.968%.\n",
            "PGD linf: Attack effectiveness 73.333%.\n",
            "PGD linf: Attack effectiveness 72.000%.\n",
            "PGD linf: Attack effectiveness 67.742%.\n",
            "PGD linf: Attack effectiveness 77.778%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 80.000%.\n",
            "PGD linf: Attack effectiveness 40.909%.\n",
            "PGD linf: Attack effectiveness 65.517%.\n",
            "PGD linf: Attack effectiveness 65.909%.\n",
            "PGD linf: Attack effectiveness 61.538%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 72.973%.\n",
            "PGD linf: Attack effectiveness 59.375%.\n",
            "PGD linf: Attack effectiveness 62.500%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 72.973%.\n",
            "PGD linf: Attack effectiveness 73.684%.\n",
            "PGD linf: Attack effectiveness 70.968%.\n",
            "PGD linf: Attack effectiveness 78.571%.\n",
            "PGD linf: Attack effectiveness 67.857%.\n",
            "PGD linf: Attack effectiveness 79.412%.\n",
            "PGD linf: Attack effectiveness 46.667%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.33%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 1000, 'step_length': 0.01, 'norm': 'linf', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd2, device, **attack_params)"
      ],
      "metadata": {
        "id": "tqEgfkUMbAJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f02e812-de50-4bf6-89f6-928f75c9eb1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 72.414%.\n",
            "PGD linf: Attack effectiveness 72.000%.\n",
            "PGD linf: Attack effectiveness 53.846%.\n",
            "PGD linf: Attack effectiveness 80.000%.\n",
            "PGD linf: Attack effectiveness 68.000%.\n",
            "PGD linf: Attack effectiveness 64.000%.\n",
            "PGD linf: Attack effectiveness 58.824%.\n",
            "PGD linf: Attack effectiveness 54.545%.\n",
            "PGD linf: Attack effectiveness 73.810%.\n",
            "PGD linf: Attack effectiveness 58.621%.\n",
            "PGD linf: Attack effectiveness 85.000%.\n",
            "PGD linf: Attack effectiveness 64.706%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 77.778%.\n",
            "PGD linf: Attack effectiveness 64.000%.\n",
            "PGD linf: Attack effectiveness 74.194%.\n",
            "PGD linf: Attack effectiveness 70.000%.\n",
            "PGD linf: Attack effectiveness 72.000%.\n",
            "PGD linf: Attack effectiveness 70.968%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 73.333%.\n",
            "PGD linf: Attack effectiveness 83.333%.\n",
            "PGD linf: Attack effectiveness 54.545%.\n",
            "PGD linf: Attack effectiveness 72.414%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 53.846%.\n",
            "PGD linf: Attack effectiveness 78.571%.\n",
            "PGD linf: Attack effectiveness 75.676%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 62.500%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 72.973%.\n",
            "PGD linf: Attack effectiveness 78.947%.\n",
            "PGD linf: Attack effectiveness 70.968%.\n",
            "PGD linf: Attack effectiveness 78.571%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 76.471%.\n",
            "PGD linf: Attack effectiveness 53.333%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 1000, 'step_length': 0.01, 'norm': 'linf', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GABElx1ezzPg",
        "outputId": "cf6dc2d9-d88c-435f-f2ae-147faaf0c425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 72.414%.\n",
            "PGD linf: Attack effectiveness 76.000%.\n",
            "PGD linf: Attack effectiveness 57.692%.\n",
            "PGD linf: Attack effectiveness 82.857%.\n",
            "PGD linf: Attack effectiveness 72.000%.\n",
            "PGD linf: Attack effectiveness 76.000%.\n",
            "PGD linf: Attack effectiveness 82.353%.\n",
            "PGD linf: Attack effectiveness 69.697%.\n",
            "PGD linf: Attack effectiveness 73.810%.\n",
            "PGD linf: Attack effectiveness 75.862%.\n",
            "PGD linf: Attack effectiveness 95.000%.\n",
            "PGD linf: Attack effectiveness 67.647%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 85.185%.\n",
            "PGD linf: Attack effectiveness 72.000%.\n",
            "PGD linf: Attack effectiveness 77.419%.\n",
            "PGD linf: Attack effectiveness 76.667%.\n",
            "PGD linf: Attack effectiveness 84.000%.\n",
            "PGD linf: Attack effectiveness 80.645%.\n",
            "PGD linf: Attack effectiveness 77.778%.\n",
            "PGD linf: Attack effectiveness 80.000%.\n",
            "PGD linf: Attack effectiveness 93.333%.\n",
            "PGD linf: Attack effectiveness 59.091%.\n",
            "PGD linf: Attack effectiveness 79.310%.\n",
            "PGD linf: Attack effectiveness 81.818%.\n",
            "PGD linf: Attack effectiveness 65.385%.\n",
            "PGD linf: Attack effectiveness 78.571%.\n",
            "PGD linf: Attack effectiveness 81.081%.\n",
            "PGD linf: Attack effectiveness 65.625%.\n",
            "PGD linf: Attack effectiveness 81.250%.\n",
            "PGD linf: Attack effectiveness 80.556%.\n",
            "PGD linf: Attack effectiveness 75.676%.\n",
            "PGD linf: Attack effectiveness 84.211%.\n",
            "PGD linf: Attack effectiveness 77.419%.\n",
            "PGD linf: Attack effectiveness 78.571%.\n",
            "PGD linf: Attack effectiveness 82.143%.\n",
            "PGD linf: Attack effectiveness 82.353%.\n",
            "PGD linf: Attack effectiveness 60.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.83%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cGjwR_talp00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NJQQUoXLmZ0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmCcaJuelpx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sgq8ZyPrlpvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RvdTlE5V1MU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsWSFfB8nWHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# validating updated insertion and removal array\n",
        "wirh considering insertion array on the run\n",
        "\n",
        "\n",
        "```\n",
        "pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "E5Dpa5hpuLu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_min(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack (loss based on goal's class, which we have to minimize the loss).\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), torch.zeros_like(y.view(-1).long()))\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, torch.zeros_like(y.view(-1).long()))\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "        #print('loss : ',criterion(y_model, y.view(-1).long()))\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "            #print(torch.abs(perturbation).sum())\n",
        "            #print('torch.abs(perturbation).sum(dim=-1) : ',torch.abs(perturbation).sum(dim=-1))\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            #print('l2norm ; ',l2norm)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        #print(torch.abs(x_next - torch.clamp(x_next + perturbation * step_length, min=0., max=1.)).sum())\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), torch.zeros_like(y.view(-1).long())).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        done = get_done(x_next, y, model)\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "bJasPS-vuzPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = mals[13:14].to(torch.float32).to(device)\n",
        "y = mals_y[13:14].to(device)\n",
        "adv = pgd_min(x, y, model_AT_rFGSM, insertion_array, removal_array, k=1000, step_length=.01, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e869a9d3-a196-4e72-d54e-8389a4f4c3d0",
        "id": "QI_tKs-1oNBs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand insertion_array and removal_array to match the batch size\n",
        "expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "# Update insertion and removal arrays based on input x\n",
        "insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))"
      ],
      "metadata": {
        "id": "5xTLkqYbrAHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.sum())\n",
        "print(adv.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j59hRfeaoo1W",
        "outputId": "a5940c9d-97b8-4c28-b67d-6e2992750db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14., device='cuda:0')\n",
            "tensor(42., device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "insert = ((adv-x) > 0)\n",
        "remove =  ((adv-x) < 0)\n",
        "same = (adv != x)\n",
        "print(insert.sum())\n",
        "print(remove.sum())\n",
        "print(same.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8HRqvvFoysS",
        "outputId": "ac618f87-64de-4d4c-dfe5-5c8672bf1698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(31, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(34, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(insert * insertion_array_updated).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deR6NC6jqzGu",
        "outputId": "c411dd1f-6c8e-43c3-da11-826cd3045c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(31, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(remove * removal_array_updated).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Am53CKBrKg8",
        "outputId": "291fe368-cd9b-4c91-f6b8-32f0c8111e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OhpF6QCUsn0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2K2YsavZtVAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = mals[3:4].to(torch.float32).to(device)\n",
        "y = mals_y[3:4].to(device)\n",
        "adv = pgd_min(x, y, model_AT_rFGSM, insertion_array, removal_array, k=1000, step_length=.01, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7044388-9d7c-4431-b1f9-d009ddaef69c",
        "id": "CfU7y5qitYVh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 0.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand insertion_array and removal_array to match the batch size\n",
        "expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "# Update insertion and removal arrays based on input x\n",
        "insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))"
      ],
      "metadata": {
        "id": "4dhqP9iJtYWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.sum())\n",
        "print(adv.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83877cad-2f9c-462b-b560-71f9042992e6",
        "id": "QdkfvZxetYWA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(128., device='cuda:0')\n",
            "tensor(93., device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "insert = ((adv-x) > 0)\n",
        "remove =  ((adv-x) < 0)\n",
        "same = (adv != x)\n",
        "print(insert.sum())\n",
        "print(remove.sum())\n",
        "print(same.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d750612-1eda-479f-f66d-16327a48e08d",
        "id": "xO-SInkGtYWA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(29, device='cuda:0')\n",
            "tensor(64, device='cuda:0')\n",
            "tensor(93, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(insert * insertion_array_updated).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c18f1f-eb60-47f7-e52a-43570fd77360",
        "id": "FM7EBlUXtYWA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(29, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(remove * removal_array_updated).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f68c97-725c-4bbe-d947-b970a29da642",
        "id": "cQCN8JCztYWB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(64, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 1000, 'step_length': 0.01, 'norm': 'linf', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu4Q10JJtoPD",
        "outputId": "52015930-78c6-44cf-c5e3-ae380ce9ed80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 72.414%.\n",
            "PGD linf: Attack effectiveness 72.000%.\n",
            "PGD linf: Attack effectiveness 53.846%.\n",
            "PGD linf: Attack effectiveness 80.000%.\n",
            "PGD linf: Attack effectiveness 72.000%.\n",
            "PGD linf: Attack effectiveness 68.000%.\n",
            "PGD linf: Attack effectiveness 76.471%.\n",
            "PGD linf: Attack effectiveness 69.697%.\n",
            "PGD linf: Attack effectiveness 73.810%.\n",
            "PGD linf: Attack effectiveness 65.517%.\n",
            "PGD linf: Attack effectiveness 90.000%.\n",
            "PGD linf: Attack effectiveness 67.647%.\n",
            "PGD linf: Attack effectiveness 60.000%.\n",
            "PGD linf: Attack effectiveness 85.185%.\n",
            "PGD linf: Attack effectiveness 68.000%.\n",
            "PGD linf: Attack effectiveness 80.645%.\n",
            "PGD linf: Attack effectiveness 73.333%.\n",
            "PGD linf: Attack effectiveness 84.000%.\n",
            "PGD linf: Attack effectiveness 77.419%.\n",
            "PGD linf: Attack effectiveness 77.778%.\n",
            "PGD linf: Attack effectiveness 76.667%.\n",
            "PGD linf: Attack effectiveness 90.000%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 72.414%.\n",
            "PGD linf: Attack effectiveness 77.273%.\n",
            "PGD linf: Attack effectiveness 65.385%.\n",
            "PGD linf: Attack effectiveness 78.571%.\n",
            "PGD linf: Attack effectiveness 75.676%.\n",
            "PGD linf: Attack effectiveness 62.500%.\n",
            "PGD linf: Attack effectiveness 71.875%.\n",
            "PGD linf: Attack effectiveness 77.778%.\n",
            "PGD linf: Attack effectiveness 72.973%.\n",
            "PGD linf: Attack effectiveness 81.579%.\n",
            "PGD linf: Attack effectiveness 77.419%.\n",
            "PGD linf: Attack effectiveness 78.571%.\n",
            "PGD linf: Attack effectiveness 82.143%.\n",
            "PGD linf: Attack effectiveness 82.353%.\n",
            "PGD linf: Attack effectiveness 53.333%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.84%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlcFrE-At2Es",
        "outputId": "7e575a64-f991-4b96-d0f5-11f540ee7b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 68.966%.\n",
            "PGD linf: Attack effectiveness 52.000%.\n",
            "PGD linf: Attack effectiveness 38.462%.\n",
            "PGD linf: Attack effectiveness 68.571%.\n",
            "PGD linf: Attack effectiveness 56.000%.\n",
            "PGD linf: Attack effectiveness 48.000%.\n",
            "PGD linf: Attack effectiveness 55.882%.\n",
            "PGD linf: Attack effectiveness 57.576%.\n",
            "PGD linf: Attack effectiveness 57.143%.\n",
            "PGD linf: Attack effectiveness 58.621%.\n",
            "PGD linf: Attack effectiveness 70.000%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 35.000%.\n",
            "PGD linf: Attack effectiveness 70.370%.\n",
            "PGD linf: Attack effectiveness 48.000%.\n",
            "PGD linf: Attack effectiveness 58.065%.\n",
            "PGD linf: Attack effectiveness 53.333%.\n",
            "PGD linf: Attack effectiveness 64.000%.\n",
            "PGD linf: Attack effectiveness 54.839%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 63.333%.\n",
            "PGD linf: Attack effectiveness 70.000%.\n",
            "PGD linf: Attack effectiveness 36.364%.\n",
            "PGD linf: Attack effectiveness 51.724%.\n",
            "PGD linf: Attack effectiveness 54.545%.\n",
            "PGD linf: Attack effectiveness 53.846%.\n",
            "PGD linf: Attack effectiveness 71.429%.\n",
            "PGD linf: Attack effectiveness 59.459%.\n",
            "PGD linf: Attack effectiveness 37.500%.\n",
            "PGD linf: Attack effectiveness 53.125%.\n",
            "PGD linf: Attack effectiveness 63.889%.\n",
            "PGD linf: Attack effectiveness 54.054%.\n",
            "PGD linf: Attack effectiveness 65.789%.\n",
            "PGD linf: Attack effectiveness 51.613%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 53.571%.\n",
            "PGD linf: Attack effectiveness 79.412%.\n",
            "PGD linf: Attack effectiveness 33.333%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11GKRtxxvDS7",
        "outputId": "6ba75f1a-a08d-44c4-bfc0-82609ca77e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l2: Attack effectiveness 72.414%.\n",
            "PGD l2: Attack effectiveness 72.000%.\n",
            "PGD l2: Attack effectiveness 53.846%.\n",
            "PGD l2: Attack effectiveness 85.714%.\n",
            "PGD l2: Attack effectiveness 72.000%.\n",
            "PGD l2: Attack effectiveness 68.000%.\n",
            "PGD l2: Attack effectiveness 76.471%.\n",
            "PGD l2: Attack effectiveness 72.727%.\n",
            "PGD l2: Attack effectiveness 71.429%.\n",
            "PGD l2: Attack effectiveness 68.966%.\n",
            "PGD l2: Attack effectiveness 90.000%.\n",
            "PGD l2: Attack effectiveness 64.706%.\n",
            "PGD l2: Attack effectiveness 65.000%.\n",
            "PGD l2: Attack effectiveness 81.481%.\n",
            "PGD l2: Attack effectiveness 68.000%.\n",
            "PGD l2: Attack effectiveness 83.871%.\n",
            "PGD l2: Attack effectiveness 70.000%.\n",
            "PGD l2: Attack effectiveness 92.000%.\n",
            "PGD l2: Attack effectiveness 77.419%.\n",
            "PGD l2: Attack effectiveness 77.778%.\n",
            "PGD l2: Attack effectiveness 80.000%.\n",
            "PGD l2: Attack effectiveness 90.000%.\n",
            "PGD l2: Attack effectiveness 50.000%.\n",
            "PGD l2: Attack effectiveness 68.966%.\n",
            "PGD l2: Attack effectiveness 72.727%.\n",
            "PGD l2: Attack effectiveness 65.385%.\n",
            "PGD l2: Attack effectiveness 85.714%.\n",
            "PGD l2: Attack effectiveness 75.676%.\n",
            "PGD l2: Attack effectiveness 62.500%.\n",
            "PGD l2: Attack effectiveness 75.000%.\n",
            "PGD l2: Attack effectiveness 80.556%.\n",
            "PGD l2: Attack effectiveness 72.973%.\n",
            "PGD l2: Attack effectiveness 81.579%.\n",
            "PGD l2: Attack effectiveness 74.194%.\n",
            "PGD l2: Attack effectiveness 78.571%.\n",
            "PGD l2: Attack effectiveness 82.143%.\n",
            "PGD l2: Attack effectiveness 82.353%.\n",
            "PGD l2: Attack effectiveness 53.333%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQlv0R8cy8ei",
        "outputId": "3b586d1b-bb6f-4ca6-e86b-68e7b14c180d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 72.414%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 46.154%.\n",
            "PGD l1: Attack effectiveness 77.143%.\n",
            "PGD l1: Attack effectiveness 72.000%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 70.588%.\n",
            "PGD l1: Attack effectiveness 60.606%.\n",
            "PGD l1: Attack effectiveness 69.048%.\n",
            "PGD l1: Attack effectiveness 65.517%.\n",
            "PGD l1: Attack effectiveness 85.000%.\n",
            "PGD l1: Attack effectiveness 61.765%.\n",
            "PGD l1: Attack effectiveness 55.000%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 77.419%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 88.000%.\n",
            "PGD l1: Attack effectiveness 64.516%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 70.000%.\n",
            "PGD l1: Attack effectiveness 76.667%.\n",
            "PGD l1: Attack effectiveness 45.455%.\n",
            "PGD l1: Attack effectiveness 65.517%.\n",
            "PGD l1: Attack effectiveness 63.636%.\n",
            "PGD l1: Attack effectiveness 61.538%.\n",
            "PGD l1: Attack effectiveness 82.143%.\n",
            "PGD l1: Attack effectiveness 70.270%.\n",
            "PGD l1: Attack effectiveness 56.250%.\n",
            "PGD l1: Attack effectiveness 62.500%.\n",
            "PGD l1: Attack effectiveness 72.222%.\n",
            "PGD l1: Attack effectiveness 72.973%.\n",
            "PGD l1: Attack effectiveness 78.947%.\n",
            "PGD l1: Attack effectiveness 74.194%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 71.429%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 53.333%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "conclusion"
      ],
      "metadata": {
        "id": "Ul_o4rkOlGbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "        #print('loss : ',criterion(y_model, y.view(-1).long()))\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "\n",
        "        pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        #pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "QlY-uEEslagY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd2(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "\n",
        "    #insertion_array_updated = torch.bitwise_or(insertion_array.to(torch.uint8), x.squeeze().to(torch.uint8) )\n",
        "    #removal_array_updated = torch.bitwise_or(removal_array.to(torch.uint8), (1 - x.squeeze().to(torch.uint8)) )\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "        #print('loss : ',criterion(y_model, y.view(-1).long()))\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "SpW_1QIilagZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_done(x, y, model):\n",
        "    # Get the model's predictions\n",
        "    outputs = model(x)\n",
        "\n",
        "    # Use argmax to get the predicted class indices\n",
        "    predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    # Ensure y is in the same shape as predicted for comparison\n",
        "    y = y.view_as(predicted)\n",
        "\n",
        "    # Determine if the predictions are incorrect\n",
        "    done = (predicted != y).bool()\n",
        "\n",
        "    return done\n",
        "\n",
        "\n",
        "def pgd_min(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack (loss based on goal's class, which we have to minimize the loss).\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), torch.zeros_like(y.view(-1).long()))\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, torch.zeros_like(y.view(-1).long()))\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "        #print('loss : ',criterion(y_model, y.view(-1).long()))\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "            #print(torch.abs(perturbation).sum())\n",
        "            #print('torch.abs(perturbation).sum(dim=-1) : ',torch.abs(perturbation).sum(dim=-1))\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            #print('l2norm ; ',l2norm)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        #print(torch.abs(x_next - torch.clamp(x_next + perturbation * step_length, min=0., max=1.)).sum())\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), torch.zeros_like(y.view(-1).long())).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        done = get_done(x_next, y, model)\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "NBZMVbXDlJHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KWM9Rk7rlFGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a1360c-0121-4b4a-af74-29cbfcf2e145",
        "id": "BALrCnWXopyU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.34%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03975ba4-44f7-44dc-9378-190d4f61177c",
        "id": "44nIZ-BOopyV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.34%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3482cec-ca56-4635-e3a6-40df6cdcd869",
        "id": "_LtUf4DpopyV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lDOzv4PEoxCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "910cc077-94db-40d8-f9c7-5089fe7bdb6c",
        "id": "TZXatuR9opyW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 80.18%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa3a4611-2a25-42f2-cf5c-1659a16d4a68",
        "id": "DPKydw6TopyW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 69.12%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb97212-bdf4-4f26-bfc6-8e75f1caec39",
        "id": "nSywqfscopyW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MHc85REZo0wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e9e502c-6dc1-4574-f730-823817f99c5a",
        "id": "ynb613QSopyX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 78.58%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3788fbe-aba1-4625-f0e5-fa1bf9848105",
        "id": "8sYbWremopyX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.21%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4087e04b-bcd7-413b-8b0f-a3a353adacb5",
        "id": "_Skn51BBopyY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hEGhljhiopKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db551d4d-5554-4691-ab91-ee604468179b",
        "id": "jNJ8MZZ9l44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.34%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PbugNsKmK4E",
        "outputId": "ac165f7d-6fcb-49fa-bcc0-7fa07b3104ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.34%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cak-U6IRmKGe",
        "outputId": "4fab09b7-8e2e-4fd2-f694-cc48a5a5daa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JaqDhY32mRVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc77889-61c3-45e2-9c3e-1c3a6579bc54",
        "id": "ZQT0WTE4l44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 86.46%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5IFBSEtmPtm",
        "outputId": "0fb02373-d479-469a-8c4e-325c53dc0301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 68.32%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpBKzLPNmQPy",
        "outputId": "ba7c0bfb-f8c8-4c0f-ad3a-f9d7f4218b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r_hA66l_mYj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9f2fa6-79d4-48e9-dc56-84c65b36deb1",
        "id": "AfSDAvhYl44L"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvZZq6OPmaEg",
        "outputId": "c25277f0-f675-4ec0-f2ef-387d5de4af5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.75%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2pkuMd_marG",
        "outputId": "040366b5-5500-4231-eb0d-b49d5e904266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ytAbwnAmfA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Study GKDE gradients"
      ],
      "metadata": {
        "id": "F5OlODkKX4jK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8VdyzW2Xerd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y.view(-1).long())\n",
        "    #print('ce: ', ce)\n",
        "    kde = KDE(adv_x, benigns, bandwidth)\n",
        "    #print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done\n",
        "\n",
        "\n",
        "def gkde(x, y, model,bens, bandwidth, penalty_factor, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural, _ = get_loss_kde(x,y,model,bens, bandwidth, penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        print('************** t ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        #y_model = model(x_var)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "        outputs = model(x_var)\n",
        "        ce_loss = criterion(outputs, y.view(-1).long())\n",
        "        print('ce_loss: ', ce_loss)\n",
        "        kde_loss = KDE(x_var, bens, bandwidth)\n",
        "        print('kde_loss: ', kde_loss)\n",
        "        ce_grad = torch.autograd.grad(ce_loss.mean(), x_var, retain_graph=True)[0].data\n",
        "        kde_grad = torch.autograd.grad(kde_loss.mean(), x_var)[0].data\n",
        "        print('ce_grad ',torch.abs(ce_grad).sum(dim=-1).detach())\n",
        "        print('kde_grad ',torch.abs(kde_grad).sum(dim=-1).detach())\n",
        "        penalty_factor = torch.abs(ce_grad).sum(dim=-1).detach()/(torch.abs(kde_grad).sum(dim=-1).detach()+ 1e-20)\n",
        "        print('penalty_factor ',penalty_factor)\n",
        "\n",
        "        if t > 5:\n",
        "          decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "        else:\n",
        "          decayed_penalty_factor = penalty_factor\n",
        "\n",
        "        # Compute loss\n",
        "        loss, _ = get_loss_kde(x_var,y,model,bens, bandwidth, decayed_penalty_factor)\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        #pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            _, done = get_loss_kde(x_next,y,model,bens, bandwidth, penalty_factor)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, y.view(-1).long())\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "uV0R8nbaXfAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-select benign samples\n",
        "benign_samples = []\n",
        "\n",
        "for x_batch, y_batch in test_loader:\n",
        "  benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "# Forward pass to get logits for benign samples\n",
        "with torch.no_grad():  # No need for gradients\n",
        "    outputs = model_AT_rFGSM(ben_x.to(torch.float32))\n",
        "\n",
        "# Calculate softmax probabilities\n",
        "probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "# Sort indices based on probabilities of class 1 (assuming class 1 is the \"positive\" class)\n",
        "sorted_indices = torch.argsort(probabilities[:, 1], descending=False)\n",
        "\n",
        "# Select the top 500 high confidence benign samples\n",
        "top_500_high_confidence_benign_samples = ben_x[sorted_indices[:500]]\n",
        "\n",
        "del benign_samples, outputs, probabilities, ben_x  # Free up memory"
      ],
      "metadata": {
        "id": "U-eZopKFjIGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv = gkde(mals.to(torch.float32).to(device), mals_y.to(device), model_AT_rFGSM, top_500_high_confidence_benign_samples,0.6,1., insertion_array, removal_array, k=100, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krs1slxHjjin",
        "outputId": "3cde2f43-6cfb-463c-8502-43b750dcde8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************** t  0\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 9.2741e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1325e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.3344e-05, 2.2177e-10, 1.1448e-15, 0.0000e+00, 2.2177e-10, 3.4137e-18,\n",
            "        1.3935e-26, 6.6971e-06, 1.2336e-39, 1.8229e-36, 1.3344e-05, 5.0246e-11,\n",
            "        2.2177e-10, 5.7728e-08, 3.5037e-15, 4.1197e-12, 1.2445e-38, 3.1590e-40,\n",
            "        8.5677e-20, 2.3542e-38, 7.7047e-27, 2.7702e-10, 2.2177e-10, 4.0407e-39,\n",
            "        1.8901e-17, 1.1674e-15, 2.3014e-07, 4.1197e-12, 7.4781e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.0327e-15, 1.5589e-35, 3.6246e-23, 0.0000e+00, 1.5589e-35, 3.7404e-14,\n",
            "        0.0000e+00, 8.7472e-02, 0.0000e+00, 0.0000e+00, 1.0327e-15, 5.3577e+02,\n",
            "        1.5589e-35, 1.6707e-14, 1.1631e-37, 1.0270e-30, 0.0000e+00, 2.1986e-10,\n",
            "        1.8128e-25, 0.0000e+00, 0.0000e+00, 1.4061e-06, 1.5589e-35, 1.8835e-19,\n",
            "        3.6079e-13, 8.1566e-07, 1.8215e-31, 1.0270e-30, 1.0897e-14])\n",
            "kde_grad  tensor([1.1016e-05, 3.5169e-10, 2.7524e-15, 0.0000e+00, 3.5169e-10, 9.5880e-18,\n",
            "        5.7000e-26, 5.5288e-06, 7.5966e-39, 1.0206e-35, 1.1016e-05, 7.7543e-11,\n",
            "        3.5169e-10, 6.9480e-08, 7.9209e-15, 7.6794e-12, 7.4443e-38, 1.9407e-39,\n",
            "        2.6343e-19, 1.4114e-37, 3.1644e-26, 4.2795e-10, 3.5169e-10, 2.4811e-38,\n",
            "        5.0840e-17, 2.8093e-15, 2.5477e-07, 7.6794e-12, 2.9783e-03])\n",
            "penalty_factor  tensor([9.3744e-11, 4.4326e-26, 1.3169e-08, 0.0000e+00, 4.4326e-26, 3.8971e+03,\n",
            "        0.0000e+00, 1.5821e+04, 0.0000e+00, 0.0000e+00, 9.3744e-11, 6.9094e+12,\n",
            "        4.4326e-26, 2.4046e-07, 1.4684e-23, 1.3374e-19, 0.0000e+00, 2.1986e+10,\n",
            "        6.6298e-07, 0.0000e+00, 0.0000e+00, 3.2857e+03, 4.4326e-26, 1.8835e+01,\n",
            "        7.0952e+03, 2.9034e+08, 7.1495e-25, 1.3374e-19, 3.6588e-12])\n",
            "************** t  1\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 9.6215e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1673e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.7364e-05, 3.5889e-10, 2.0438e-15, 0.0000e+00, 3.5889e-10, 7.1692e-18,\n",
            "        1.3935e-26, 6.9177e-06, 1.2336e-39, 1.8229e-36, 1.7364e-05, 9.2329e-11,\n",
            "        3.5889e-10, 7.3458e-08, 5.6621e-15, 6.4538e-12, 1.2445e-38, 1.0376e-39,\n",
            "        2.0702e-19, 2.3542e-38, 7.7047e-27, 4.3162e-10, 3.5889e-10, 9.6569e-39,\n",
            "        3.9067e-17, 2.5587e-15, 2.8502e-07, 6.4538e-12, 7.6893e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([3.5289e-15, 1.4416e-33, 7.3212e-22, 0.0000e+00, 1.4416e-33, 1.7363e-11,\n",
            "        0.0000e+00, 8.1916e-01, 0.0000e+00, 0.0000e+00, 3.5289e-15, 6.2337e+02,\n",
            "        1.4416e-33, 2.8014e-13, 2.0506e-35, 8.6054e-29, 0.0000e+00, 6.6531e-09,\n",
            "        9.6210e-25, 0.0000e+00, 0.0000e+00, 4.9014e-06, 1.4416e-33, 2.6390e-18,\n",
            "        1.0897e-12, 5.1903e-06, 1.0666e-28, 8.6054e-29, 1.5972e-13])\n",
            "kde_grad  tensor([1.8160e-05, 7.0789e-10, 5.7878e-15, 0.0000e+00, 7.0789e-10, 2.4803e-17,\n",
            "        5.7000e-26, 7.5852e-06, 7.5966e-39, 1.0206e-35, 1.8160e-05, 1.5668e-10,\n",
            "        7.0789e-10, 1.0875e-07, 1.4909e-14, 1.4090e-11, 7.4443e-38, 6.7503e-39,\n",
            "        6.9992e-19, 1.4114e-37, 3.1644e-26, 7.4803e-10, 7.0789e-10, 6.1113e-38,\n",
            "        1.0927e-16, 6.8721e-15, 4.7459e-07, 1.4090e-11, 5.2694e-03])\n",
            "penalty_factor  tensor([1.9432e-10, 2.0365e-24, 1.2649e-07, 0.0000e+00, 2.0365e-24, 6.9973e+05,\n",
            "        0.0000e+00, 1.0799e+05, 0.0000e+00, 0.0000e+00, 1.9432e-10, 3.9787e+12,\n",
            "        2.0365e-24, 2.5760e-06, 1.3754e-21, 6.1073e-18, 0.0000e+00, 6.6531e+11,\n",
            "        1.3552e-06, 0.0000e+00, 0.0000e+00, 6.5524e+03, 2.0365e-24, 2.6390e+02,\n",
            "        9.9721e+03, 7.5526e+08, 2.2474e-22, 6.1073e-18, 3.0310e-11])\n",
            "************** t  2\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.3584e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1650e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.3439e-05, 6.2128e-10, 4.0406e-15, 0.0000e+00, 6.2128e-10, 1.7692e-17,\n",
            "        1.3935e-26, 7.5188e-06, 1.2336e-39, 1.8229e-36, 2.3439e-05, 1.7606e-10,\n",
            "        6.2128e-10, 9.8817e-08, 1.0016e-14, 1.0751e-11, 1.2445e-38, 2.4089e-39,\n",
            "        5.3579e-19, 2.3542e-38, 7.7047e-27, 7.0119e-10, 6.2128e-10, 2.1177e-38,\n",
            "        8.2252e-17, 5.9727e-15, 4.0464e-07, 1.0751e-11, 8.2887e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([7.4656e-15, 1.1246e-32, 1.7981e-21, 0.0000e+00, 1.1246e-32, 3.3273e-11,\n",
            "        0.0000e+00, 1.0796e+00, 0.0000e+00, 0.0000e+00, 7.4656e-15, 6.2854e+02,\n",
            "        1.1246e-32, 9.4188e-13, 8.2866e-35, 3.4244e-28, 0.0000e+00, 1.0506e-07,\n",
            "        1.2217e-24, 0.0000e+00, 0.0000e+00, 1.1980e-05, 1.1246e-32, 2.9213e-17,\n",
            "        1.8892e-12, 1.1184e-05, 5.3788e-28, 3.4244e-28, 5.5975e-13])\n",
            "kde_grad  tensor([2.6128e-05, 1.2949e-09, 1.1551e-14, 0.0000e+00, 1.2949e-09, 6.1039e-17,\n",
            "        5.7000e-26, 8.8794e-06, 7.5966e-39, 1.0206e-35, 2.6128e-05, 2.9445e-10,\n",
            "        1.2949e-09, 1.5242e-07, 2.6504e-14, 2.4106e-11, 7.4443e-38, 1.6271e-38,\n",
            "        1.8109e-18, 1.4114e-37, 3.1644e-26, 1.2027e-09, 1.2949e-09, 1.3819e-37,\n",
            "        2.2895e-16, 1.6048e-14, 6.9808e-07, 2.4106e-11, 6.6194e-03])\n",
            "penalty_factor  tensor([2.8574e-10, 8.6852e-24, 1.5568e-07, 0.0000e+00, 8.6852e-24, 5.4501e+05,\n",
            "        0.0000e+00, 1.2159e+05, 0.0000e+00, 0.0000e+00, 2.8574e-10, 2.1346e+12,\n",
            "        8.6852e-24, 6.1794e-06, 3.1266e-21, 1.4205e-17, 0.0000e+00, 1.0506e+13,\n",
            "        6.7096e-07, 0.0000e+00, 0.0000e+00, 9.9610e+03, 8.6852e-24, 2.9213e+03,\n",
            "        8.2511e+03, 6.9690e+08, 7.7051e-22, 1.4205e-17, 8.4562e-11])\n",
            "************** t  3\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.7025e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1608e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.2010e-05, 1.0892e-09, 7.9941e-15, 0.0000e+00, 1.0892e-09, 4.2879e-17,\n",
            "        1.3935e-26, 8.1964e-06, 1.2336e-39, 1.8229e-36, 3.2010e-05, 3.3198e-10,\n",
            "        1.0892e-09, 1.3365e-07, 1.7660e-14, 1.7798e-11, 1.2445e-38, 4.9348e-39,\n",
            "        1.3681e-18, 2.3542e-38, 7.7047e-27, 1.1198e-09, 1.0892e-09, 4.7752e-38,\n",
            "        1.7110e-16, 1.3825e-14, 5.8241e-07, 1.7798e-11, 9.0112e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.1756e-14, 6.8905e-32, 4.0493e-21, 0.0000e+00, 6.8905e-32, 6.2882e-11,\n",
            "        0.0000e+00, 1.3587e+00, 0.0000e+00, 0.0000e+00, 2.1756e-14, 6.8419e+02,\n",
            "        6.8905e-32, 2.9358e-12, 3.3108e-34, 1.3261e-27, 0.0000e+00, 1.2461e-06,\n",
            "        1.5574e-24, 0.0000e+00, 0.0000e+00, 2.3855e-05, 6.8905e-32, 2.6250e-16,\n",
            "        3.2374e-12, 2.3583e-05, 2.6036e-27, 1.3261e-27, 1.5457e-12])\n",
            "kde_grad  tensor([3.5867e-05, 2.2996e-09, 2.2653e-14, 0.0000e+00, 2.2996e-09, 1.4590e-16,\n",
            "        5.7000e-26, 1.0199e-05, 7.5966e-39, 1.0206e-35, 3.5867e-05, 5.4258e-10,\n",
            "        2.2996e-09, 2.0900e-07, 4.6321e-14, 4.0487e-11, 7.4443e-38, 3.4378e-38,\n",
            "        4.5750e-18, 1.4114e-37, 3.1644e-26, 1.9005e-09, 2.2996e-09, 3.1902e-37,\n",
            "        4.7136e-16, 3.6733e-14, 9.9710e-07, 4.0487e-11, 7.8553e-03])\n",
            "penalty_factor  tensor([6.0657e-10, 2.9964e-23, 1.7875e-07, 0.0000e+00, 2.9964e-23, 4.3097e+05,\n",
            "        0.0000e+00, 1.3322e+05, 0.0000e+00, 0.0000e+00, 6.0657e-10, 1.2610e+12,\n",
            "        2.9964e-23, 1.4047e-05, 7.1475e-21, 3.2754e-17, 0.0000e+00, 1.2461e+14,\n",
            "        3.3967e-07, 0.0000e+00, 0.0000e+00, 1.2552e+04, 2.9964e-23, 2.6250e+04,\n",
            "        6.8682e+03, 6.4203e+08, 2.6112e-21, 3.2754e-17, 1.9678e-10])\n",
            "************** t  4\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 2.2715e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1565e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1921e-07, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.3643e-05, 1.8847e-09, 1.5592e-14, 0.0000e+00, 1.8847e-09, 1.0099e-16,\n",
            "        1.3935e-26, 8.9815e-06, 1.2336e-39, 1.8229e-36, 4.3643e-05, 6.1583e-10,\n",
            "        1.8847e-09, 1.8032e-07, 3.0713e-14, 2.8450e-11, 1.2445e-38, 1.0078e-38,\n",
            "        3.4176e-18, 2.3542e-38, 7.7047e-27, 1.7539e-09, 1.8847e-09, 9.7802e-38,\n",
            "        3.5012e-16, 3.1429e-14, 8.3200e-07, 2.8450e-11, 9.9633e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.2167e-14, 4.3156e-31, 9.1189e-21, 0.0000e+00, 4.3156e-31, 1.1911e-10,\n",
            "        0.0000e+00, 1.5993e+00, 0.0000e+00, 0.0000e+00, 6.2167e-14, 6.7873e+02,\n",
            "        4.3156e-31, 8.9621e-12, 1.3228e-33, 3.3705e-27, 0.0000e+00, 1.2298e-05,\n",
            "        2.3477e-24, 0.0000e+00, 0.0000e+00, 1.1821e-04, 4.3156e-31, 1.9823e-15,\n",
            "        5.5479e-12, 1.0407e-04, 1.2603e-26, 3.3705e-27, 3.9053e-12])\n",
            "kde_grad  tensor([4.8400e-05, 4.0373e-09, 4.3796e-14, 0.0000e+00, 4.0373e-09, 3.3865e-16,\n",
            "        5.7000e-26, 1.1508e-05, 7.5966e-39, 1.0206e-35, 4.8400e-05, 9.8416e-10,\n",
            "        4.0373e-09, 2.8340e-07, 7.9848e-14, 6.7716e-11, 7.4443e-38, 7.1722e-38,\n",
            "        1.1324e-17, 1.4114e-37, 3.1644e-26, 2.9657e-09, 4.0373e-09, 6.7114e-37,\n",
            "        9.5516e-16, 8.2624e-14, 1.4134e-06, 6.7716e-11, 8.7465e-03])\n",
            "penalty_factor  tensor([1.2844e-09, 1.0689e-22, 2.0821e-07, 0.0000e+00, 1.0689e-22, 3.5173e+05,\n",
            "        0.0000e+00, 1.3897e+05, 0.0000e+00, 0.0000e+00, 1.2844e-09, 6.8965e+11,\n",
            "        1.0689e-22, 3.1624e-05, 1.6567e-20, 4.9773e-17, 0.0000e+00, 1.2298e+15,\n",
            "        2.0714e-07, 0.0000e+00, 0.0000e+00, 3.9858e+04, 1.0689e-22, 1.9823e+05,\n",
            "        5.8083e+03, 1.2595e+09, 8.9162e-21, 4.9773e-17, 4.4650e-10])\n",
            "************** t  5\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 2.7973e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1572e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1921e-07,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.5763e-07, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.9109e-05, 3.2439e-09, 2.9981e-14, 0.0000e+00, 3.2439e-09, 2.3105e-16,\n",
            "        1.3935e-26, 9.9041e-06, 1.2336e-39, 1.8229e-36, 5.9109e-05, 1.1235e-09,\n",
            "        3.2439e-09, 2.4199e-07, 5.2683e-14, 4.6266e-11, 1.2445e-38, 1.8472e-38,\n",
            "        8.3749e-18, 2.3542e-38, 7.7047e-27, 2.7205e-09, 3.2439e-09, 1.8805e-37,\n",
            "        7.0558e-16, 7.0214e-14, 1.1796e-06, 4.6266e-11, 1.1023e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.7764e-13, 2.0958e-30, 2.0493e-20, 0.0000e+00, 2.0958e-30, 2.2579e-10,\n",
            "        0.0000e+00, 2.1647e+00, 0.0000e+00, 0.0000e+00, 1.7764e-13, 6.8874e+02,\n",
            "        2.0958e-30, 2.7023e-11, 5.2853e-33, 1.2417e-26, 0.0000e+00, 7.0598e-05,\n",
            "        3.8284e-24, 0.0000e+00, 0.0000e+00, 2.6931e-04, 2.0958e-30, 1.2279e-14,\n",
            "        9.8367e-12, 2.1428e-04, 6.1003e-26, 1.2417e-26, 9.3877e-12])\n",
            "kde_grad  tensor([6.4872e-05, 6.9745e-09, 8.3465e-14, 0.0000e+00, 6.9745e-09, 7.6330e-16,\n",
            "        5.7000e-26, 1.2766e-05, 7.5966e-39, 1.0206e-35, 6.4872e-05, 1.7547e-09,\n",
            "        6.9745e-09, 3.8130e-07, 1.3575e-13, 1.1018e-10, 7.4443e-38, 1.3453e-37,\n",
            "        2.7499e-17, 1.4114e-37, 3.1644e-26, 4.5359e-09, 6.9745e-09, 1.3167e-36,\n",
            "        1.9064e-15, 1.8260e-13, 1.9885e-06, 1.1018e-10, 9.6349e-03])\n",
            "penalty_factor  tensor([2.7384e-09, 3.0049e-22, 2.4553e-07, 0.0000e+00, 3.0049e-22, 2.9581e+05,\n",
            "        0.0000e+00, 1.6957e+05, 0.0000e+00, 0.0000e+00, 2.7384e-09, 3.9252e+11,\n",
            "        3.0049e-22, 7.0872e-05, 3.8933e-20, 1.1270e-16, 0.0000e+00, 7.0598e+15,\n",
            "        1.3917e-07, 0.0000e+00, 0.0000e+00, 5.9372e+04, 3.0049e-22, 1.2279e+06,\n",
            "        5.1598e+03, 1.1735e+09, 3.0678e-20, 1.1270e-16, 9.7434e-10])\n",
            "************** t  6\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 3.4756e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1589e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.3842e-07,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 4.7684e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.9524e-05, 5.5630e-09, 5.6800e-14, 0.0000e+00, 5.5630e-09, 5.1339e-16,\n",
            "        1.3935e-26, 1.0927e-05, 1.2336e-39, 1.8229e-36, 7.9524e-05, 2.0154e-09,\n",
            "        5.5630e-09, 3.2410e-07, 8.9097e-14, 7.4817e-11, 1.2445e-38, 4.2564e-38,\n",
            "        2.0134e-17, 2.3542e-38, 7.7047e-27, 4.1390e-09, 5.5630e-09, 3.2551e-37,\n",
            "        1.4004e-15, 1.5422e-13, 1.6600e-06, 7.4817e-11, 1.2156e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([5.0761e-13, 1.1923e-29, 4.5796e-20, 0.0000e+00, 1.1923e-29, 4.2856e-10,\n",
            "        0.0000e+00, 2.6888e+00, 0.0000e+00, 0.0000e+00, 5.0761e-13, 6.8874e+02,\n",
            "        1.1923e-29, 8.1428e-11, 1.9879e-32, 4.5203e-26, 0.0000e+00, 1.7382e-04,\n",
            "        6.2429e-24, 0.0000e+00, 0.0000e+00, 5.6683e-04, 1.1923e-29, 6.8372e-14,\n",
            "        1.7545e-11, 4.3569e-04, 2.9529e-25, 4.5203e-26, 2.2721e-11])\n",
            "kde_grad  tensor([8.6362e-05, 1.1845e-08, 1.5682e-13, 0.0000e+00, 1.1845e-08, 1.6707e-15,\n",
            "        5.7000e-26, 1.4064e-05, 7.5966e-39, 1.0206e-35, 8.6362e-05, 3.0702e-09,\n",
            "        1.1845e-08, 5.0702e-07, 2.2767e-13, 1.7659e-10, 7.4443e-38, 3.1597e-37,\n",
            "        6.5492e-17, 1.4114e-37, 3.1644e-26, 6.8824e-09, 1.1845e-08, 2.3220e-36,\n",
            "        3.7472e-15, 3.9641e-13, 2.7763e-06, 1.7659e-10, 1.0625e-02])\n",
            "penalty_factor  tensor([5.8777e-09, 1.0066e-21, 2.9203e-07, 0.0000e+00, 1.0066e-21, 2.5652e+05,\n",
            "        0.0000e+00, 1.9118e+05, 0.0000e+00, 0.0000e+00, 5.8777e-09, 2.2433e+11,\n",
            "        1.0066e-21, 1.6060e-04, 8.7313e-20, 2.5598e-16, 0.0000e+00, 1.7382e+16,\n",
            "        9.5309e-08, 0.0000e+00, 0.0000e+00, 8.2359e+04, 1.0066e-21, 6.8372e+06,\n",
            "        4.6821e+03, 1.0991e+09, 1.0636e-19, 2.5598e-16, 2.1385e-09])\n",
            "************** t  7\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 4.2848e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1601e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1921e-06,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.4305e-06, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.0729e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.0628e-04, 9.4263e-09, 1.0608e-13, 0.0000e+00, 9.4263e-09, 1.1080e-15,\n",
            "        1.3935e-26, 1.2037e-05, 1.2336e-39, 1.8229e-36, 1.0628e-04, 3.5552e-09,\n",
            "        9.4263e-09, 4.3129e-07, 1.4868e-13, 1.1955e-10, 1.2445e-38, 1.0787e-37,\n",
            "        4.7480e-17, 2.3542e-38, 7.7047e-27, 6.2459e-09, 9.4263e-09, 4.9218e-37,\n",
            "        2.7346e-15, 3.3286e-13, 2.3183e-06, 1.1955e-10, 1.3389e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.4505e-12, 6.8402e-29, 1.0251e-19, 0.0000e+00, 6.8402e-29, 8.1343e-10,\n",
            "        0.0000e+00, 3.2077e+00, 0.0000e+00, 0.0000e+00, 1.4505e-12, 6.8874e+02,\n",
            "        6.8402e-29, 2.4536e-10, 7.9423e-32, 1.7351e-25, 0.0000e+00, 8.2211e-04,\n",
            "        1.0180e-23, 0.0000e+00, 0.0000e+00, 1.1842e-03, 6.8402e-29, 3.2599e-13,\n",
            "        3.1381e-11, 9.5006e-04, 1.4367e-24, 1.7351e-25, 5.5322e-11])\n",
            "kde_grad  tensor([1.1419e-04, 1.9874e-08, 2.9045e-13, 0.0000e+00, 1.9874e-08, 3.5508e-15,\n",
            "        5.7000e-26, 1.5445e-05, 7.5966e-39, 1.0206e-35, 1.1419e-04, 5.3065e-09,\n",
            "        1.9874e-08, 6.6984e-07, 3.7653e-13, 2.8007e-10, 7.4443e-38, 8.1377e-37,\n",
            "        1.5296e-16, 1.4114e-37, 3.1644e-26, 1.0238e-08, 1.9874e-08, 3.5794e-36,\n",
            "        7.2556e-15, 8.4546e-13, 3.8467e-06, 2.8007e-10, 1.1652e-02])\n",
            "penalty_factor  tensor([1.2702e-08, 3.4418e-21, 3.5292e-07, 0.0000e+00, 3.4418e-21, 2.2908e+05,\n",
            "        0.0000e+00, 2.0768e+05, 0.0000e+00, 0.0000e+00, 1.2702e-08, 1.2979e+11,\n",
            "        3.4418e-21, 3.6630e-04, 2.1093e-19, 6.1953e-16, 0.0000e+00, 8.2211e+16,\n",
            "        6.6551e-08, 0.0000e+00, 0.0000e+00, 1.1567e+05, 3.4418e-21, 3.2599e+07,\n",
            "        4.3251e+03, 1.1237e+09, 3.7348e-19, 6.1953e-16, 4.7480e-09])\n",
            "************** t  8\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 5.2738e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1634e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.3842e-06,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.2186e-06, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 2.3842e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.4109e-04, 1.5773e-08, 1.9543e-13, 0.0000e+00, 1.5773e-08, 2.3227e-15,\n",
            "        1.3935e-26, 1.3229e-05, 1.2336e-39, 1.8229e-36, 1.4109e-04, 6.2076e-09,\n",
            "        1.5773e-08, 5.7024e-07, 2.4473e-13, 1.8863e-10, 1.2445e-38, 2.5987e-37,\n",
            "        1.0982e-16, 2.3542e-38, 7.7047e-27, 9.3026e-09, 1.5773e-08, 6.8872e-37,\n",
            "        5.2354e-15, 7.0592e-13, 3.2080e-06, 1.8863e-10, 1.4707e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([4.2057e-12, 3.9267e-28, 2.2939e-19, 0.0000e+00, 3.9267e-28, 1.5439e-09,\n",
            "        0.0000e+00, 3.9058e+00, 0.0000e+00, 0.0000e+00, 4.2057e-12, 7.2351e+02,\n",
            "        3.9267e-28, 7.4628e-10, 3.1733e-31, 6.6947e-25, 0.0000e+00, 1.4471e-03,\n",
            "        1.6601e-23, 0.0000e+00, 0.0000e+00, 2.6792e-03, 3.9267e-28, 1.6372e-12,\n",
            "        5.7497e-11, 2.0282e-03, 6.9817e-24, 6.6947e-25, 1.3459e-10])\n",
            "kde_grad  tensor([1.4998e-04, 3.2956e-08, 5.3021e-13, 0.0000e+00, 3.2956e-08, 7.3285e-15,\n",
            "        5.7000e-26, 1.6925e-05, 7.5966e-39, 1.0206e-35, 1.4998e-04, 9.1385e-09,\n",
            "        3.2956e-08, 8.7919e-07, 6.1417e-13, 4.4027e-10, 7.4443e-38, 1.9921e-36,\n",
            "        3.5031e-16, 1.4114e-37, 3.1644e-26, 1.5011e-08, 3.2956e-08, 5.0994e-36,\n",
            "        1.3854e-14, 1.7715e-12, 5.2990e-06, 4.4027e-10, 1.2770e-02])\n",
            "penalty_factor  tensor([2.8042e-08, 1.1915e-20, 4.3265e-07, 0.0000e+00, 1.1915e-20, 2.1067e+05,\n",
            "        0.0000e+00, 2.3078e+05, 0.0000e+00, 0.0000e+00, 2.8042e-08, 7.9171e+10,\n",
            "        1.1915e-20, 8.4883e-04, 5.1668e-19, 1.5206e-15, 0.0000e+00, 1.4471e+17,\n",
            "        4.7387e-08, 0.0000e+00, 0.0000e+00, 1.7849e+05, 1.1915e-20, 1.6372e+08,\n",
            "        4.1502e+03, 1.1449e+09, 1.3176e-18, 1.5206e-15, 1.0539e-08])\n",
            "************** t  9\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.4359e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1659e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 5.0068e-06,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1525e-06, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 5.0068e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.8606e-04, 2.6093e-08, 3.5491e-13, 0.0000e+00, 2.6093e-08, 4.7292e-15,\n",
            "        1.3935e-26, 1.4507e-05, 1.2336e-39, 1.8229e-36, 1.8606e-04, 1.0723e-08,\n",
            "        2.6093e-08, 7.4910e-07, 3.9731e-13, 2.9515e-10, 1.2445e-38, 5.7132e-37,\n",
            "        2.4915e-16, 2.3542e-38, 7.7047e-27, 1.3669e-08, 2.6093e-08, 8.5414e-37,\n",
            "        9.9268e-15, 1.4694e-12, 4.4129e-06, 2.9515e-10, 1.6128e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.2110e-11, 2.2532e-27, 5.1334e-19, 0.0000e+00, 2.2532e-27, 2.9304e-09,\n",
            "        0.0000e+00, 4.4885e+00, 0.0000e+00, 0.0000e+00, 1.2110e-11, 8.0757e+02,\n",
            "        2.2532e-27, 2.2748e-09, 1.2919e-30, 2.5709e-24, 0.0000e+00, 2.9371e-03,\n",
            "        2.7070e-23, 0.0000e+00, 0.0000e+00, 5.9480e-03, 2.2532e-27, 8.4685e-12,\n",
            "        1.0324e-10, 4.2652e-03, 3.3973e-23, 2.5709e-24, 3.2731e-10])\n",
            "kde_grad  tensor([1.9564e-04, 5.3972e-08, 9.5406e-13, 0.0000e+00, 5.3972e-08, 1.4687e-14,\n",
            "        5.7000e-26, 1.8504e-05, 7.5966e-39, 1.0206e-35, 1.9564e-04, 1.5559e-08,\n",
            "        5.3972e-08, 1.1465e-06, 9.8803e-13, 6.8409e-10, 7.4443e-38, 4.4199e-36,\n",
            "        7.8671e-16, 1.4114e-37, 3.1644e-26, 2.1708e-08, 5.3972e-08, 6.4365e-36,\n",
            "        2.6007e-14, 3.6484e-12, 7.2310e-06, 6.8409e-10, 1.3942e-02])\n",
            "penalty_factor  tensor([6.1900e-08, 4.1748e-20, 5.3806e-07, 0.0000e+00, 4.1748e-20, 1.9952e+05,\n",
            "        0.0000e+00, 2.4257e+05, 0.0000e+00, 0.0000e+00, 6.1900e-08, 5.1902e+10,\n",
            "        4.1748e-20, 1.9842e-03, 1.3075e-18, 3.7581e-15, 0.0000e+00, 2.9371e+17,\n",
            "        3.4409e-08, 0.0000e+00, 0.0000e+00, 2.7400e+05, 4.1748e-20, 8.4685e+08,\n",
            "        3.9698e+03, 1.1691e+09, 4.6982e-18, 3.7581e-15, 2.3476e-08])\n",
            "************** t  10\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 7.8545e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1676e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.0967e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.6451e-05, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.0490e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.4373e-04, 4.2647e-08, 6.3539e-13, 0.0000e+00, 4.2647e-08, 9.3527e-15,\n",
            "        1.3935e-26, 1.5873e-05, 1.2336e-39, 1.8229e-36, 2.4373e-04, 1.8265e-08,\n",
            "        4.2647e-08, 9.7771e-07, 6.3489e-13, 4.5699e-10, 1.2445e-38, 1.4313e-36,\n",
            "        5.5432e-16, 2.3542e-38, 7.7047e-27, 1.9819e-08, 4.2647e-08, 9.2592e-37,\n",
            "        1.8536e-14, 3.0086e-12, 6.0246e-06, 4.5699e-10, 1.7647e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([3.4871e-11, 1.2930e-26, 1.1488e-18, 0.0000e+00, 1.2930e-26, 5.5621e-09,\n",
            "        0.0000e+00, 5.6970e+00, 0.0000e+00, 0.0000e+00, 3.4871e-11, 8.0761e+02,\n",
            "        1.2930e-26, 6.9140e-09, 4.8563e-30, 9.8724e-24, 0.0000e+00, 6.4069e-03,\n",
            "        4.4143e-23, 0.0000e+00, 0.0000e+00, 1.4238e-02, 1.2930e-26, 4.3973e-11,\n",
            "        1.8508e-10, 8.7869e-03, 1.6531e-22, 9.8724e-24, 7.9603e-10])\n",
            "kde_grad  tensor([2.5348e-04, 8.7325e-08, 1.6922e-12, 0.0000e+00, 8.7325e-08, 2.8583e-14,\n",
            "        5.7000e-26, 2.0186e-05, 7.5966e-39, 1.0206e-35, 2.5348e-04, 2.7023e-08,\n",
            "        8.7325e-08, 1.4853e-06, 1.5689e-12, 1.0517e-09, 7.4443e-38, 1.1163e-35,\n",
            "        1.7324e-15, 1.4114e-37, 3.1644e-26, 3.0969e-08, 8.7325e-08, 7.1079e-36,\n",
            "        4.8076e-14, 7.3783e-12, 9.7922e-06, 1.0517e-09, 1.5188e-02])\n",
            "penalty_factor  tensor([1.3757e-07, 1.4807e-19, 6.7886e-07, 0.0000e+00, 1.4807e-19, 1.9459e+05,\n",
            "        0.0000e+00, 2.8223e+05, 0.0000e+00, 0.0000e+00, 1.3757e-07, 2.9886e+10,\n",
            "        1.4807e-19, 4.6550e-03, 3.0954e-18, 9.3873e-15, 0.0000e+00, 6.4069e+17,\n",
            "        2.5480e-08, 0.0000e+00, 0.0000e+00, 4.5976e+05, 1.4807e-19, 4.3973e+09,\n",
            "        3.8498e+03, 1.1909e+09, 1.6882e-17, 9.3873e-15, 5.2413e-08])\n",
            "************** t  11\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 9.6846e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1653e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.3484e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.8742e-05, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 2.2053e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.1715e-04, 6.8872e-08, 1.1214e-12, 0.0000e+00, 6.8872e-08, 1.7965e-14,\n",
            "        1.3935e-26, 1.7329e-05, 1.2336e-39, 1.8229e-36, 3.1715e-04, 3.1652e-08,\n",
            "        6.8872e-08, 1.2678e-06, 1.0027e-12, 7.0012e-10, 1.2445e-38, 3.2395e-36,\n",
            "        1.2095e-15, 2.3542e-38, 7.7047e-27, 2.8324e-08, 6.8872e-08, 8.8475e-37,\n",
            "        3.4088e-14, 6.0391e-12, 8.1628e-06, 7.0012e-10, 1.9266e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.0041e-10, 7.4198e-26, 2.5707e-18, 0.0000e+00, 7.4198e-26, 1.0557e-08,\n",
            "        0.0000e+00, 7.0794e+00, 0.0000e+00, 0.0000e+00, 1.0041e-10, 8.6126e+02,\n",
            "        7.4198e-26, 2.1014e-08, 1.9657e-29, 3.7912e-23, 0.0000e+00, 1.3550e-02,\n",
            "        7.1983e-23, 0.0000e+00, 0.0000e+00, 3.3975e-02, 7.4198e-26, 1.0527e-10,\n",
            "        3.3274e-10, 1.8490e-02, 8.0440e-22, 3.7912e-23, 1.9798e-09])\n",
            "kde_grad  tensor([3.2620e-04, 1.3958e-07, 2.9585e-12, 0.0000e+00, 1.3958e-07, 5.4014e-14,\n",
            "        5.7000e-26, 2.1971e-05, 7.5966e-39, 1.0206e-35, 3.2620e-04, 4.8205e-08,\n",
            "        1.3958e-07, 1.9117e-06, 2.4576e-12, 1.5996e-09, 7.4443e-38, 2.5468e-35,\n",
            "        3.7406e-15, 1.4114e-37, 3.1644e-26, 4.3647e-08, 1.3958e-07, 6.9165e-36,\n",
            "        8.7515e-14, 1.4673e-11, 1.3159e-05, 1.5996e-09, 1.6507e-02])\n",
            "penalty_factor  tensor([3.0782e-07, 5.3157e-19, 8.6891e-07, 0.0000e+00, 5.3157e-19, 1.9545e+05,\n",
            "        0.0000e+00, 3.2221e+05, 0.0000e+00, 0.0000e+00, 3.0782e-07, 1.7866e+10,\n",
            "        5.3157e-19, 1.0992e-02, 7.9986e-18, 2.3700e-14, 0.0000e+00, 1.3550e+18,\n",
            "        1.9243e-08, 0.0000e+00, 0.0000e+00, 7.7841e+05, 5.3157e-19, 1.0527e+10,\n",
            "        3.8021e+03, 1.2601e+09, 6.1127e-17, 2.3700e-14, 1.1994e-07])\n",
            "************** t  12\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.1958e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1680e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 4.2914e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.3098e-05, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 4.5895e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.0996e-04, 1.0989e-07, 1.9509e-12, 0.0000e+00, 1.0989e-07, 3.3518e-14,\n",
            "        1.3935e-26, 1.8867e-05, 1.2336e-39, 1.8229e-36, 4.0996e-04, 5.5146e-08,\n",
            "        1.0989e-07, 1.6334e-06, 1.5654e-12, 1.0613e-09, 1.2445e-38, 6.6719e-36,\n",
            "        2.5880e-15, 2.3542e-38, 7.7047e-27, 3.9996e-08, 1.0989e-07, 9.2804e-37,\n",
            "        6.1737e-14, 1.1931e-11, 1.0976e-05, 1.0613e-09, 2.0964e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.9738e-10, 4.2564e-25, 5.7382e-18, 0.0000e+00, 4.2564e-25, 2.0299e-08,\n",
            "        0.0000e+00, 8.9003e+00, 0.0000e+00, 0.0000e+00, 2.9738e-10, 8.5971e+02,\n",
            "        4.2564e-25, 6.3868e-08, 8.5612e-29, 1.4894e-22, 0.0000e+00, 3.1191e-02,\n",
            "        1.1738e-22, 0.0000e+00, 0.0000e+00, 8.6752e-02, 4.2564e-25, 3.4541e-10,\n",
            "        5.9819e-10, 3.8384e-02, 3.9142e-21, 1.4894e-22, 4.8686e-09])\n",
            "kde_grad  tensor([4.1694e-04, 2.2042e-07, 5.0985e-12, 0.0000e+00, 2.2042e-07, 9.9114e-14,\n",
            "        5.7000e-26, 2.3884e-05, 7.5966e-39, 1.0206e-35, 4.1694e-04, 8.5672e-08,\n",
            "        2.2042e-07, 2.4444e-06, 3.8124e-12, 2.4073e-09, 7.4443e-38, 5.2857e-35,\n",
            "        7.9194e-15, 1.4114e-37, 3.1644e-26, 6.0617e-08, 2.2042e-07, 7.3480e-36,\n",
            "        1.5687e-13, 2.8646e-11, 1.7549e-05, 2.4073e-09, 1.7962e-02])\n",
            "penalty_factor  tensor([7.1325e-07, 1.9311e-18, 1.1255e-06, 0.0000e+00, 1.9311e-18, 2.0481e+05,\n",
            "        0.0000e+00, 3.7264e+05, 0.0000e+00, 0.0000e+00, 7.1325e-07, 1.0035e+10,\n",
            "        1.9311e-18, 2.6129e-02, 2.2456e-17, 6.1869e-14, 0.0000e+00, 3.1191e+18,\n",
            "        1.4822e-08, 0.0000e+00, 0.0000e+00, 1.4312e+06, 1.9311e-18, 3.4541e+10,\n",
            "        3.8133e+03, 1.3400e+09, 2.2304e-16, 6.1869e-14, 2.7105e-07])\n",
            "************** t  13\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.4786e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1731e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 5.9007e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.3100e-04, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 9.5720e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.2610e-04, 1.7324e-07, 3.3347e-12, 0.0000e+00, 1.7324e-07, 6.0738e-14,\n",
            "        1.3935e-26, 2.0506e-05, 1.2336e-39, 1.8229e-36, 5.2610e-04, 9.6354e-08,\n",
            "        1.7324e-07, 2.0908e-06, 2.4173e-12, 1.5892e-09, 1.2445e-38, 1.0904e-35,\n",
            "        5.4303e-15, 2.3542e-38, 7.7047e-27, 5.5748e-08, 1.7324e-07, 8.9664e-37,\n",
            "        1.1011e-13, 2.3171e-11, 1.4647e-05, 1.5892e-09, 2.2786e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([8.6840e-10, 2.4426e-24, 1.2986e-17, 0.0000e+00, 2.4426e-24, 3.8968e-08,\n",
            "        0.0000e+00, 1.0989e+01, 0.0000e+00, 0.0000e+00, 8.6840e-10, 8.4578e+02,\n",
            "        2.4426e-24, 1.9190e-07, 3.7744e-28, 5.8492e-22, 0.0000e+00, 3.0702e-02,\n",
            "        1.9163e-22, 0.0000e+00, 0.0000e+00, 2.1778e-01, 2.4426e-24, 1.1206e-09,\n",
            "        1.0748e-09, 8.0050e-02, 1.9046e-20, 5.8492e-22, 1.2201e-08])\n",
            "kde_grad  tensor([5.3002e-04, 3.4386e-07, 8.6703e-12, 0.0000e+00, 3.4386e-07, 1.7660e-13,\n",
            "        5.7000e-26, 2.5882e-05, 7.5966e-39, 1.0206e-35, 5.3002e-04, 1.5007e-07,\n",
            "        3.4386e-07, 3.1051e-06, 5.8486e-12, 3.5873e-09, 7.4443e-38, 8.7043e-35,\n",
            "        1.6439e-14, 1.4114e-37, 3.1644e-26, 8.3073e-08, 3.4386e-07, 7.1876e-36,\n",
            "        2.7688e-13, 5.4927e-11, 2.3224e-05, 3.5873e-09, 1.9435e-02])\n",
            "penalty_factor  tensor([1.6384e-06, 7.1036e-18, 1.4977e-06, 0.0000e+00, 7.1036e-18, 2.2066e+05,\n",
            "        0.0000e+00, 4.2460e+05, 0.0000e+00, 0.0000e+00, 1.6384e-06, 5.6360e+09,\n",
            "        7.1036e-18, 6.1800e-02, 6.4536e-17, 1.6305e-13, 0.0000e+00, 3.0702e+18,\n",
            "        1.1657e-08, 0.0000e+00, 0.0000e+00, 2.6216e+06, 7.1036e-18, 1.1206e+11,\n",
            "        3.8818e+03, 1.4574e+09, 8.2010e-16, 1.6305e-13, 6.2779e-07])\n",
            "************** t  14\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.8276e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1802e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.0514e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 5.8717e-04, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.9954e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([6.7104e-04, 2.6983e-07, 5.6377e-12, 0.0000e+00, 2.6983e-07, 1.0691e-13,\n",
            "        1.3935e-26, 2.2239e-05, 1.2336e-39, 1.8229e-36, 6.7104e-04, 1.6729e-07,\n",
            "        2.6983e-07, 2.6575e-06, 3.6856e-12, 2.3585e-09, 1.2445e-38, 1.9248e-35,\n",
            "        1.1130e-14, 2.3542e-38, 7.7047e-27, 7.6707e-08, 2.6983e-07, 7.8965e-37,\n",
            "        1.9308e-13, 4.4215e-11, 1.9397e-05, 2.3585e-09, 2.4711e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.3759e-09, 1.3978e-23, 2.9203e-17, 0.0000e+00, 1.3978e-23, 7.4804e-08,\n",
            "        0.0000e+00, 1.3560e+01, 0.0000e+00, 0.0000e+00, 2.3759e-09, 8.4578e+02,\n",
            "        1.3978e-23, 5.8047e-07, 1.6764e-27, 2.2809e-21, 0.0000e+00, 4.8473e-02,\n",
            "        3.1503e-22, 0.0000e+00, 0.0000e+00, 5.7562e-01, 1.3978e-23, 3.6952e-09,\n",
            "        1.9412e-09, 1.6687e-01, 9.2678e-20, 2.2809e-21, 3.0250e-08])\n",
            "kde_grad  tensor([6.6832e-04, 5.2993e-07, 1.4518e-11, 0.0000e+00, 5.2993e-07, 3.0553e-13,\n",
            "        5.7000e-26, 2.7983e-05, 7.5966e-39, 1.0206e-35, 6.6832e-04, 2.5965e-07,\n",
            "        5.2993e-07, 3.9215e-06, 8.8778e-12, 5.2843e-09, 7.4443e-38, 1.5471e-34,\n",
            "        3.3477e-14, 1.4114e-37, 3.1644e-26, 1.1236e-07, 5.2993e-07, 6.4075e-36,\n",
            "        4.8153e-13, 1.0346e-10, 3.0499e-05, 5.2843e-09, 2.0983e-02])\n",
            "penalty_factor  tensor([3.5550e-06, 2.6376e-17, 2.0115e-06, 0.0000e+00, 2.6376e-17, 2.4483e+05,\n",
            "        0.0000e+00, 4.8457e+05, 0.0000e+00, 0.0000e+00, 3.5550e-06, 3.2573e+09,\n",
            "        2.6376e-17, 1.4802e-01, 1.8883e-16, 4.3164e-13, 0.0000e+00, 4.8473e+18,\n",
            "        9.4103e-09, 0.0000e+00, 0.0000e+00, 5.1229e+06, 2.6376e-17, 3.6952e+11,\n",
            "        4.0313e+03, 1.6129e+09, 3.0387e-15, 4.3164e-13, 1.4416e-06])\n",
            "************** t  15\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 2.2574e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1892e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.7773e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.5096e-03, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 4.1619e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([8.4833e-04, 4.1523e-07, 9.3956e-12, 0.0000e+00, 4.1523e-07, 1.8276e-13,\n",
            "        1.3935e-26, 2.4064e-05, 1.2336e-39, 1.8229e-36, 8.4833e-04, 2.8799e-07,\n",
            "        4.1523e-07, 3.3576e-06, 5.5626e-12, 3.4632e-09, 1.2445e-38, 3.9479e-35,\n",
            "        2.2457e-14, 2.3542e-38, 7.7047e-27, 1.0421e-07, 4.1523e-07, 6.2834e-37,\n",
            "        3.3342e-13, 8.2898e-11, 2.5493e-05, 3.4632e-09, 2.6739e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([7.1261e-09, 8.0236e-23, 6.7292e-17, 0.0000e+00, 8.0236e-23, 1.4360e-07,\n",
            "        0.0000e+00, 1.6808e+01, 0.0000e+00, 0.0000e+00, 7.1261e-09, 8.5183e+02,\n",
            "        8.0236e-23, 1.7541e-06, 7.1136e-27, 9.1390e-21, 0.0000e+00, 7.7008e-02,\n",
            "        5.1731e-22, 0.0000e+00, 0.0000e+00, 1.4793e+00, 8.0236e-23, 1.2407e-08,\n",
            "        3.5163e-09, 3.4798e-01, 4.5097e-19, 9.1390e-21, 7.4994e-08])\n",
            "kde_grad  tensor([8.4165e-04, 8.0681e-07, 2.3961e-11, 0.0000e+00, 8.0681e-07, 5.1654e-13,\n",
            "        5.7000e-26, 3.0188e-05, 7.5966e-39, 1.0206e-35, 8.4165e-04, 4.4235e-07,\n",
            "        8.0681e-07, 4.9165e-06, 1.3315e-11, 7.7010e-09, 7.4443e-38, 3.1870e-34,\n",
            "        6.6805e-14, 1.4114e-37, 3.1644e-26, 1.5000e-07, 8.0681e-07, 5.1626e-36,\n",
            "        8.2463e-13, 1.9144e-10, 3.9746e-05, 7.7010e-09, 2.2603e-02])\n",
            "penalty_factor  tensor([8.4668e-06, 9.9449e-17, 2.8084e-06, 0.0000e+00, 9.9449e-17, 2.7800e+05,\n",
            "        0.0000e+00, 5.5677e+05, 0.0000e+00, 0.0000e+00, 8.4668e-06, 1.9257e+09,\n",
            "        9.9449e-17, 3.5677e-01, 5.3427e-16, 1.1867e-12, 0.0000e+00, 7.7008e+18,\n",
            "        7.7436e-09, 0.0000e+00, 0.0000e+00, 9.8615e+06, 9.9449e-17, 1.2407e+12,\n",
            "        4.2641e+03, 1.8176e+09, 1.1346e-14, 1.1867e-12, 3.3179e-06])\n",
            "************** t  16\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 2.7881e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2003e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.6449e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.9350e-03, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 8.6771e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.0671e-03, 6.3132e-07, 1.5393e-11, 0.0000e+00, 6.3132e-07, 3.0767e-13,\n",
            "        1.3935e-26, 2.5982e-05, 1.2336e-39, 1.8229e-36, 1.0671e-03, 4.8964e-07,\n",
            "        6.3132e-07, 4.2146e-06, 8.3033e-12, 5.0313e-09, 1.2445e-38, 7.8333e-35,\n",
            "        4.4430e-14, 2.3542e-38, 7.7047e-27, 1.3978e-07, 6.3132e-07, 4.5382e-37,\n",
            "        5.6795e-13, 1.5270e-10, 3.3250e-05, 5.0313e-09, 2.8870e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9924e-08, 4.6059e-22, 1.5674e-16, 0.0000e+00, 4.6059e-22, 2.7896e-07,\n",
            "        0.0000e+00, 2.0280e+01, 0.0000e+00, 0.0000e+00, 1.9924e-08, 8.4538e+02,\n",
            "        4.6059e-22, 5.3006e-06, 3.1616e-26, 3.6071e-20, 0.0000e+00, 1.5679e-01,\n",
            "        8.4947e-22, 0.0000e+00, 0.0000e+00, 3.7263e+00, 4.6059e-22, 4.1067e-08,\n",
            "        6.3555e-09, 7.2541e-01, 2.2046e-18, 3.6071e-20, 1.8631e-07])\n",
            "kde_grad  tensor([1.0485e-03, 1.2135e-06, 3.9018e-11, 0.0000e+00, 1.2135e-06, 8.7041e-13,\n",
            "        5.7000e-26, 3.2494e-05, 7.5966e-39, 1.0206e-35, 1.0485e-03, 7.4300e-07,\n",
            "        1.2135e-06, 6.1235e-06, 1.9731e-11, 1.1103e-08, 7.4443e-38, 6.3461e-34,\n",
            "        1.3070e-13, 1.4114e-37, 3.1644e-26, 1.9767e-07, 1.2135e-06, 3.7747e-36,\n",
            "        1.3897e-12, 3.4799e-10, 5.1398e-05, 1.1103e-08, 2.4293e-02])\n",
            "penalty_factor  tensor([1.9002e-05, 3.7956e-16, 4.0172e-06, 0.0000e+00, 3.7956e-16, 3.2049e+05,\n",
            "        0.0000e+00, 6.2413e+05, 0.0000e+00, 0.0000e+00, 1.9002e-05, 1.1378e+09,\n",
            "        3.7956e-16, 8.6562e-01, 1.6023e-15, 3.2488e-12, 0.0000e+00, 1.5679e+19,\n",
            "        6.4992e-09, 0.0000e+00, 0.0000e+00, 1.8851e+07, 3.7956e-16, 4.1067e+12,\n",
            "        4.5734e+03, 2.0846e+09, 4.2893e-14, 3.2488e-12, 7.6690e-06])\n",
            "************** t  17\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 3.4449e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2130e+01,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.0227e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.0129e-02, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.8176e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.3327e-03, 9.4834e-07, 2.4927e-11, 0.0000e+00, 9.4834e-07, 5.1093e-13,\n",
            "        1.3935e-26, 2.7974e-05, 1.2336e-39, 1.8229e-36, 1.3327e-03, 8.2139e-07,\n",
            "        9.4834e-07, 5.2559e-06, 1.2246e-11, 7.2278e-09, 1.2445e-38, 1.0968e-34,\n",
            "        8.6193e-14, 2.3542e-38, 7.7047e-27, 1.8505e-07, 9.4834e-07, 2.9821e-37,\n",
            "        9.5269e-13, 2.7637e-10, 4.3013e-05, 7.2278e-09, 3.1101e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([5.7026e-08, 2.7031e-21, 3.6255e-16, 0.0000e+00, 2.7031e-21, 5.2643e-07,\n",
            "        0.0000e+00, 2.4626e+01, 0.0000e+00, 0.0000e+00, 5.7026e-08, 8.8683e+02,\n",
            "        2.7031e-21, 1.6178e-05, 1.2815e-25, 1.4425e-19, 0.0000e+00, 1.3535e-01,\n",
            "        1.3949e-21, 0.0000e+00, 0.0000e+00, 9.3261e+00, 2.7031e-21, 1.4985e-07,\n",
            "        1.1878e-08, 1.5049e+00, 1.0778e-17, 1.4425e-19, 4.7795e-07])\n",
            "kde_grad  tensor([1.2992e-03, 1.8029e-06, 6.2567e-11, 0.0000e+00, 1.8029e-06, 1.4448e-12,\n",
            "        5.7000e-26, 3.4932e-05, 7.5966e-39, 1.0206e-35, 1.2992e-03, 1.2291e-06,\n",
            "        1.8029e-06, 7.5767e-06, 2.8898e-11, 1.5841e-08, 7.4443e-38, 8.9565e-34,\n",
            "        2.5071e-13, 1.4114e-37, 3.1644e-26, 2.5737e-07, 1.8029e-06, 2.5106e-36,\n",
            "        2.3059e-12, 6.2135e-10, 6.6001e-05, 1.5841e-08, 2.6052e-02])\n",
            "penalty_factor  tensor([4.3894e-05, 1.4993e-15, 5.7946e-06, 0.0000e+00, 1.4993e-15, 3.6436e+05,\n",
            "        0.0000e+00, 7.0496e+05, 0.0000e+00, 0.0000e+00, 4.3894e-05, 7.2153e+08,\n",
            "        1.4993e-15, 2.1353e+00, 4.4346e-15, 9.1061e-12, 0.0000e+00, 1.3535e+19,\n",
            "        5.5639e-09, 0.0000e+00, 0.0000e+00, 3.6236e+07, 1.4993e-15, 1.4985e+13,\n",
            "        5.1513e+03, 2.4220e+09, 1.6329e-13, 9.1061e-12, 1.8346e-05])\n",
            "************** t  18\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 4.2234e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2254e+01,\n",
            "        -0.0000e+00, 1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00, 5.0401e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.5038e-02, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 3.7916e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.6551e-03, 1.4020e-06, 3.9793e-11, 0.0000e+00, 1.4020e-06, 8.3654e-13,\n",
            "        1.3935e-26, 3.0069e-05, 1.2336e-39, 1.8229e-36, 1.6551e-03, 1.3592e-06,\n",
            "        1.4020e-06, 6.5118e-06, 1.7852e-11, 1.0245e-08, 1.2445e-38, 1.8071e-34,\n",
            "        1.6396e-13, 2.3542e-38, 7.7047e-27, 2.4194e-07, 1.4020e-06, 1.7506e-37,\n",
            "        1.5737e-12, 4.9143e-10, 5.5250e-05, 1.0245e-08, 3.3430e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.6369e-07, 1.6110e-20, 8.3779e-16, 0.0000e+00, 1.6110e-20, 9.9394e-07,\n",
            "        0.0000e+00, 2.9451e+01, 0.0000e+00, 0.0000e+00, 1.6369e-07, 8.9632e+02,\n",
            "        1.6110e-20, 1.2621e-04, 5.6956e-25, 5.8129e-19, 0.0000e+00, 1.9682e-01,\n",
            "        2.2835e-21, 0.0000e+00, 0.0000e+00, 2.2981e+01, 1.6110e-20, 2.5517e-07,\n",
            "        2.2375e-08, 3.1271e+00, 5.2655e-17, 5.8129e-19, 1.1918e-06])\n",
            "kde_grad  tensor([1.5945e-03, 2.6548e-06, 9.8888e-11, 0.0000e+00, 2.6548e-06, 2.3704e-12,\n",
            "        5.7000e-26, 3.7433e-05, 7.5966e-39, 1.0206e-35, 1.5945e-03, 2.0004e-06,\n",
            "        2.6548e-06, 9.3130e-06, 4.1823e-11, 2.2396e-08, 7.4443e-38, 1.4826e-33,\n",
            "        4.7147e-13, 1.4114e-37, 3.1644e-26, 3.3085e-07, 2.6548e-06, 1.4960e-36,\n",
            "        3.7673e-12, 1.0899e-09, 8.4043e-05, 2.2396e-08, 2.7875e-02])\n",
            "penalty_factor  tensor([1.0266e-04, 6.0683e-15, 8.4720e-06, 0.0000e+00, 6.0683e-15, 4.1932e+05,\n",
            "        0.0000e+00, 7.8676e+05, 0.0000e+00, 0.0000e+00, 1.0266e-04, 4.4806e+08,\n",
            "        6.0683e-15, 1.3552e+01, 1.3618e-14, 2.5955e-11, 0.0000e+00, 1.9682e+19,\n",
            "        4.8433e-09, 0.0000e+00, 0.0000e+00, 6.9460e+07, 6.0683e-15, 2.5517e+13,\n",
            "        5.9393e+03, 2.8693e+09, 6.2653e-13, 2.5955e-11, 4.2754e-05])\n",
            "************** t  19\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 5.1572e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2373e+01,\n",
            "        -0.0000e+00, 2.3842e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.8707e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 6.2633e-02, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 7.9675e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.0418e-03, 2.0556e-06, 6.2619e-11, 0.0000e+00, 2.0556e-06, 1.3801e-12,\n",
            "        1.3935e-26, 3.2249e-05, 1.2336e-39, 1.8229e-36, 2.0418e-03, 2.2124e-06,\n",
            "        2.0556e-06, 8.0152e-06, 2.5754e-11, 1.4414e-08, 1.2445e-38, 3.0400e-34,\n",
            "        3.0160e-13, 2.3542e-38, 7.7047e-27, 3.1242e-07, 2.0556e-06, 9.7096e-38,\n",
            "        2.5204e-12, 8.5854e-10, 7.0427e-05, 1.4414e-08, 3.5854e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([4.7506e-07, 9.4556e-20, 1.9363e-15, 0.0000e+00, 9.4556e-20, 2.1254e-06,\n",
            "        0.0000e+00, 3.4943e+01, 0.0000e+00, 0.0000e+00, 4.7506e-07, 8.6847e+02,\n",
            "        9.4556e-20, 3.0404e-04, 2.7990e-24, 2.3341e-18, 0.0000e+00, 2.9214e-01,\n",
            "        3.9691e-21, 0.0000e+00, 0.0000e+00, 5.5863e+01, 9.4556e-20, 7.8681e-07,\n",
            "        3.3459e-08, 6.0946e+00, 2.5726e-16, 2.3341e-18, 2.9911e-06])\n",
            "kde_grad  tensor([1.9436e-03, 3.8494e-06, 1.5405e-10, 0.0000e+00, 3.8494e-06, 4.0496e-12,\n",
            "        5.7000e-26, 4.0024e-05, 7.5966e-39, 1.0206e-35, 1.9436e-03, 3.2125e-06,\n",
            "        3.8494e-06, 1.1372e-05, 6.0063e-11, 3.1263e-08, 7.4443e-38, 2.5034e-33,\n",
            "        8.7169e-13, 1.4114e-37, 3.1644e-26, 4.1993e-07, 3.8494e-06, 8.3951e-37,\n",
            "        6.1020e-12, 1.8778e-09, 1.0619e-04, 3.1263e-08, 2.9758e-02])\n",
            "penalty_factor  tensor([2.4442e-04, 2.4563e-14, 1.2569e-05, 0.0000e+00, 2.4563e-14, 5.2485e+05,\n",
            "        0.0000e+00, 8.7305e+05, 0.0000e+00, 0.0000e+00, 2.4442e-04, 2.7034e+08,\n",
            "        2.4563e-14, 2.6736e+01, 4.6600e-14, 7.4661e-11, 0.0000e+00, 2.9214e+19,\n",
            "        4.5534e-09, 0.0000e+00, 0.0000e+00, 1.3303e+08, 2.4563e-14, 7.8681e+13,\n",
            "        5.4833e+03, 3.2457e+09, 2.4225e-12, 7.4661e-11, 1.0051e-04])\n",
            "************** t  20\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.2250e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2471e+01,\n",
            "        -0.0000e+00, 7.1526e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1544e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.4812e-01, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.5113e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.5022e-03, 2.9778e-06, 9.7133e-11, 0.0000e+00, 2.9778e-06, 2.3126e-12,\n",
            "        1.3935e-26, 3.4492e-05, 1.2336e-39, 1.8229e-36, 2.5022e-03, 3.5531e-06,\n",
            "        2.9778e-06, 9.7958e-06, 3.6799e-11, 2.0064e-08, 1.2445e-38, 5.0474e-34,\n",
            "        5.5159e-13, 2.3542e-38, 7.7047e-27, 3.9713e-07, 2.9778e-06, 5.7717e-38,\n",
            "        4.0283e-12, 1.4616e-09, 8.9088e-05, 2.0064e-08, 3.8368e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.3797e-06, 5.5499e-19, 4.4404e-15, 0.0000e+00, 5.5499e-19, 4.2915e-06,\n",
            "        0.0000e+00, 3.8607e+01, 0.0000e+00, 0.0000e+00, 1.3797e-06, 8.4467e+02,\n",
            "        5.5499e-19, 9.2140e-04, 1.3689e-23, 9.3725e-18, 0.0000e+00, 5.5687e-01,\n",
            "        6.7238e-21, 0.0000e+00, 0.0000e+00, 1.1442e+02, 5.5499e-19, 2.4000e-06,\n",
            "        6.2570e-08, 1.2828e+01, 1.2569e-15, 9.3725e-18, 8.0025e-06])\n",
            "kde_grad  tensor([2.3531e-03, 5.5139e-06, 2.3654e-10, 0.0000e+00, 5.5139e-06, 6.9474e-12,\n",
            "        5.7000e-26, 4.2740e-05, 7.5966e-39, 1.0206e-35, 2.3531e-03, 5.0669e-06,\n",
            "        5.5139e-06, 1.3805e-05, 8.5422e-11, 4.3171e-08, 7.4443e-38, 4.1739e-33,\n",
            "        1.5758e-12, 1.4114e-37, 3.1644e-26, 5.2910e-07, 5.5139e-06, 5.0391e-37,\n",
            "        9.6769e-12, 3.1934e-09, 1.3315e-04, 4.3171e-08, 3.1698e-02])\n",
            "penalty_factor  tensor([5.8633e-04, 1.0065e-13, 1.8772e-05, 0.0000e+00, 1.0065e-13, 6.1771e+05,\n",
            "        0.0000e+00, 9.0329e+05, 0.0000e+00, 0.0000e+00, 5.8633e-04, 1.6670e+08,\n",
            "        1.0065e-13, 6.6742e+01, 1.6025e-13, 2.1710e-10, 0.0000e+00, 5.5687e+19,\n",
            "        4.2669e-09, 0.0000e+00, 0.0000e+00, 2.1626e+08, 1.0065e-13, 2.4000e+14,\n",
            "        6.4659e+03, 4.0170e+09, 9.4397e-12, 2.1710e-10, 2.5246e-04])\n",
            "************** t  21\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 7.4942e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2569e+01,\n",
            "        -0.0000e+00, 2.3842e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, 4.3085e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.2735e-01, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 3.0934e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.0461e-03, 4.2617e-06, 1.4844e-10, 0.0000e+00, 4.2617e-06, 3.9019e-12,\n",
            "        1.3935e-26, 3.6767e-05, 1.2336e-39, 1.8229e-36, 3.0461e-03, 5.6199e-06,\n",
            "        4.2617e-06, 1.1900e-05, 5.2042e-11, 2.7630e-08, 1.2445e-38, 6.8836e-34,\n",
            "        9.8855e-13, 2.3542e-38, 7.7047e-27, 5.0002e-07, 4.2617e-06, 3.1516e-38,\n",
            "        6.3542e-12, 2.4634e-09, 1.1183e-04, 2.7630e-08, 4.0968e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([3.9859e-06, 3.2635e-18, 1.0252e-14, 0.0000e+00, 3.2635e-18, 9.1512e-06,\n",
            "        0.0000e+00, 4.6466e+01, 0.0000e+00, 0.0000e+00, 3.9859e-06, 8.4467e+02,\n",
            "        3.2635e-18, 2.9924e-03, 5.4114e-23, 3.7568e-17, 0.0000e+00, 2.4101e-01,\n",
            "        1.1393e-20, 0.0000e+00, 0.0000e+00, 2.3711e+02, 3.2635e-18, 6.9404e-06,\n",
            "        1.1563e-07, 2.2832e+01, 6.1421e-15, 3.7568e-17, 2.1127e-05])\n",
            "kde_grad  tensor([2.8295e-03, 7.8020e-06, 3.5808e-10, 0.0000e+00, 7.8020e-06, 1.1887e-11,\n",
            "        5.7000e-26, 4.5631e-05, 7.5966e-39, 1.0206e-35, 2.8295e-03, 7.8661e-06,\n",
            "        7.8020e-06, 1.6636e-05, 1.2032e-10, 5.8974e-08, 7.4443e-38, 5.7966e-33,\n",
            "        2.7931e-12, 1.4114e-37, 3.1644e-26, 6.5546e-07, 7.8020e-06, 2.7778e-37,\n",
            "        1.5096e-11, 5.3117e-09, 1.6565e-04, 5.8974e-08, 3.3689e-02])\n",
            "penalty_factor  tensor([1.4087e-03, 4.1829e-13, 2.8630e-05, 0.0000e+00, 4.1829e-13, 7.6985e+05,\n",
            "        0.0000e+00, 1.0183e+06, 0.0000e+00, 0.0000e+00, 1.4087e-03, 1.0738e+08,\n",
            "        4.1829e-13, 1.7988e+02, 4.4974e-13, 6.3702e-10, 0.0000e+00, 2.4101e+19,\n",
            "        4.0789e-09, 0.0000e+00, 0.0000e+00, 3.6175e+08, 4.1829e-13, 6.9404e+14,\n",
            "        7.6601e+03, 4.2985e+09, 3.7078e-11, 6.3702e-10, 6.2713e-04])\n",
            "************** t  22\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 9.1079e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2667e+01,\n",
            "        -0.0000e+00, 7.2717e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.0371e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 6.7009e-01, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0830e-02, -0.0000e+00, -0.0000e+00, 1.1921e-07],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.6835e-03, 6.0225e-06, 2.2374e-10, 0.0000e+00, 6.0225e-06, 6.5839e-12,\n",
            "        1.3935e-26, 3.9171e-05, 1.2336e-39, 1.8229e-36, 3.6835e-03, 8.7530e-06,\n",
            "        6.0225e-06, 1.4363e-05, 7.1434e-11, 3.7643e-08, 1.2445e-38, 8.4426e-34,\n",
            "        1.7381e-12, 2.3542e-38, 7.7047e-27, 6.2218e-07, 6.0225e-06, 1.6268e-38,\n",
            "        9.8699e-12, 4.0724e-09, 1.3931e-04, 3.7643e-08, 4.3647e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.1515e-05, 1.9682e-17, 2.3669e-14, 0.0000e+00, 1.9682e-17, 1.8054e-05,\n",
            "        0.0000e+00, 5.6946e+01, 0.0000e+00, 0.0000e+00, 1.1515e-05, 8.4467e+02,\n",
            "        1.9682e-17, 9.2084e-03, 1.7500e-22, 1.5072e-16, 0.0000e+00, 6.1792e-01,\n",
            "        1.9295e-20, 0.0000e+00, 0.0000e+00, 4.1425e+02, 1.9682e-17, 7.8554e-06,\n",
            "        2.1346e-07, 4.6475e+01, 2.9789e-14, 1.5072e-16, 1.4015e-04])\n",
            "kde_grad  tensor([3.3792e-03, 1.0911e-05, 5.3414e-10, 0.0000e+00, 1.0911e-05, 2.0178e-11,\n",
            "        5.7000e-26, 4.8464e-05, 7.5966e-39, 1.0206e-35, 3.3792e-03, 1.2019e-05,\n",
            "        1.0911e-05, 1.9914e-05, 1.6939e-10, 7.9691e-08, 7.4443e-38, 7.1492e-33,\n",
            "        4.8528e-12, 1.4114e-37, 3.1644e-26, 8.0107e-07, 1.0911e-05, 1.4471e-37,\n",
            "        2.3186e-11, 8.6876e-09, 2.0450e-04, 7.9691e-08, 3.5724e-02])\n",
            "penalty_factor  tensor([3.4076e-03, 1.8040e-12, 4.4312e-05, 0.0000e+00, 1.8040e-12, 8.9475e+05,\n",
            "        0.0000e+00, 1.1750e+06, 0.0000e+00, 0.0000e+00, 3.4076e-03, 7.0277e+07,\n",
            "        1.8040e-12, 4.6241e+02, 1.0331e-12, 1.8912e-09, 0.0000e+00, 6.1792e+19,\n",
            "        3.9761e-09, 0.0000e+00, 0.0000e+00, 5.1712e+08, 1.8040e-12, 7.8554e+14,\n",
            "        9.2066e+03, 5.3496e+09, 1.4567e-10, 1.8912e-09, 3.9232e-03])\n",
            "************** t  23\n",
            "ce_loss:  tensor([-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1921e-07,\n",
            "        -0.0000e+00, 1.1084e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2755e+01,\n",
            "        -0.0000e+00, 2.2292e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2432e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2218e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 1.1798e-01, -0.0000e+00, -0.0000e+00, 2.3842e-07],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.4246e-03, 8.3941e-06, 3.3241e-10, 0.0000e+00, 8.3941e-06, 1.0930e-11,\n",
            "        1.3935e-26, 4.1640e-05, 1.2336e-39, 1.8229e-36, 4.4246e-03, 1.3424e-05,\n",
            "        8.3941e-06, 1.7221e-05, 9.9090e-11, 5.0736e-08, 1.2445e-38, 8.6693e-34,\n",
            "        2.9962e-12, 2.3542e-38, 7.7047e-27, 7.6513e-07, 8.3941e-06, 1.2415e-38,\n",
            "        1.5096e-11, 6.6253e-09, 1.7184e-04, 5.0736e-08, 4.6397e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([3.3129e-05, 1.1721e-16, 5.4644e-14, 0.0000e+00, 1.1721e-16, 9.0756e-05,\n",
            "        0.0000e+00, 7.3485e+01, 0.0000e+00, 0.0000e+00, 3.3129e-05, 8.6119e+02,\n",
            "        1.1721e-16, 2.8367e-02, 8.3935e-22, 6.0465e-16, 0.0000e+00, 5.4442e-01,\n",
            "        3.4457e-20, 0.0000e+00, 0.0000e+00, 6.2200e+02, 1.1721e-16, 1.4841e-05,\n",
            "        3.9501e-07, 7.8930e+01, 1.4303e-13, 6.0465e-16, 3.0610e-04])\n",
            "kde_grad  tensor([4.0083e-03, 1.5096e-05, 7.8531e-10, 0.0000e+00, 1.5096e-05, 3.3896e-11,\n",
            "        5.7000e-26, 5.1359e-05, 7.5966e-39, 1.0206e-35, 4.0083e-03, 1.8075e-05,\n",
            "        1.5096e-05, 2.3681e-05, 2.3377e-10, 1.0652e-07, 7.4443e-38, 7.3896e-33,\n",
            "        8.2653e-12, 1.4114e-37, 3.1644e-26, 9.6711e-07, 1.5096e-05, 1.1133e-37,\n",
            "        3.5063e-11, 1.3944e-08, 2.5127e-04, 1.0652e-07, 3.7798e-02])\n",
            "penalty_factor  tensor([8.2650e-03, 7.7645e-12, 6.9583e-05, 0.0000e+00, 7.7645e-12, 2.6775e+06,\n",
            "        0.0000e+00, 1.4308e+06, 0.0000e+00, 0.0000e+00, 8.2650e-03, 4.7645e+07,\n",
            "        7.7645e-12, 1.1979e+03, 3.5905e-12, 5.6762e-09, 0.0000e+00, 5.4442e+19,\n",
            "        4.1689e-09, 0.0000e+00, 0.0000e+00, 6.4315e+08, 7.7645e-12, 1.4841e+15,\n",
            "        1.1266e+04, 5.6606e+09, 5.6922e-10, 5.6762e-09, 8.0984e-03])\n",
            "************** t  24\n",
            "ce_loss:  tensor([1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1921e-07,\n",
            "        -0.0000e+00, 1.3565e-01, -0.0000e+00, -0.0000e+00, 1.1921e-07, 1.2850e+01,\n",
            "        -0.0000e+00, 6.9735e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.0638e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.0220e+00, -0.0000e+00, 1.1921e-07,\n",
            "        -0.0000e+00, 2.1319e-01, -0.0000e+00, -0.0000e+00, 5.9605e-07],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.2796e-03, 1.1584e-05, 4.8683e-10, 0.0000e+00, 1.1584e-05, 1.8138e-11,\n",
            "        1.3935e-26, 4.4165e-05, 1.2336e-39, 1.8229e-36, 5.2796e-03, 2.0259e-05,\n",
            "        1.1584e-05, 2.0502e-05, 1.3606e-10, 6.7649e-08, 1.2445e-38, 1.0510e-33,\n",
            "        4.9430e-12, 2.3542e-38, 7.7047e-27, 9.3154e-07, 1.1584e-05, 8.7284e-39,\n",
            "        2.2725e-11, 1.0584e-08, 2.1080e-04, 6.7649e-08, 4.9129e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.7267e-04, 6.9966e-16, 1.2616e-13, 0.0000e+00, 6.9966e-16, 1.3321e-04,\n",
            "        0.0000e+00, 8.6611e+01, 0.0000e+00, 0.0000e+00, 1.7267e-04, 9.1898e+02,\n",
            "        6.9966e-16, 9.0538e-02, 4.0176e-21, 2.4257e-15, 0.0000e+00, 8.6326e-01,\n",
            "        3.5221e-20, 0.0000e+00, 0.0000e+00, 7.7761e+02, 6.9966e-16, 7.2180e-05,\n",
            "        7.3705e-07, 1.4121e+02, 6.8612e-13, 2.4257e-15, 7.8157e-04])\n",
            "kde_grad  tensor([4.7222e-03, 2.0590e-05, 1.1380e-09, 0.0000e+00, 2.0590e-05, 5.6073e-11,\n",
            "        5.7000e-26, 5.4305e-05, 7.5966e-39, 1.0206e-35, 4.7222e-03, 2.6776e-05,\n",
            "        2.0590e-05, 2.7997e-05, 3.1929e-10, 1.4085e-07, 7.4443e-38, 8.9934e-33,\n",
            "        1.3883e-11, 1.4114e-37, 3.1644e-26, 1.1849e-06, 2.0590e-05, 7.8908e-38,\n",
            "        5.2221e-11, 2.1991e-08, 3.0543e-04, 1.4085e-07, 4.0118e-02])\n",
            "penalty_factor  tensor([3.6567e-02, 3.3981e-11, 1.1086e-04, 0.0000e+00, 3.3981e-11, 2.3756e+06,\n",
            "        0.0000e+00, 1.5949e+06, 0.0000e+00, 0.0000e+00, 3.6567e-02, 3.4321e+07,\n",
            "        3.3981e-11, 3.2339e+03, 1.2583e-11, 1.7222e-08, 0.0000e+00, 8.6326e+19,\n",
            "        2.5370e-09, 0.0000e+00, 0.0000e+00, 6.5624e+08, 3.3981e-11, 7.2180e+15,\n",
            "        1.4114e+04, 6.4213e+09, 2.2464e-09, 1.7222e-08, 1.9482e-02])\n",
            "************** t  25\n",
            "ce_loss:  tensor([4.7684e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.5763e-07,\n",
            "        -0.0000e+00, 1.6666e-01, -0.0000e+00, -0.0000e+00, 4.7684e-07, 1.2994e+01,\n",
            "        -0.0000e+00, 2.2337e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.3695e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.8549e+00, -0.0000e+00, 1.1921e-07,\n",
            "        -0.0000e+00, 3.7503e-01, -0.0000e+00, -0.0000e+00, 1.5497e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([6.2579e-03, 1.5795e-05, 7.0280e-10, 0.0000e+00, 1.5795e-05, 2.9581e-11,\n",
            "        1.3935e-26, 4.6740e-05, 1.2336e-39, 1.8229e-36, 6.2579e-03, 3.0088e-05,\n",
            "        1.5795e-05, 2.4260e-05, 1.8490e-10, 8.9233e-08, 1.2445e-38, 1.0822e-33,\n",
            "        8.1912e-12, 2.3542e-38, 7.7047e-27, 1.1411e-06, 1.5795e-05, 5.8047e-39,\n",
            "        3.3703e-11, 1.6629e-08, 2.5661e-04, 8.9233e-08, 5.1994e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([5.9639e-04, 4.0390e-15, 2.9606e-13, 0.0000e+00, 4.0390e-15, 3.0305e-04,\n",
            "        0.0000e+00, 1.0732e+02, 0.0000e+00, 0.0000e+00, 5.9639e-04, 9.0729e+02,\n",
            "        4.0390e-15, 2.9412e-01, 1.9236e-20, 9.7317e-15, 0.0000e+00, 1.3613e+00,\n",
            "        5.9651e-20, 0.0000e+00, 0.0000e+00, 8.0062e+02, 4.0390e-15, 1.0615e-04,\n",
            "        1.3940e-06, 2.2193e+02, 3.2639e-12, 9.7317e-15, 2.0345e-03])\n",
            "kde_grad  tensor([5.5253e-03, 2.7741e-05, 1.6253e-09, 0.0000e+00, 2.7741e-05, 9.1334e-11,\n",
            "        5.7000e-26, 5.7292e-05, 7.5966e-39, 1.0206e-35, 5.5253e-03, 3.9077e-05,\n",
            "        2.7741e-05, 3.2853e-05, 4.3150e-10, 1.8422e-07, 7.4443e-38, 9.3034e-33,\n",
            "        2.2731e-11, 1.4114e-37, 3.1644e-26, 1.4739e-06, 2.7741e-05, 5.2897e-38,\n",
            "        7.6554e-11, 3.4043e-08, 3.6840e-04, 1.8422e-07, 4.2258e-02])\n",
            "penalty_factor  tensor([1.0794e-01, 1.4560e-10, 1.8216e-04, 0.0000e+00, 1.4560e-10, 3.3181e+06,\n",
            "        0.0000e+00, 1.8733e+06, 0.0000e+00, 0.0000e+00, 1.0794e-01, 2.3218e+07,\n",
            "        1.4560e-10, 8.9524e+03, 4.4580e-11, 5.2827e-08, 0.0000e+00, 1.3613e+20,\n",
            "        2.6242e-09, 0.0000e+00, 0.0000e+00, 5.4320e+08, 1.4560e-10, 1.0615e+16,\n",
            "        1.8210e+04, 6.5190e+09, 8.8598e-09, 5.2827e-08, 4.8144e-02])\n",
            "************** t  26\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 4.4692e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, 1.1921e-07,\n",
            "        -0.0000e+00, 6.1914e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1644e-07, 1.2445e-38, 1.1125e-33,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 4.9838e-39,\n",
            "        4.9220e-11, 2.5654e-08, 3.0965e-04, 1.1644e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9864e-14, 0.0000e+00, 2.5096e+00,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 8.7417e-05,\n",
            "        2.5566e-06, 3.3728e+02, 1.5691e-11, 3.9864e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3833e-07, 7.4443e-38, 9.6021e-33,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 4.5553e-38,\n",
            "        1.1049e-10, 5.1785e-08, 4.4160e-04, 2.3833e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6726e-07, 0.0000e+00, 2.5096e+20,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 8.7417e+15,\n",
            "        2.3139e+04, 6.5131e+09, 3.5533e-08, 1.6726e-07, 1.1778e-01])\n",
            "************** t  27\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.9865e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, 2.3842e-07,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 7.1086e-34,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 4.5859e-39,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 1.5815e+00,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.2689e-04,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 6.1962e-33,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 4.2131e-38,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 1.5815e+20,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.2689e+16,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  28\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.6794e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, 1.1921e-07,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 5.6759e-34,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 4.5072e-39,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 1.0004e+00,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.2443e-04,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 5.0309e-33,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 4.1589e-38,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 1.0004e+20,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.2443e+16,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  29\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.1640e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, 1.1921e-07,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 3.4072e-34,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 2.6789e-39,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 9.7035e-01,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 7.3542e-05,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 3.0465e-33,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 2.4936e-38,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 9.7035e+19,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 7.3542e+15,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  30\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.7962e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, 1.1921e-07,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 2.5663e-34,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 2.6105e-39,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 1.0698e+00,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 9.0641e-05,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 2.3085e-33,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 2.4403e-38,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 1.0698e+20,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 9.0641e+15,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  31\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.0034e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, 1.1921e-07,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.5639e-34,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.9591e-39,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 1.0163e+00,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 7.2719e-05,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.4180e-33,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.8396e-38,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 1.0163e+20,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 7.2719e+15,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  32\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.3307e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, 1.1921e-07,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.1227e-34,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.9938e-39,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 7.9304e-01,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.0902e-04,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.0265e-33,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.8822e-38,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 7.9304e+19,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.0902e+16,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  33\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.5438e-03,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 6.8834e-35,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.2836e-39,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 8.1842e-01,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.5713e-05,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 6.3396e-34,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.2234e-38,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 8.1842e+19,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.5713e+15,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  34\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 4.1881e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 4.8070e-35,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.2986e-39,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 2.8436e-01,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.7493e-05,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 4.4980e-34,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.2417e-38,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 2.8436e+19,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.7493e+15,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  35\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 5.4785e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 2.5604e-35,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 9.4980e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 3.3244e-01,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.5860e-05,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 2.4177e-34,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 9.1228e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 3.3244e+19,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.5860e+15,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  36\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 5.1187e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.7664e-35,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 7.9826e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 2.5997e-01,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.6605e-05,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.6765e-34,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 7.7197e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 2.5997e+19,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.6605e+15,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  37\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 4.1452e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.4933e-35,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 4.9125e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 2.5155e-01,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.0303e-05,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.4249e-34,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 4.7795e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 2.5155e+19,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.0303e+15,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  38\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 4.2954e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 9.8673e-36,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 4.1829e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 2.1815e-01,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 9.0513e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 9.4625e-35,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 4.0971e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 2.1815e+19,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 9.0513e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  39\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.1633e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 8.5839e-36,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 3.9184e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 1.8860e-01,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 8.1751e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 8.2704e-35,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 3.8542e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 1.8860e+19,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 8.1751e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  40\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.2157e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 5.0023e-36,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 2.8384e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 1.9298e-01,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 7.6821e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 4.8489e-35,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 2.7943e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 1.9298e+19,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 7.6821e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  41\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 8.9165e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 3.4534e-36,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 2.0632e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 5.6079e-02,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 4.4378e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 3.3973e-35,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 2.0435e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 5.6079e+18,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 4.4378e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  42\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2135e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 2.1779e-36,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.9885e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 7.3854e-02,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 4.4543e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 2.1530e-35,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.9907e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 7.3854e+18,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 4.4543e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  43\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.2242e-04,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.4900e-36,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.6184e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 6.2385e-02,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 5.5908e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.4787e-35,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.6278e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 6.2385e+18,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 5.5908e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  44\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 8.3920e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.1646e-36,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.1288e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 5.2783e-02,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 3.2583e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.1611e-35,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.1295e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 5.2783e+18,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 3.2583e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  45\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.9416e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 7.3051e-37,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.1310e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 5.0666e-02,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 2.6702e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 7.3158e-36,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.1369e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 5.0666e+18,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 2.6702e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  46\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 6.2225e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 5.9391e-37,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.0618e-40,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 4.4532e-02,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 2.1188e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 5.9721e-36,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.0567e-39,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 4.4532e+18,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 2.1188e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  47\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 4.5299e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 3.8936e-37,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 8.0262e-41,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 2.1090e-02,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 2.9738e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 3.9535e-36,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 8.0093e-40,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 2.1090e+18,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 2.9738e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  48\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.2424e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 3.1564e-37,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 5.7592e-41,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 2.0390e-02,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 2.1837e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 3.2160e-36,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 5.7781e-40,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 2.0390e+18,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 2.1837e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  49\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.8623e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.9490e-37,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 5.0612e-41,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 2.0337e-02,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.6624e-06,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.9939e-36,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 5.1532e-40,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 2.0337e+18,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.6624e+14,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  50\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.0265e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.3856e-37,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 3.5115e-41,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 1.2733e-02,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 3.1835e-07,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.4243e-36,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 3.6834e-40,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 1.2733e+18,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 3.1835e+13,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  51\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.5391e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 8.3671e-38,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 2.3197e-41,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 1.8458e-02,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 3.5875e-07,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 8.6358e-37,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 2.4167e-40,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 1.8458e+18,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 3.5875e+13,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  52\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.7762e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 6.3329e-38,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.3333e-41,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 9.3821e-03,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 3.7196e-07,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 6.5826e-37,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.3294e-40,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 9.3821e+17,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 3.7196e+13,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  53\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.2983e-06,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 4.3516e-38,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.2591e-41,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 6.2664e-03,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 3.2667e-07,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 4.5421e-37,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.3142e-40,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 6.2664e+17,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 3.2667e+13,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  54\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1206e-05,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 2.4183e-38,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 9.4209e-42,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 5.7960e-03,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.2587e-07,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 2.5391e-37,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.0819e-40,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 5.7960e+17,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.2587e+13,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  55\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 6.9141e-06,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 2.1644e-38,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 6.4880e-42,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 4.6549e-03,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.8145e-07,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 2.2787e-37,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 6.7442e-41,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 4.6549e+17,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.8145e+13,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  56\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 6.6757e-06,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.1720e-38,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 5.0166e-42,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 4.2098e-03,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 2.1241e-07,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.2411e-37,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 5.3978e-41,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 4.2098e+17,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 2.1241e+13,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  57\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.4305e-06,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 8.4371e-39,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 2.7690e-42,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 9.9183e-04,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 1.0377e-07,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 9.0401e-38,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 2.2414e-41,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 9.9183e+16,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 1.0377e+13,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  58\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.1458e-06,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 4.3123e-39,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.8147e-42,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 1.3847e-03,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 8.4882e-08,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 4.6509e-38,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.1279e-41,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 1.3847e+17,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 8.4882e+12,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  59\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.1526e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.7881e-06,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7507e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 3.5643e-39,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.9072e-42,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 6.0788e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 7.6007e-04,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 5.5465e-08,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4623e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 3.8596e-38,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.2871e-41,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 4.1570e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 7.6007e+16,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 5.5465e+12,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  60\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 8.3446e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.0729e-06,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7349e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 3.3532e-39,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.1827e-42,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 7.4752e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 6.5045e-04,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 4.4465e-08,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4593e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 3.6427e-38,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 2.6485e-42,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 5.1226e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 6.5045e+16,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 4.4465e+12,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  61\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 8.3446e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.3113e-06,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7349e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 2.2390e-39,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 9.1365e-43,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 7.4752e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 6.9707e-04,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 2.7952e-08,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4593e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 2.4436e-38,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.7404e-42,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 5.1226e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 6.9707e+16,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 2.7952e+12,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  62\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 8.3446e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 4.7684e-07,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7349e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.4871e-39,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 8.0014e-43,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 7.4752e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 3.2369e-04,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 4.2270e-08,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4593e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.6332e-38,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 1.7488e-42,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 5.1226e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 3.2369e+16,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 4.2270e+12,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  63\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 8.3446e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 5.9605e-07,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7349e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 8.3216e-40,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 4.7224e-43,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 7.4752e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 3.0920e-04,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 3.7796e-08,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4593e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 9.2109e-39,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 8.7021e-43,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 5.1226e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 3.0920e+16,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 3.7796e+12,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  64\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 8.3446e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.5763e-07,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7349e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 6.9701e-40,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 4.7644e-43,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 7.4752e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 2.4260e-04,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 3.5582e-08,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4593e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 7.7439e-39,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 8.7301e-43,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 5.1226e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 2.4260e+16,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 3.5582e+12,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  65\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.5763e-07,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 4.7736e-40,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 3.0408e-43,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 2.6126e-04,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 3.6042e-09,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 5.3343e-39,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 2.6126e+16,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 3.6042e+11,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  66\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 2.5788e-40,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.9198e-43,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 7.6144e-06,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 4.9122e-09,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 2.9398e-39,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 7.6144e+14,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 4.9122e+11,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  67\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.5860e-40,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.4854e-43,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 1.3604e-05,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 4.7867e-09,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.8137e-39,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 1.3604e+15,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 4.7867e+11,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  68\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1228e-05, 9.9954e-10, 0.0000e+00, 2.1228e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1228e-05, 2.8520e-05, 2.4854e-10, 1.1631e-07, 1.2445e-38, 1.1483e-40,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1228e-05, 1.3593e-43,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1631e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.3692e-14, 6.9082e-13, 0.0000e+00, 2.3692e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.3692e-14, 9.1241e-01, 8.9618e-20, 3.9945e-14, 0.0000e+00, 1.5624e-05,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.3692e-14, 2.9895e-09,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 3.9945e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.7001e-05, 2.2886e-09, 0.0000e+00, 3.7001e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.7001e-05, 3.8296e-05, 5.7699e-10, 2.3851e-07, 7.4443e-38, 1.3282e-39,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.7001e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3851e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 6.4031e-10, 3.0185e-04, 0.0000e+00, 6.4031e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        6.4031e-10, 2.3825e+04, 1.5532e-10, 1.6747e-07, 0.0000e+00, 1.5624e+15,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 6.4031e-10, 2.9895e+11,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 1.6747e-07, 1.1778e-01])\n",
            "************** t  69\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1193e-05, 9.9954e-10, 0.0000e+00, 2.1193e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1193e-05, 2.8520e-05, 2.4854e-10, 1.1612e-07, 1.2445e-38, 7.4636e-41,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1193e-05, 9.6690e-44,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1612e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.9957e-14, 6.9082e-13, 0.0000e+00, 2.9957e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.9957e-14, 9.1241e-01, 8.9618e-20, 4.9364e-14, 0.0000e+00, 5.8181e-06,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.9957e-14, 2.4066e-09,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 4.9364e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6980e-05, 2.2886e-09, 0.0000e+00, 3.6980e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6980e-05, 3.8296e-05, 5.7699e-10, 2.3834e-07, 7.4443e-38, 8.6682e-40,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6980e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3834e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 8.1007e-10, 3.0185e-04, 0.0000e+00, 8.1007e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        8.1007e-10, 2.3825e+04, 1.5532e-10, 2.0712e-07, 0.0000e+00, 5.8181e+14,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 8.1007e-10, 2.4066e+11,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 2.0712e-07, 1.1778e-01])\n",
            "************** t  70\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1193e-05, 9.9954e-10, 0.0000e+00, 2.1193e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1193e-05, 2.8520e-05, 2.4854e-10, 1.1612e-07, 1.2445e-38, 7.0352e-41,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1193e-05, 7.2868e-44,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1612e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.9957e-14, 6.9082e-13, 0.0000e+00, 2.9957e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.9957e-14, 9.1241e-01, 8.9618e-20, 4.9364e-14, 0.0000e+00, 4.9077e-06,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.9957e-14, 1.9063e-09,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 4.9364e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6980e-05, 2.2886e-09, 0.0000e+00, 3.6980e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6980e-05, 3.8296e-05, 5.7699e-10, 2.3834e-07, 7.4443e-38, 8.2299e-40,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6980e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3834e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 8.1007e-10, 3.0185e-04, 0.0000e+00, 8.1007e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        8.1007e-10, 2.3825e+04, 1.5532e-10, 2.0712e-07, 0.0000e+00, 4.9077e+14,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 8.1007e-10, 1.9063e+11,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 2.0712e-07, 1.1778e-01])\n",
            "************** t  71\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1193e-05, 9.9954e-10, 0.0000e+00, 2.1193e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1193e-05, 2.8520e-05, 2.4854e-10, 1.1612e-07, 1.2445e-38, 4.4854e-41,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1193e-05, 5.3249e-44,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1612e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.9957e-14, 6.9082e-13, 0.0000e+00, 2.9957e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.9957e-14, 9.1241e-01, 8.9618e-20, 4.9364e-14, 0.0000e+00, 4.4979e-06,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.9957e-14, 8.8757e-10,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 4.9364e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6980e-05, 2.2886e-09, 0.0000e+00, 3.6980e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6980e-05, 3.8296e-05, 5.7699e-10, 2.3834e-07, 7.4443e-38, 5.1948e-40,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6980e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3834e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 8.1007e-10, 3.0185e-04, 0.0000e+00, 8.1007e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        8.1007e-10, 2.3825e+04, 1.5532e-10, 2.0712e-07, 0.0000e+00, 4.4979e+14,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 8.1007e-10, 8.8757e+10,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 2.0712e-07, 1.1778e-01])\n",
            "************** t  72\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1193e-05, 9.9954e-10, 0.0000e+00, 2.1193e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1193e-05, 2.8520e-05, 2.4854e-10, 1.1612e-07, 1.2445e-38, 4.3366e-41,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1193e-05, 2.5223e-44,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1612e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.9957e-14, 6.9082e-13, 0.0000e+00, 2.9957e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.9957e-14, 9.1241e-01, 8.9618e-20, 4.9364e-14, 0.0000e+00, 3.4402e-06,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.9957e-14, 4.9902e-10,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 4.9364e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6980e-05, 2.2886e-09, 0.0000e+00, 3.6980e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6980e-05, 3.8296e-05, 5.7699e-10, 2.3834e-07, 7.4443e-38, 5.0223e-40,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6980e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3834e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 8.1007e-10, 3.0185e-04, 0.0000e+00, 8.1007e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        8.1007e-10, 2.3825e+04, 1.5532e-10, 2.0712e-07, 0.0000e+00, 3.4402e+14,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 8.1007e-10, 4.9902e+10,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 2.0712e-07, 1.1778e-01])\n",
            "************** t  73\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1193e-05, 9.9954e-10, 0.0000e+00, 2.1193e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1193e-05, 2.8520e-05, 2.4854e-10, 1.1612e-07, 1.2445e-38, 2.9310e-41,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1193e-05, 2.1019e-44,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1612e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.9957e-14, 6.9082e-13, 0.0000e+00, 2.9957e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.9957e-14, 9.1241e-01, 8.9618e-20, 4.9364e-14, 0.0000e+00, 3.6347e-06,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.9957e-14, 2.0767e-10,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 4.9364e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6980e-05, 2.2886e-09, 0.0000e+00, 3.6980e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6980e-05, 3.8296e-05, 5.7699e-10, 2.3834e-07, 7.4443e-38, 3.4628e-40,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6980e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3834e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 8.1007e-10, 3.0185e-04, 0.0000e+00, 8.1007e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        8.1007e-10, 2.3825e+04, 1.5532e-10, 2.0712e-07, 0.0000e+00, 3.6347e+14,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 8.1007e-10, 2.0767e+10,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 2.0712e-07, 1.1778e-01])\n",
            "************** t  74\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1193e-05, 9.9954e-10, 0.0000e+00, 2.1193e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1193e-05, 2.8520e-05, 2.4854e-10, 1.1612e-07, 1.2445e-38, 1.7991e-41,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1193e-05, 1.4013e-44,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1612e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.9957e-14, 6.9082e-13, 0.0000e+00, 2.9957e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.9957e-14, 9.1241e-01, 8.9618e-20, 4.9364e-14, 0.0000e+00, 1.2155e-06,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.9957e-14, 3.4184e-10,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 4.9364e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6980e-05, 2.2886e-09, 0.0000e+00, 3.6980e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6980e-05, 3.8296e-05, 5.7699e-10, 2.3834e-07, 7.4443e-38, 2.1240e-40,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6980e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3834e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 8.1007e-10, 3.0185e-04, 0.0000e+00, 8.1007e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        8.1007e-10, 2.3825e+04, 1.5532e-10, 2.0712e-07, 0.0000e+00, 1.2155e+14,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 8.1007e-10, 3.4184e+10,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 2.0712e-07, 1.1778e-01])\n",
            "************** t  75\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1193e-05, 9.9954e-10, 0.0000e+00, 2.1193e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1193e-05, 2.8520e-05, 2.4854e-10, 1.1612e-07, 1.2445e-38, 1.1883e-41,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1193e-05, 9.8091e-45,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1612e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.9957e-14, 6.9082e-13, 0.0000e+00, 2.9957e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.9957e-14, 9.1241e-01, 8.9618e-20, 4.9364e-14, 0.0000e+00, 1.2257e-06,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.9957e-14, 1.8058e-10,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 4.9364e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6980e-05, 2.2886e-09, 0.0000e+00, 3.6980e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6980e-05, 3.8296e-05, 5.7699e-10, 2.3834e-07, 7.4443e-38, 1.3389e-40,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6980e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3834e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 8.1007e-10, 3.0185e-04, 0.0000e+00, 8.1007e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        8.1007e-10, 2.3825e+04, 1.5532e-10, 2.0712e-07, 0.0000e+00, 1.2257e+14,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 8.1007e-10, 1.8058e+10,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 2.0712e-07, 1.1778e-01])\n",
            "************** t  76\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1193e-05, 9.9954e-10, 0.0000e+00, 2.1193e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1193e-05, 2.8520e-05, 2.4854e-10, 1.1592e-07, 1.2445e-38, 1.0248e-41,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1193e-05, 9.8091e-45,\n",
            "        4.9193e-11, 2.5629e-08, 3.0862e-04, 1.1592e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.9957e-14, 6.9082e-13, 0.0000e+00, 2.9957e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.9957e-14, 9.1241e-01, 8.9618e-20, 5.8213e-14, 0.0000e+00, 6.9531e-07,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.9957e-14, 1.3291e-10,\n",
            "        2.5549e-06, 3.3248e+02, 1.5630e-11, 5.8213e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6980e-05, 2.2886e-09, 0.0000e+00, 3.6980e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6980e-05, 3.8296e-05, 5.7699e-10, 2.3816e-07, 7.4443e-38, 1.1524e-40,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6980e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4367e-04, 2.3816e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 8.1007e-10, 3.0185e-04, 0.0000e+00, 8.1007e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        8.1007e-10, 2.3825e+04, 1.5532e-10, 2.4443e-07, 0.0000e+00, 6.9531e+13,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 8.1007e-10, 1.3291e+10,\n",
            "        2.3116e+04, 6.4160e+09, 3.5229e-08, 2.4443e-07, 1.1778e-01])\n",
            "************** t  77\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1157e-05, 9.9954e-10, 0.0000e+00, 2.1157e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1157e-05, 2.8520e-05, 2.4854e-10, 1.1592e-07, 1.2445e-38, 6.0788e-42,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1157e-05, 4.2039e-45,\n",
            "        4.9193e-11, 2.5629e-08, 3.0811e-04, 1.1592e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 3.5665e-14, 6.9082e-13, 0.0000e+00, 3.5665e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        3.5665e-14, 9.1241e-01, 8.9618e-20, 5.8213e-14, 0.0000e+00, 1.3419e-06,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 3.5665e-14, 1.2939e-10,\n",
            "        2.5549e-06, 3.3248e+02, 1.9245e-11, 5.8213e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6959e-05, 2.2886e-09, 0.0000e+00, 3.6959e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6959e-05, 3.8296e-05, 5.7699e-10, 2.3816e-07, 7.4443e-38, 7.0275e-41,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6959e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4352e-04, 2.3816e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 9.6498e-10, 3.0185e-04, 0.0000e+00, 9.6498e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        9.6498e-10, 2.3825e+04, 1.5532e-10, 2.4443e-07, 0.0000e+00, 1.3419e+14,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 9.6498e-10, 1.2939e+10,\n",
            "        2.3116e+04, 6.4160e+09, 4.3391e-08, 2.4443e-07, 1.1778e-01])\n",
            "************** t  78\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1157e-05, 9.9954e-10, 0.0000e+00, 2.1157e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1157e-05, 2.8520e-05, 2.4812e-10, 1.1592e-07, 1.2445e-38, 3.5341e-42,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1157e-05, 2.8026e-45,\n",
            "        4.9193e-11, 2.5629e-08, 3.0811e-04, 1.1592e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 3.5665e-14, 6.9082e-13, 0.0000e+00, 3.5665e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        3.5665e-14, 9.1241e-01, 1.0539e-19, 5.8213e-14, 0.0000e+00, 5.1062e-07,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 3.5665e-14, 9.9462e-11,\n",
            "        2.5549e-06, 3.3248e+02, 1.9245e-11, 5.8213e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6959e-05, 2.2886e-09, 0.0000e+00, 3.6959e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6959e-05, 3.8296e-05, 5.7651e-10, 2.3816e-07, 7.4443e-38, 4.0412e-41,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6959e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4352e-04, 2.3816e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 9.6498e-10, 3.0185e-04, 0.0000e+00, 9.6498e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        9.6498e-10, 2.3825e+04, 1.8281e-10, 2.4443e-07, 0.0000e+00, 5.1062e+13,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 9.6498e-10, 9.9462e+09,\n",
            "        2.3116e+04, 6.4160e+09, 4.3391e-08, 2.4443e-07, 1.1778e-01])\n",
            "************** t  79\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1157e-05, 9.9954e-10, 0.0000e+00, 2.1157e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1157e-05, 2.8520e-05, 2.4812e-10, 1.1592e-07, 1.2445e-38, 2.9974e-42,\n",
            "        1.3308e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1157e-05, 2.8026e-45,\n",
            "        4.9193e-11, 2.5629e-08, 3.0811e-04, 1.1592e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 3.5665e-14, 6.9082e-13, 0.0000e+00, 3.5665e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        3.5665e-14, 9.1241e-01, 1.0539e-19, 5.8213e-14, 0.0000e+00, 3.9513e-07,\n",
            "        1.0103e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 3.5665e-14, 3.5979e-11,\n",
            "        2.5549e-06, 3.3248e+02, 1.9245e-11, 5.8213e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6959e-05, 2.2886e-09, 0.0000e+00, 3.6959e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6959e-05, 3.8296e-05, 5.7651e-10, 2.3816e-07, 7.4443e-38, 3.4629e-41,\n",
            "        3.6484e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6959e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4352e-04, 2.3816e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 9.6498e-10, 3.0185e-04, 0.0000e+00, 9.6498e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        9.6498e-10, 2.3825e+04, 1.8281e-10, 2.4443e-07, 0.0000e+00, 3.9513e+13,\n",
            "        2.7690e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 9.6498e-10, 3.5979e+09,\n",
            "        2.3116e+04, 6.4160e+09, 4.3391e-08, 2.4443e-07, 1.1778e-01])\n",
            "************** t  80\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 9.5367e-07,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1157e-05, 9.9954e-10, 0.0000e+00, 2.1157e-05, 4.7270e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1157e-05, 2.8520e-05, 2.4771e-10, 1.1592e-07, 1.2445e-38, 1.7026e-42,\n",
            "        1.3290e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1157e-05, 1.4013e-45,\n",
            "        4.9193e-11, 2.5629e-08, 3.0811e-04, 1.1592e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 3.5665e-14, 6.9082e-13, 0.0000e+00, 3.5665e-14, 8.4679e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        3.5665e-14, 9.1241e-01, 1.2169e-19, 5.8213e-14, 0.0000e+00, 3.0875e-07,\n",
            "        1.0847e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 3.5665e-14, 3.9535e-11,\n",
            "        2.5549e-06, 3.3248e+02, 1.9245e-11, 5.8213e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6959e-05, 2.2886e-09, 0.0000e+00, 3.6959e-05, 1.4577e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6959e-05, 3.8296e-05, 5.7602e-10, 2.3816e-07, 7.4443e-38, 1.8158e-41,\n",
            "        3.6460e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6959e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4352e-04, 2.3816e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 9.6498e-10, 3.0185e-04, 0.0000e+00, 9.6498e-10, 5.8089e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        9.6498e-10, 2.3825e+04, 2.1126e-10, 2.4443e-07, 0.0000e+00, 3.0875e+13,\n",
            "        2.9752e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 9.6498e-10, 3.9535e+09,\n",
            "        2.3116e+04, 6.4160e+09, 4.3391e-08, 2.4443e-07, 1.1778e-01])\n",
            "************** t  81\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1921e-06,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1157e-05, 9.9954e-10, 0.0000e+00, 2.1157e-05, 4.7008e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1157e-05, 2.8520e-05, 2.4771e-10, 1.1592e-07, 1.2445e-38, 1.4181e-42,\n",
            "        1.3290e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1157e-05, 0.0000e+00,\n",
            "        4.9193e-11, 2.5629e-08, 3.0811e-04, 1.1592e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 3.5665e-14, 6.9082e-13, 0.0000e+00, 3.5665e-14, 9.5206e-04,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        3.5665e-14, 9.1241e-01, 1.2169e-19, 5.8213e-14, 0.0000e+00, 2.6122e-07,\n",
            "        1.0847e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 3.5665e-14, 2.3322e-11,\n",
            "        2.5549e-06, 3.3248e+02, 1.9245e-11, 5.8213e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6959e-05, 2.2886e-09, 0.0000e+00, 3.6959e-05, 1.4515e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6959e-05, 3.8296e-05, 5.7602e-10, 2.3816e-07, 7.4443e-38, 1.5112e-41,\n",
            "        3.6460e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6959e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4352e-04, 2.3816e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 9.6498e-10, 3.0185e-04, 0.0000e+00, 9.6498e-10, 6.5593e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        9.6498e-10, 2.3825e+04, 2.1126e-10, 2.4443e-07, 0.0000e+00, 2.6122e+13,\n",
            "        2.9752e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 9.6498e-10, 2.3322e+09,\n",
            "        2.3116e+04, 6.4160e+09, 4.3391e-08, 2.4443e-07, 1.1778e-01])\n",
            "************** t  82\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.1921e-06,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1157e-05, 9.9954e-10, 0.0000e+00, 2.1157e-05, 4.6670e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1157e-05, 2.8520e-05, 2.4771e-10, 1.1592e-07, 1.2445e-38, 8.8422e-43,\n",
            "        1.3290e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1157e-05, 0.0000e+00,\n",
            "        4.9193e-11, 2.5629e-08, 3.0759e-04, 1.1592e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 3.5665e-14, 6.9082e-13, 0.0000e+00, 3.5665e-14, 1.0261e-03,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        3.5665e-14, 9.1241e-01, 1.2169e-19, 5.8213e-14, 0.0000e+00, 2.1329e-07,\n",
            "        1.0847e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 3.5665e-14, 3.6155e-11,\n",
            "        2.5549e-06, 3.3248e+02, 2.2617e-11, 5.8213e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6959e-05, 2.2886e-09, 0.0000e+00, 3.6959e-05, 1.4526e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6959e-05, 3.8296e-05, 5.7602e-10, 2.3816e-07, 7.4443e-38, 8.1387e-42,\n",
            "        3.6460e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6959e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4337e-04, 2.3816e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 9.6498e-10, 3.0185e-04, 0.0000e+00, 9.6498e-10, 7.0637e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        9.6498e-10, 2.3825e+04, 2.1126e-10, 2.4443e-07, 0.0000e+00, 2.1329e+13,\n",
            "        2.9752e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 9.6498e-10, 3.6155e+09,\n",
            "        2.3116e+04, 6.4160e+09, 5.1012e-08, 2.4443e-07, 1.1778e-01])\n",
            "************** t  83\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.3113e-06,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1157e-05, 9.9788e-10, 0.0000e+00, 2.1157e-05, 4.6540e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1157e-05, 2.8520e-05, 2.4771e-10, 1.1592e-07, 1.2445e-38, 6.1657e-43,\n",
            "        1.3290e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1157e-05, 0.0000e+00,\n",
            "        4.9193e-11, 2.5629e-08, 3.0759e-04, 1.1592e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 3.5665e-14, 7.7334e-13, 0.0000e+00, 3.5665e-14, 1.1348e-03,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        3.5665e-14, 9.1241e-01, 1.2169e-19, 5.8213e-14, 0.0000e+00, 1.3439e-07,\n",
            "        1.0847e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 3.5665e-14, 1.4856e-11,\n",
            "        2.5549e-06, 3.3248e+02, 2.2617e-11, 5.8213e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6959e-05, 2.2867e-09, 0.0000e+00, 3.6959e-05, 1.4495e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6959e-05, 3.8296e-05, 5.7602e-10, 2.3816e-07, 7.4443e-38, 7.1088e-42,\n",
            "        3.6460e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6959e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4337e-04, 2.3816e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 9.6498e-10, 3.3819e-04, 0.0000e+00, 9.6498e-10, 7.8286e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        9.6498e-10, 2.3825e+04, 2.1126e-10, 2.4443e-07, 0.0000e+00, 1.3439e+13,\n",
            "        2.9752e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 9.6498e-10, 1.4856e+09,\n",
            "        2.3116e+04, 6.4160e+09, 5.1012e-08, 2.4443e-07, 1.1778e-01])\n",
            "************** t  84\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.3113e-06,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1157e-05, 9.9788e-10, 0.0000e+00, 2.1157e-05, 4.6463e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1157e-05, 2.8520e-05, 2.4771e-10, 1.1592e-07, 1.2445e-38, 4.0357e-43,\n",
            "        1.3290e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1157e-05, 0.0000e+00,\n",
            "        4.9193e-11, 2.5629e-08, 3.0759e-04, 1.1592e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 3.5665e-14, 7.7334e-13, 0.0000e+00, 3.5665e-14, 1.1652e-03,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        3.5665e-14, 9.1241e-01, 1.2169e-19, 5.8213e-14, 0.0000e+00, 1.5055e-07,\n",
            "        1.0847e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 3.5665e-14, 1.3647e-11,\n",
            "        2.5549e-06, 3.3248e+02, 2.2617e-11, 5.8213e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6959e-05, 2.2867e-09, 0.0000e+00, 3.6959e-05, 1.4480e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6959e-05, 3.8296e-05, 5.7602e-10, 2.3816e-07, 7.4443e-38, 4.0189e-42,\n",
            "        3.6460e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6959e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4337e-04, 2.3816e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 9.6498e-10, 3.3819e-04, 0.0000e+00, 9.6498e-10, 8.0473e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        9.6498e-10, 2.3825e+04, 2.1126e-10, 2.4443e-07, 0.0000e+00, 1.5055e+13,\n",
            "        2.9752e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 9.6498e-10, 1.3647e+09,\n",
            "        2.3116e+04, 6.4160e+09, 5.1012e-08, 2.4443e-07, 1.1778e-01])\n",
            "************** t  85\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.4305e-06,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1099e-05, 9.9788e-10, 0.0000e+00, 2.1099e-05, 4.6385e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1099e-05, 2.8520e-05, 2.4771e-10, 1.1560e-07, 1.2445e-38, 3.2790e-43,\n",
            "        1.3290e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1099e-05, 0.0000e+00,\n",
            "        4.9193e-11, 2.5629e-08, 3.0759e-04, 1.1560e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 4.5095e-14, 7.7334e-13, 0.0000e+00, 4.5095e-14, 1.2494e-03,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        4.5095e-14, 9.1241e-01, 1.2169e-19, 7.1940e-14, 0.0000e+00, 9.4592e-08,\n",
            "        1.0847e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 4.5095e-14, 1.0531e-11,\n",
            "        2.5549e-06, 3.3248e+02, 2.2617e-11, 7.1940e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6897e-05, 2.2867e-09, 0.0000e+00, 3.6897e-05, 1.4465e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6897e-05, 3.8296e-05, 5.7602e-10, 2.3772e-07, 7.4443e-38, 4.0217e-42,\n",
            "        3.6460e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6897e-05, 0.0000e+00,\n",
            "        1.1052e-10, 5.1820e-08, 4.4337e-04, 2.3772e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 1.2222e-09, 3.3819e-04, 0.0000e+00, 1.2222e-09, 8.6373e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        1.2222e-09, 2.3825e+04, 2.1126e-10, 3.0262e-07, 0.0000e+00, 9.4592e+12,\n",
            "        2.9752e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 1.2222e-09, 1.0531e+09,\n",
            "        2.3116e+04, 6.4160e+09, 5.1012e-08, 3.0262e-07, 1.1778e-01])\n",
            "************** t  86\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.5497e-06,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1099e-05, 9.9788e-10, 0.0000e+00, 2.1099e-05, 4.6231e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1099e-05, 2.8520e-05, 2.4771e-10, 1.1560e-07, 1.2445e-38, 2.2141e-43,\n",
            "        1.3290e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1099e-05, 0.0000e+00,\n",
            "        4.9128e-11, 2.5629e-08, 3.0759e-04, 1.1560e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 4.5095e-14, 7.7334e-13, 0.0000e+00, 4.5095e-14, 1.2218e-03,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        4.5095e-14, 9.1241e-01, 1.2169e-19, 7.1940e-14, 0.0000e+00, 7.8410e-08,\n",
            "        1.0847e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 4.5095e-14, 9.2384e-12,\n",
            "        2.7097e-06, 3.3248e+02, 2.2617e-11, 7.1940e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6897e-05, 2.2867e-09, 0.0000e+00, 3.6897e-05, 1.4434e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6897e-05, 3.8296e-05, 5.7602e-10, 2.3772e-07, 7.4443e-38, 2.0123e-42,\n",
            "        3.6460e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6897e-05, 0.0000e+00,\n",
            "        1.1047e-10, 5.1820e-08, 4.4337e-04, 2.3772e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 1.2222e-09, 3.3819e-04, 0.0000e+00, 1.2222e-09, 8.4643e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        1.2222e-09, 2.3825e+04, 2.1126e-10, 3.0262e-07, 0.0000e+00, 7.8410e+12,\n",
            "        2.9752e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 1.2222e-09, 9.2384e+08,\n",
            "        2.4529e+04, 6.4160e+09, 5.1012e-08, 3.0262e-07, 1.1778e-01])\n",
            "************** t  87\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.5497e-06,\n",
            "        -0.0000e+00, 2.0537e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1099e-05, 9.9788e-10, 0.0000e+00, 2.1099e-05, 4.6205e-11,\n",
            "        1.3935e-26, 4.9356e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1099e-05, 2.8520e-05, 2.4771e-10, 1.1560e-07, 1.2445e-38, 1.8777e-43,\n",
            "        1.3290e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1099e-05, 0.0000e+00,\n",
            "        4.9128e-11, 2.5629e-08, 3.0759e-04, 1.1560e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 4.5095e-14, 7.7334e-13, 0.0000e+00, 4.5095e-14, 1.2220e-03,\n",
            "        0.0000e+00, 1.3274e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        4.5095e-14, 9.1241e-01, 1.2169e-19, 7.1940e-14, 0.0000e+00, 4.9371e-08,\n",
            "        1.0847e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 4.5095e-14, 6.6160e-13,\n",
            "        2.7097e-06, 3.3248e+02, 2.2617e-11, 7.1940e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6897e-05, 2.2867e-09, 0.0000e+00, 3.6897e-05, 1.4435e-10,\n",
            "        5.7000e-26, 6.0308e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6897e-05, 3.8296e-05, 5.7602e-10, 2.3772e-07, 7.4443e-38, 2.0207e-42,\n",
            "        3.6460e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6897e-05, 0.0000e+00,\n",
            "        1.1047e-10, 5.1820e-08, 4.4337e-04, 2.3772e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 1.2222e-09, 3.3819e-04, 0.0000e+00, 1.2222e-09, 8.4653e+06,\n",
            "        0.0000e+00, 2.2010e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        1.2222e-09, 2.3825e+04, 2.1126e-10, 3.0262e-07, 0.0000e+00, 4.9371e+12,\n",
            "        2.9752e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 1.2222e-09, 6.6160e+07,\n",
            "        2.4529e+04, 6.4160e+09, 5.1012e-08, 3.0262e-07, 1.1778e-01])\n",
            "************** t  88\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.5497e-06,\n",
            "        -0.0000e+00, 2.2213e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1099e-05, 9.9656e-10, 0.0000e+00, 2.1099e-05, 4.6128e-11,\n",
            "        1.3935e-26, 4.9274e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1099e-05, 2.8520e-05, 2.4730e-10, 1.1541e-07, 1.2445e-38, 1.0370e-43,\n",
            "        1.3290e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1099e-05, 0.0000e+00,\n",
            "        4.9128e-11, 2.5629e-08, 3.0759e-04, 1.1541e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 4.5095e-14, 8.1875e-13, 0.0000e+00, 4.5095e-14, 1.2441e-03,\n",
            "        0.0000e+00, 1.4242e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        4.5095e-14, 9.1241e-01, 1.3339e-19, 7.8562e-14, 0.0000e+00, 5.9498e-08,\n",
            "        1.0847e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 4.5095e-14, 1.0612e-12,\n",
            "        2.7097e-06, 3.3248e+02, 2.2617e-11, 7.8562e-14, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6897e-05, 2.2855e-09, 0.0000e+00, 3.6897e-05, 1.4420e-10,\n",
            "        5.7000e-26, 6.0302e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6897e-05, 3.8296e-05, 5.7554e-10, 2.3755e-07, 7.4443e-38, 0.0000e+00,\n",
            "        3.6460e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6897e-05, 0.0000e+00,\n",
            "        1.1047e-10, 5.1820e-08, 4.4337e-04, 2.3755e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 1.2222e-09, 3.5823e-04, 0.0000e+00, 1.2222e-09, 8.6280e+06,\n",
            "        0.0000e+00, 2.3617e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        1.2222e-09, 2.3825e+04, 2.3177e-10, 3.3072e-07, 0.0000e+00, 5.9498e+12,\n",
            "        2.9752e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 1.2222e-09, 1.0612e+08,\n",
            "        2.4529e+04, 6.4160e+09, 5.1012e-08, 3.3072e-07, 1.1778e-01])\n",
            "************** t  89\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.5497e-06,\n",
            "        -0.0000e+00, 2.2213e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1040e-05, 9.9656e-10, 0.0000e+00, 2.1040e-05, 4.6128e-11,\n",
            "        1.3935e-26, 4.9274e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1040e-05, 2.8520e-05, 2.4689e-10, 1.1471e-07, 1.2445e-38, 6.8664e-44,\n",
            "        1.3290e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1040e-05, 0.0000e+00,\n",
            "        4.9046e-11, 2.5629e-08, 3.0674e-04, 1.1471e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 5.5132e-14, 8.1875e-13, 0.0000e+00, 5.5132e-14, 1.2441e-03,\n",
            "        0.0000e+00, 1.4242e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        5.5132e-14, 9.1241e-01, 1.4532e-19, 1.0796e-13, 0.0000e+00, 2.1288e-08,\n",
            "        1.0847e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 5.5132e-14, 1.2506e-12,\n",
            "        2.9089e-06, 3.3248e+02, 2.7848e-11, 1.0796e-13, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6835e-05, 2.2855e-09, 0.0000e+00, 3.6835e-05, 1.4420e-10,\n",
            "        5.7000e-26, 6.0302e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6835e-05, 3.8296e-05, 5.7505e-10, 2.3676e-07, 7.4443e-38, 0.0000e+00,\n",
            "        3.6460e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6835e-05, 0.0000e+00,\n",
            "        1.1038e-10, 5.1820e-08, 4.4273e-04, 2.3676e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 1.4967e-09, 3.5823e-04, 0.0000e+00, 1.4967e-09, 8.6280e+06,\n",
            "        0.0000e+00, 2.3617e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        1.4967e-09, 2.3825e+04, 2.5271e-10, 4.5600e-07, 0.0000e+00, 2.1288e+12,\n",
            "        2.9752e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 1.4967e-09, 1.2506e+08,\n",
            "        2.6354e+04, 6.4160e+09, 6.2901e-08, 4.5600e-07, 1.1778e-01])\n",
            "************** t  90\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.6689e-06,\n",
            "        -0.0000e+00, 2.3793e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.1040e-05, 9.9324e-10, 0.0000e+00, 2.1040e-05, 4.5991e-11,\n",
            "        1.3935e-26, 4.9192e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.1040e-05, 2.8520e-05, 2.4547e-10, 1.1350e-07, 1.2445e-38, 4.3440e-44,\n",
            "        1.3268e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.1040e-05, 0.0000e+00,\n",
            "        4.8964e-11, 2.5629e-08, 3.0674e-04, 1.1350e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 5.5132e-14, 9.5788e-13, 0.0000e+00, 5.5132e-14, 1.3269e-03,\n",
            "        0.0000e+00, 1.5139e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        5.5132e-14, 9.1241e-01, 1.9381e-19, 1.7821e-13, 0.0000e+00, 3.7844e-08,\n",
            "        1.1426e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 5.5132e-14, 6.7272e-13,\n",
            "        3.0879e-06, 3.3248e+02, 2.7848e-11, 1.7821e-13, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6835e-05, 2.2817e-09, 0.0000e+00, 3.6835e-05, 1.4394e-10,\n",
            "        5.7000e-26, 6.0296e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6835e-05, 3.8296e-05, 5.7316e-10, 2.3536e-07, 7.4443e-38, 0.0000e+00,\n",
            "        3.6425e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6835e-05, 0.0000e+00,\n",
            "        1.1029e-10, 5.1820e-08, 4.4273e-04, 2.3536e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 1.4967e-09, 4.1980e-04, 0.0000e+00, 1.4967e-09, 9.2185e+06,\n",
            "        0.0000e+00, 2.5108e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        1.4967e-09, 2.3825e+04, 3.3814e-10, 7.5717e-07, 0.0000e+00, 3.7844e+12,\n",
            "        3.1369e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 1.4967e-09, 6.7272e+07,\n",
            "        2.7998e+04, 6.4160e+09, 6.2901e-08, 7.5717e-07, 1.1778e-01])\n",
            "************** t  91\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.6689e-06,\n",
            "        -0.0000e+00, 2.3793e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 3.9339e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.0889e-05, 9.9324e-10, 0.0000e+00, 2.0889e-05, 4.5915e-11,\n",
            "        1.3935e-26, 4.9192e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.0889e-05, 2.8520e-05, 2.4438e-10, 1.1312e-07, 1.2445e-38, 3.0829e-44,\n",
            "        1.3202e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.0889e-05, 0.0000e+00,\n",
            "        4.8964e-11, 2.5629e-08, 3.0674e-04, 1.1312e-07, 5.4903e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 7.9119e-14, 9.5788e-13, 0.0000e+00, 7.9119e-14, 1.3458e-03,\n",
            "        0.0000e+00, 1.5139e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        7.9119e-14, 9.1241e-01, 2.3971e-19, 2.0206e-13, 0.0000e+00, 2.1529e-08,\n",
            "        1.3183e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 7.9119e-14, 4.7593e-13,\n",
            "        3.0879e-06, 3.3248e+02, 2.7848e-11, 2.0206e-13, 5.2307e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6690e-05, 2.2817e-09, 0.0000e+00, 3.6690e-05, 1.4379e-10,\n",
            "        5.7000e-26, 6.0296e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6690e-05, 3.8296e-05, 5.7156e-10, 2.3501e-07, 7.4443e-38, 0.0000e+00,\n",
            "        3.6319e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6690e-05, 0.0000e+00,\n",
            "        1.1029e-10, 5.1820e-08, 4.4273e-04, 2.3501e-07, 4.4412e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 2.1564e-09, 4.1980e-04, 0.0000e+00, 2.1564e-09, 9.3597e+06,\n",
            "        0.0000e+00, 2.5108e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        2.1564e-09, 2.3825e+04, 4.1940e-10, 8.5980e-07, 0.0000e+00, 2.1529e+12,\n",
            "        3.6298e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 2.1564e-09, 4.7593e+07,\n",
            "        2.7998e+04, 6.4160e+09, 6.2901e-08, 8.5980e-07, 1.1778e-01])\n",
            "************** t  92\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.0266e-06,\n",
            "        -0.0000e+00, 2.3793e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.0797e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 4.7684e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.0784e-05, 9.9046e-10, 0.0000e+00, 2.0784e-05, 4.5584e-11,\n",
            "        1.3935e-26, 4.9192e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.0784e-05, 2.8520e-05, 2.4398e-10, 1.1275e-07, 1.2445e-38, 2.6625e-44,\n",
            "        1.3061e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.0784e-05, 0.0000e+00,\n",
            "        4.8964e-11, 2.5629e-08, 3.0436e-04, 1.1275e-07, 5.4812e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 9.9385e-14, 1.0489e-12, 0.0000e+00, 9.9385e-14, 1.5875e-03,\n",
            "        0.0000e+00, 1.5139e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        9.9385e-14, 9.1241e-01, 2.5426e-19, 2.2778e-13, 0.0000e+00, 1.1966e-08,\n",
            "        1.7405e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 9.9385e-14, 4.0324e-13,\n",
            "        3.0879e-06, 3.3248e+02, 4.1812e-11, 2.2778e-13, 6.2966e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6626e-05, 2.2791e-09, 0.0000e+00, 3.6626e-05, 1.4302e-10,\n",
            "        5.7000e-26, 6.0296e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6626e-05, 3.8296e-05, 5.7107e-10, 2.3466e-07, 7.4443e-38, 0.0000e+00,\n",
            "        3.6079e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6626e-05, 0.0000e+00,\n",
            "        1.1029e-10, 5.1820e-08, 4.4163e-04, 2.3466e-07, 4.4443e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 2.7135e-09, 4.6024e-04, 0.0000e+00, 2.7135e-09, 1.1100e+07,\n",
            "        0.0000e+00, 2.5108e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        2.7135e-09, 2.3825e+04, 4.4523e-10, 9.7069e-07, 0.0000e+00, 1.1966e+12,\n",
            "        4.8240e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 2.7135e-09, 4.0324e+07,\n",
            "        2.7998e+04, 6.4160e+09, 9.4675e-08, 9.7069e-07, 1.4168e-01])\n",
            "************** t  93\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.1458e-06,\n",
            "        -0.0000e+00, 2.3793e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.7277e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 4.7684e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.0543e-05, 9.8343e-10, 0.0000e+00, 2.0543e-05, 4.5357e-11,\n",
            "        1.3935e-26, 4.9192e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.0543e-05, 2.8473e-05, 2.4316e-10, 1.1119e-07, 1.2445e-38, 1.2612e-44,\n",
            "        1.2838e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.0543e-05, 0.0000e+00,\n",
            "        4.8964e-11, 2.5629e-08, 3.0217e-04, 1.1119e-07, 5.4812e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 1.5609e-13, 1.3278e-12, 0.0000e+00, 1.5609e-13, 1.6920e-03,\n",
            "        0.0000e+00, 1.5139e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        1.5609e-13, 9.8517e-01, 2.8340e-19, 3.8897e-13, 0.0000e+00, 1.7106e-08,\n",
            "        2.3371e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 1.5609e-13, 3.4996e-13,\n",
            "        3.0879e-06, 3.3248e+02, 5.9412e-11, 3.8897e-13, 6.2966e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6398e-05, 2.2702e-09, 0.0000e+00, 3.6398e-05, 1.4257e-10,\n",
            "        5.7000e-26, 6.0296e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6398e-05, 3.8287e-05, 5.7010e-10, 2.3249e-07, 7.4443e-38, 0.0000e+00,\n",
            "        3.5833e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6398e-05, 0.0000e+00,\n",
            "        1.1029e-10, 5.1820e-08, 4.4019e-04, 2.3249e-07, 4.4443e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 4.2884e-09, 5.8488e-04, 0.0000e+00, 4.2884e-09, 1.1868e+07,\n",
            "        0.0000e+00, 2.5108e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        4.2884e-09, 2.5731e+04, 4.9711e-10, 1.6730e-06, 0.0000e+00, 1.7106e+12,\n",
            "        6.5222e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 4.2884e-09, 3.4996e+07,\n",
            "        2.7998e+04, 6.4160e+09, 1.3497e-07, 1.6730e-06, 1.4168e-01])\n",
            "************** t  94\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 2.8610e-06,\n",
            "        -0.0000e+00, 2.4862e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 7.9243e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.0152e-01, -0.0000e+00, -0.0000e+00, 4.7684e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 2.0204e-05, 9.7853e-10, 0.0000e+00, 2.0204e-05, 4.4459e-11,\n",
            "        1.3935e-26, 4.9110e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        2.0204e-05, 2.8447e-05, 2.4048e-10, 1.0948e-07, 1.2445e-38, 8.4078e-45,\n",
            "        1.2689e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 2.0204e-05, 0.0000e+00,\n",
            "        4.8964e-11, 2.5629e-08, 3.0067e-04, 1.0948e-07, 5.4812e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 2.7386e-13, 1.5421e-12, 0.0000e+00, 2.7386e-13, 2.2602e-03,\n",
            "        0.0000e+00, 1.5738e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        2.7386e-13, 1.0187e+00, 4.2651e-19, 5.9814e-13, 0.0000e+00, 4.1129e-09,\n",
            "        2.9197e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 2.7386e-13, 3.3061e-13,\n",
            "        3.0879e-06, 3.3248e+02, 7.1959e-11, 5.9814e-13, 6.2966e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.6184e-05, 2.2645e-09, 0.0000e+00, 3.6184e-05, 1.4042e-10,\n",
            "        5.7000e-26, 6.0290e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.6184e-05, 3.8301e-05, 5.6565e-10, 2.3078e-07, 7.4443e-38, 0.0000e+00,\n",
            "        3.5587e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.6184e-05, 0.0000e+00,\n",
            "        1.1029e-10, 5.1820e-08, 4.3972e-04, 2.3078e-07, 4.4443e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 7.5687e-09, 6.8099e-04, 0.0000e+00, 7.5687e-09, 1.6096e+07,\n",
            "        0.0000e+00, 2.6104e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        7.5687e-09, 2.6596e+04, 7.5402e-10, 2.5918e-06, 0.0000e+00, 4.1129e+11,\n",
            "        8.2044e-09, 0.0000e+00, 0.0000e+00, 4.5195e+08, 7.5687e-09, 3.3061e+07,\n",
            "        2.7998e+04, 6.4160e+09, 1.6365e-07, 2.5918e-06, 1.4168e-01])\n",
            "************** t  95\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.5763e-06,\n",
            "        -0.0000e+00, 2.7832e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 8.3721e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.1954e-01, -0.0000e+00, -0.0000e+00, 5.4836e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 1.9947e-05, 9.5915e-10, 0.0000e+00, 1.9947e-05, 4.3595e-11,\n",
            "        1.3935e-26, 4.8892e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        1.9947e-05, 2.8392e-05, 2.3598e-10, 1.0642e-07, 1.2445e-38, 5.6052e-45,\n",
            "        1.2442e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 1.9947e-05, 0.0000e+00,\n",
            "        4.8710e-11, 2.5553e-08, 2.9567e-04, 1.0642e-07, 5.4674e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 4.1850e-13, 2.6178e-12, 0.0000e+00, 4.1850e-13, 2.8565e-03,\n",
            "        0.0000e+00, 1.7715e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        4.1850e-13, 1.0673e+00, 6.2750e-19, 1.3455e-12, 0.0000e+00, 7.1434e-09,\n",
            "        4.1078e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 4.1850e-13, 2.7901e-13,\n",
            "        3.5176e-06, 3.4682e+02, 1.3490e-10, 1.3455e-12, 7.1250e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.5915e-05, 2.2381e-09, 0.0000e+00, 3.5915e-05, 1.3853e-10,\n",
            "        5.7000e-26, 6.0210e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.5915e-05, 3.8324e-05, 5.5868e-10, 2.2658e-07, 7.4443e-38, 0.0000e+00,\n",
            "        3.5133e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.5915e-05, 0.0000e+00,\n",
            "        1.0990e-10, 5.1763e-08, 4.3636e-04, 2.2658e-07, 4.4537e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 1.1652e-08, 1.1697e-03, 0.0000e+00, 1.1652e-08, 2.0621e+07,\n",
            "        0.0000e+00, 2.9422e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        1.1652e-08, 2.7849e+04, 1.1232e-09, 5.9384e-06, 0.0000e+00, 7.1434e+11,\n",
            "        1.1692e-08, 0.0000e+00, 0.0000e+00, 4.5195e+08, 1.1652e-08, 2.7901e+07,\n",
            "        3.2007e+04, 6.7003e+09, 3.0915e-07, 5.9384e-06, 1.5998e-01])\n",
            "************** t  96\n",
            "ce_loss:  tensor([1.4305e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 4.8876e-06,\n",
            "        -0.0000e+00, 3.0219e-01, -0.0000e+00, -0.0000e+00, 1.4305e-06, 1.3179e+01,\n",
            "        -0.0000e+00, 8.9188e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.4070e-01, -0.0000e+00, -0.0000e+00, 5.3644e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3683e-03, 1.9121e-05, 9.3529e-10, 0.0000e+00, 1.9121e-05, 4.2283e-11,\n",
            "        1.3935e-26, 4.8702e-05, 1.2336e-39, 1.8229e-36, 7.3683e-03, 3.5426e-05,\n",
            "        1.9121e-05, 2.8345e-05, 2.2511e-10, 1.0084e-07, 1.2445e-38, 4.2039e-45,\n",
            "        1.1994e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 1.9121e-05, 0.0000e+00,\n",
            "        4.8414e-11, 2.5468e-08, 2.9030e-04, 1.0084e-07, 5.4522e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.9002e-03, 1.2881e-12, 4.5810e-12, 0.0000e+00, 1.2881e-12, 4.0113e-03,\n",
            "        0.0000e+00, 1.8173e+02, 0.0000e+00, 0.0000e+00, 1.9002e-03, 9.0729e+02,\n",
            "        1.2881e-12, 1.1465e+00, 1.5331e-18, 4.7265e-12, 0.0000e+00, 8.1981e-09,\n",
            "        7.2053e-19, 0.0000e+00, 0.0000e+00, 7.5818e+02, 1.2881e-12, 1.0414e-13,\n",
            "        4.0162e-06, 3.5115e+02, 2.2382e-10, 4.7265e-12, 7.1324e-03])\n",
            "kde_grad  tensor([6.4210e-03, 3.5122e-05, 2.2074e-09, 0.0000e+00, 3.5122e-05, 1.3525e-10,\n",
            "        5.7000e-26, 6.0139e-05, 7.5966e-39, 1.0206e-35, 6.4210e-03, 4.5603e-05,\n",
            "        3.5122e-05, 3.8315e-05, 5.4374e-10, 2.1875e-07, 7.4443e-38, 0.0000e+00,\n",
            "        3.4282e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.5122e-05, 0.0000e+00,\n",
            "        1.0951e-10, 5.1688e-08, 4.3455e-04, 2.1875e-07, 4.4936e-02])\n",
            "penalty_factor  tensor([2.9594e-01, 3.6675e-08, 2.0753e-03, 0.0000e+00, 3.6675e-08, 2.9659e+07,\n",
            "        0.0000e+00, 3.0218e+06, 0.0000e+00, 0.0000e+00, 2.9594e-01, 1.9896e+07,\n",
            "        3.6675e-08, 2.9923e+04, 2.8196e-09, 2.1607e-05, 0.0000e+00, 8.1981e+11,\n",
            "        2.1018e-08, 0.0000e+00, 0.0000e+00, 4.5195e+08, 3.6675e-08, 1.0414e+07,\n",
            "        3.6674e+04, 6.7936e+09, 5.1507e-07, 2.1607e-05, 1.5872e-01])\n",
            "************** t  97\n",
            "ce_loss:  tensor([1.5497e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 7.9870e-06,\n",
            "        -0.0000e+00, 3.4971e-01, -0.0000e+00, -0.0000e+00, 1.5497e-06, 1.3211e+01,\n",
            "        -0.0000e+00, 1.1195e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6016e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 6.6328e-01, -0.0000e+00, -0.0000e+00, 7.7486e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3438e-03, 1.7888e-05, 8.8329e-10, 0.0000e+00, 1.7888e-05, 4.0080e-11,\n",
            "        1.3935e-26, 4.8230e-05, 1.2336e-39, 1.8229e-36, 7.3438e-03, 3.5367e-05,\n",
            "        1.7888e-05, 2.8125e-05, 2.1263e-10, 9.4373e-08, 1.2445e-38, 2.8026e-45,\n",
            "        1.1338e-11, 2.3542e-38, 7.7047e-27, 1.3064e-06, 1.7888e-05, 0.0000e+00,\n",
            "        4.8172e-11, 2.5342e-08, 2.7614e-04, 9.4373e-08, 5.4134e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.1339e-03, 5.4040e-12, 1.2580e-11, 0.0000e+00, 5.4040e-12, 6.3600e-03,\n",
            "        0.0000e+00, 2.0563e+02, 0.0000e+00, 0.0000e+00, 2.1339e-03, 9.2584e+02,\n",
            "        5.4040e-12, 1.4200e+00, 5.0864e-18, 1.6838e-11, 0.0000e+00, 3.4510e-09,\n",
            "        1.4544e-18, 0.0000e+00, 0.0000e+00, 7.5818e+02, 5.4040e-12, 1.4629e-13,\n",
            "        4.2553e-06, 3.6174e+02, 8.0768e-10, 1.6838e-11, 1.0088e-02])\n",
            "kde_grad  tensor([6.4277e-03, 3.3780e-05, 2.1304e-09, 0.0000e+00, 3.3780e-05, 1.2966e-10,\n",
            "        5.7000e-26, 6.0017e-05, 7.5966e-39, 1.0206e-35, 6.4277e-03, 4.5595e-05,\n",
            "        3.3780e-05, 3.8234e-05, 5.2254e-10, 2.0942e-07, 7.4443e-38, 0.0000e+00,\n",
            "        3.2927e-11, 1.4114e-37, 3.1644e-26, 1.6776e-06, 3.3780e-05, 0.0000e+00,\n",
            "        1.0924e-10, 5.1577e-08, 4.2500e-04, 2.0942e-07, 4.5011e-02])\n",
            "penalty_factor  tensor([3.3198e-01, 1.5997e-07, 5.9050e-03, 0.0000e+00, 1.5997e-07, 4.9053e+07,\n",
            "        0.0000e+00, 3.4262e+06, 0.0000e+00, 0.0000e+00, 3.3198e-01, 2.0306e+07,\n",
            "        1.5997e-07, 3.7140e+04, 9.7340e-09, 8.0406e-05, 0.0000e+00, 3.4510e+11,\n",
            "        4.4172e-08, 0.0000e+00, 0.0000e+00, 4.5195e+08, 1.5997e-07, 1.4629e+07,\n",
            "        3.8953e+04, 7.0135e+09, 1.9004e-06, 8.0406e-05, 2.2412e-01])\n",
            "************** t  98\n",
            "ce_loss:  tensor([1.5497e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.7285e-05,\n",
            "        -0.0000e+00, 4.4721e-01, -0.0000e+00, -0.0000e+00, 1.5497e-06, 1.3241e+01,\n",
            "        -0.0000e+00, 1.5107e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6242e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 7.2348e-01, -0.0000e+00, -0.0000e+00, 8.5830e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3438e-03, 1.6265e-05, 8.1999e-10, 0.0000e+00, 1.6265e-05, 3.5905e-11,\n",
            "        1.3935e-26, 4.7223e-05, 1.2336e-39, 1.8229e-36, 7.3438e-03, 3.5288e-05,\n",
            "        1.6265e-05, 2.7753e-05, 1.8955e-10, 8.4881e-08, 1.2445e-38, 1.4013e-45,\n",
            "        1.0168e-11, 2.3542e-38, 7.7047e-27, 1.3043e-06, 1.6265e-05, 0.0000e+00,\n",
            "        4.7080e-11, 2.4979e-08, 2.4968e-04, 8.4881e-08, 5.3954e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.1339e-03, 2.8229e-11, 3.5035e-11, 0.0000e+00, 2.8229e-11, 1.4107e-02,\n",
            "        0.0000e+00, 1.8642e+02, 0.0000e+00, 0.0000e+00, 2.1339e-03, 9.0729e+02,\n",
            "        2.8229e-11, 1.9575e+00, 1.9307e-17, 7.9623e-11, 0.0000e+00, 1.8764e-09,\n",
            "        4.3260e-18, 0.0000e+00, 0.0000e+00, 7.5865e+02, 2.8229e-11, 6.6025e-14,\n",
            "        5.8134e-06, 3.7138e+02, 5.2958e-09, 7.9623e-11, 1.1202e-02])\n",
            "kde_grad  tensor([6.4277e-03, 3.1836e-05, 2.0261e-09, 0.0000e+00, 3.1836e-05, 1.1863e-10,\n",
            "        5.7000e-26, 5.9487e-05, 7.5966e-39, 1.0206e-35, 6.4277e-03, 4.5629e-05,\n",
            "        3.1836e-05, 3.8153e-05, 4.8325e-10, 1.9437e-07, 7.4443e-38, 0.0000e+00,\n",
            "        3.0326e-11, 1.4114e-37, 3.1644e-26, 1.6773e-06, 3.1836e-05, 0.0000e+00,\n",
            "        1.0766e-10, 5.1220e-08, 4.0575e-04, 1.9437e-07, 4.5068e-02])\n",
            "penalty_factor  tensor([3.3198e-01, 8.8672e-07, 1.7292e-02, 0.0000e+00, 8.8672e-07, 1.1892e+08,\n",
            "        0.0000e+00, 3.1338e+06, 0.0000e+00, 0.0000e+00, 3.3198e-01, 1.9884e+07,\n",
            "        8.8672e-07, 5.1308e+04, 3.9953e-08, 4.0964e-04, 0.0000e+00, 1.8764e+11,\n",
            "        1.4265e-07, 0.0000e+00, 0.0000e+00, 4.5231e+08, 8.8672e-07, 6.6025e+06,\n",
            "        5.3996e+04, 7.2507e+09, 1.3052e-05, 4.0964e-04, 2.4857e-01])\n",
            "************** t  99\n",
            "ce_loss:  tensor([2.1458e-06, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 4.7087e-05,\n",
            "        -0.0000e+00, 4.4754e-01, -0.0000e+00, -0.0000e+00, 2.1458e-06, 1.3320e+01,\n",
            "        -0.0000e+00, 2.7434e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, -0.0000e+00, -0.0000e+00, 3.6575e+00, -0.0000e+00, -0.0000e+00,\n",
            "        -0.0000e+00, 8.4011e-01, -0.0000e+00, -0.0000e+00, 1.7404e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.2578e-03, 1.2266e-05, 6.6911e-10, 0.0000e+00, 1.2266e-05, 2.9898e-11,\n",
            "        1.3935e-26, 4.6031e-05, 1.2336e-39, 1.8229e-36, 7.2578e-03, 3.5015e-05,\n",
            "        1.2266e-05, 2.6827e-05, 1.4931e-10, 6.4846e-08, 1.2445e-38, 1.4013e-45,\n",
            "        7.7829e-12, 2.3542e-38, 7.7047e-27, 1.2999e-06, 1.2266e-05, 0.0000e+00,\n",
            "        4.4662e-11, 2.4025e-08, 2.0739e-04, 6.4846e-08, 5.2651e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.9067e-03, 5.8433e-10, 2.7148e-10, 0.0000e+00, 5.8433e-10, 3.7705e-02,\n",
            "        0.0000e+00, 2.4103e+02, 0.0000e+00, 0.0000e+00, 2.9067e-03, 9.2584e+02,\n",
            "        5.8433e-10, 3.4353e+00, 1.8361e-16, 1.1033e-09, 0.0000e+00, 1.4530e-09,\n",
            "        3.1562e-17, 0.0000e+00, 0.0000e+00, 7.6962e+02, 5.8433e-10, 9.8756e-14,\n",
            "        9.7430e-06, 4.1465e+02, 5.3841e-08, 1.1033e-09, 2.2469e-02])\n",
            "kde_grad  tensor([6.4358e-03, 2.6570e-05, 1.7454e-09, 0.0000e+00, 2.6570e-05, 1.0181e-10,\n",
            "        5.7000e-26, 5.9750e-05, 7.5966e-39, 1.0206e-35, 6.4358e-03, 4.5543e-05,\n",
            "        2.6570e-05, 3.7699e-05, 4.0898e-10, 1.5991e-07, 7.4443e-38, 0.0000e+00,\n",
            "        2.4614e-11, 1.4114e-37, 3.1644e-26, 1.6767e-06, 2.6570e-05, 0.0000e+00,\n",
            "        1.0401e-10, 5.0178e-08, 3.6442e-04, 1.5991e-07, 4.5190e-02])\n",
            "penalty_factor  tensor([4.5164e-01, 2.1992e-05, 1.5554e-01, 0.0000e+00, 2.1992e-05, 3.7035e+08,\n",
            "        0.0000e+00, 4.0340e+06, 0.0000e+00, 0.0000e+00, 4.5164e-01, 2.0329e+07,\n",
            "        2.1992e-05, 9.1123e+04, 4.4895e-07, 6.8995e-03, 0.0000e+00, 1.4530e+11,\n",
            "        1.2823e-06, 0.0000e+00, 0.0000e+00, 4.5902e+08, 2.1992e-05, 9.8756e+06,\n",
            "        9.3670e+04, 8.2634e+09, 1.4774e-04, 6.8995e-03, 4.9722e-01])\n",
            "PGD linf: Attack effectiveness 55.172%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KDE(top_500_high_confidence_benign_samples[:1], top_500_high_confidence_benign_samples, 0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f69a7a-f057-4d64-dfed-ed340f57e640",
        "id": "VOMCDbzGz4WV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0462], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KDE(mals.to(device), top_500_high_confidence_benign_samples, 0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou-DsXVKz__Q",
        "outputId": "79272e49-ab94-4c52-8590-778242ebc244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.3344e-05, 2.2177e-10, 1.1448e-15, 0.0000e+00, 2.2177e-10, 3.4137e-18,\n",
              "        1.3935e-26, 6.6971e-06, 1.2336e-39, 1.8229e-36, 1.3344e-05, 5.0246e-11,\n",
              "        2.2177e-10, 5.7728e-08, 3.5037e-15, 4.1197e-12, 1.2445e-38, 3.1590e-40,\n",
              "        8.5677e-20, 2.3542e-38, 7.7047e-27, 2.7702e-10, 2.2177e-10, 4.0407e-39,\n",
              "        1.8901e-17, 1.1674e-15, 2.3014e-07, 4.1197e-12, 7.4781e-03])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KDE(top_500_high_confidence_benign_samples, top_500_high_confidence_benign_samples, 0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad26ebd-178b-4472-abeb-5e391dc05ddf",
        "id": "lTIxz5QFz4WW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0995, 1.0995, 1.0995, 1.0995, 1.0995, 1.0244, 1.0995, 1.0244, 1.0244,\n",
              "        1.0244, 0.1000, 1.0995, 0.1000, 0.2199, 0.3237, 0.1000, 1.0995, 1.9344,\n",
              "        0.9219, 0.9219, 0.1569, 0.8929, 0.1552, 1.0244, 1.9344, 0.4189, 1.0244,\n",
              "        0.1063, 1.0244, 0.1000, 0.1000, 0.1300, 0.1000, 1.9344, 0.1038, 1.9344,\n",
              "        1.9344, 0.1000, 1.9344, 0.9219, 0.2001, 0.1000, 0.3195, 0.1081, 1.9344,\n",
              "        0.1250, 0.1143, 0.2000, 0.1026, 0.9219, 1.9344, 1.0995, 0.2000, 0.1000,\n",
              "        1.9344, 0.4189, 0.1251, 1.9344, 0.9219, 0.1559, 0.2273, 0.3001, 0.9219,\n",
              "        0.2273, 0.1065, 0.3001, 0.1307, 0.9219, 0.8929, 0.5761, 1.9344, 1.9344,\n",
              "        1.9344, 0.1021, 0.2199, 0.1000, 0.2000, 1.9344, 0.8929, 1.9344, 0.1307,\n",
              "        0.9219, 1.0244, 0.1584, 0.1157, 0.3195, 0.1388, 0.5761, 0.1076, 0.2000,\n",
              "        0.3001, 1.9344, 0.2199, 0.3237, 0.1569, 1.9344, 0.2001, 0.5823, 0.8929,\n",
              "        0.3164])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zf0SckOmaOJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KDE(top_500_high_confidence_benign_samples, top_500_high_confidence_benign_samples, 0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhmvPK-7gnx5",
        "outputId": "881a224d-ac2d-4495-e071-aa4c4be2b620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0995, 1.0995, 1.0995, 1.0995, 1.0995, 1.0244, 1.0995, 1.0244, 1.0244,\n",
              "        1.0244, 0.1000, 1.0995, 0.1000, 0.2199, 0.3237, 0.1000, 1.0995, 1.9344,\n",
              "        0.9219, 0.9219, 0.1569, 0.8929, 0.1552, 1.0244, 1.9344, 0.4189, 1.0244,\n",
              "        0.1063, 1.0244, 0.1000, 0.1000, 0.1300, 0.1000, 1.9344, 0.1038, 1.9344,\n",
              "        1.9344, 0.1000, 1.9344, 0.9219, 0.2001, 0.1000, 0.3195, 0.1081, 1.9344,\n",
              "        0.1250, 0.1143, 0.2000, 0.1026, 0.9219, 1.9344, 1.0995, 0.2000, 0.1000,\n",
              "        1.9344, 0.4189, 0.1251, 1.9344, 0.9219, 0.1559, 0.2273, 0.3001, 0.9219,\n",
              "        0.2273, 0.1065, 0.3001, 0.1307, 0.9219, 0.8929, 0.5761, 1.9344, 1.9344,\n",
              "        1.9344, 0.1021, 0.2199, 0.1000, 0.2000, 1.9344, 0.8929, 1.9344, 0.1307,\n",
              "        0.9219, 1.0244, 0.1584, 0.1157, 0.3195, 0.1388, 0.5761, 0.1076, 0.2000,\n",
              "        0.3001, 1.9344, 0.2199, 0.3237, 0.1569, 1.9344, 0.2001, 0.5823, 0.8929,\n",
              "        0.3164])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KDE(mals, top_500_high_confidence_benign_samples, 0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-Cj5yipzIyT",
        "outputId": "a82ba158-1747-4e03-982c-45b8490fa331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.3344e-05, 2.2177e-10, 1.1448e-15, 0.0000e+00, 2.2177e-10, 3.4137e-18,\n",
              "        1.3935e-26, 6.6971e-06, 1.2336e-39, 1.8229e-36, 1.3344e-05, 5.0246e-11,\n",
              "        2.2177e-10, 5.7728e-08, 3.5037e-15, 4.1197e-12, 1.2445e-38, 3.1590e-40,\n",
              "        8.5677e-20, 2.3542e-38, 7.7047e-27, 2.7702e-10, 2.2177e-10, 4.0407e-39,\n",
              "        1.8901e-17, 1.1674e-15, 2.3014e-07, 4.1197e-12, 7.4781e-03])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dCx4yRxESe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_done(x, y, model):\n",
        "    # Get the model's predictions\n",
        "    outputs = model(x)\n",
        "\n",
        "    # Use argmax to get the predicted class indices\n",
        "    predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    # Ensure y is in the same shape as predicted for comparison\n",
        "    y = y.view_as(predicted)\n",
        "\n",
        "    # Determine if the predictions are incorrect\n",
        "    done = (predicted != y).bool()\n",
        "\n",
        "    return done\n",
        "\n",
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Compute CE loss\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y)\n",
        "    #print('ce ',ce)\n",
        "\n",
        "    # Compute KDE loss\n",
        "    kde = KDE(adv_x, benigns, bandwidth)\n",
        "    #print('kde ',kde)\n",
        "\n",
        "    # Combine the losses with the penalty factor\n",
        "    loss = ce - penalty_factor * kde\n",
        "    #print('loss ',loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gkde(x, y, model,benigns, bandwidth, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "        initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "\n",
        "    :param x: Feature vector\n",
        "    :param y: Ground truth labels\n",
        "    :param model: Neural network model\n",
        "    :param RBFModel: Gaussian model for KDE\n",
        "    :param insertion_array: Array for insertion operations\n",
        "    :param removal_array: Array for removal operations\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf', 'l2', 'l1')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    #target's class\n",
        "    traget_labels = torch.zeros_like(y.view(-1).long())\n",
        "\n",
        "    # Compute natural loss and penalty_factor\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), traget_labels)\n",
        "    kde = KDE(x, benigns, bandwidth)\n",
        "    #penalty_factor = 0.\n",
        "    penalty_factor = 1e6\n",
        "    #print(penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    for t in range(k):\n",
        "        print('*************** t ',t)\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "        outputs = model(x_var)\n",
        "        ce_loss = criterion(outputs, traget_labels)\n",
        "        print('ce_loss: ', ce_loss)\n",
        "        kde_loss = KDE(x_var, benigns, bandwidth)\n",
        "        print('kde_loss: ', kde_loss)\n",
        "        ce_grad = torch.autograd.grad(ce_loss.mean(), x_var, retain_graph=True)[0].data\n",
        "        kde_grad = torch.autograd.grad(kde_loss.mean(), x_var)[0].data\n",
        "        print('ce_grad ',torch.abs(ce_grad).sum(dim=-1).detach())\n",
        "        print('kde_grad ',torch.abs(kde_grad).sum(dim=-1).detach())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde(x_var,traget_labels,model,benigns, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "        elif norm == 'l1':\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1', 'l2', or 'linf' norm.\")\n",
        "\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    if random:\n",
        "        round_threshold = torch.rand_like(x_next)\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, traget_labels).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size(0) * 100:.3f}%.\")\n",
        "\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "VBdPXckRESw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv = gkde(mals.to(torch.float32).to(device), mals_y.to(device), model_AT_rFGSM, top_500_high_confidence_benign_samples,0.6, insertion_array, removal_array, k=100, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c202679-c741-496f-c09a-6b7993b55a69",
        "id": "ep1TpS0gESw7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************** t  0\n",
            "ce_loss:  tensor([4.1028e+01, 8.6630e+01, 5.8158e+01, 1.8685e+02, 8.6630e+01, 3.6857e+01,\n",
            "        1.5623e+02, 9.2854e+00, 1.8450e+02, 1.0696e+02, 4.1028e+01, 1.2040e-05,\n",
            "        8.6630e+01, 3.8186e+01, 9.1592e+01, 7.5509e+01, 1.2146e+02, 2.8487e+01,\n",
            "        6.3303e+01, 9.9407e+01, 1.4897e+02, 1.9638e+01, 8.6630e+01, 4.9636e+01,\n",
            "        3.4985e+01, 2.0074e+01, 7.7117e+01, 7.5509e+01, 3.8682e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.3344e-05, 2.2177e-10, 1.1448e-15, 0.0000e+00, 2.2177e-10, 3.4137e-18,\n",
            "        1.3935e-26, 6.6971e-06, 1.2336e-39, 1.8229e-36, 1.3344e-05, 5.0246e-11,\n",
            "        2.2177e-10, 5.7728e-08, 3.5037e-15, 4.1197e-12, 1.2445e-38, 3.1590e-40,\n",
            "        8.5677e-20, 2.3542e-38, 7.7047e-27, 2.7702e-10, 2.2177e-10, 4.0407e-39,\n",
            "        1.8901e-17, 1.1674e-15, 2.3014e-07, 4.1197e-12, 7.4781e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  1\n",
            "ce_loss:  tensor([3.8930e+01, 8.1252e+01, 5.4561e+01, 1.8050e+02, 8.1252e+01, 3.0279e+01,\n",
            "        1.4982e+02, 6.5895e+00, 1.7741e+02, 1.0231e+02, 3.8930e+01, 8.4638e-06,\n",
            "        8.1252e+01, 3.4357e+01, 8.6054e+01, 7.0332e+01, 1.1706e+02, 2.4853e+01,\n",
            "        6.0047e+01, 9.3228e+01, 1.4309e+02, 1.7637e+01, 8.1252e+01, 4.6975e+01,\n",
            "        3.3508e+01, 1.7785e+01, 6.9806e+01, 7.0332e+01, 3.6410e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.7481e-05, 3.2444e-10, 1.5661e-15, 0.0000e+00, 3.2444e-10, 5.1213e-18,\n",
            "        2.2153e-26, 6.9365e-06, 3.6995e-39, 7.1828e-36, 1.7481e-05, 9.2380e-11,\n",
            "        3.2444e-10, 7.0069e-08, 4.8779e-15, 5.5370e-12, 5.8609e-38, 1.0459e-39,\n",
            "        1.2037e-19, 4.9772e-38, 1.4259e-26, 3.8639e-10, 3.2444e-10, 1.0220e-38,\n",
            "        2.9978e-17, 1.9726e-15, 2.5856e-07, 5.5370e-12, 7.7116e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  2\n",
            "ce_loss:  tensor([3.7697e+01, 7.5129e+01, 5.0083e+01, 1.7474e+02, 7.5129e+01, 2.5249e+01,\n",
            "        1.4335e+02, 5.0435e+00, 1.7031e+02, 9.7716e+01, 3.7697e+01, 8.2254e-06,\n",
            "        7.5129e+01, 3.0199e+01, 8.0268e+01, 6.5271e+01, 1.1249e+02, 2.1447e+01,\n",
            "        5.6916e+01, 8.7844e+01, 1.3668e+02, 1.5970e+01, 7.5129e+01, 4.4444e+01,\n",
            "        3.1907e+01, 1.5580e+01, 6.2219e+01, 6.5271e+01, 3.6912e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.3883e-05, 3.8361e-10, 2.0089e-15, 0.0000e+00, 3.8361e-10, 5.7168e-18,\n",
            "        2.6224e-26, 7.0469e-06, 8.1165e-39, 2.0340e-35, 2.3883e-05, 1.7992e-10,\n",
            "        3.8361e-10, 6.9996e-08, 5.4021e-15, 5.9843e-12, 2.2279e-37, 2.1919e-39,\n",
            "        1.3901e-19, 8.4430e-38, 2.0278e-26, 4.7897e-10, 3.8361e-10, 2.1283e-38,\n",
            "        4.3941e-17, 2.5209e-15, 2.1052e-07, 5.9843e-12, 9.0025e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  3\n",
            "ce_loss:  tensor([3.6372e+01, 6.8012e+01, 4.6156e+01, 1.6872e+02, 6.8012e+01, 2.1276e+01,\n",
            "        1.3708e+02, 4.0988e+00, 1.6330e+02, 9.2996e+01, 3.6372e+01, 8.1062e-06,\n",
            "        6.8012e+01, 2.5732e+01, 7.4219e+01, 5.9230e+01, 1.0791e+02, 1.8765e+01,\n",
            "        5.3867e+01, 8.3245e+01, 1.3027e+02, 1.3951e+01, 6.8012e+01, 4.1988e+01,\n",
            "        3.0173e+01, 1.3419e+01, 5.5117e+01, 5.9230e+01, 3.4501e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.2474e-05, 3.5571e-10, 2.0376e-15, 0.0000e+00, 3.5571e-10, 7.6090e-18,\n",
            "        2.2872e-26, 6.9976e-06, 1.3032e-38, 4.8171e-35, 3.2474e-05, 3.3850e-10,\n",
            "        3.5571e-10, 5.6601e-08, 4.7640e-15, 5.8324e-12, 6.6298e-37, 5.0324e-39,\n",
            "        1.4140e-19, 1.1735e-37, 2.1743e-26, 5.5507e-10, 3.5571e-10, 5.0171e-38,\n",
            "        5.8801e-17, 2.9546e-15, 1.2714e-07, 5.8324e-12, 9.5536e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  4\n",
            "ce_loss:  tensor([3.5693e+01, 6.0436e+01, 4.2251e+01, 1.6281e+02, 6.0436e+01, 1.7927e+01,\n",
            "        1.3122e+02, 2.9584e+00, 1.5689e+02, 8.8479e+01, 3.5693e+01, 1.3351e-05,\n",
            "        6.0436e+01, 2.1148e+01, 6.9034e+01, 5.2443e+01, 1.0354e+02, 1.6370e+01,\n",
            "        5.0637e+01, 7.8845e+01, 1.2464e+02, 1.2020e+01, 6.0436e+01, 3.9746e+01,\n",
            "        2.8391e+01, 1.1675e+01, 4.8357e+01, 5.2443e+01, 3.4963e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.6947e-05, 2.5335e-10, 1.8091e-15, 0.0000e+00, 2.5335e-10, 1.0246e-17,\n",
            "        1.7469e-26, 8.0763e-06, 1.6811e-38, 1.0668e-34, 4.6947e-05, 6.5464e-10,\n",
            "        2.5335e-10, 3.5302e-08, 3.2485e-15, 4.1125e-12, 1.5588e-36, 8.9929e-39,\n",
            "        1.1511e-19, 1.2433e-37, 2.2122e-26, 5.4535e-10, 2.5335e-10, 1.0030e-37,\n",
            "        7.3290e-17, 2.8866e-15, 5.8597e-08, 4.1125e-12, 1.1083e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  5\n",
            "ce_loss:  tensor([3.4153e+01, 5.4125e+01, 3.8365e+01, 1.5739e+02, 5.4125e+01, 1.6181e+01,\n",
            "        1.2538e+02, 3.1100e+00, 1.5047e+02, 8.4070e+01, 3.4153e+01, 7.6294e-06,\n",
            "        5.4125e+01, 1.8826e+01, 6.3195e+01, 4.6690e+01, 9.9030e+01, 1.4972e+01,\n",
            "        4.7197e+01, 7.4499e+01, 1.1906e+02, 1.0320e+01, 5.4125e+01, 3.8128e+01,\n",
            "        2.6527e+01, 9.6715e+00, 4.3945e+01, 4.6690e+01, 3.2560e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([6.0873e-05, 1.3940e-10, 1.3233e-15, 0.0000e+00, 1.3940e-10, 7.8138e-18,\n",
            "        9.8363e-27, 9.0182e-06, 1.7344e-38, 2.0068e-34, 6.0873e-05, 1.1552e-09,\n",
            "        1.3940e-10, 1.9010e-08, 2.1643e-15, 2.5068e-12, 3.3104e-36, 1.7560e-38,\n",
            "        8.3941e-20, 1.3680e-37, 1.7296e-26, 4.8314e-10, 1.3940e-10, 1.5532e-37,\n",
            "        8.0618e-17, 3.1185e-15, 2.1080e-08, 2.5068e-12, 1.1773e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  6\n",
            "ce_loss:  tensor([3.4010e+01, 4.8596e+01, 3.4752e+01, 1.5182e+02, 4.8596e+01, 1.3492e+01,\n",
            "        1.1958e+02, 2.6949e+00, 1.4409e+02, 7.9969e+01, 3.4010e+01, 1.1921e-05,\n",
            "        4.8596e+01, 1.8937e+01, 5.7903e+01, 4.0158e+01, 9.4331e+01, 1.2748e+01,\n",
            "        4.3888e+01, 7.0171e+01, 1.1359e+02, 8.8632e+00, 4.8596e+01, 3.6127e+01,\n",
            "        2.4837e+01, 9.4074e+00, 3.9406e+01, 4.0158e+01, 3.2815e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([8.6440e-05, 1.0158e-10, 7.7744e-16, 0.0000e+00, 1.0158e-10, 9.3283e-18,\n",
            "        4.1493e-27, 1.0434e-05, 1.3102e-38, 4.6153e-34, 8.6440e-05, 2.1388e-09,\n",
            "        1.0158e-10, 1.7292e-08, 1.0008e-15, 1.0983e-12, 5.7929e-36, 5.1872e-38,\n",
            "        4.8253e-20, 1.1814e-37, 1.0012e-26, 3.9555e-10, 1.0158e-10, 2.8090e-37,\n",
            "        8.0780e-17, 4.2774e-15, 1.1214e-08, 1.0983e-12, 1.3749e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  7\n",
            "ce_loss:  tensor([3.2153e+01, 4.4087e+01, 3.3239e+01, 1.4629e+02, 4.4087e+01, 1.1476e+01,\n",
            "        1.1361e+02, 2.5695e+00, 1.3775e+02, 7.6312e+01, 3.2153e+01, 6.6757e-06,\n",
            "        4.4087e+01, 1.5597e+01, 5.3609e+01, 3.5886e+01, 8.9677e+01, 1.1759e+01,\n",
            "        4.0825e+01, 6.6155e+01, 1.0816e+02, 7.5149e+00, 4.4087e+01, 3.4263e+01,\n",
            "        2.3218e+01, 7.5782e+00, 3.5800e+01, 3.5886e+01, 3.0683e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.1005e-04, 5.1548e-11, 9.3912e-16, 0.0000e+00, 5.1548e-11, 9.0561e-18,\n",
            "        1.4918e-27, 1.1225e-05, 7.4976e-39, 5.6524e-34, 1.1005e-04, 3.6655e-09,\n",
            "        5.1548e-11, 1.9620e-08, 4.9293e-16, 5.9008e-13, 7.7354e-36, 7.2068e-38,\n",
            "        2.2751e-20, 9.2832e-38, 4.3627e-27, 3.7771e-10, 5.1548e-11, 4.9585e-37,\n",
            "        7.2501e-17, 4.0019e-15, 6.0169e-09, 5.9008e-13, 1.4340e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  8\n",
            "ce_loss:  tensor([3.2166e+01, 3.9352e+01, 3.0879e+01, 1.4076e+02, 3.9352e+01, 1.0441e+01,\n",
            "        1.0791e+02, 2.6108e+00, 1.3175e+02, 7.2063e+01, 3.2166e+01, 1.0133e-05,\n",
            "        3.9352e+01, 1.6618e+01, 5.0377e+01, 3.2789e+01, 8.5046e+01, 9.6797e+00,\n",
            "        3.8293e+01, 6.2264e+01, 1.0274e+02, 7.1608e+00, 3.9352e+01, 3.2438e+01,\n",
            "        2.0866e+01, 7.1068e+00, 3.1948e+01, 3.2789e+01, 3.0697e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.5413e-04, 2.4821e-11, 4.7479e-16, 0.0000e+00, 2.4821e-11, 9.8035e-18,\n",
            "        5.4667e-28, 1.3350e-05, 3.1532e-39, 8.7733e-34, 1.5413e-04, 6.6402e-09,\n",
            "        2.4821e-11, 1.4917e-08, 3.1224e-16, 3.4873e-13, 8.1030e-36, 1.9693e-37,\n",
            "        1.0023e-20, 5.7106e-38, 1.4431e-27, 8.3776e-10, 2.4821e-11, 7.4939e-37,\n",
            "        5.7613e-17, 4.1681e-15, 6.1339e-09, 3.4873e-13, 1.6802e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  9\n",
            "ce_loss:  tensor([3.0319e+01, 3.5838e+01, 2.8099e+01, 1.3528e+02, 3.5838e+01, 1.0520e+01,\n",
            "        1.0230e+02, 2.4138e+00, 1.2573e+02, 6.8229e+01, 3.0319e+01, 5.4836e-06,\n",
            "        3.5838e+01, 1.3429e+01, 4.6459e+01, 2.9519e+01, 8.0610e+01, 8.0906e+00,\n",
            "        3.6513e+01, 5.9381e+01, 9.8085e+01, 6.0780e+00, 3.5838e+01, 3.0702e+01,\n",
            "        1.8984e+01, 6.2101e+00, 2.9006e+01, 2.9519e+01, 2.8741e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.9385e-04, 9.2558e-12, 4.6361e-16, 0.0000e+00, 9.2558e-12, 1.9438e-17,\n",
            "        1.3779e-28, 1.4175e-05, 1.5986e-39, 1.3124e-33, 1.9385e-04, 1.1332e-08,\n",
            "        9.2558e-12, 1.4697e-08, 1.9281e-16, 2.9821e-13, 6.5077e-36, 3.3926e-37,\n",
            "        8.0055e-21, 2.8475e-38, 3.6321e-28, 5.7929e-10, 9.2558e-12, 1.0145e-36,\n",
            "        4.4128e-17, 3.3585e-15, 3.5561e-09, 2.9821e-13, 1.7360e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  10\n",
            "ce_loss:  tensor([3.0361e+01, 3.2539e+01, 2.7095e+01, 1.2994e+02, 3.2539e+01, 9.1584e+00,\n",
            "        9.6984e+01, 2.5860e+00, 1.2004e+02, 6.5066e+01, 3.0361e+01, 8.8214e-06,\n",
            "        3.2539e+01, 1.3960e+01, 4.2792e+01, 2.6997e+01, 7.6399e+01, 6.9529e+00,\n",
            "        3.4944e+01, 5.6746e+01, 9.3713e+01, 5.3933e+00, 3.2539e+01, 2.9421e+01,\n",
            "        1.7172e+01, 5.9933e+00, 2.5695e+01, 2.6997e+01, 2.8654e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.6685e-04, 6.5668e-12, 3.0685e-16, 0.0000e+00, 6.5668e-12, 1.8554e-17,\n",
            "        3.1733e-29, 1.6543e-05, 6.2563e-40, 1.3894e-33, 2.6685e-04, 2.1211e-08,\n",
            "        6.5668e-12, 9.2419e-09, 1.3699e-16, 1.6664e-13, 4.6991e-36, 5.2027e-37,\n",
            "        2.2694e-21, 2.6258e-38, 1.5758e-28, 1.2546e-09, 6.5668e-12, 1.2218e-36,\n",
            "        2.9813e-17, 4.2569e-15, 2.2972e-09, 1.6664e-13, 2.0071e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  11\n",
            "ce_loss:  tensor([2.8225e+01, 2.9476e+01, 2.4512e+01, 1.2471e+02, 2.9476e+01, 8.7359e+00,\n",
            "        9.2509e+01, 2.0550e+00, 1.1476e+02, 6.1659e+01, 2.8225e+01, 5.7220e-06,\n",
            "        2.9476e+01, 1.1969e+01, 3.9288e+01, 2.3714e+01, 7.2707e+01, 5.6736e+00,\n",
            "        3.2897e+01, 5.3758e+01, 8.9624e+01, 4.9634e+00, 2.9476e+01, 2.7452e+01,\n",
            "        1.5670e+01, 5.1828e+00, 2.5034e+01, 2.3714e+01, 2.6819e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.3075e-04, 6.5836e-12, 1.9371e-16, 0.0000e+00, 6.5836e-12, 4.0721e-17,\n",
            "        1.3238e-29, 1.7419e-05, 4.4818e-40, 1.4603e-33, 3.3075e-04, 3.8476e-08,\n",
            "        6.5836e-12, 9.2313e-09, 6.0136e-17, 1.3758e-13, 3.0403e-36, 8.8526e-37,\n",
            "        3.0239e-21, 3.7140e-38, 1.1006e-28, 9.7228e-10, 6.5836e-12, 1.2623e-36,\n",
            "        1.8949e-17, 3.2929e-15, 9.9868e-10, 1.3758e-13, 2.0726e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  12\n",
            "ce_loss:  tensor([2.8177e+01, 2.6952e+01, 2.2112e+01, 1.1949e+02, 2.6952e+01, 9.5389e+00,\n",
            "        8.7798e+01, 2.3999e+00, 1.0980e+02, 5.8715e+01, 2.8177e+01, 7.1525e-06,\n",
            "        2.6952e+01, 1.0179e+01, 3.6835e+01, 2.1433e+01, 6.8981e+01, 4.8317e+00,\n",
            "        3.1625e+01, 5.1693e+01, 8.6030e+01, 5.0014e+00, 2.6952e+01, 2.5698e+01,\n",
            "        1.4825e+01, 3.7228e+00, 2.3241e+01, 2.1433e+01, 2.6577e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.4859e-04, 2.3624e-12, 1.4023e-16, 0.0000e+00, 2.3624e-12, 2.7602e-17,\n",
            "        2.2904e-30, 2.0128e-05, 1.4820e-40, 1.1573e-33, 4.4859e-04, 7.4124e-08,\n",
            "        2.3624e-12, 1.0043e-08, 2.9125e-17, 7.7540e-14, 2.4236e-36, 2.1854e-36,\n",
            "        2.0070e-21, 2.1498e-38, 3.3468e-29, 1.4016e-09, 2.3624e-12, 1.1834e-36,\n",
            "        2.5482e-17, 3.9978e-15, 2.5103e-09, 7.7540e-14, 2.3989e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  13\n",
            "ce_loss:  tensor([2.6093e+01, 2.4256e+01, 2.1059e+01, 1.1439e+02, 2.4256e+01, 7.5106e+00,\n",
            "        8.3343e+01, 1.8842e+00, 1.0444e+02, 5.5686e+01, 2.6093e+01, 5.0068e-06,\n",
            "        2.4256e+01, 9.5717e+00, 3.5082e+01, 2.2721e+01, 6.5309e+01, 4.1872e+00,\n",
            "        2.9868e+01, 4.9893e+01, 8.1769e+01, 3.9296e+00, 2.4256e+01, 2.4055e+01,\n",
            "        1.3727e+01, 3.5677e+00, 2.0930e+01, 2.2721e+01, 2.4829e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.4871e-04, 2.4888e-12, 1.5264e-16, 0.0000e+00, 2.4888e-12, 5.9678e-17,\n",
            "        1.0077e-30, 2.0913e-05, 8.2241e-41, 8.9597e-34, 5.4871e-04, 1.3197e-07,\n",
            "        2.4888e-12, 1.2445e-08, 2.4968e-17, 4.2783e-14, 1.6511e-36, 2.6825e-36,\n",
            "        9.2691e-22, 5.4920e-38, 1.5752e-29, 1.0312e-09, 2.4888e-12, 9.6559e-37,\n",
            "        1.4052e-17, 3.0484e-15, 1.7410e-09, 4.2783e-14, 2.4416e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  14\n",
            "ce_loss:  tensor([2.6116e+01, 2.2150e+01, 1.9908e+01, 1.0945e+02, 2.2150e+01, 8.0429e+00,\n",
            "        7.9491e+01, 2.1196e+00, 9.9586e+01, 5.3317e+01, 2.6116e+01, 4.8876e-06,\n",
            "        2.2150e+01, 1.0518e+01, 3.2422e+01, 1.9530e+01, 6.1778e+01, 3.0575e+00,\n",
            "        2.8138e+01, 4.7200e+01, 7.7675e+01, 3.6365e+00, 2.2150e+01, 2.2730e+01,\n",
            "        1.2610e+01, 2.1501e+00, 2.0194e+01, 1.9530e+01, 2.4554e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.3267e-04, 1.7433e-12, 5.5143e-17, 0.0000e+00, 1.7433e-12, 4.9468e-17,\n",
            "        3.6823e-31, 2.3968e-05, 3.4237e-41, 2.3987e-33, 7.3267e-04, 2.4630e-07,\n",
            "        1.7433e-12, 1.0458e-08, 1.2749e-17, 3.9192e-14, 8.6367e-37, 8.1521e-36,\n",
            "        8.5610e-22, 4.8823e-38, 6.1725e-30, 1.6726e-09, 1.7433e-12, 7.6385e-37,\n",
            "        1.7523e-17, 3.5995e-15, 1.9369e-09, 3.9192e-14, 2.8324e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  15\n",
            "ce_loss:  tensor([2.3942e+01, 2.1279e+01, 1.9508e+01, 1.0500e+02, 2.1279e+01, 6.2354e+00,\n",
            "        7.5647e+01, 1.7008e+00, 9.5483e+01, 5.1006e+01, 2.3942e+01, 3.3379e-06,\n",
            "        2.1279e+01, 9.0695e+00, 3.0269e+01, 1.8889e+01, 5.8730e+01, 3.1739e+00,\n",
            "        2.7514e+01, 4.5701e+01, 7.4198e+01, 2.9821e+00, 2.1279e+01, 2.2061e+01,\n",
            "        1.4937e+01, 2.3869e+00, 1.8083e+01, 1.8889e+01, 2.2789e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([8.8628e-04, 8.5598e-13, 1.3578e-16, 0.0000e+00, 8.5598e-13, 9.3441e-17,\n",
            "        7.0917e-32, 2.5586e-05, 1.2514e-41, 1.4156e-33, 8.8628e-04, 4.2383e-07,\n",
            "        8.5598e-13, 1.0019e-08, 1.0728e-17, 3.9246e-14, 5.6956e-37, 8.7475e-36,\n",
            "        2.5507e-22, 9.0462e-38, 1.7802e-30, 1.0965e-09, 8.5598e-13, 8.3105e-37,\n",
            "        2.2088e-17, 2.5046e-15, 1.9703e-09, 3.9246e-14, 2.8605e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  16\n",
            "ce_loss:  tensor([2.4206e+01, 1.9655e+01, 1.8462e+01, 1.0049e+02, 1.9655e+01, 7.3036e+00,\n",
            "        7.1824e+01, 2.4572e+00, 9.0619e+01, 4.8324e+01, 2.4206e+01, 3.5763e-06,\n",
            "        1.9655e+01, 6.3381e+00, 2.8099e+01, 1.7080e+01, 5.6461e+01, 1.9973e+00,\n",
            "        2.6865e+01, 4.3609e+01, 7.0732e+01, 1.6490e+00, 1.9655e+01, 2.0710e+01,\n",
            "        1.2041e+01, 1.4656e+00, 1.7988e+01, 1.7080e+01, 2.2704e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.1681e-03, 3.0480e-12, 8.9182e-17, 0.0000e+00, 3.0480e-12, 8.1178e-17,\n",
            "        1.7466e-32, 2.8984e-05, 6.6800e-42, 3.5487e-33, 1.1681e-03, 7.5470e-07,\n",
            "        3.0480e-12, 1.9064e-08, 1.5783e-17, 3.6753e-14, 2.0194e-36, 2.3217e-35,\n",
            "        5.6135e-22, 3.7848e-38, 4.7865e-31, 2.0036e-09, 3.0480e-12, 6.2851e-37,\n",
            "        2.4554e-17, 3.0089e-15, 3.1004e-09, 3.6753e-14, 3.3073e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  17\n",
            "ce_loss:  tensor([2.1977e+01, 1.8071e+01, 1.9891e+01, 9.7608e+01, 1.8071e+01, 5.0471e+00,\n",
            "        6.8821e+01, 1.3486e+00, 8.6058e+01, 4.6682e+01, 2.1977e+01, 2.5034e-06,\n",
            "        1.8071e+01, 5.7812e+00, 2.6443e+01, 1.7092e+01, 5.3780e+01, 1.2412e+00,\n",
            "        2.4849e+01, 4.1451e+01, 6.7235e+01, 1.3668e+00, 1.8071e+01, 1.9215e+01,\n",
            "        1.3407e+01, 8.3890e-01, 1.6676e+01, 1.7092e+01, 2.0778e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.3926e-03, 2.3270e-12, 9.1585e-17, 0.0000e+00, 2.3270e-12, 1.4139e-16,\n",
            "        2.5736e-32, 2.9693e-05, 2.7690e-42, 1.8196e-33, 1.3926e-03, 1.2466e-06,\n",
            "        2.3270e-12, 1.9287e-08, 6.2643e-18, 5.3939e-14, 8.9073e-37, 3.7610e-35,\n",
            "        5.4865e-22, 6.6769e-38, 2.1266e-31, 3.1841e-09, 2.3270e-12, 5.6177e-37,\n",
            "        2.7105e-17, 2.7090e-15, 2.4707e-09, 5.3939e-14, 3.3383e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  18\n",
            "ce_loss:  tensor([2.2013e+01, 1.6773e+01, 1.6994e+01, 9.3360e+01, 1.6773e+01, 5.4467e+00,\n",
            "        6.6223e+01, 1.9694e+00, 8.2025e+01, 4.3745e+01, 2.2013e+01, 2.5034e-06,\n",
            "        1.6773e+01, 7.0613e+00, 2.5578e+01, 1.5793e+01, 5.0919e+01, 1.0557e+00,\n",
            "        2.5027e+01, 3.9658e+01, 6.4660e+01, 1.2907e+00, 1.6773e+01, 1.8592e+01,\n",
            "        9.9354e+00, 5.7871e-01, 1.5751e+01, 1.5793e+01, 2.0639e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.8137e-03, 3.1064e-12, 6.7468e-17, 0.0000e+00, 3.1064e-12, 2.5256e-16,\n",
            "        2.3421e-33, 3.3514e-05, 1.7698e-42, 3.2529e-33, 1.8137e-03, 2.1270e-06,\n",
            "        3.1064e-12, 1.5352e-08, 5.0899e-18, 3.0001e-14, 2.1347e-36, 4.4845e-35,\n",
            "        8.4475e-22, 3.0566e-38, 3.7930e-31, 2.5292e-09, 3.1064e-12, 3.5964e-37,\n",
            "        2.7210e-17, 1.9341e-15, 2.6295e-09, 3.0001e-14, 3.8426e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  19\n",
            "ce_loss:  tensor([1.9672e+01, 1.5918e+01, 1.6716e+01, 9.0029e+01, 1.5918e+01, 5.1999e+00,\n",
            "        6.3207e+01, 1.3196e+00, 7.8904e+01, 4.2088e+01, 1.9672e+01, 2.0266e-06,\n",
            "        1.5918e+01, 6.3989e+00, 2.3160e+01, 1.3436e+01, 4.9448e+01, 5.8847e-01,\n",
            "        2.2852e+01, 3.8102e+01, 6.1725e+01, 6.0001e-01, 1.5918e+01, 1.7096e+01,\n",
            "        9.7839e+00, 2.7849e-01, 1.4825e+01, 1.3436e+01, 1.8822e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.1455e-03, 1.4460e-12, 9.5575e-17, 0.0000e+00, 1.4460e-12, 1.9964e-16,\n",
            "        4.5558e-33, 3.5045e-05, 3.5313e-43, 5.9003e-33, 2.1455e-03, 3.3581e-06,\n",
            "        1.4460e-12, 1.1013e-08, 5.4618e-18, 7.5676e-14, 6.8760e-37, 9.3766e-35,\n",
            "        2.9113e-22, 3.1284e-38, 1.2031e-31, 4.0008e-09, 1.4460e-12, 2.9233e-37,\n",
            "        4.2729e-17, 1.8455e-15, 1.8013e-09, 7.5676e-14, 3.8399e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  20\n",
            "ce_loss:  tensor([1.9643e+01, 1.4240e+01, 1.4835e+01, 8.6439e+01, 1.4240e+01, 4.0998e+00,\n",
            "        6.0304e+01, 2.2266e+00, 7.5410e+01, 3.9924e+01, 1.9643e+01, 1.7881e-06,\n",
            "        1.4240e+01, 5.4978e+00, 2.1828e+01, 1.3610e+01, 4.7861e+01, 4.0302e-01,\n",
            "        2.2212e+01, 3.6581e+01, 5.9404e+01, 6.8242e-01, 1.4240e+01, 1.5850e+01,\n",
            "        8.6865e+00, 2.5945e-01, 1.3430e+01, 1.3610e+01, 1.8572e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.7405e-03, 4.1643e-12, 8.5173e-17, 0.0000e+00, 4.1643e-12, 4.6201e-16,\n",
            "        1.7676e-33, 3.9155e-05, 1.4027e-42, 3.1230e-33, 2.7405e-03, 5.5701e-06,\n",
            "        4.1643e-12, 8.1600e-09, 3.2419e-18, 5.0746e-14, 6.6765e-36, 1.2883e-34,\n",
            "        2.1649e-22, 1.8538e-38, 1.3000e-31, 3.2686e-09, 4.1643e-12, 2.0776e-37,\n",
            "        2.2764e-17, 1.2899e-15, 2.0354e-09, 5.0746e-14, 4.4077e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  21\n",
            "ce_loss:  tensor([1.7375e+01, 1.4344e+01, 1.4716e+01, 8.2429e+01, 1.4344e+01, 5.1285e+00,\n",
            "        5.6939e+01, 9.9396e-01, 7.2113e+01, 3.8089e+01, 1.7375e+01, 1.4305e-06,\n",
            "        1.4344e+01, 3.2504e+00, 2.0137e+01, 1.4417e+01, 4.5695e+01, 2.2342e-01,\n",
            "        2.1870e+01, 3.3889e+01, 5.7013e+01, 3.5319e-01, 1.4344e+01, 1.5034e+01,\n",
            "        8.0217e+00, 1.1194e-01, 1.2279e+01, 1.4417e+01, 1.6923e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.2348e-03, 2.5751e-12, 8.9800e-17, 0.0000e+00, 2.5751e-12, 3.1245e-16,\n",
            "        2.2930e-33, 3.9933e-05, 6.6141e-43, 7.6455e-33, 3.2348e-03, 8.5912e-06,\n",
            "        2.5751e-12, 1.1890e-08, 1.8657e-18, 4.5685e-14, 1.0423e-35, 3.8489e-34,\n",
            "        4.5002e-22, 4.1106e-38, 1.9121e-32, 4.4103e-09, 2.5751e-12, 1.1408e-37,\n",
            "        2.3778e-17, 1.2894e-15, 2.2463e-09, 4.5685e-14, 4.3998e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  22\n",
            "ce_loss:  tensor([1.7484e+01, 1.1966e+01, 1.4026e+01, 7.9643e+01, 1.1966e+01, 2.9334e+00,\n",
            "        5.5441e+01, 1.6438e+00, 6.8557e+01, 3.6389e+01, 1.7484e+01, 1.1921e-06,\n",
            "        1.1966e+01, 2.5427e+00, 1.9675e+01, 1.3335e+01, 4.6571e+01, 1.6399e-01,\n",
            "        2.1412e+01, 3.3621e+01, 5.3585e+01, 2.9682e-01, 1.1966e+01, 1.3578e+01,\n",
            "        7.6932e+00, 8.9878e-02, 1.0006e+01, 1.3335e+01, 1.6574e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.0346e-03, 4.2906e-12, 7.5003e-17, 0.0000e+00, 4.2906e-12, 4.6089e-16,\n",
            "        4.0105e-34, 4.4590e-05, 2.0417e-42, 3.1086e-33, 4.0346e-03, 1.3715e-05,\n",
            "        4.2906e-12, 1.2899e-08, 7.7742e-18, 2.8883e-14, 1.4200e-35, 8.3001e-34,\n",
            "        5.1630e-22, 3.4159e-38, 3.0460e-32, 3.3235e-09, 4.2906e-12, 8.2443e-38,\n",
            "        5.0444e-17, 1.2127e-15, 4.0775e-09, 2.8883e-14, 5.0113e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  23\n",
            "ce_loss:  tensor([1.5023e+01, 1.2180e+01, 1.5112e+01, 7.5552e+01, 1.2180e+01, 4.1376e+00,\n",
            "        5.2433e+01, 6.7151e-01, 6.6211e+01, 3.3920e+01, 1.5023e+01, 8.3446e-07,\n",
            "        1.2180e+01, 4.8253e+00, 1.8579e+01, 1.0727e+01, 4.2628e+01, 1.5910e-01,\n",
            "        2.2487e+01, 3.4581e+01, 5.1841e+01, 1.2301e-01, 1.2180e+01, 1.2759e+01,\n",
            "        7.6965e+00, 5.5545e-02, 1.1458e+01, 1.0727e+01, 1.5041e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.6961e-03, 3.6705e-12, 8.2787e-17, 0.0000e+00, 3.6705e-12, 8.7444e-16,\n",
            "        4.1425e-34, 4.5461e-05, 3.1669e-43, 6.9690e-33, 4.6961e-03, 2.0449e-05,\n",
            "        3.6705e-12, 7.7224e-09, 2.9832e-18, 3.7101e-14, 2.1275e-35, 7.2055e-34,\n",
            "        3.5244e-22, 3.9902e-38, 9.5511e-33, 5.3268e-09, 3.6705e-12, 5.2009e-38,\n",
            "        2.4901e-17, 1.0758e-15, 2.0740e-09, 3.7101e-14, 4.9443e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  24\n",
            "ce_loss:  tensor([1.5234e+01, 1.0495e+01, 1.3032e+01, 7.2154e+01, 1.0495e+01, 4.9132e+00,\n",
            "        5.0659e+01, 1.2283e+00, 6.2259e+01, 3.2701e+01, 1.5234e+01, 7.1526e-07,\n",
            "        1.0495e+01, 3.5272e+00, 2.0377e+01, 1.0060e+01, 3.9933e+01, 9.8363e-02,\n",
            "        1.9971e+01, 3.0088e+01, 4.9081e+01, 7.1411e-02, 1.0495e+01, 1.1994e+01,\n",
            "        6.5052e+00, 3.2479e-02, 9.2378e+00, 1.0060e+01, 1.4734e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.7992e-03, 5.5766e-12, 5.8388e-17, 0.0000e+00, 5.5766e-12, 5.6796e-16,\n",
            "        3.6854e-33, 5.0317e-05, 7.6511e-43, 5.3774e-33, 5.7992e-03, 3.1751e-05,\n",
            "        5.5766e-12, 5.0452e-09, 4.1585e-18, 4.4548e-14, 1.3965e-34, 1.4559e-33,\n",
            "        3.7221e-22, 6.3653e-38, 6.8484e-33, 7.4569e-09, 5.5766e-12, 3.1058e-38,\n",
            "        5.1644e-17, 1.2595e-15, 1.7578e-09, 4.4548e-14, 5.6502e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  25\n",
            "ce_loss:  tensor([1.2680e+01, 1.1741e+01, 1.1590e+01, 6.8885e+01, 1.1741e+01, 2.6597e+00,\n",
            "        4.9908e+01, 5.5398e-01, 6.0348e+01, 3.0033e+01, 1.2680e+01, 5.9605e-07,\n",
            "        1.1741e+01, 1.2849e+00, 1.6576e+01, 9.1883e+00, 4.2379e+01, 7.6340e-02,\n",
            "        2.1253e+01, 2.9492e+01, 4.8575e+01, 3.3864e-02, 1.1741e+01, 1.0874e+01,\n",
            "        6.4180e+00, 1.7458e-02, 7.8190e+00, 9.1883e+00, 1.2948e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([6.6641e-03, 2.7522e-12, 6.9669e-17, 0.0000e+00, 2.7522e-12, 1.1795e-15,\n",
            "        2.6086e-34, 5.1658e-05, 1.4125e-42, 9.7499e-33, 6.6641e-03, 4.5891e-05,\n",
            "        2.7522e-12, 6.1870e-09, 4.0130e-18, 4.9660e-14, 1.3582e-34, 2.3120e-33,\n",
            "        2.2422e-22, 2.9567e-38, 1.0680e-32, 9.0548e-09, 2.7522e-12, 1.7192e-38,\n",
            "        4.8571e-17, 1.0179e-15, 2.8158e-09, 4.9660e-14, 5.5871e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  26\n",
            "ce_loss:  tensor([1.2734e+01, 8.5219e+00, 1.0903e+01, 6.4947e+01, 8.5219e+00, 3.6707e+00,\n",
            "        4.7012e+01, 1.1825e+00, 6.0341e+01, 2.9155e+01, 1.2734e+01, 4.7684e-07,\n",
            "        8.5219e+00, 6.3199e-01, 1.5813e+01, 8.8044e+00, 3.8916e+01, 5.7303e-02,\n",
            "        1.9466e+01, 2.8537e+01, 4.7324e+01, 1.6871e-02, 8.5219e+00, 1.0342e+01,\n",
            "        7.1414e+00, 9.4348e-03, 7.3639e+00, 8.8044e+00, 1.2644e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([8.0890e-03, 4.8379e-12, 6.4162e-17, 0.0000e+00, 4.8379e-12, 7.1827e-16,\n",
            "        2.1448e-33, 5.6586e-05, 1.2261e-42, 1.0148e-32, 8.0890e-03, 6.9034e-05,\n",
            "        4.8379e-12, 5.3085e-09, 7.1603e-18, 4.5760e-14, 2.1109e-34, 2.4000e-33,\n",
            "        3.4968e-22, 1.0380e-37, 8.1513e-33, 1.7499e-08, 4.8379e-12, 8.9247e-39,\n",
            "        5.2879e-17, 8.6078e-16, 2.4480e-09, 4.5760e-14, 6.3072e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  27\n",
            "ce_loss:  tensor([1.0361e+01, 7.8391e+00, 9.8513e+00, 6.2402e+01, 7.8391e+00, 1.6850e+00,\n",
            "        4.6601e+01, 3.5696e-01, 5.6101e+01, 3.0166e+01, 1.0361e+01, 3.5763e-07,\n",
            "        7.8391e+00, 2.6323e-01, 1.5350e+01, 7.3644e+00, 3.6291e+01, 4.3522e-02,\n",
            "        1.7418e+01, 2.7762e+01, 4.4931e+01, 5.5149e-03, 7.8391e+00, 9.8083e+00,\n",
            "        5.2764e+00, 5.0051e-03, 5.4537e+00, 7.3644e+00, 1.0936e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.2133e-03, 1.0141e-11, 6.8842e-17, 0.0000e+00, 1.0141e-11, 1.2028e-15,\n",
            "        2.6078e-33, 5.7473e-05, 1.1743e-42, 1.5095e-32, 9.2133e-03, 9.7909e-05,\n",
            "        1.0141e-11, 5.9781e-09, 3.1024e-18, 4.8063e-14, 3.8043e-33, 3.8146e-33,\n",
            "        4.2782e-22, 1.3980e-37, 1.0502e-32, 3.0315e-08, 1.0141e-11, 1.0149e-38,\n",
            "        3.8288e-17, 8.8940e-16, 2.9232e-09, 4.8063e-14, 6.2402e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  28\n",
            "ce_loss:  tensor([9.9003e+00, 7.6373e+00, 1.0169e+01, 5.9955e+01, 7.6373e+00, 4.1579e+00,\n",
            "        4.6417e+01, 8.1046e-01, 5.2726e+01, 2.7399e+01, 9.9003e+00, 3.5763e-07,\n",
            "        7.6373e+00, 2.3391e-01, 1.3012e+01, 8.7862e+00, 3.6519e+01, 3.4934e-02,\n",
            "        1.7323e+01, 2.8053e+01, 4.4478e+01, 3.2658e-03, 7.6373e+00, 8.9009e+00,\n",
            "        6.1685e+00, 1.8613e-03, 6.2471e+00, 8.7862e+00, 1.0504e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.1004e-02, 4.0630e-12, 4.7888e-17, 0.0000e+00, 4.0630e-12, 6.7569e-16,\n",
            "        1.7675e-33, 6.2701e-05, 9.5821e-42, 1.2884e-32, 1.1004e-02, 1.4151e-04,\n",
            "        4.0630e-12, 5.1484e-09, 6.9825e-18, 2.2826e-14, 9.1102e-34, 4.1620e-33,\n",
            "        1.3123e-21, 1.1983e-37, 9.2683e-33, 6.5556e-08, 4.0630e-12, 5.3180e-39,\n",
            "        4.0916e-17, 7.6160e-16, 2.6785e-09, 2.2826e-14, 6.9745e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  29\n",
            "ce_loss:  tensor([7.7026e+00, 5.8384e+00, 8.0544e+00, 5.6255e+01, 5.8384e+00, 1.0837e+00,\n",
            "        4.3904e+01, 2.0897e-01, 5.1982e+01, 2.4985e+01, 7.7026e+00, 2.3842e-07,\n",
            "        5.8384e+00, 7.2960e-02, 1.2820e+01, 5.7877e+00, 3.3960e+01, 2.4265e-02,\n",
            "        1.7137e+01, 2.5890e+01, 4.2889e+01, 2.4790e-03, 5.8384e+00, 9.1140e+00,\n",
            "        4.4160e+00, 7.8480e-04, 5.3155e+00, 5.7877e+00, 8.9914e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.2416e-02, 7.4410e-12, 7.6589e-17, 0.0000e+00, 7.4410e-12, 9.3655e-16,\n",
            "        1.2658e-33, 6.3658e-05, 3.0100e-42, 6.2212e-32, 1.2416e-02, 1.9358e-04,\n",
            "        7.4410e-12, 5.0962e-09, 1.7613e-17, 2.9979e-14, 1.3904e-32, 8.5307e-33,\n",
            "        4.0240e-22, 1.5704e-37, 5.9049e-33, 1.2878e-07, 7.4410e-12, 5.3848e-39,\n",
            "        3.4239e-17, 7.6520e-16, 1.3385e-09, 2.9979e-14, 6.8888e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  30\n",
            "ce_loss:  tensor([7.2468e+00, 5.5440e+00, 8.6821e+00, 5.4924e+01, 5.5440e+00, 2.3846e+00,\n",
            "        4.0669e+01, 5.2440e-01, 4.8612e+01, 2.4741e+01, 7.2468e+00, 2.3842e-07,\n",
            "        5.5440e+00, 3.3122e-02, 1.2455e+01, 5.8726e+00, 3.3815e+01, 2.5131e-02,\n",
            "        1.6011e+01, 2.6187e+01, 3.9562e+01, 1.6334e-03, 5.5440e+00, 7.6882e+00,\n",
            "        4.8530e+00, 4.6314e-04, 3.4738e+00, 5.8726e+00, 8.4373e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.4552e-02, 1.0046e-11, 1.1167e-16, 0.0000e+00, 1.0046e-11, 1.4180e-15,\n",
            "        1.1070e-32, 6.8811e-05, 1.8839e-41, 4.2485e-32, 1.4552e-02, 2.7062e-04,\n",
            "        1.0046e-11, 4.5800e-09, 6.8134e-18, 4.6126e-14, 1.5732e-31, 2.1699e-32,\n",
            "        1.0999e-21, 1.9188e-37, 7.1962e-32, 2.3304e-07, 1.0046e-11, 2.3596e-39,\n",
            "        3.2337e-17, 7.8304e-16, 1.8903e-09, 4.6126e-14, 7.6270e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  31\n",
            "ce_loss:  tensor([4.9094e+00, 6.6864e+00, 7.9782e+00, 5.2993e+01, 6.6864e+00, 2.6414e+00,\n",
            "        4.1439e+01, 1.2373e-01, 4.6590e+01, 2.2250e+01, 4.9094e+00, 1.1921e-07,\n",
            "        6.6864e+00, 1.3552e-02, 1.3447e+01, 5.9865e+00, 3.2641e+01, 1.9355e-02,\n",
            "        1.7466e+01, 2.3921e+01, 4.0607e+01, 1.0901e-03, 6.6864e+00, 7.6519e+00,\n",
            "        3.3442e+00, 1.9143e-04, 4.4208e+00, 5.9865e+00, 7.0630e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.6220e-02, 4.2372e-12, 4.5532e-17, 0.0000e+00, 4.2372e-12, 1.0005e-15,\n",
            "        1.0515e-32, 6.9653e-05, 1.4010e-40, 2.0097e-31, 1.6220e-02, 3.6186e-04,\n",
            "        4.2372e-12, 5.0644e-09, 7.2752e-18, 2.4182e-14, 4.0488e-32, 1.4545e-32,\n",
            "        9.2172e-22, 2.2902e-37, 5.1996e-32, 3.8408e-07, 4.2372e-12, 2.0959e-39,\n",
            "        2.4583e-17, 7.3112e-16, 2.8159e-09, 2.4182e-14, 7.5292e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  32\n",
            "ce_loss:  tensor([4.4832e+00, 4.4800e+00, 6.6056e+00, 5.0166e+01, 4.4800e+00, 7.3508e-01,\n",
            "        3.9132e+01, 3.1141e-01, 4.5876e+01, 2.1857e+01, 4.4832e+00, 1.1921e-07,\n",
            "        4.4800e+00, 4.6255e-03, 1.0730e+01, 3.9075e+00, 3.1078e+01, 1.1133e-02,\n",
            "        1.7139e+01, 2.4838e+01, 3.7923e+01, 7.2382e-04, 4.4800e+00, 6.5686e+00,\n",
            "        2.4609e+00, 1.0943e-04, 4.7691e+00, 3.9075e+00, 6.3101e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.8748e-02, 4.8206e-12, 6.4995e-17, 0.0000e+00, 4.8206e-12, 1.6605e-15,\n",
            "        7.1519e-33, 7.4853e-05, 3.2917e-41, 1.1942e-30, 1.8748e-02, 4.8819e-04,\n",
            "        4.8206e-12, 7.5617e-09, 5.8044e-18, 2.9607e-14, 4.0609e-31, 2.6724e-32,\n",
            "        5.5438e-22, 2.9167e-37, 4.1731e-32, 6.1833e-07, 4.8206e-12, 8.7658e-40,\n",
            "        3.6159e-17, 4.9292e-16, 1.7038e-09, 2.9607e-14, 8.3222e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  33\n",
            "ce_loss:  tensor([2.0850e+00, 4.7386e+00, 6.1405e+00, 4.8316e+01, 4.7386e+00, 1.9009e+00,\n",
            "        3.6119e+01, 6.4286e-02, 4.2708e+01, 2.1072e+01, 2.0850e+00, 1.1921e-07,\n",
            "        4.7386e+00, 1.8949e-03, 9.0711e+00, 5.2002e+00, 3.1163e+01, 8.5015e-03,\n",
            "        1.5955e+01, 2.3311e+01, 3.5171e+01, 4.0702e-04, 4.7386e+00, 6.3566e+00,\n",
            "        2.9377e+00, 5.7219e-05, 2.5661e+00, 5.2002e+00, 5.0255e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.0619e-02, 3.0556e-12, 4.3166e-17, 0.0000e+00, 3.0556e-12, 1.0637e-15,\n",
            "        2.6882e-32, 7.5497e-05, 3.8868e-40, 4.0756e-31, 2.0619e-02, 6.3034e-04,\n",
            "        3.0556e-12, 1.9735e-08, 1.0040e-17, 3.6078e-14, 8.1547e-31, 4.5243e-32,\n",
            "        6.6490e-22, 2.5044e-37, 5.1018e-31, 9.2526e-07, 3.0556e-12, 6.8583e-40,\n",
            "        2.9771e-17, 5.9839e-16, 1.4847e-09, 3.6078e-14, 8.1926e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  34\n",
            "ce_loss:  tensor([1.6846e+00, 3.0193e+00, 8.0543e+00, 4.4719e+01, 3.0193e+00, 3.1581e-01,\n",
            "        3.4001e+01, 1.6410e-01, 4.0802e+01, 1.8953e+01, 1.6846e+00, 1.1921e-07,\n",
            "        3.0193e+00, 1.0344e-03, 7.9534e+00, 6.0331e+00, 3.0757e+01, 6.2645e-03,\n",
            "        1.3999e+01, 2.0465e+01, 3.8563e+01, 2.7152e-04, 3.0193e+00, 5.4370e+00,\n",
            "        1.7562e+00, 1.1741e-04, 4.1742e+00, 6.0331e+00, 4.0988e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.3453e-02, 3.3231e-12, 3.8999e-17, 0.0000e+00, 3.3231e-12, 1.5752e-15,\n",
            "        1.5829e-31, 8.0776e-05, 4.7884e-39, 2.2733e-30, 2.3453e-02, 8.2756e-04,\n",
            "        3.3231e-12, 4.9999e-08, 1.3522e-17, 1.4590e-14, 8.0322e-31, 7.3257e-32,\n",
            "        1.3226e-21, 1.0423e-36, 4.1885e-31, 1.3690e-06, 3.3231e-12, 2.3858e-40,\n",
            "        1.9340e-17, 3.8617e-16, 9.8402e-10, 1.4590e-14, 8.9703e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  35\n",
            "ce_loss:  tensor([2.8706e-01, 2.4744e+00, 5.9123e+00, 4.3348e+01, 2.4744e+00, 8.0279e-02,\n",
            "        3.4305e+01, 3.3500e-02, 4.0827e+01, 1.9541e+01, 2.8706e-01, -0.0000e+00,\n",
            "        2.4744e+00, 7.6253e-04, 7.3373e+00, 2.8939e+00, 2.8659e+01, 4.0092e-03,\n",
            "        1.3534e+01, 2.0156e+01, 3.4904e+01, 1.5663e-04, 2.4744e+00, 5.1107e+00,\n",
            "        1.9217e+00, 2.8371e-05, 1.8174e+00, 2.8939e+00, 3.0214e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.5565e-02, 4.0536e-12, 2.3257e-17, 0.0000e+00, 4.0536e-12, 1.7727e-15,\n",
            "        5.8276e-32, 8.1241e-05, 2.2130e-39, 3.0412e-30, 2.5565e-02, 1.0375e-03,\n",
            "        4.0536e-12, 1.1594e-07, 2.3540e-17, 1.9642e-14, 1.8104e-30, 1.0597e-31,\n",
            "        2.9670e-21, 3.7891e-36, 2.3811e-31, 1.9082e-06, 4.0536e-12, 1.5207e-40,\n",
            "        1.5738e-17, 5.5051e-16, 9.0954e-10, 1.9642e-14, 8.9642e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  36\n",
            "ce_loss:  tensor([4.2514e-01, 4.5562e+00, 3.8287e+00, 4.1690e+01, 4.5562e+00, 4.8421e-02,\n",
            "        3.1226e+01, 8.0305e-02, 3.9974e+01, 1.8591e+01, 4.2514e-01, -0.0000e+00,\n",
            "        4.5562e+00, 3.5244e-04, 6.8710e+00, 6.7786e+00, 2.6148e+01, 2.8925e-03,\n",
            "        1.4468e+01, 2.0000e+01, 3.1663e+01, 1.1038e-04, 4.5562e+00, 4.5093e+00,\n",
            "        1.2376e+00, 2.6583e-05, 1.7388e+00, 6.7786e+00, 1.9307e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.8566e-02, 1.9916e-12, 2.5807e-17, 0.0000e+00, 1.9916e-12, 1.7584e-15,\n",
            "        2.6014e-31, 8.6489e-05, 2.5113e-39, 3.0960e-30, 2.8566e-02, 1.3270e-03,\n",
            "        1.9916e-12, 2.4270e-07, 1.2513e-17, 8.2475e-15, 9.3738e-30, 1.0526e-31,\n",
            "        9.1198e-22, 9.3413e-37, 2.4182e-30, 2.6466e-06, 1.9916e-12, 8.6967e-41,\n",
            "        9.7569e-18, 3.7147e-16, 1.2769e-09, 8.2475e-15, 9.5781e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  37\n",
            "ce_loss:  tensor([2.1956e-02, 1.7368e+00, 3.0148e+00, 4.1442e+01, 1.7368e+00, 1.6917e-02,\n",
            "        3.1129e+01, 1.5805e-02, 3.7407e+01, 1.5842e+01, 2.1956e-02, -0.0000e+00,\n",
            "        1.7368e+00, 3.0513e-04, 5.7654e+00, 3.9140e+00, 2.4994e+01, 2.2121e-03,\n",
            "        1.2597e+01, 1.7842e+01, 3.2357e+01, 6.5325e-05, 1.7368e+00, 3.6060e+00,\n",
            "        6.6441e-01, 1.8477e-05, 3.8078e+00, 3.9140e+00, 1.2252e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.0573e-02, 1.8086e-12, 3.2593e-17, 0.0000e+00, 1.8086e-12, 1.7195e-15,\n",
            "        1.2643e-30, 8.6938e-05, 3.4587e-39, 1.5868e-29, 3.0573e-02, 1.6217e-03,\n",
            "        1.8086e-12, 4.6495e-07, 1.1749e-17, 5.4131e-15, 5.5551e-29, 1.7105e-31,\n",
            "        1.8673e-21, 3.0956e-36, 3.5552e-30, 3.5277e-06, 1.8086e-12, 4.0360e-41,\n",
            "        8.7356e-18, 5.2948e-16, 7.5143e-10, 5.4131e-15, 9.5715e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  38\n",
            "ce_loss:  tensor([4.3266e-02, 2.0502e+00, 2.9672e+00, 3.7828e+01, 2.0502e+00, 8.8074e-03,\n",
            "        3.0251e+01, 4.0702e-02, 3.4553e+01, 1.6038e+01, 4.3266e-02, -0.0000e+00,\n",
            "        2.0502e+00, 1.4280e-04, 6.3330e+00, 3.6932e+00, 2.6418e+01, 1.4466e-03,\n",
            "        1.2655e+01, 1.9750e+01, 3.1337e+01, 4.2557e-05, 2.0502e+00, 3.4506e+00,\n",
            "        8.2110e-01, 7.6294e-06, 7.6769e-01, 3.6932e+00, 5.2498e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.3954e-02, 2.5143e-12, 2.1350e-17, 0.0000e+00, 2.5143e-12, 1.4233e-15,\n",
            "        2.1743e-31, 9.1633e-05, 2.9669e-38, 5.9875e-29, 3.3954e-02, 1.9896e-03,\n",
            "        2.5143e-12, 8.5965e-07, 3.9921e-18, 4.2269e-15, 3.6300e-29, 1.3939e-31,\n",
            "        1.9492e-21, 3.0014e-36, 2.7126e-30, 4.6764e-06, 2.5143e-12, 5.3106e-41,\n",
            "        7.4123e-18, 4.8418e-16, 9.1047e-10, 4.2269e-15, 1.0199e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  39\n",
            "ce_loss:  tensor([2.4873e-03, 3.7330e+00, 1.6091e+00, 3.7479e+01, 3.7330e+00, 6.9091e-03,\n",
            "        2.7455e+01, 8.3192e-03, 3.2619e+01, 1.5735e+01, 2.4873e-03, -0.0000e+00,\n",
            "        3.7330e+00, 1.1384e-04, 4.1837e+00, 1.8534e+00, 2.3934e+01, 9.6692e-04,\n",
            "        1.3370e+01, 1.6913e+01, 2.9711e+01, 2.5391e-05, 3.7330e+00, 2.9910e+00,\n",
            "        4.3695e-01, 1.9073e-05, 1.5113e+00, 1.8534e+00, 2.9972e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.5778e-02, 1.2825e-12, 2.2566e-17, 0.0000e+00, 1.2825e-12, 1.4712e-15,\n",
            "        1.2216e-30, 9.1803e-05, 1.3790e-37, 2.0975e-29, 3.5778e-02, 2.3387e-03,\n",
            "        1.2825e-12, 1.4717e-06, 5.1473e-18, 5.4417e-15, 7.1946e-29, 1.4501e-31,\n",
            "        1.7000e-21, 2.6163e-36, 2.4897e-30, 5.9785e-06, 1.2825e-12, 1.5811e-41,\n",
            "        4.5711e-18, 4.0201e-16, 1.0007e-09, 5.4417e-15, 9.9954e-02],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  40\n",
            "ce_loss:  tensor([4.5661e-03, 8.7514e-01, 1.0927e+00, 3.4443e+01, 8.7514e-01, 1.0924e-02,\n",
            "        2.7221e+01, 2.1179e-02, 3.3340e+01, 1.3181e+01, 4.5661e-03, -0.0000e+00,\n",
            "        8.7514e-01, 6.4729e-05, 3.0094e+00, 1.1887e+00, 2.1455e+01, 5.9837e-04,\n",
            "        1.3951e+01, 1.5512e+01, 2.7573e+01, 1.6808e-05, 8.7514e-01, 2.3397e+00,\n",
            "        2.5889e-01, 3.3379e-06, 2.4538e+00, 1.1887e+00, 9.4124e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.9034e-02, 1.0613e-12, 1.6150e-17, 0.0000e+00, 1.0613e-12, 9.8479e-16,\n",
            "        3.1632e-30, 9.6064e-05, 1.3218e-37, 6.1097e-29, 3.9034e-02, 2.8031e-03,\n",
            "        1.0613e-12, 2.4502e-06, 6.9174e-18, 6.7700e-15, 3.4055e-28, 1.5288e-31,\n",
            "        8.6679e-22, 8.6900e-36, 1.6199e-29, 7.6001e-06, 1.0613e-12, 2.1586e-41,\n",
            "        3.5350e-18, 5.3906e-16, 5.2902e-10, 6.7700e-15, 1.0710e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  41\n",
            "ce_loss:  tensor([4.2072e-04, 1.0382e+00, 5.8139e-01, 3.1320e+01, 1.0382e+00, 2.9816e-03,\n",
            "        2.6855e+01, 4.5296e-03, 3.0832e+01, 1.3659e+01, 4.2072e-04, -0.0000e+00,\n",
            "        1.0382e+00, 8.2132e-05, 2.9106e+00, 3.3597e+00, 2.3453e+01, 4.8483e-04,\n",
            "        1.3345e+01, 1.6666e+01, 2.8506e+01, 9.8943e-06, 1.0382e+00, 1.9283e+00,\n",
            "        3.2388e-01, 1.3590e-05, 1.6281e-01, 3.3597e+00, 4.5345e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.0972e-02, 1.1842e-12, 1.9053e-17, 1.4013e-45, 1.1842e-12, 1.2045e-15,\n",
            "        8.3008e-31, 9.6028e-05, 2.1516e-37, 6.8499e-29, 4.0972e-02, 3.1869e-03,\n",
            "        1.1842e-12, 3.7852e-06, 6.8752e-18, 2.5143e-15, 2.2092e-28, 1.7783e-31,\n",
            "        6.0428e-22, 5.4445e-36, 9.7868e-30, 9.2728e-06, 1.1842e-12, 1.0845e-41,\n",
            "        1.7345e-18, 3.9470e-16, 6.1286e-10, 2.5143e-15, 1.0479e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  42\n",
            "ce_loss:  tensor([9.3631e-04, 2.2363e+00, 3.4986e-01, 2.9451e+01, 2.2363e+00, 2.1406e-03,\n",
            "        2.3975e+01, 1.0945e-02, 2.8064e+01, 1.3383e+01, 9.3631e-04, -0.0000e+00,\n",
            "        2.2363e+00, 3.6477e-05, 3.1837e+00, 6.6820e-01, 2.0616e+01, 2.5615e-04,\n",
            "        1.0789e+01, 1.4550e+01, 2.6851e+01, 7.0333e-06, 2.2363e+00, 2.1788e+00,\n",
            "        1.7533e-01, 1.5497e-06, 2.8973e-01, 6.6820e-01, 1.7123e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.3889e-02, 5.8873e-13, 1.0363e-17, 1.6816e-44, 5.8873e-13, 9.7665e-16,\n",
            "        3.7618e-30, 9.9985e-05, 1.1453e-36, 5.6611e-29, 4.3889e-02, 3.6924e-03,\n",
            "        5.8873e-13, 5.8632e-06, 2.3669e-18, 2.9319e-15, 1.4521e-28, 1.5882e-31,\n",
            "        9.7847e-22, 5.8528e-36, 1.0411e-29, 1.1419e-05, 5.8873e-13, 1.6203e-41,\n",
            "        1.4696e-18, 5.1345e-16, 7.4587e-10, 2.9319e-15, 1.1165e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  43\n",
            "ce_loss:  tensor([9.4409e-05, 3.0194e-01, 1.1254e-01, 3.0987e+01, 3.0194e-01, 1.3000e-03,\n",
            "        2.3669e+01, 2.4963e-03, 2.7387e+01, 1.1530e+01, 9.4409e-05, -0.0000e+00,\n",
            "        3.0194e-01, 1.2921e-04, 1.7353e+00, 3.9993e-01, 1.8315e+01, 1.4590e-04,\n",
            "        1.0246e+01, 1.5960e+01, 2.4078e+01, 4.0531e-06, 3.0194e-01, 1.5485e+00,\n",
            "        1.7543e-01, 1.3113e-06, 9.4324e-01, 3.9993e-01, 9.4218e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.5787e-02, 7.3709e-13, 1.0722e-17, 2.2421e-44, 7.3709e-13, 7.5565e-16,\n",
            "        1.4779e-29, 9.9615e-05, 3.3349e-36, 1.5076e-28, 4.5787e-02, 4.1058e-03,\n",
            "        7.3709e-13, 8.1182e-06, 2.7665e-18, 2.8583e-15, 6.0011e-28, 2.2247e-31,\n",
            "        1.8151e-21, 4.9457e-36, 5.9817e-29, 1.3512e-05, 7.3709e-13, 7.8192e-42,\n",
            "        9.0827e-19, 3.2678e-16, 4.0356e-10, 2.8583e-15, 1.0918e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  44\n",
            "ce_loss:  tensor([1.9775e-04, 1.1757e+01, 5.0511e-02, 2.6657e+01, 1.1757e+01, 1.3333e-03,\n",
            "        2.3040e+01, 5.5021e-03, 2.7944e+01, 9.6109e+00, 1.9775e-04, -0.0000e+00,\n",
            "        1.1757e+01, 1.9312e-05, 1.2608e+00, 1.3940e+00, 1.7790e+01, 1.1324e-04,\n",
            "        1.0920e+01, 1.4304e+01, 2.6028e+01, 3.4571e-06, 1.1757e+01, 1.1026e+00,\n",
            "        1.5291e-01, 1.0729e-06, 5.0260e-02, 1.3940e+00, 3.9162e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.8183e-02, 6.5128e-13, 8.8440e-18, 4.4842e-44, 6.5128e-13, 4.7590e-16,\n",
            "        5.5016e-30, 1.0349e-04, 2.2411e-36, 4.3764e-28, 4.8183e-02, 4.5908e-03,\n",
            "        6.5128e-13, 1.2083e-05, 3.8247e-18, 1.0507e-15, 1.9968e-27, 2.0831e-31,\n",
            "        8.1431e-22, 2.2512e-36, 3.6632e-29, 1.5983e-05, 6.5128e-13, 3.6434e-42,\n",
            "        4.9500e-19, 3.1180e-16, 4.0437e-10, 1.0507e-15, 1.1480e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  45\n",
            "ce_loss:  tensor([2.2530e-05, 1.3911e+00, 2.6095e-02, 2.3745e+01, 1.3911e+00, 7.3072e-04,\n",
            "        2.0374e+01, 1.3893e-03, 2.5204e+01, 8.9671e+00, 2.2530e-05, -0.0000e+00,\n",
            "        1.3911e+00, 1.9550e-05, 1.7359e+00, 1.5431e-01, 1.8074e+01, 8.9761e-05,\n",
            "        9.3604e+00, 1.2066e+01, 2.3796e+01, 2.1458e-06, 1.3911e+00, 8.5435e-01,\n",
            "        1.1739e-01, 4.7684e-07, 9.8488e-03, 1.5431e-01, 2.3139e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.9518e-02, 3.2267e-13, 6.3700e-18, 2.9147e-43, 3.2267e-13, 5.8684e-16,\n",
            "        1.9878e-29, 1.0236e-04, 3.7643e-36, 8.2332e-28, 4.9518e-02, 5.0315e-03,\n",
            "        3.2267e-13, 1.5852e-05, 1.6977e-18, 1.4029e-15, 7.5630e-28, 2.8392e-31,\n",
            "        1.4907e-21, 5.2866e-36, 3.0824e-29, 1.8405e-05, 3.2267e-13, 3.0352e-42,\n",
            "        3.1951e-19, 2.3566e-16, 5.1688e-10, 1.4029e-15, 1.1276e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  46\n",
            "ce_loss:  tensor([4.8517e-05, 1.3394e-01, 1.4914e-02, 2.5551e+01, 1.3394e-01, 2.0862e-03,\n",
            "        2.0856e+01, 2.9510e-03, 2.2396e+01, 1.0505e+01, 4.8517e-05, -0.0000e+00,\n",
            "        1.3394e-01, 6.6757e-06, 9.5280e-01, 1.1030e+00, 1.5439e+01, 5.1378e-05,\n",
            "        9.3933e+00, 1.1663e+01, 2.0773e+01, 1.4305e-06, 1.3394e-01, 8.9196e-01,\n",
            "        8.1850e-02, 2.3842e-07, 3.7373e-03, 1.1030e+00, 8.9296e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.1362e-02, 3.6044e-13, 7.3234e-18, 2.6485e-43, 3.6044e-13, 3.2312e-16,\n",
            "        2.5778e-29, 1.0581e-04, 2.1903e-35, 1.0198e-27, 5.1362e-02, 5.3605e-03,\n",
            "        3.6044e-13, 2.1922e-05, 1.5293e-18, 1.3612e-15, 2.2862e-27, 2.7455e-31,\n",
            "        1.8307e-21, 1.3558e-35, 1.2478e-28, 2.1220e-05, 3.6044e-13, 1.2163e-42,\n",
            "        1.3610e-19, 1.7939e-16, 5.4456e-10, 1.3612e-15, 1.1738e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  47\n",
            "ce_loss:  tensor([5.8412e-06, 2.6433e+00, 5.8116e-03, 2.1754e+01, 2.6433e+00, 5.7299e-04,\n",
            "        2.0248e+01, 7.6396e-04, 2.1201e+01, 8.0831e+00, 5.8412e-06, -0.0000e+00,\n",
            "        2.6433e+00, 4.8876e-06, 6.1613e-01, 1.4081e+00, 1.8404e+01, 3.9934e-05,\n",
            "        1.0182e+01, 1.1951e+01, 2.0562e+01, 8.3446e-07, 2.6433e+00, 6.0096e-01,\n",
            "        5.1611e-02, 1.3113e-06, 1.8414e-03, 1.4081e+00, 6.4269e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.2143e-02, 4.3594e-13, 4.0898e-18, 4.8065e-43, 4.3594e-13, 3.0884e-16,\n",
            "        1.3302e-29, 1.0432e-04, 9.5519e-35, 1.0215e-27, 5.2143e-02, 5.7237e-03,\n",
            "        4.3594e-13, 2.7039e-05, 1.9551e-18, 6.9022e-16, 1.4852e-27, 3.3198e-31,\n",
            "        7.9618e-22, 4.1905e-36, 3.7715e-28, 2.3846e-05, 4.3594e-13, 1.1435e-42,\n",
            "        8.1654e-20, 1.2175e-16, 1.0516e-09, 6.9022e-16, 1.1466e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  48\n",
            "ce_loss:  tensor([1.5020e-05, 4.3684e-01, 2.5664e-03, 1.8784e+01, 4.3684e-01, 3.7151e-04,\n",
            "        1.9519e+01, 1.5390e-03, 2.2067e+01, 6.4566e+00, 1.5020e-05, -0.0000e+00,\n",
            "        4.3684e-01, 2.1458e-06, 7.9996e-01, 6.3883e-02, 1.6194e+01, 2.4199e-05,\n",
            "        8.2748e+00, 9.6899e+00, 1.9982e+01, 5.9605e-07, 4.3684e-01, 5.8374e-01,\n",
            "        4.2797e-02, 1.1921e-07, 1.3628e-03, 6.3883e-02, 2.1265e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3487e-02, 2.3281e-13, 3.8342e-18, 2.4369e-42, 2.3281e-13, 2.1577e-16,\n",
            "        1.6081e-29, 1.0723e-04, 6.3319e-35, 1.8879e-27, 5.3487e-02, 5.9111e-03,\n",
            "        2.3281e-13, 3.5415e-05, 8.9315e-19, 7.9152e-16, 2.2904e-27, 1.6953e-31,\n",
            "        9.1823e-22, 9.9205e-36, 6.3606e-29, 2.6739e-05, 2.3281e-13, 8.6320e-43,\n",
            "        6.9982e-20, 1.0950e-16, 2.5080e-09, 7.9152e-16, 1.1882e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  49\n",
            "ce_loss:  tensor([1.6689e-06, 7.4897e-02, 9.0963e-04, 1.7914e+01, 7.4897e-02, 3.5542e-04,\n",
            "        1.6537e+01, 4.2561e-04, 1.9473e+01, 9.2550e+00, 1.6689e-06, -0.0000e+00,\n",
            "        7.4897e-02, 1.6689e-06, 2.8926e-01, 5.1430e+00, 1.3285e+01, 1.6212e-05,\n",
            "        9.4689e+00, 1.2538e+01, 1.7569e+01, 3.5763e-07, 7.4897e-02, 4.8088e-01,\n",
            "        3.0286e-02, 1.1921e-07, 8.5675e-04, 5.1430e+00, 1.4721e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3463e-02, 2.1586e-13, 2.8278e-18, 9.5765e-42, 2.1586e-13, 1.8969e-16,\n",
            "        4.7540e-29, 1.0531e-04, 8.5829e-35, 1.5018e-27, 5.3463e-02, 6.0810e-03,\n",
            "        2.1586e-13, 4.1307e-05, 1.1159e-18, 5.4751e-16, 6.7208e-27, 1.2960e-31,\n",
            "        6.5497e-22, 8.2071e-36, 1.7612e-28, 2.9026e-05, 2.1586e-13, 3.1529e-43,\n",
            "        3.0221e-20, 6.6095e-17, 8.3632e-09, 5.4751e-16, 1.1587e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  50\n",
            "ce_loss:  tensor([5.0068e-06, 1.2121e+00, 5.8133e-04, 1.6697e+01, 1.2121e+00, 2.3696e-04,\n",
            "        1.4717e+01, 7.8611e-04, 1.6875e+01, 6.7465e+00, 5.0068e-06, -0.0000e+00,\n",
            "        1.2121e+00, 8.3446e-07, 1.1806e-01, 1.9963e-01, 1.1944e+01, 1.1921e-05,\n",
            "        1.0141e+01, 9.7113e+00, 1.9536e+01, 3.5763e-07, 1.2121e+00, 3.6733e-01,\n",
            "        2.3205e-02, 1.1921e-07, 4.9817e-04, 1.9963e-01, 5.2212e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.4145e-02, 2.0393e-13, 2.5872e-18, 4.5332e-42, 2.0393e-13, 1.1261e-16,\n",
            "        1.4037e-28, 1.0771e-04, 2.9746e-34, 1.1665e-27, 5.4145e-02, 6.0945e-03,\n",
            "        2.0393e-13, 5.2034e-05, 1.4841e-18, 2.9437e-16, 1.2421e-26, 9.5905e-32,\n",
            "        3.5800e-22, 4.5090e-36, 1.1613e-28, 3.1939e-05, 2.0393e-13, 2.1019e-43,\n",
            "        1.7634e-20, 4.9201e-17, 2.6771e-08, 2.9437e-16, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  51\n",
            "ce_loss:  tensor([9.5367e-07, 1.6974e-01, 2.8320e-04, 1.5458e+01, 1.6974e-01, 3.5649e-04,\n",
            "        1.8997e+01, 3.2551e-04, 1.7899e+01, 4.7905e+00, 9.5367e-07, -0.0000e+00,\n",
            "        1.6974e-01, 1.1802e-05, 6.8670e-02, 2.7911e-02, 1.2990e+01, 1.0133e-05,\n",
            "        1.0139e+01, 8.5150e+00, 1.8476e+01, 2.3842e-07, 1.6974e-01, 3.5476e-01,\n",
            "        1.8689e-02, 1.7881e-06, 4.0511e-04, 2.7911e-02, 8.4754e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3285e-02, 1.1285e-13, 1.7649e-18, 1.8983e-41, 1.1285e-13, 6.7884e-17,\n",
            "        1.0370e-28, 1.0554e-04, 9.3213e-34, 2.0249e-27, 5.3285e-02, 6.1387e-03,\n",
            "        1.1285e-13, 5.6063e-05, 1.8619e-18, 3.6988e-16, 2.5818e-26, 8.9733e-32,\n",
            "        2.3604e-22, 9.1454e-36, 7.6778e-29, 3.3938e-05, 1.1285e-13, 1.2472e-43,\n",
            "        9.4276e-21, 2.6802e-17, 7.2183e-08, 3.6988e-16, 1.1529e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  52\n",
            "ce_loss:  tensor([5.3644e-06, 6.0739e-02, 3.5816e-04, 1.6893e+01, 6.0739e-02, 5.7967e-04,\n",
            "        1.6219e+01, 7.8742e-04, 1.7682e+01, 4.7661e+00, 5.3644e-06, -0.0000e+00,\n",
            "        6.0739e-02, 4.7684e-07, 3.9877e-02, 3.2007e-02, 1.2870e+01, 1.3709e-05,\n",
            "        7.8504e+00, 8.9780e+00, 1.7868e+01, 2.3842e-07, 6.0739e-02, 4.3767e-01,\n",
            "        1.5577e-02, -0.0000e+00, 3.7413e-04, 3.2007e-02, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3995e-02, 1.1723e-13, 1.6425e-18, 1.8777e-41, 1.1723e-13, 1.0153e-16,\n",
            "        8.1260e-29, 1.0765e-04, 4.0634e-34, 3.1286e-27, 5.3995e-02, 6.0878e-03,\n",
            "        1.1723e-13, 7.1452e-05, 1.1181e-18, 4.3440e-16, 1.3459e-26, 5.2467e-32,\n",
            "        2.7645e-22, 4.2106e-36, 6.9618e-29, 3.6828e-05, 1.1723e-13, 1.1351e-43,\n",
            "        7.6497e-21, 3.5975e-17, 1.8666e-07, 4.3440e-16, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  53\n",
            "ce_loss:  tensor([9.5367e-07, 7.4793e-02, 1.7069e-04, 1.7541e+01, 7.4793e-02, 5.4654e-04,\n",
            "        1.3705e+01, 3.2551e-04, 1.6576e+01, 8.4663e+00, 9.5367e-07, -0.0000e+00,\n",
            "        7.4793e-02, 1.1563e-05, 3.5602e-02, 4.3850e-03, 1.2742e+01, 9.1791e-06,\n",
            "        8.0773e+00, 8.0802e+00, 1.6412e+01, 2.3842e-07, 7.4793e-02, 2.8948e-01,\n",
            "        1.4052e-02, 4.7684e-07, 2.3769e-02, 4.3850e-03, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 6.2017e-13, 1.0557e-18, 1.5902e-41, 6.2017e-13, 8.9811e-17,\n",
            "        1.9146e-28, 1.0554e-04, 8.9980e-34, 2.5041e-27, 5.3552e-02, 6.1387e-03,\n",
            "        6.2017e-13, 7.4491e-05, 1.2078e-18, 3.5535e-16, 2.9536e-26, 5.6050e-32,\n",
            "        4.0493e-22, 4.6772e-36, 2.3093e-28, 3.8648e-05, 6.2017e-13, 4.9045e-44,\n",
            "        4.5019e-21, 1.7207e-17, 3.8497e-07, 3.5535e-16, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  54\n",
            "ce_loss:  tensor([5.3644e-06, 3.7485e-01, 2.5698e-04, 1.5385e+01, 3.7485e-01, 2.6425e-04,\n",
            "        1.5358e+01, 7.8742e-04, 1.7517e+01, 5.2954e+00, 5.3644e-06, -0.0000e+00,\n",
            "        3.7485e-01, 3.5763e-07, 3.4866e-02, 1.6247e-02, 1.2717e+01, 8.5830e-06,\n",
            "        9.0831e+00, 9.2945e+00, 1.9612e+01, 2.3842e-07, 3.7485e-01, 2.1984e-01,\n",
            "        1.3313e-02, -0.0000e+00, 4.4622e-04, 1.6247e-02, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 6.4968e-13, 1.1208e-18, 2.2501e-41, 6.4968e-13, 9.3450e-17,\n",
            "        1.7469e-28, 1.0765e-04, 3.6917e-34, 1.6228e-27, 5.3935e-02, 6.0878e-03,\n",
            "        6.4968e-13, 9.2231e-05, 5.4857e-19, 3.0814e-16, 1.2742e-26, 2.8126e-32,\n",
            "        1.8989e-22, 2.2468e-36, 1.6059e-28, 4.1346e-05, 6.4968e-13, 5.3249e-44,\n",
            "        3.0217e-21, 2.2489e-17, 8.5949e-07, 3.0814e-16, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  55\n",
            "ce_loss:  tensor([9.5367e-07, 5.0354e-01, 1.1396e-04, 1.7242e+01, 5.0354e-01, 1.6128e-04,\n",
            "        1.4670e+01, 3.2551e-04, 1.6131e+01, 3.6132e+00, 9.5367e-07, -0.0000e+00,\n",
            "        5.0354e-01, 8.1062e-06, 2.2581e-02, 2.8277e-03, 1.2332e+01, 6.7949e-06,\n",
            "        7.1968e+00, 9.8078e+00, 1.7413e+01, 2.3842e-07, 5.0354e-01, 3.9468e-01,\n",
            "        1.0452e-02, 3.5763e-07, 3.3594e-01, 2.8277e-03, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 4.2831e-13, 7.9649e-19, 1.7708e-41, 4.2831e-13, 5.2012e-17,\n",
            "        1.1657e-28, 1.0554e-04, 1.3174e-33, 2.5441e-27, 5.3552e-02, 6.1387e-03,\n",
            "        4.2831e-13, 9.3534e-05, 7.0352e-19, 2.1895e-16, 2.5302e-26, 2.0406e-32,\n",
            "        3.2353e-22, 1.6875e-36, 1.1023e-28, 4.2840e-05, 4.2831e-13, 4.7644e-44,\n",
            "        1.6217e-21, 1.1410e-17, 1.5988e-06, 2.1895e-16, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  56\n",
            "ce_loss:  tensor([5.3644e-06, 5.1554e-02, 1.0514e-04, 1.4929e+01, 5.1554e-02, 1.7284e-04,\n",
            "        1.4052e+01, 7.8742e-04, 1.7238e+01, 4.6120e+00, 5.3644e-06, -0.0000e+00,\n",
            "        5.1554e-02, 2.3842e-07, 3.7778e-02, 8.7044e-04, 1.2434e+01, 6.0797e-06,\n",
            "        8.2190e+00, 8.8176e+00, 1.5999e+01, 2.3842e-07, 5.1554e-02, 2.0694e-01,\n",
            "        8.1808e-03, -0.0000e+00, 3.4898e-04, 8.7044e-04, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 3.9285e-13, 9.0518e-19, 2.4497e-41, 3.9285e-13, 3.5686e-17,\n",
            "        2.5228e-28, 1.0765e-04, 5.6285e-34, 3.3791e-27, 5.3935e-02, 6.0878e-03,\n",
            "        3.9285e-13, 1.1301e-04, 3.7559e-19, 1.9204e-16, 1.2250e-26, 1.1544e-32,\n",
            "        2.3263e-22, 8.7429e-37, 3.1239e-28, 4.5485e-05, 3.9285e-13, 2.2421e-44,\n",
            "        9.5246e-22, 1.3236e-17, 2.9926e-06, 1.9204e-16, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  57\n",
            "ce_loss:  tensor([9.5367e-07, 3.6923e+01, 7.4503e-05, 1.7005e+01, 3.6923e+01, 1.3696e-04,\n",
            "        1.5750e+01, 3.2551e-04, 1.6107e+01, 5.1721e+00, 9.5367e-07, -0.0000e+00,\n",
            "        3.6923e+01, 9.6559e-06, 4.5119e-02, 5.1247e-04, 1.2117e+01, 6.1989e-06,\n",
            "        7.3989e+00, 9.5768e+00, 1.6726e+01, 2.3842e-07, 3.6923e+01, 2.0349e-01,\n",
            "        5.5235e-03, 2.3842e-07, 8.8343e-01, 5.1247e-04, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 1.9529e-13, 5.7092e-19, 1.8852e-41, 1.9529e-13, 4.0018e-17,\n",
            "        2.1586e-28, 1.0554e-04, 1.8723e-33, 1.7329e-27, 5.3552e-02, 6.1387e-03,\n",
            "        1.9529e-13, 1.1110e-04, 5.4657e-19, 2.0081e-16, 2.4413e-26, 6.4976e-33,\n",
            "        3.0729e-22, 5.5000e-37, 7.9739e-29, 4.6817e-05, 1.9529e-13, 2.3822e-44,\n",
            "        5.0654e-22, 7.9504e-18, 5.1630e-06, 2.0081e-16, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  58\n",
            "ce_loss:  tensor([5.3644e-06, 1.1083e-01, 5.1259e-05, 1.5167e+01, 1.1083e-01, 1.0597e-04,\n",
            "        1.6984e+01, 7.8742e-04, 1.6589e+01, 3.6952e+00, 5.3644e-06, -0.0000e+00,\n",
            "        1.1083e-01, 1.1921e-07, 2.6315e-02, 4.3109e-04, 1.1853e+01, 5.9604e-06,\n",
            "        9.6222e+00, 7.9456e+00, 1.5822e+01, 2.3842e-07, 1.1083e-01, 2.0364e-01,\n",
            "        5.8833e-03, -0.0000e+00, 2.7998e-04, 4.3109e-04, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 2.2396e-13, 5.4601e-19, 1.7285e-41, 2.2396e-13, 2.4948e-17,\n",
            "        1.2732e-28, 1.0765e-04, 8.4480e-34, 1.8145e-27, 5.3935e-02, 6.0878e-03,\n",
            "        2.2396e-13, 1.3245e-04, 3.3826e-19, 1.3813e-16, 1.1074e-26, 5.1422e-33,\n",
            "        1.7583e-22, 4.2367e-37, 2.1966e-28, 4.9412e-05, 2.2396e-13, 1.1210e-44,\n",
            "        3.7523e-22, 1.0353e-17, 9.3537e-06, 1.3813e-16, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  59\n",
            "ce_loss:  tensor([9.5367e-07, 1.0855e+00, 4.5537e-05, 1.7159e+01, 1.0855e+00, 2.1634e-04,\n",
            "        1.5198e+01, 3.2551e-04, 1.6308e+01, 4.8022e+00, 9.5367e-07, -0.0000e+00,\n",
            "        1.0855e+00, 1.3947e-05, 1.1622e-02, 5.5334e-04, 1.2324e+01, 4.8876e-06,\n",
            "        9.3524e+00, 9.6656e+00, 1.7499e+01, 2.3842e-07, 1.0855e+00, 1.7517e-01,\n",
            "        4.7569e-03, -0.0000e+00, 5.0494e-01, 5.5334e-04, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 2.6290e-13, 4.6397e-19, 1.2373e-41, 2.6290e-13, 1.2906e-17,\n",
            "        1.4228e-28, 1.0554e-04, 2.4691e-33, 1.1351e-27, 5.3552e-02, 6.1387e-03,\n",
            "        2.6290e-13, 1.2675e-04, 3.1894e-19, 1.1977e-16, 2.0662e-26, 4.1403e-33,\n",
            "        1.1645e-22, 3.5937e-37, 1.3037e-28, 5.0522e-05, 2.6290e-13, 9.8091e-45,\n",
            "        2.0958e-22, 5.1511e-18, 1.5047e-05, 1.1977e-16, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  60\n",
            "ce_loss:  tensor([5.3644e-06, 1.2950e-01, 3.7193e-05, 1.4372e+01, 1.2950e-01, 1.1062e-04,\n",
            "        1.3153e+01, 7.8742e-04, 1.7487e+01, 3.3862e+00, 5.3644e-06, -0.0000e+00,\n",
            "        1.2950e-01, 1.1921e-07, 2.6075e-02, 6.2232e-04, 1.2706e+01, 6.1989e-06,\n",
            "        9.4422e+00, 8.2915e+00, 1.8733e+01, 2.3842e-07, 1.2950e-01, 1.8780e-01,\n",
            "        4.1310e-03, -0.0000e+00, 2.5508e-04, 6.2232e-04, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 1.4824e-13, 3.5436e-19, 1.7540e-41, 1.4824e-13, 2.2111e-17,\n",
            "        3.2374e-28, 1.0765e-04, 2.2743e-33, 1.6221e-27, 5.3935e-02, 6.0878e-03,\n",
            "        1.4824e-13, 1.4908e-04, 1.7194e-19, 1.2740e-16, 1.0479e-26, 3.9625e-33,\n",
            "        8.1562e-23, 1.7661e-37, 9.4651e-29, 5.2947e-05, 1.4824e-13, 5.6052e-45,\n",
            "        1.3880e-22, 4.6756e-18, 2.6659e-05, 1.2740e-16, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  61\n",
            "ce_loss:  tensor([9.5367e-07, 6.3472e-02, 7.9033e-05, 1.3947e+01, 6.3472e-02, 1.0240e-04,\n",
            "        1.4646e+01, 3.2551e-04, 1.9458e+01, 5.1992e+00, 9.5367e-07, -0.0000e+00,\n",
            "        6.3472e-02, 3.6955e-06, 1.6113e-02, 2.6485e-04, 1.6238e+01, 5.1260e-06,\n",
            "        7.4134e+00, 7.0363e+00, 1.6995e+01, 2.3842e-07, 6.3472e-02, 1.6373e-01,\n",
            "        3.3660e-03, -0.0000e+00, 5.1888e-01, 2.6485e-04, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 1.6733e-13, 2.9726e-19, 5.3960e-41, 1.6733e-13, 1.2416e-17,\n",
            "        1.7857e-28, 1.0554e-04, 1.8668e-33, 1.3398e-27, 5.3552e-02, 6.1387e-03,\n",
            "        1.6733e-13, 1.4189e-04, 2.1359e-19, 9.0245e-17, 5.9665e-27, 2.8347e-33,\n",
            "        9.2325e-23, 1.8372e-37, 5.5171e-29, 5.3778e-05, 1.6733e-13, 4.2039e-45,\n",
            "        6.8497e-23, 2.1527e-18, 3.9470e-05, 9.0245e-17, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  62\n",
            "ce_loss:  tensor([5.3644e-06, 5.6743e-01, 3.7550e-05, 1.4109e+01, 5.6743e-01, 7.8317e-05,\n",
            "        1.3063e+01, 7.8742e-04, 1.6610e+01, 5.9270e+00, 5.3644e-06, -0.0000e+00,\n",
            "        5.6743e-01, 1.1921e-07, 1.1870e-02, 8.1470e-04, 1.2649e+01, 5.1260e-06,\n",
            "        8.4673e+00, 7.7370e+00, 1.8596e+01, 2.3842e-07, 5.6743e-01, 1.8053e-01,\n",
            "        3.5638e-03, -0.0000e+00, 1.2790e-04, 8.1470e-04, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 1.1645e-13, 2.9084e-19, 2.3470e-41, 1.1645e-13, 6.8520e-18,\n",
            "        3.9765e-28, 1.0765e-04, 1.2689e-33, 9.0269e-28, 5.3935e-02, 6.0878e-03,\n",
            "        1.1645e-13, 1.6254e-04, 1.2904e-19, 6.4343e-17, 3.5798e-27, 3.4067e-33,\n",
            "        6.9697e-23, 1.0286e-37, 4.1796e-29, 5.6022e-05, 1.1645e-13, 2.8026e-45,\n",
            "        5.7670e-23, 3.2749e-18, 6.6184e-05, 6.4343e-17, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  63\n",
            "ce_loss:  tensor([9.5367e-07, 4.7383e-02, 1.0931e-04, 1.3700e+01, 4.7383e-02, 7.5337e-05,\n",
            "        1.4982e+01, 3.2551e-04, 1.5427e+01, 4.2700e+00, 9.5367e-07, -0.0000e+00,\n",
            "        4.7383e-02, 4.6492e-06, 5.2628e-03, 3.8938e-04, 1.1351e+01, 3.9339e-06,\n",
            "        9.0458e+00, 7.3302e+00, 1.6264e+01, 2.3842e-07, 4.7383e-02, 2.2317e-01,\n",
            "        1.9979e-03, 1.1921e-07, 3.7520e-01, 3.8938e-04, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 1.3595e-13, 2.0703e-19, 6.6961e-41, 1.3595e-13, 4.4104e-18,\n",
            "        2.7736e-28, 1.0554e-04, 3.7178e-33, 7.2203e-28, 5.3552e-02, 6.1387e-03,\n",
            "        1.3595e-13, 1.5200e-04, 1.5243e-19, 3.8981e-17, 8.1980e-27, 2.0932e-33,\n",
            "        7.5093e-23, 1.9563e-37, 3.0414e-29, 5.6525e-05, 1.3595e-13, 2.8026e-45,\n",
            "        2.4133e-23, 1.6135e-18, 8.9890e-05, 3.8981e-17, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  64\n",
            "ce_loss:  tensor([5.3644e-06, 1.1639e+01, 3.5047e-05, 1.3791e+01, 1.1639e+01, 5.4940e-04,\n",
            "        1.6414e+01, 7.8742e-04, 1.5883e+01, 6.1409e+00, 5.3644e-06, -0.0000e+00,\n",
            "        1.1639e+01, 1.1921e-07, 2.1248e-02, 1.1646e-04, 1.1424e+01, 3.9339e-06,\n",
            "        8.3320e+00, 8.0336e+00, 1.4657e+01, 1.1921e-07, 1.1639e+01, 1.5883e-01,\n",
            "        1.8632e-03, -0.0000e+00, 8.7853e-05, 1.1646e-04, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 1.2414e-13, 2.0127e-19, 2.3889e-41, 1.2414e-13, 5.2080e-18,\n",
            "        2.3934e-28, 1.0765e-04, 1.6833e-33, 5.3597e-28, 5.3935e-02, 6.0878e-03,\n",
            "        1.2414e-13, 1.7298e-04, 6.5434e-20, 2.5793e-17, 7.2841e-27, 1.4488e-33,\n",
            "        6.0869e-23, 8.4246e-38, 6.8791e-29, 5.8500e-05, 1.2414e-13, 1.4013e-45,\n",
            "        1.7345e-23, 2.7156e-18, 1.3779e-04, 2.5793e-17, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  65\n",
            "ce_loss:  tensor([9.5367e-07, 1.0063e-01, 4.2795e-05, 1.3568e+01, 1.0063e-01, 9.3098e-05,\n",
            "        1.5122e+01, 3.2551e-04, 1.5553e+01, 4.7941e+00, 9.5367e-07, -0.0000e+00,\n",
            "        1.0063e-01, 3.8147e-06, 3.9831e-03, 9.1310e-05, 1.1027e+01, 3.4571e-06,\n",
            "        7.3548e+00, 9.0522e+00, 1.6665e+01, 1.1921e-07, 1.0063e-01, 1.9146e-01,\n",
            "        1.9670e-03, -0.0000e+00, 5.9769e-01, 9.1310e-05, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 9.3160e-14, 1.4768e-19, 6.3419e-41, 9.3160e-14, 6.0945e-18,\n",
            "        1.0898e-28, 1.0554e-04, 4.7465e-33, 3.7222e-28, 5.3552e-02, 6.1387e-03,\n",
            "        9.3160e-14, 1.6079e-04, 6.8123e-20, 1.8502e-17, 1.2934e-26, 1.0955e-33,\n",
            "        6.7995e-23, 7.9334e-38, 5.4598e-29, 5.8895e-05, 9.3160e-14, 1.4013e-45,\n",
            "        9.5605e-24, 1.2741e-18, 1.7554e-04, 1.8502e-17, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  66\n",
            "ce_loss:  tensor([5.3644e-06, 3.2503e+00, 3.1590e-05, 1.3965e+01, 3.2503e+00, 6.2106e-05,\n",
            "        1.2803e+01, 7.8742e-04, 1.6521e+01, 2.8180e+00, 5.3644e-06, -0.0000e+00,\n",
            "        3.2503e+00, 1.1921e-07, 5.6364e-03, 9.1429e-05, 1.1279e+01, 3.9339e-06,\n",
            "        7.4278e+00, 7.8834e+00, 1.7929e+01, 1.1921e-07, 3.2503e+00, 1.3682e-01,\n",
            "        1.2629e-03, -0.0000e+00, 4.0054e-05, 9.1429e-05, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 8.8935e-14, 1.5535e-19, 2.4133e-41, 8.8935e-14, 3.7249e-18,\n",
            "        2.4890e-28, 1.0765e-04, 2.4570e-33, 5.3730e-28, 5.3935e-02, 6.0878e-03,\n",
            "        8.8935e-14, 1.8291e-04, 5.2340e-20, 1.4290e-17, 6.1089e-27, 7.4292e-34,\n",
            "        1.0927e-22, 4.2705e-38, 3.9193e-29, 6.0320e-05, 8.8935e-14, 0.0000e+00,\n",
            "        5.8360e-24, 1.4942e-18, 2.5278e-04, 1.4290e-17, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  67\n",
            "ce_loss:  tensor([9.5367e-07, 3.7764e-02, 1.0514e-04, 1.3134e+01, 3.7764e-02, 5.9960e-05,\n",
            "        1.3999e+01, 3.2551e-04, 1.9636e+01, 3.7130e+00, 9.5367e-07, -0.0000e+00,\n",
            "        3.7764e-02, 4.4107e-06, 3.3208e-03, 3.5405e-05, 1.0902e+01, 3.0994e-06,\n",
            "        9.8563e+00, 8.7286e+00, 1.6794e+01, 1.1921e-07, 3.7764e-02, 1.6470e-01,\n",
            "        1.3679e-03, -0.0000e+00, 1.1097e-01, 3.5405e-05, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 6.0269e-14, 1.2412e-19, 6.5295e-41, 6.0269e-14, 3.1233e-18,\n",
            "        2.6200e-28, 1.0554e-04, 1.9573e-33, 8.1116e-28, 5.3552e-02, 6.1387e-03,\n",
            "        6.0269e-14, 1.6890e-04, 4.2684e-20, 9.0092e-18, 1.2171e-26, 5.2646e-34,\n",
            "        7.9922e-23, 3.5724e-38, 2.2709e-29, 6.0862e-05, 6.0269e-14, 0.0000e+00,\n",
            "        2.6017e-24, 7.8408e-19, 3.0288e-04, 9.0092e-18, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  68\n",
            "ce_loss:  tensor([5.3644e-06, 3.6230e+01, 2.9563e-05, 1.3415e+01, 3.6230e+01, 7.6053e-05,\n",
            "        1.6009e+01, 7.8742e-04, 1.6014e+01, 3.9892e+00, 5.3644e-06, -0.0000e+00,\n",
            "        3.6230e+01, 1.1921e-07, 3.0251e-03, 8.2244e-04, 1.2243e+01, 3.9339e-06,\n",
            "        7.6887e+00, 6.9208e+00, 1.8094e+01, 1.1921e-07, 3.6230e+01, 1.2910e-01,\n",
            "        9.3226e-04, -0.0000e+00, 2.3961e-05, 8.2244e-04, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 3.6305e-14, 1.2289e-19, 2.3343e-41, 3.6305e-14, 1.7654e-18,\n",
            "        1.4473e-28, 1.0765e-04, 1.4574e-33, 4.4827e-28, 5.3935e-02, 6.0878e-03,\n",
            "        3.6305e-14, 1.9121e-04, 3.6478e-20, 8.2194e-18, 8.7597e-27, 4.5078e-34,\n",
            "        7.1327e-23, 2.5959e-38, 1.7337e-29, 6.1345e-05, 3.6305e-14, 0.0000e+00,\n",
            "        1.7001e-24, 9.5482e-19, 4.1874e-04, 8.2194e-18, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  69\n",
            "ce_loss:  tensor([9.5367e-07, 8.6856e-02, 4.4941e-05, 1.2697e+01, 8.6856e-02, 8.0940e-05,\n",
            "        1.4707e+01, 3.2551e-04, 1.5174e+01, 3.4931e+00, 9.5367e-07, -0.0000e+00,\n",
            "        8.6856e-02, 4.4107e-06, 3.5738e-03, 1.1515e-04, 1.4432e+01, 4.7684e-06,\n",
            "        7.3545e+00, 8.4274e+00, 1.6651e+01, 1.1921e-07, 8.6856e-02, 1.4700e-01,\n",
            "        1.0367e-03, -0.0000e+00, 8.2971e-04, 1.1515e-04, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 3.5904e-14, 8.8349e-20, 5.5535e-41, 3.5904e-14, 1.5017e-18,\n",
            "        1.4047e-28, 1.0554e-04, 4.1698e-33, 6.2519e-28, 5.3552e-02, 6.1387e-03,\n",
            "        3.5904e-14, 1.7589e-04, 2.8219e-20, 5.7412e-18, 4.9354e-27, 3.5268e-34,\n",
            "        8.5874e-23, 1.8341e-38, 7.6802e-30, 6.1657e-05, 3.5904e-14, 0.0000e+00,\n",
            "        9.4391e-25, 8.0712e-19, 4.8722e-04, 5.7412e-18, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  70\n",
            "ce_loss:  tensor([5.3644e-06, 8.1387e-01, 2.1934e-05, 1.4217e+01, 8.1387e-01, 5.6861e-05,\n",
            "        1.2417e+01, 7.8742e-04, 1.5349e+01, 4.0409e+00, 5.3644e-06, -0.0000e+00,\n",
            "        8.1387e-01, 1.1921e-07, 7.0033e-03, 5.1974e-05, 1.1922e+01, 3.9339e-06,\n",
            "        9.1735e+00, 6.7555e+00, 1.4431e+01, 1.1921e-07, 8.1387e-01, 1.1514e-01,\n",
            "        6.8486e-04, -0.0000e+00, 1.9073e-05, 5.1974e-05, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 3.6564e-14, 9.1581e-20, 3.7692e-41, 3.6564e-14, 1.3896e-18,\n",
            "        2.1747e-28, 1.0765e-04, 2.1489e-33, 4.2627e-28, 5.3935e-02, 6.0878e-03,\n",
            "        3.6564e-14, 1.9837e-04, 2.5121e-20, 5.1387e-18, 4.2414e-27, 4.2559e-34,\n",
            "        5.4879e-23, 1.3451e-38, 2.0721e-29, 6.1979e-05, 3.6564e-14, 0.0000e+00,\n",
            "        7.9849e-25, 5.6663e-19, 6.3434e-04, 5.1387e-18, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  71\n",
            "ce_loss:  tensor([9.5367e-07, 2.8086e-02, 2.5510e-05, 1.5082e+01, 2.8086e-02, 6.1987e-05,\n",
            "        1.4114e+01, 3.2551e-04, 1.5056e+01, 6.4101e+00, 9.5367e-07, -0.0000e+00,\n",
            "        2.8086e-02, 4.2915e-06, 1.7644e-03, 2.6092e-04, 1.0723e+01, 3.2186e-06,\n",
            "        8.4984e+00, 6.3412e+00, 1.7901e+01, 1.1921e-07, 2.8086e-02, 9.3886e-02,\n",
            "        7.2953e-04, -0.0000e+00, 7.3311e-05, 2.6092e-04, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 2.1929e-14, 6.3495e-20, 2.3113e-41, 2.1929e-14, 5.6731e-19,\n",
            "        3.8852e-28, 1.0554e-04, 4.9896e-33, 3.4230e-28, 5.3552e-02, 6.1387e-03,\n",
            "        2.1929e-14, 1.8158e-04, 1.9348e-20, 3.6743e-18, 8.5774e-27, 2.6866e-34,\n",
            "        4.0190e-23, 2.5539e-38, 1.0736e-29, 6.2156e-05, 2.1929e-14, 0.0000e+00,\n",
            "        4.0644e-25, 6.1636e-19, 7.2992e-04, 3.6743e-18, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  72\n",
            "ce_loss:  tensor([5.3644e-06, 3.5591e+00, 2.0504e-05, 1.3138e+01, 3.5591e+00, 4.2557e-05,\n",
            "        1.3872e+01, 7.8742e-04, 1.5607e+01, 3.3667e+00, 5.3644e-06, -0.0000e+00,\n",
            "        3.5591e+00, 1.1921e-07, 1.7455e-03, 3.8981e-05, 1.1318e+01, 3.4571e-06,\n",
            "        8.0341e+00, 7.3334e+00, 1.5193e+01, 1.1921e-07, 3.5591e+00, 1.5796e-01,\n",
            "        4.9007e-04, -0.0000e+00, 1.2994e-05, 3.8981e-05, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 2.0188e-14, 5.7094e-20, 2.2810e-41, 2.0188e-14, 6.7104e-19,\n",
            "        1.7619e-28, 1.0765e-04, 2.0508e-33, 2.3990e-28, 5.3935e-02, 6.0878e-03,\n",
            "        2.0188e-14, 2.0389e-04, 1.4035e-20, 4.0952e-18, 4.6024e-27, 2.3073e-34,\n",
            "        3.9280e-23, 9.0870e-39, 8.3919e-30, 6.2348e-05, 2.0188e-14, 0.0000e+00,\n",
            "        3.1474e-25, 4.6868e-19, 9.0839e-04, 4.0952e-18, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  73\n",
            "ce_loss:  tensor([9.5367e-07, 1.9104e-02, 4.2676e-05, 1.5477e+01, 1.9104e-02, 3.7312e-05,\n",
            "        1.4050e+01, 3.2551e-04, 1.5053e+01, 2.8120e+00, 9.5367e-07, -0.0000e+00,\n",
            "        1.9104e-02, 2.6226e-06, 3.2597e-03, 1.5603e-03, 1.0484e+01, 2.6226e-06,\n",
            "        6.3145e+00, 6.3619e+00, 1.4149e+01, 1.1921e-07, 1.9104e-02, 9.3440e-02,\n",
            "        6.0087e-04, -0.0000e+00, 5.6265e-05, 1.5603e-03, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 1.6559e-14, 4.9633e-20, 1.6405e-41, 1.6559e-14, 4.4964e-19,\n",
            "        3.1009e-28, 1.0554e-04, 4.9741e-33, 3.6890e-28, 5.3552e-02, 6.1387e-03,\n",
            "        1.6559e-14, 1.8686e-04, 6.9002e-21, 2.5483e-18, 8.1218e-27, 1.2607e-34,\n",
            "        5.5272e-23, 1.6513e-38, 1.6160e-29, 6.2387e-05, 1.6559e-14, 0.0000e+00,\n",
            "        2.4713e-25, 3.7738e-19, 1.0115e-03, 2.5483e-18, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  74\n",
            "ce_loss:  tensor([5.3644e-06, 6.4994e+00, 1.5497e-05, 1.3533e+01, 6.4994e+00, 2.5749e-05,\n",
            "        1.3586e+01, 7.8742e-04, 1.5710e+01, 4.1855e+00, 5.3644e-06, -0.0000e+00,\n",
            "        6.4994e+00, 1.1921e-07, 1.7571e-03, 3.2901e-05, 1.1232e+01, 3.2186e-06,\n",
            "        6.8870e+00, 7.6255e+00, 1.6670e+01, 1.1921e-07, 6.4994e+00, 8.5987e-02,\n",
            "        3.5089e-04, -0.0000e+00, 1.0610e-05, 3.2901e-05, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 1.6004e-14, 4.6595e-20, 9.0748e-42, 1.6004e-14, 3.3999e-19,\n",
            "        1.6954e-28, 1.0765e-04, 2.0099e-33, 2.6366e-28, 5.3935e-02, 6.0878e-03,\n",
            "        1.6004e-14, 2.0752e-04, 9.9963e-21, 1.5034e-18, 3.7972e-27, 1.2352e-34,\n",
            "        8.4402e-23, 6.7074e-39, 1.0334e-29, 6.2445e-05, 1.6004e-14, 0.0000e+00,\n",
            "        1.1479e-25, 2.8782e-19, 1.2187e-03, 1.5034e-18, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  75\n",
            "ce_loss:  tensor([9.5367e-07, 1.2405e-02, 1.5020e-05, 1.5331e+01, 1.2405e-02, 2.9802e-05,\n",
            "        1.4096e+01, 3.2551e-04, 1.4970e+01, 5.2091e+00, 9.5367e-07, -0.0000e+00,\n",
            "        1.2405e-02, 1.6689e-06, 2.5556e-03, 1.8358e-05, 1.0480e+01, 2.6226e-06,\n",
            "        7.9924e+00, 7.5466e+00, 1.6674e+01, 1.1921e-07, 1.2405e-02, 9.3538e-02,\n",
            "        2.9905e-04, -0.0000e+00, 4.9351e-05, 1.8358e-05, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 1.0555e-14, 3.3121e-20, 5.7902e-42, 1.0555e-14, 2.5539e-19,\n",
            "        3.0595e-28, 1.0554e-04, 4.3489e-33, 1.9480e-28, 5.3552e-02, 6.1387e-03,\n",
            "        1.0555e-14, 1.9061e-04, 6.4439e-21, 8.7238e-19, 7.3419e-27, 7.9760e-35,\n",
            "        4.6861e-23, 4.7235e-39, 6.3421e-30, 6.2387e-05, 1.0555e-14, 0.0000e+00,\n",
            "        7.1214e-26, 2.4707e-19, 1.3182e-03, 8.7238e-19, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  76\n",
            "ce_loss:  tensor([5.3644e-06, 4.4467e-03, 1.0967e-05, 1.2593e+01, 4.4467e-03, 2.0504e-05,\n",
            "        1.3643e+01, 7.8742e-04, 1.6051e+01, 3.8934e+00, 5.3644e-06, -0.0000e+00,\n",
            "        4.4467e-03, 1.1921e-07, 8.3817e-04, 1.6689e-05, 1.1666e+01, 3.0994e-06,\n",
            "        9.1573e+00, 7.2156e+00, 1.5017e+01, 1.1921e-07, 4.4467e-03, 7.9438e-02,\n",
            "        2.5305e-04, -0.0000e+00, 8.4638e-06, 1.6689e-05, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 1.1322e-14, 2.9207e-20, 6.1531e-42, 1.1322e-14, 2.4891e-19,\n",
            "        1.3683e-28, 1.0765e-04, 2.9729e-33, 1.6353e-28, 5.3935e-02, 6.0878e-03,\n",
            "        1.1322e-14, 2.1030e-04, 9.1629e-21, 6.8541e-19, 6.2527e-27, 1.0808e-34,\n",
            "        4.4324e-23, 2.6866e-39, 4.4006e-30, 6.2445e-05, 1.1322e-14, 0.0000e+00,\n",
            "        3.6795e-26, 2.7196e-19, 1.5517e-03, 6.8541e-19, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  77\n",
            "ce_loss:  tensor([9.5367e-07, 5.7821e-02, 7.4265e-05, 1.5250e+01, 5.7821e-02, 5.5312e-05,\n",
            "        1.4006e+01, 3.2551e-04, 1.9314e+01, 5.3801e+00, 9.5367e-07, -0.0000e+00,\n",
            "        5.7821e-02, 1.7881e-06, 2.5852e-03, 3.1590e-05, 1.4237e+01, 3.5763e-06,\n",
            "        7.3039e+00, 7.9665e+00, 1.3892e+01, 1.1921e-07, 5.7821e-02, 8.6903e-02,\n",
            "        2.8153e-04, -0.0000e+00, 4.4702e-05, 3.1590e-05, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 9.5674e-15, 2.3322e-20, 3.6364e-42, 9.5674e-15, 1.6608e-19,\n",
            "        2.3057e-28, 1.0554e-04, 2.2476e-33, 1.0470e-28, 5.3552e-02, 6.1387e-03,\n",
            "        9.5674e-15, 1.9253e-04, 4.1455e-21, 4.1363e-19, 3.2839e-27, 7.6122e-35,\n",
            "        2.5610e-23, 2.2213e-39, 1.0384e-29, 6.2387e-05, 9.5674e-15, 0.0000e+00,\n",
            "        2.1330e-26, 1.4936e-19, 1.6399e-03, 4.1363e-19, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  78\n",
            "ce_loss:  tensor([5.3644e-06, 1.8370e-03, 1.3590e-05, 1.2417e+01, 1.8370e-03, 1.6570e-05,\n",
            "        1.4133e+01, 7.8742e-04, 1.5571e+01, 3.4129e+00, 5.3644e-06, -0.0000e+00,\n",
            "        1.8370e-03, 1.1921e-07, 6.5353e-04, 1.1444e-05, 1.1601e+01, 3.0994e-06,\n",
            "        6.5266e+00, 6.3244e+00, 1.5458e+01, 1.1921e-07, 1.8370e-03, 7.0812e-02,\n",
            "        2.2897e-04, -0.0000e+00, 6.7949e-06, 1.1444e-05, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 1.3799e-14, 2.4485e-20, 2.5237e-42, 1.3799e-14, 2.0112e-19,\n",
            "        1.5770e-28, 1.0765e-04, 1.2480e-33, 7.2620e-29, 5.3935e-02, 6.0878e-03,\n",
            "        1.3799e-14, 2.1196e-04, 6.2702e-21, 4.7918e-19, 3.0746e-27, 6.3308e-35,\n",
            "        4.1211e-23, 1.5804e-39, 3.1183e-30, 6.2445e-05, 1.3799e-14, 0.0000e+00,\n",
            "        1.2419e-26, 1.4967e-19, 1.8909e-03, 4.7918e-19, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  79\n",
            "ce_loss:  tensor([9.5367e-07, 6.3823e+00, 1.8835e-05, 1.2286e+01, 6.3823e+00, 1.9908e-05,\n",
            "        1.6520e+01, 3.2551e-04, 1.4702e+01, 2.2485e+00, 9.5367e-07, -0.0000e+00,\n",
            "        6.3823e+00, 1.6689e-06, 1.1030e-03, 8.7022e-06, 1.0157e+01, 2.3842e-06,\n",
            "        8.2546e+00, 7.8352e+00, 1.3815e+01, 1.1921e-07, 6.3823e+00, 8.9538e-02,\n",
            "        2.5019e-04, 2.3842e-07, 2.6941e-05, 8.7022e-06, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 1.2575e-14, 1.7663e-20, 6.0816e-42, 1.2575e-14, 1.3827e-19,\n",
            "        9.1885e-29, 1.0554e-04, 2.9085e-33, 1.0414e-28, 5.3552e-02, 6.1387e-03,\n",
            "        1.2575e-14, 1.9374e-04, 4.9307e-21, 2.8989e-19, 5.5687e-27, 3.0196e-35,\n",
            "        2.5128e-23, 1.2083e-39, 8.1051e-30, 6.2387e-05, 1.2575e-14, 0.0000e+00,\n",
            "        1.0618e-26, 1.0720e-19, 1.9887e-03, 2.8989e-19, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  80\n",
            "ce_loss:  tensor([5.3644e-06, 1.0889e-03, 1.1444e-05, 1.2573e+01, 1.0889e-03, 1.3828e-05,\n",
            "        1.3735e+01, 7.8742e-04, 1.5645e+01, 4.0973e+00, 5.3644e-06, -0.0000e+00,\n",
            "        1.0889e-03, 1.1921e-07, 1.4935e-03, 1.5020e-05, 1.1465e+01, 2.3842e-06,\n",
            "        8.5531e+00, 6.8366e+00, 1.5048e+01, 1.1921e-07, 1.0889e-03, 6.5681e-02,\n",
            "        1.6974e-04, -0.0000e+00, 5.8412e-06, 1.5020e-05, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 9.3976e-15, 1.4538e-20, 2.1636e-42, 9.3976e-15, 9.9349e-20,\n",
            "        8.2302e-29, 1.0765e-04, 3.2612e-33, 1.0820e-28, 5.3935e-02, 6.0878e-03,\n",
            "        9.3976e-15, 2.1271e-04, 2.4404e-21, 2.4934e-19, 3.3971e-27, 2.7867e-35,\n",
            "        1.7419e-23, 8.4926e-40, 3.3705e-30, 6.2445e-05, 9.3976e-15, 0.0000e+00,\n",
            "        6.4073e-27, 1.7341e-19, 2.2300e-03, 2.4934e-19, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  81\n",
            "ce_loss:  tensor([9.5367e-07, 2.0928e+00, 7.8678e-06, 1.2190e+01, 2.0928e+00, 3.5643e-05,\n",
            "        1.2633e+01, 3.2551e-04, 1.8322e+01, 3.7643e+00, 9.5367e-07, -0.0000e+00,\n",
            "        2.0928e+00, 1.7881e-06, 6.0957e-04, 1.6332e-05, 1.4262e+01, 2.3842e-06,\n",
            "        8.6121e+00, 5.4691e+00, 1.7880e+01, 1.1921e-07, 2.0928e+00, 1.0901e-01,\n",
            "        2.3148e-04, -0.0000e+00, 2.5272e-05, 1.6332e-05, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 6.7648e-15, 9.5352e-21, 5.0755e-42, 6.7648e-15, 6.9179e-20,\n",
            "        1.0730e-28, 1.0554e-04, 1.8712e-33, 6.4405e-29, 5.3552e-02, 6.1387e-03,\n",
            "        6.7648e-15, 1.9400e-04, 2.8769e-21, 1.5174e-19, 2.0770e-27, 2.2883e-35,\n",
            "        1.2636e-23, 1.0844e-39, 2.2564e-30, 6.2387e-05, 6.7648e-15, 0.0000e+00,\n",
            "        5.1428e-27, 9.3036e-20, 2.2942e-03, 1.5174e-19, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  82\n",
            "ce_loss:  tensor([5.3644e-06, 5.3475e-04, 1.0490e-05, 1.2669e+01, 5.3475e-04, 1.1086e-05,\n",
            "        1.3138e+01, 7.8742e-04, 1.6046e+01, 3.3031e+00, 5.3644e-06, -0.0000e+00,\n",
            "        5.3475e-04, 1.1921e-07, 2.1689e-03, 1.0490e-05, 1.1322e+01, 2.6226e-06,\n",
            "        6.6583e+00, 6.8347e+00, 1.5369e+01, 1.1921e-07, 5.3475e-04, 6.8252e-02,\n",
            "        1.6688e-04, -0.0000e+00, 4.7684e-06, 1.0490e-05, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 5.2419e-15, 7.8523e-21, 1.8988e-42, 5.2419e-15, 5.3771e-20,\n",
            "        1.1561e-28, 1.0765e-04, 1.2484e-33, 6.8435e-29, 5.3935e-02, 6.0878e-03,\n",
            "        5.2419e-15, 2.1271e-04, 1.5104e-21, 1.0172e-19, 1.1574e-27, 2.5284e-35,\n",
            "        1.4557e-23, 7.6628e-40, 8.5807e-31, 6.2445e-05, 5.2419e-15, 0.0000e+00,\n",
            "        3.3898e-27, 7.8816e-20, 2.5435e-03, 1.0172e-19, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  83\n",
            "ce_loss:  tensor([9.5367e-07, 1.7410e-01, 7.0333e-06, 1.2258e+01, 1.7410e-01, 1.8477e-05,\n",
            "        1.5682e+01, 3.2551e-04, 1.8268e+01, 3.4275e+00, 9.5367e-07, -0.0000e+00,\n",
            "        1.7410e-01, 1.7881e-06, 5.5822e-04, 9.2983e-06, 1.0080e+01, 2.1458e-06,\n",
            "        7.4965e+00, 7.0863e+00, 1.3407e+01, 1.1921e-07, 1.7410e-01, 8.8089e-02,\n",
            "        1.1741e-04, -0.0000e+00, 2.3246e-05, 9.2983e-06, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 3.2042e-15, 4.5895e-21, 5.2381e-42, 3.2042e-15, 4.1230e-20,\n",
            "        5.9828e-29, 1.0554e-04, 9.3013e-34, 3.4315e-29, 5.3552e-02, 6.1387e-03,\n",
            "        3.2042e-15, 1.9400e-04, 1.9317e-21, 8.6537e-20, 2.6490e-27, 1.1229e-35,\n",
            "        1.2200e-23, 4.9125e-40, 2.3978e-30, 6.2387e-05, 3.2042e-15, 0.0000e+00,\n",
            "        1.7700e-27, 4.3095e-20, 2.5782e-03, 8.6537e-20, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  84\n",
            "ce_loss:  tensor([5.3644e-06, 2.7474e-04, 8.5830e-06, 1.2889e+01, 2.7474e-04, 9.7751e-06,\n",
            "        1.3561e+01, 7.8742e-04, 1.5930e+01, 3.1959e+00, 5.3644e-06, -0.0000e+00,\n",
            "        2.7474e-04, 1.1921e-07, 1.9001e-03, 5.1260e-06, 1.1415e+01, 2.3842e-06,\n",
            "        5.7497e+00, 6.2826e+00, 1.4882e+01, 1.1921e-07, 2.7474e-04, 6.8215e-02,\n",
            "        1.1241e-04, -0.0000e+00, 4.1723e-06, 5.1260e-06, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 2.7443e-15, 3.3328e-21, 1.6409e-42, 2.7443e-15, 4.9922e-20,\n",
            "        5.1023e-29, 1.0765e-04, 4.5866e-34, 3.7821e-29, 5.3935e-02, 6.0878e-03,\n",
            "        2.7443e-15, 2.1271e-04, 8.5017e-22, 5.3653e-20, 1.9981e-27, 1.1150e-35,\n",
            "        1.6099e-23, 4.3358e-40, 9.3978e-31, 6.2445e-05, 2.7443e-15, 0.0000e+00,\n",
            "        1.2866e-27, 6.8367e-20, 2.8197e-03, 5.3653e-20, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  85\n",
            "ce_loss:  tensor([9.5367e-07, 5.9026e-02, 6.3181e-06, 1.2174e+01, 5.9026e-02, 1.8358e-05,\n",
            "        1.2069e+01, 3.2551e-04, 1.4130e+01, 3.9965e+00, 9.5367e-07, -0.0000e+00,\n",
            "        5.9026e-02, 1.7881e-06, 5.5488e-04, 8.3446e-06, 1.2834e+01, 2.7418e-06,\n",
            "        6.6673e+00, 7.3477e+00, 1.7390e+01, 1.1921e-07, 5.9026e-02, 5.5724e-02,\n",
            "        1.2981e-04, -0.0000e+00, 2.0981e-05, 8.3446e-06, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 1.6031e-15, 2.7949e-21, 3.7471e-42, 1.6031e-15, 3.1099e-20,\n",
            "        8.6966e-29, 1.0554e-04, 1.0954e-33, 2.0255e-29, 5.3552e-02, 6.1387e-03,\n",
            "        1.6031e-15, 1.9400e-04, 1.2864e-21, 4.4110e-20, 1.4339e-27, 1.0806e-35,\n",
            "        2.9803e-23, 3.4888e-40, 6.4507e-31, 6.2387e-05, 1.6031e-15, 0.0000e+00,\n",
            "        9.2995e-28, 3.8965e-20, 2.8252e-03, 4.4110e-20, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  86\n",
            "ce_loss:  tensor([5.3644e-06, 2.0001e-04, 3.3259e-05, 1.2565e+01, 2.0001e-04, 7.0333e-06,\n",
            "        1.3636e+01, 7.8742e-04, 1.5130e+01, 6.0645e+00, 5.3644e-06, -0.0000e+00,\n",
            "        2.0001e-04, 1.1921e-07, 9.0880e-04, 1.9431e-05, 1.1345e+01, 2.0266e-06,\n",
            "        7.3090e+00, 6.7435e+00, 1.5472e+01, 1.1921e-07, 2.0001e-04, 9.5303e-02,\n",
            "        9.2979e-05, -0.0000e+00, 3.6955e-06, 1.9431e-05, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 1.7336e-15, 2.2365e-21, 1.4700e-42, 1.7336e-15, 3.6023e-20,\n",
            "        4.5626e-29, 1.0765e-04, 1.2929e-33, 1.3747e-29, 5.3935e-02, 6.0878e-03,\n",
            "        1.7336e-15, 2.1271e-04, 4.9500e-22, 3.6948e-20, 1.4559e-27, 1.0672e-35,\n",
            "        1.4390e-23, 2.2674e-40, 3.4762e-31, 6.2445e-05, 1.7336e-15, 0.0000e+00,\n",
            "        6.6080e-28, 3.9351e-20, 3.0428e-03, 3.6948e-20, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  87\n",
            "ce_loss:  tensor([9.5367e-07, 4.8951e-03, 5.6028e-06, 1.2292e+01, 4.8951e-03, 1.0610e-05,\n",
            "        1.2138e+01, 3.2551e-04, 1.7255e+01, 2.8779e+00, 9.5367e-07, -0.0000e+00,\n",
            "        4.8951e-03, 1.7881e-06, 4.3538e-04, 4.8876e-06, 1.0068e+01, 1.7881e-06,\n",
            "        8.7673e+00, 7.2396e+00, 1.3455e+01, 1.1921e-07, 4.8951e-03, 5.8598e-02,\n",
            "        1.0967e-04, -0.0000e+00, 1.8596e-05, 4.8876e-06, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 1.2106e-15, 1.6969e-21, 3.8354e-42, 1.2106e-15, 2.2420e-20,\n",
            "        8.1510e-29, 1.0554e-04, 1.0010e-33, 8.3117e-30, 5.3552e-02, 6.1387e-03,\n",
            "        1.2106e-15, 1.9400e-04, 7.7199e-22, 3.6844e-20, 1.6837e-27, 5.7367e-36,\n",
            "        1.2784e-23, 1.8427e-40, 8.7468e-31, 6.2387e-05, 1.2106e-15, 0.0000e+00,\n",
            "        4.6043e-28, 3.9198e-20, 2.9969e-03, 3.6844e-20, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  88\n",
            "ce_loss:  tensor([5.3644e-06, 1.1110e-04, 5.4836e-06, 1.3267e+01, 1.1110e-04, 6.9141e-06,\n",
            "        1.3134e+01, 7.8742e-04, 1.5752e+01, 2.6991e+00, 5.3644e-06, -0.0000e+00,\n",
            "        1.1110e-04, 1.1921e-07, 1.3854e-03, 6.9141e-06, 1.1518e+01, 1.9073e-06,\n",
            "        7.2033e+00, 5.9564e+00, 1.4550e+01, 1.1921e-07, 1.1110e-04, 5.4306e-02,\n",
            "        7.4741e-05, -0.0000e+00, 3.4571e-06, 6.9141e-06, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 1.2142e-15, 1.1751e-21, 2.2281e-42, 1.2142e-15, 1.8693e-20,\n",
            "        6.5559e-29, 1.0765e-04, 6.9819e-34, 1.0335e-29, 5.3935e-02, 6.0878e-03,\n",
            "        1.2142e-15, 2.1271e-04, 4.6808e-22, 2.4852e-20, 1.5836e-27, 5.6984e-36,\n",
            "        6.7291e-24, 1.2988e-40, 1.6039e-30, 6.2445e-05, 1.2142e-15, 0.0000e+00,\n",
            "        3.0624e-28, 2.9638e-20, 3.2035e-03, 2.4852e-20, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  89\n",
            "ce_loss:  tensor([9.5367e-07, 9.0236e-04, 4.2915e-06, 1.5135e+01, 9.0236e-04, 8.4638e-06,\n",
            "        1.5778e+01, 3.2551e-04, 1.3832e+01, 3.8973e+00, 9.5367e-07, -0.0000e+00,\n",
            "        9.0236e-04, 1.7881e-06, 4.6969e-04, 3.4571e-06, 1.2214e+01, 2.0266e-06,\n",
            "        5.7628e+00, 7.7688e+00, 1.4934e+01, 1.1921e-07, 9.0236e-04, 6.2189e-02,\n",
            "        8.8807e-05, -0.0000e+00, 2.1100e-05, 3.4571e-06, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 8.3636e-16, 9.5114e-22, 1.8637e-42, 8.3636e-16, 1.2311e-20,\n",
            "        3.5998e-29, 1.0554e-04, 1.6713e-33, 6.6919e-30, 5.3552e-02, 6.1387e-03,\n",
            "        8.3636e-16, 1.9400e-04, 8.0055e-22, 2.0803e-20, 8.9639e-28, 4.9004e-36,\n",
            "        1.2075e-23, 1.0950e-40, 4.5855e-31, 6.2387e-05, 8.3636e-16, 0.0000e+00,\n",
            "        2.1060e-28, 3.8439e-20, 3.1101e-03, 2.0803e-20, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  90\n",
            "ce_loss:  tensor([5.3644e-06, 6.1987e-05, 7.9870e-06, 1.1919e+01, 6.1987e-05, 9.7751e-06,\n",
            "        1.3473e+01, 7.8742e-04, 1.4915e+01, 5.1603e+00, 5.3644e-06, -0.0000e+00,\n",
            "        6.1987e-05, 1.1921e-07, 3.1196e-03, 2.5034e-06, 1.1496e+01, 1.6689e-06,\n",
            "        6.4270e+00, 6.6778e+00, 1.4013e+01, 1.1921e-07, 6.1987e-05, 5.1317e-02,\n",
            "        5.8172e-05, -0.0000e+00, 3.3379e-06, 2.5034e-06, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 9.2335e-16, 6.5385e-22, 1.3060e-42, 9.2335e-16, 8.4650e-21,\n",
            "        2.0856e-29, 1.0765e-04, 1.4710e-33, 5.1300e-30, 5.3935e-02, 6.0878e-03,\n",
            "        9.2335e-16, 2.1271e-04, 3.8228e-22, 9.7326e-21, 7.2084e-28, 3.9337e-36,\n",
            "        8.0252e-24, 4.1904e-41, 1.4843e-30, 6.2445e-05, 9.2335e-16, 0.0000e+00,\n",
            "        9.7133e-29, 1.9840e-20, 3.3306e-03, 9.7326e-21, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  91\n",
            "ce_loss:  tensor([9.5367e-07, 5.3404e-05, 4.0531e-06, 1.5541e+01, 5.3404e-05, 6.6757e-06,\n",
            "        1.1931e+01, 3.2551e-04, 1.8265e+01, 3.6106e+00, 9.5367e-07, -0.0000e+00,\n",
            "        5.3404e-05, 1.7881e-06, 2.9917e-04, 3.3379e-06, 9.3006e+00, 1.6689e-06,\n",
            "        6.1918e+00, 5.1693e+00, 1.4372e+01, 1.1921e-07, 5.3404e-05, 5.6408e-02,\n",
            "        7.2238e-05, -0.0000e+00, 2.7537e-05, 3.3379e-06, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 5.8558e-16, 5.3724e-22, 8.5479e-43, 5.8558e-16, 6.1356e-21,\n",
            "        3.6542e-29, 1.0554e-04, 9.8855e-34, 4.2036e-30, 5.3552e-02, 6.1387e-03,\n",
            "        5.8558e-16, 1.9400e-04, 6.0263e-22, 5.9822e-21, 1.2919e-27, 2.5435e-36,\n",
            "        9.7027e-24, 8.4165e-41, 4.7641e-31, 6.2387e-05, 5.8558e-16, 0.0000e+00,\n",
            "        7.6778e-29, 3.4839e-20, 3.1434e-03, 5.9822e-21, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  92\n",
            "ce_loss:  tensor([5.3644e-06, 2.3722e-05, 1.1086e-05, 1.2587e+01, 2.3722e-05, 3.5763e-06,\n",
            "        1.3511e+01, 7.8742e-04, 1.5686e+01, 2.0657e+00, 5.3644e-06, -0.0000e+00,\n",
            "        2.3722e-05, 1.1921e-07, 2.4113e-04, 7.6294e-06, 1.0238e+01, 1.6689e-06,\n",
            "        7.8049e+00, 6.5966e+00, 1.4063e+01, 1.1921e-07, 2.3722e-05, 6.4857e-02,\n",
            "        4.8636e-05, -0.0000e+00, 3.4571e-06, 7.6294e-06, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 4.4531e-16, 4.9940e-22, 6.1097e-43, 4.4531e-16, 2.8149e-21,\n",
            "        1.8359e-29, 1.0765e-04, 4.0448e-34, 3.2290e-30, 5.3935e-02, 6.0878e-03,\n",
            "        4.4531e-16, 2.1271e-04, 2.8401e-22, 5.2188e-21, 1.5907e-27, 1.9329e-36,\n",
            "        6.0127e-24, 5.8396e-41, 1.0643e-30, 6.2445e-05, 4.4531e-16, 0.0000e+00,\n",
            "        4.3768e-29, 1.7862e-20, 3.3744e-03, 5.2188e-21, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  93\n",
            "ce_loss:  tensor([9.5367e-07, 8.6423e-05, 3.6955e-06, 1.2227e+01, 8.6423e-05, 4.1723e-06,\n",
            "        1.1952e+01, 3.2551e-04, 1.3753e+01, 3.8522e+00, 9.5367e-07, -0.0000e+00,\n",
            "        8.6423e-05, 1.7881e-06, 2.4852e-04, 3.5763e-06, 1.0972e+01, 2.1458e-06,\n",
            "        7.5636e+00, 6.9719e+00, 1.5602e+01, 1.1921e-07, 8.6423e-05, 5.6963e-02,\n",
            "        5.0663e-05, -0.0000e+00, 1.7881e-05, 3.5763e-06, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 2.3306e-16, 4.5065e-22, 1.3144e-42, 2.3306e-16, 1.9813e-21,\n",
            "        3.1831e-29, 1.0554e-04, 9.5937e-34, 2.6144e-30, 5.3552e-02, 6.1387e-03,\n",
            "        2.3306e-16, 1.9400e-04, 3.1884e-22, 6.4684e-21, 1.3153e-27, 1.5958e-36,\n",
            "        5.4240e-24, 5.3656e-41, 4.9564e-31, 6.2387e-05, 2.3306e-16, 0.0000e+00,\n",
            "        3.3095e-29, 2.4742e-20, 3.1859e-03, 6.4684e-21, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  94\n",
            "ce_loss:  tensor([5.3644e-06, 2.1219e-05, 1.0014e-05, 1.2595e+01, 2.1219e-05, 2.7418e-06,\n",
            "        1.4078e+01, 7.8742e-04, 1.5912e+01, 5.0770e+00, 5.3644e-06, -0.0000e+00,\n",
            "        2.1219e-05, 1.1921e-07, 6.1040e-04, 1.9073e-06, 1.2254e+01, 1.5497e-06,\n",
            "        7.1712e+00, 6.6193e+00, 1.6466e+01, 1.1921e-07, 2.1219e-05, 6.1111e-02,\n",
            "        3.0040e-05, -0.0000e+00, 3.4571e-06, 1.9073e-06, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 2.1663e-16, 3.8955e-22, 1.5428e-42, 2.1663e-16, 8.9086e-22,\n",
            "        1.4729e-29, 1.0765e-04, 8.5335e-34, 1.4217e-30, 5.3935e-02, 6.0878e-03,\n",
            "        2.1663e-16, 2.1271e-04, 1.7356e-22, 2.7650e-21, 6.6919e-28, 2.6010e-36,\n",
            "        3.7923e-24, 3.3710e-41, 3.6224e-31, 6.2445e-05, 2.1663e-16, 0.0000e+00,\n",
            "        1.4546e-29, 1.3865e-20, 3.3955e-03, 2.7650e-21, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  95\n",
            "ce_loss:  tensor([9.5367e-07, 1.0133e-05, 3.4571e-06, 1.4684e+01, 1.0133e-05, 2.3842e-06,\n",
            "        1.5613e+01, 3.2551e-04, 1.6303e+01, 2.9628e+00, 9.5367e-07, -0.0000e+00,\n",
            "        1.0133e-05, 1.7881e-06, 1.5532e-04, 2.1458e-06, 1.1371e+01, 1.4305e-06,\n",
            "        5.6466e+00, 7.1336e+00, 1.4845e+01, 1.1921e-07, 1.0133e-05, 5.3017e-02,\n",
            "        3.7550e-05, -0.0000e+00, 1.9669e-05, 2.1458e-06, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 1.2091e-16, 3.6796e-22, 8.0995e-43, 1.2091e-16, 1.0220e-21,\n",
            "        1.1746e-29, 1.0554e-04, 3.8656e-34, 1.2493e-30, 5.3552e-02, 6.1387e-03,\n",
            "        1.2091e-16, 1.9400e-04, 2.6047e-22, 2.4493e-21, 5.3127e-28, 2.2048e-36,\n",
            "        4.1893e-24, 3.1811e-41, 2.4494e-31, 6.2387e-05, 1.2091e-16, 0.0000e+00,\n",
            "        1.5871e-29, 9.7931e-21, 3.1953e-03, 2.4493e-21, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  96\n",
            "ce_loss:  tensor([5.3644e-06, 2.9206e-05, 1.0371e-05, 1.1848e+01, 2.9206e-05, 6.4373e-06,\n",
            "        1.3778e+01, 7.8742e-04, 1.5805e+01, 1.8100e+00, 5.3644e-06, -0.0000e+00,\n",
            "        2.9206e-05, 1.1921e-07, 2.6735e-04, 7.7486e-06, 1.1211e+01, 1.7881e-06,\n",
            "        6.5510e+00, 5.8741e+00, 1.3427e+01, 1.1921e-07, 2.9206e-05, 5.9885e-02,\n",
            "        2.3007e-05, -0.0000e+00, 3.4571e-06, 7.7486e-06, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 8.0215e-17, 2.8088e-22, 8.2957e-43, 8.0215e-17, 5.4988e-22,\n",
            "        7.2997e-30, 1.0765e-04, 3.2205e-34, 1.9050e-30, 5.3935e-02, 6.0878e-03,\n",
            "        8.0215e-17, 2.1271e-04, 1.8522e-22, 2.1443e-21, 3.1422e-28, 2.0255e-36,\n",
            "        4.5851e-24, 2.3309e-41, 5.6629e-31, 6.2445e-05, 8.0215e-17, 0.0000e+00,\n",
            "        8.4145e-30, 1.0255e-20, 3.4001e-03, 2.1443e-21, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  97\n",
            "ce_loss:  tensor([9.5367e-07, 1.1206e-05, 3.3379e-06, 1.5128e+01, 1.1206e-05, 2.1458e-06,\n",
            "        1.1594e+01, 3.2551e-04, 1.3687e+01, 3.7241e+00, 9.5367e-07, -0.0000e+00,\n",
            "        1.1206e-05, 1.7881e-06, 1.0299e-04, 4.7684e-06, 1.0500e+01, 1.6689e-06,\n",
            "        7.6681e+00, 7.5492e+00, 1.4612e+01, 1.1921e-07, 1.1206e-05, 5.0008e-02,\n",
            "        4.2438e-05, -0.0000e+00, 1.8239e-05, 4.7684e-06, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 6.4616e-17, 2.8570e-22, 5.4090e-43, 6.4616e-17, 7.3684e-22,\n",
            "        1.1447e-29, 1.0554e-04, 5.2284e-34, 1.6461e-30, 5.3552e-02, 6.1387e-03,\n",
            "        6.4616e-17, 1.9400e-04, 2.2339e-22, 2.8907e-21, 2.6747e-28, 2.1793e-36,\n",
            "        3.3064e-24, 1.8871e-41, 2.6576e-31, 6.2387e-05, 6.4616e-17, 0.0000e+00,\n",
            "        7.6742e-30, 6.8688e-21, 3.1989e-03, 2.8907e-21, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  98\n",
            "ce_loss:  tensor([5.3644e-06, 5.3644e-06, 6.3181e-06, 1.2534e+01, 5.3644e-06, 1.1921e-06,\n",
            "        1.2746e+01, 7.8742e-04, 1.4803e+01, 4.5225e+00, 5.3644e-06, -0.0000e+00,\n",
            "        5.3644e-06, 1.1921e-07, 2.0621e-04, 6.5565e-06, 8.9167e+00, 1.4305e-06,\n",
            "        6.7271e+00, 6.3392e+00, 1.6927e+01, 1.1921e-07, 5.3644e-06, 4.1950e-02,\n",
            "        2.1219e-05, -0.0000e+00, 3.4571e-06, 6.5565e-06, 5.1855e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3935e-02, 3.3747e-17, 2.0422e-22, 3.5173e-43, 3.3747e-17, 3.8772e-22,\n",
            "        1.0189e-29, 1.0765e-04, 1.1395e-33, 1.0298e-30, 5.3935e-02, 6.0878e-03,\n",
            "        3.3747e-17, 2.1271e-04, 1.3335e-22, 2.5123e-21, 4.8971e-28, 1.6127e-36,\n",
            "        2.4535e-24, 9.8904e-42, 2.1490e-31, 6.2445e-05, 3.3747e-17, 0.0000e+00,\n",
            "        5.3578e-30, 1.0805e-20, 3.4001e-03, 2.5123e-21, 1.1902e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "*************** t  99\n",
            "ce_loss:  tensor([9.5367e-07, 2.5391e-05, 2.8610e-06, 1.4799e+01, 2.5391e-05, 1.3113e-06,\n",
            "        1.5295e+01, 3.2551e-04, 1.4968e+01, 2.7837e+00, 9.5367e-07, -0.0000e+00,\n",
            "        2.5391e-05, 1.7881e-06, 8.1297e-05, 3.2186e-06, 9.3950e+00, 1.7881e-06,\n",
            "        5.4443e+00, 5.0777e+00, 1.5164e+01, 1.1921e-07, 2.5391e-05, 6.4237e-02,\n",
            "        3.7073e-05, -0.0000e+00, 1.8239e-05, 3.2186e-06, 8.2251e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.3552e-02, 2.6728e-17, 1.6308e-22, 2.6625e-43, 2.6728e-17, 1.3729e-22,\n",
            "        7.6119e-30, 1.0554e-04, 5.4178e-34, 7.4133e-31, 5.3552e-02, 6.1387e-03,\n",
            "        2.6728e-17, 1.9400e-04, 7.9936e-23, 2.2176e-21, 8.2115e-28, 8.3784e-37,\n",
            "        2.4493e-24, 2.0777e-41, 1.0287e-31, 6.2387e-05, 2.6728e-17, 0.0000e+00,\n",
            "        3.5654e-30, 5.5248e-21, 3.1989e-03, 2.2176e-21, 1.1542e-01],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "PGD linf: Attack effectiveness 72.414%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different kinds of GKDE"
      ],
      "metadata": {
        "id": "ghFEgIubQVGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-select benign samples\n",
        "benign_samples = []\n",
        "for x_batch, y_batch in test_loader:\n",
        "  benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "# Forward pass to get logits for benign samples\n",
        "with torch.no_grad():  # No need for gradients\n",
        "    outputs = model_AT_rFGSM(ben_x.to(torch.float32))\n",
        "\n",
        "# Calculate softmax probabilities\n",
        "probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "# Sort indices based on probabilities of class 1 (assuming class 1 is the \"positive\" class)\n",
        "sorted_indices = torch.argsort(probabilities[:, 1], descending=False)\n",
        "\n",
        "# Select the top 1000 high confidence benign samples\n",
        "top_1000_high_confidence_benign_samples = ben_x[sorted_indices[:1000]]\n",
        "\n",
        "# Set to track indices of samples to be removed\n",
        "removed_set = set()\n",
        "\n",
        "# Step 1: Identify similar samples\n",
        "for i in range(len(top_1000_high_confidence_benign_samples)):\n",
        "    if i in removed_set:\n",
        "        continue\n",
        "    sample1 = top_1000_high_confidence_benign_samples[i]\n",
        "    for j in range(i + 1, len(top_1000_high_confidence_benign_samples)):\n",
        "        if j in removed_set:\n",
        "            continue\n",
        "        sample2 = top_1000_high_confidence_benign_samples[j]\n",
        "        if torch.abs(sample1 - sample2).sum().item() < 5:\n",
        "            removed_set.add(j)\n",
        "\n",
        "# Step 2: Select samples that are not in removed_set\n",
        "selected_samples = [sample for idx, sample in enumerate(top_1000_high_confidence_benign_samples) if idx not in removed_set]\n",
        "\n",
        "# Step 3: Stack tensors along a new dimension\n",
        "selected_benigns = torch.stack(selected_samples)\n",
        "\n",
        "del benign_samples, outputs, probabilities, top_1000_high_confidence_benign_samples, selected_samples   # Free up memory"
      ],
      "metadata": {
        "id": "YLO4kDBORXNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_done(x, y, model):\n",
        "    # Get the model's predictions\n",
        "    outputs = model(x)\n",
        "\n",
        "    # Use argmax to get the predicted class indices\n",
        "    predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    # Ensure y is in the same shape as predicted for comparison\n",
        "    y = y.view_as(predicted)\n",
        "\n",
        "    # Determine if the predictions are incorrect\n",
        "    done = (predicted != y).bool()\n",
        "\n",
        "    return done"
      ],
      "metadata": {
        "id": "sbCNYQPAQvLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multidimensional KDE implementation\n",
        "def KDE(x, data, bandwidth,kernel):\n",
        "    \"\"\"\n",
        "    Compute the kernel density estimate (KDE) for given data points.\n",
        "\n",
        "    Parameters:\n",
        "        x (torch.Tensor): Points at which to evaluate the KDE (shape: [num_samples, num_dimensions]).\n",
        "        data (torch.Tensor): Data points used to estimate the density (shape: [num_data_points, num_dimensions]).\n",
        "        bandwidth (float): Bandwidth parameter for the KDE.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Density estimate at each point in x (shape: [num_samples,]).\n",
        "    \"\"\"\n",
        "    n = data.shape[0]  # Number of data points\n",
        "    d = x.shape[1]  # Dimensionality of the data\n",
        "\n",
        "    # Convert bandwidth to tensor\n",
        "    bandwidth_tensor = torch.tensor(bandwidth)\n",
        "\n",
        "    # Calculate standardized distances for all data points\n",
        "    u = torch.abs(x[:, None, :] - data)\n",
        "\n",
        "    # Compute kernel contributions for all data points\n",
        "    if kernel == 'gaussian':\n",
        "        kernel_contributions = 10. * torch.exp(-0.5 * torch.sum(u**2, dim=-1) / bandwidth**2)\n",
        "    else:\n",
        "        kernel_contributions = (1./d) * torch.exp(-1. * torch.sum(u, dim=-1) / bandwidth_tensor)\n",
        "\n",
        "    # Sum contributions across all data points\n",
        "    estimate = torch.mean(kernel_contributions, dim=1)\n",
        "\n",
        "    # Normalize the density estimate by the number of points and the bandwidth raised to the dimensionality\n",
        "    #estimate /= (bandwidth_tensor ** d)\n",
        "\n",
        "    return estimate\n"
      ],
      "metadata": {
        "id": "izCn5s8Y7tdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde_old(adv_x,y,model,benigns, bandwidth, penalty_factor,kernel):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y.view(-1).long())\n",
        "    #print('ce: ', ce)\n",
        "    kde = KDE(adv_x, benigns, bandwidth,kernel)\n",
        "    #print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    return loss_no_reduction\n",
        "\n",
        "\n",
        "def gkde_old(x, y, model,bens, bandwidth, penalty_factor, kernel, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde_old(x_var,y,model,bens, bandwidth, penalty_factor, kernel)\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        #pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, y.view(-1).long()).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "y8be3sudY43I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde_old(adv_x,y,model,benigns, bandwidth, penalty_factor,kernel):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y.view(-1).long())\n",
        "    #print('ce: ', ce)\n",
        "    kde = KDE(adv_x, benigns, bandwidth,kernel)\n",
        "    #print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    return loss_no_reduction\n",
        "\n",
        "\n",
        "def gkde_old2(x, y, model,bens, bandwidth, penalty_factor, kernel, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde_old(x_var,y,model,bens, bandwidth, penalty_factor, kernel)\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, y.view(-1).long()).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "co0DuPkBMf2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    if (attack ==  gkde) or (attack ==  mimicry) or (attack ==  gkde_old) or (attack ==  gkde_old2):\n",
        "      # Pre-select benign samples\n",
        "      benign_samples = []\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "      ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "      # Forward pass to get logits for benign samples\n",
        "      with torch.no_grad():  # No need for gradients\n",
        "          outputs = model_AT_rFGSM(ben_x.to(torch.float32))\n",
        "\n",
        "      # Calculate softmax probabilities\n",
        "      probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "      # Sort indices based on probabilities of class 1 (assuming class 1 is the \"positive\" class)\n",
        "      sorted_indices = torch.argsort(probabilities[:, 1], descending=False)\n",
        "\n",
        "      # Select the top 500 high confidence benign samples\n",
        "      top_1000_high_confidence_benign_samples = ben_x[sorted_indices[:1000]]\n",
        "\n",
        "      # Set to track indices of samples to be removed\n",
        "      removed_set = set()\n",
        "\n",
        "      # Step 1: Identify similar samples\n",
        "      for i in range(len(top_1000_high_confidence_benign_samples)):\n",
        "          if i in removed_set:\n",
        "              continue\n",
        "          sample1 = top_1000_high_confidence_benign_samples[i]\n",
        "          for j in range(i + 1, len(top_1000_high_confidence_benign_samples)):\n",
        "              if j in removed_set:\n",
        "                  continue\n",
        "              sample2 = top_1000_high_confidence_benign_samples[j]\n",
        "              if torch.abs(sample1 - sample2).sum().item() < 5:\n",
        "                  removed_set.add(j)\n",
        "\n",
        "      # Step 2: Select samples that are not in removed_set\n",
        "      selected_samples = [sample for idx, sample in enumerate(top_1000_high_confidence_benign_samples) if idx not in removed_set]\n",
        "\n",
        "      # Step 3: Stack tensors along a new dimension\n",
        "      selected_benigns = torch.stack(selected_samples)\n",
        "\n",
        "      del benign_samples, outputs, probabilities, ben_x, top_1000_high_confidence_benign_samples, selected_samples   # Free up memory\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    n_samples = 0\n",
        "    cor_test = 0\n",
        "    cor_ad_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            #outputs = model(x_test)\n",
        "            #predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            #acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            #avg_acc_test.append(acc_test)\n",
        "\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "            n_samples += len(mal_y_batch)\n",
        "\n",
        "            outputs = model(mal_x_batch)\n",
        "            predicted = outputs.argmax(1)\n",
        "            cor_test += (predicted == 1).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            if attack == mimicry:\n",
        "                pertb_mal_x = mimicry(top_500_high_confidence_benign_samples, mal_x_batch, model, **kwargs)\n",
        "            elif (attack == gkde):\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde(mal_x_batch, mal_y_batch, model, selected_benigns, **kwargs)\n",
        "            elif (attack == gkde_old):\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde_old(mal_x_batch, mal_y_batch, model, selected_benigns, **kwargs)\n",
        "            elif (attack == gkde_old2):\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde_old2(mal_x_batch, mal_y_batch, model, selected_benigns, **kwargs)\n",
        "            else :\n",
        "                with torch.enable_grad():\n",
        "                    pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_test += (y_pred == 1).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Accuracy of just malwares (without attack): {(cor_test / n_samples) * 100:.4}% | Under attack: {(cor_ad_test / n_samples) * 100:.4}%.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "p5bJtpokI_uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict0(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    if (attack ==  gkde) or (attack ==  mimicry) or (attack ==  gkde_old) or (attack ==  gkde_old2):\n",
        "      # Pre-select benign samples\n",
        "      benign_samples = []\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "      ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "      # Forward pass to get logits for benign samples\n",
        "      with torch.no_grad():  # No need for gradients\n",
        "          outputs = model_AT_rFGSM(ben_x.to(torch.float32))\n",
        "\n",
        "      # Calculate softmax probabilities\n",
        "      probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "      # Sort indices based on probabilities of class 1 (assuming class 1 is the \"positive\" class)\n",
        "      sorted_indices = torch.argsort(probabilities[:, 1], descending=False)\n",
        "\n",
        "      # Select the top 500 high confidence benign samples\n",
        "      selected_benigns = ben_x[sorted_indices[:500]]\n",
        "\n",
        "\n",
        "      del benign_samples, outputs, probabilities, ben_x   # Free up memory\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    n_samples = 0\n",
        "    cor_test = 0\n",
        "    cor_ad_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            #outputs = model(x_test)\n",
        "            #predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            #acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            #avg_acc_test.append(acc_test)\n",
        "\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "            n_samples += len(mal_y_batch)\n",
        "\n",
        "            outputs = model(mal_x_batch)\n",
        "            predicted = outputs.argmax(1)\n",
        "            cor_test += (predicted == 1).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            if attack == mimicry:\n",
        "                pertb_mal_x = mimicry(selected_benigns, mal_x_batch, model, **kwargs)\n",
        "            elif (attack == gkde):\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde(mal_x_batch, mal_y_batch, model, selected_benigns, **kwargs)\n",
        "            elif (attack == gkde_old):\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde_old(mal_x_batch, mal_y_batch, model, selected_benigns, **kwargs)\n",
        "            elif (attack == gkde_old2):\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde_old2(mal_x_batch, mal_y_batch, model, selected_benigns, **kwargs)\n",
        "            else :\n",
        "                with torch.enable_grad():\n",
        "                    pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_test += (y_pred == 1).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Accuracy of just malwares (without attack): {(cor_test / n_samples) * 100:.4}% | Under attack: {(cor_ad_test / n_samples) * 100:.4}%.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Gv05ZocqXdFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict2(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    if (attack ==  gkde) or (attack ==  mimicry) or (attack ==  gkde_old) or (attack ==  gkde_old2):\n",
        "      # Pre-select benign samples\n",
        "      benign_samples = []\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "      ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "      selected_samples = ben_x[100]\n",
        "      del benign_samples\n",
        "\n",
        "    model.eval()\n",
        "    n_samples = 0\n",
        "    cor_test = 0\n",
        "    cor_ad_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            #outputs = model(x_test)\n",
        "            #predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            #acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            #avg_acc_test.append(acc_test)\n",
        "\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "            n_samples += len(mal_y_batch)\n",
        "\n",
        "            outputs = model(mal_x_batch)\n",
        "            predicted = outputs.argmax(1)\n",
        "            cor_test += (predicted == 1).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            if attack == mimicry:\n",
        "                pertb_mal_x = mimicry(top_500_high_confidence_benign_samples, mal_x_batch, model, **kwargs)\n",
        "            elif (attack == gkde):\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde(mal_x_batch, mal_y_batch, model, selected_benigns, **kwargs)\n",
        "            elif (attack == gkde_old):\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde_old(mal_x_batch, mal_y_batch, model, selected_benigns, **kwargs)\n",
        "            elif (attack == gkde_old2):\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde_old2(mal_x_batch, mal_y_batch, model, selected_benigns, **kwargs)\n",
        "            else :\n",
        "                with torch.enable_grad():\n",
        "                    pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_test += (y_pred == 1).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Accuracy of just malwares (without attack): {(cor_test / n_samples) * 100:.4}% | Under attack: {(cor_ad_test / n_samples) * 100:.4}%.\")\n"
      ],
      "metadata": {
        "id": "mX2CUeHZ0j3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gkde_old(maximize loss & default removal insertion arrays), adv_predict(top benigns), laplacian\n",
        "\n",
        "penalty_factors = [1,10,100,1000,1e4,1e5]\n",
        "bandwidths = [1.,2.,3.,5.,10.,15.,20.,30.,40.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbc498a-4692-4dee-eb5b-b960fd31245a",
        "id": "N_lecXmXcIEa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* penalty_factor: 1 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 76.37%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 83.45%.\n",
            "********* penalty_factor: 1 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.52%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 70.0%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 67.52%.\n",
            "********* penalty_factor: 1 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 70.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 62.83%.\n",
            "********* penalty_factor: 1 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.19%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 64.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 58.05%.\n",
            "********* penalty_factor: 1 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 56.46%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.77%.\n",
            "********* penalty_factor: 1 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 54.6%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.42%.\n",
            "********* penalty_factor: 1 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.24%.\n",
            "********* penalty_factor: 1 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.19%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.15%.\n",
            "********* penalty_factor: 1 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.06%.\n",
            "********* penalty_factor: 10 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 75.4%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 79.38%.\n",
            "********* penalty_factor: 10 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.52%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 68.67%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 65.04%.\n",
            "********* penalty_factor: 10 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.43%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 66.11%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 60.8%.\n",
            "********* penalty_factor: 10 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 64.51%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 56.11%.\n",
            "********* penalty_factor: 10 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 56.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.42%.\n",
            "********* penalty_factor: 10 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.08%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.24%.\n",
            "********* penalty_factor: 10 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.62%.\n",
            "********* penalty_factor: 10 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.53%.\n",
            "********* penalty_factor: 10 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.65%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.71%.\n",
            "********* penalty_factor: 100 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.76%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 75.22%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 77.35%.\n",
            "********* penalty_factor: 100 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.52%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 68.23%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 63.19%.\n",
            "********* penalty_factor: 100 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 65.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 59.73%.\n",
            "********* penalty_factor: 100 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 61.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.27%.\n",
            "********* penalty_factor: 100 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.32%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 56.11%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.71%.\n",
            "********* penalty_factor: 100 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.23%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.8%.\n",
            "********* penalty_factor: 100 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.09%.\n",
            "********* penalty_factor: 100 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.97%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.18%.\n",
            "********* penalty_factor: 100 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.18%.\n",
            "********* penalty_factor: 1000 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.76%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 73.36%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 75.66%.\n",
            "********* penalty_factor: 1000 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 64.69%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 61.86%.\n",
            "********* penalty_factor: 1000 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.23%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 64.6%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 57.26%.\n",
            "********* penalty_factor: 1000 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.32%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 57.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.65%.\n",
            "********* penalty_factor: 1000 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.44%.\n",
            "********* penalty_factor: 1000 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.53%.\n",
            "********* penalty_factor: 1000 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.71%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.09%.\n",
            "********* penalty_factor: 1000 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.97%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.71%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "********* penalty_factor: 1000 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 73.45%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 72.3%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 63.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 59.47%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.23%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 63.98%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 55.4%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 58.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.42%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.36%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.15%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.3%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.71%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.32%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 71.33%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 69.91%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 63.19%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 57.7%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.95%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 59.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.98%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.89%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.8%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.45%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.8%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.35%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.63%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.53%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.54%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.54%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gkde_old(maximize loss & default removal insertion arrays), adv_predict2(random benigns), laplacian\n",
        "\n",
        "penalty_factors = [10,100,1000,1e4,1e5]\n",
        "bandwidths = [5.,10.,15.,20.,30.,40.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e71da573-eba6-4745-f572-d34968d0ac89",
        "id": "NOaZSky91tDS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* penalty_factor: 10 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 61.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.48%.\n",
            "********* penalty_factor: 10 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.81%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.33%.\n",
            "********* penalty_factor: 10 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.1%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.8%.\n",
            "********* penalty_factor: 10 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.92%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.71%.\n",
            "********* penalty_factor: 10 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.62%.\n",
            "********* penalty_factor: 10 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.74%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.35%.\n",
            "********* penalty_factor: 100 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 59.82%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.68%.\n",
            "********* penalty_factor: 100 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.67%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.19%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.06%.\n",
            "********* penalty_factor: 100 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.33%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.53%.\n",
            "********* penalty_factor: 100 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.33%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.09%.\n",
            "********* penalty_factor: 100 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.33%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 100 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.76%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 56.46%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.15%.\n",
            "********* penalty_factor: 1000 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.3%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "********* penalty_factor: 1000 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 1000 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.14%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.71%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 1000 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.97%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.97%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 56.55%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.35%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.33%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.18%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.33%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.09%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 30.0 ******************\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3e10c3c015c9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mattack_params\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m{\u001b[0m\u001b[0;34m'bandwidth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'penalty_factor'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpenalty_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'laplac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'insertion_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minsertion_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'removal_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mremoval_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step_length'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_report_loss_diff'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0madv_predict2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_AT_rFGSM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkde_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattack_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mattack_params\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m{\u001b[0m\u001b[0;34m'bandwidth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'penalty_factor'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpenalty_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'laplac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'insertion_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minsertion_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'removal_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mremoval_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step_length'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_report_loss_diff'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-d49f3b3ba210>\u001b[0m in \u001b[0;36madv_predict2\u001b[0;34m(test_loader, model, attack, device, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattack\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgkde_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                   \u001b[0mpertb_mal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgkde_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmal_y_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_benigns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattack\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgkde_old2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-87032243fc66>\u001b[0m in \u001b[0;36mgkde_old\u001b[0;34m(x, y, model, bens, bandwidth, penalty_factor, kernel, insertion_array, removal_array, k, step_length, norm, initial_rounding_threshold, round_threshold, random, is_report_loss_diff, is_sample)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mperturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;31m# stop perturbing the examples that are successful to evade the victim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gkde_old(maximize loss & default removal insertion arrays), adv_predict0(top 500 confidence benigns), laplacian\n",
        "\n",
        "penalty_factors = [10,100,1000]\n",
        "bandwidths = [10.,20.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict0(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict0(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict0(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8MXwjFUYd2j",
        "outputId": "6e298225-9a15-40b9-b58e-c90082c8aa4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* penalty_factor: 10 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.43%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 56.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.19%.\n",
            "********* penalty_factor: 10 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 54.69%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.04%.\n",
            "********* penalty_factor: 100 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 55.22%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.57%.\n",
            "********* penalty_factor: 100 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.14%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.74%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.59%.\n",
            "********* penalty_factor: 1000 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.19%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.77%.\n",
            "********* penalty_factor: 1000 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.5%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEuv7Nay1Xky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gkde_old2(maximize loss & updated removal insertion arrays), adv_predict(top benigns), laplacian\n",
        "\n",
        "penalty_factors = [1,10,100,1000,1e4,1e5]\n",
        "bandwidths = [1.,2.,3.,5.,10.,15.,20.,30.,40.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1rExFdCclMZ",
        "outputId": "8be64a63-679e-416c-edde-42812c239161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* penalty_factor: 1 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.2%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.71%.\n",
            "********* penalty_factor: 1 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.61%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.67%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.21%.\n",
            "********* penalty_factor: 1 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.43%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.32%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.27%.\n",
            "********* penalty_factor: 1 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.28%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.54%.\n",
            "********* penalty_factor: 1 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.67%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.63%.\n",
            "********* penalty_factor: 1 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.72%.\n",
            "********* penalty_factor: 1 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.16%.\n",
            "********* penalty_factor: 1 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.07%.\n",
            "********* penalty_factor: 1 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.45%.\n",
            "********* penalty_factor: 10 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.03%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.26%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.53%.\n",
            "********* penalty_factor: 10 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.61%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.48%.\n",
            "********* penalty_factor: 10 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.52%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.76%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.98%.\n",
            "********* penalty_factor: 10 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.04%.\n",
            "********* penalty_factor: 10 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.65%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.67%.\n",
            "********* penalty_factor: 10 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.17%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.74%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.31%.\n",
            "********* penalty_factor: 10 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.48%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.96%.\n",
            "********* penalty_factor: 10 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.42%.\n",
            "********* penalty_factor: 10 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.51%.\n",
            "********* penalty_factor: 100 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.94%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.52%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.38%.\n",
            "********* penalty_factor: 100 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.61%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.56%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.92%.\n",
            "********* penalty_factor: 100 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.47%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.81%.\n",
            "********* penalty_factor: 100 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.14%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.36%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.87%.\n",
            "********* penalty_factor: 100 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.69%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.03%.\n",
            "********* penalty_factor: 100 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.23%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.29%.\n",
            "********* penalty_factor: 100 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.37%.\n",
            "********* penalty_factor: 100 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.6%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.29%.\n",
            "********* penalty_factor: 100 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.78%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.2%.\n",
            "********* penalty_factor: 1000 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.94%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.52%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.12%.\n",
            "********* penalty_factor: 1000 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.56%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.19%.\n",
            "********* penalty_factor: 1000 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.32%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.16%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.34%.\n",
            "********* penalty_factor: 1000 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.76%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.71%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.88%.\n",
            "********* penalty_factor: 1000 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.82%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.0%.\n",
            "********* penalty_factor: 1000 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.65%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.24%.\n",
            "********* penalty_factor: 1000 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.97%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.65%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.42%.\n",
            "********* penalty_factor: 1000 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.65%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.04%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.95%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.78%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.32%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.67%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.38%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.62%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.74%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.36%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.07%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.07%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.89%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.3%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.3%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.21%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.64%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.74%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.29%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.58%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.53%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.19%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.45%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.07%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.49%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.34%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.84%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.63%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.34%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.02%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.54%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.66%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.54%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.25%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.66%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gkde_old2(maximize loss & updated removal insertion arrays), adv_predict2(random benigns), laplacian\n",
        "\n",
        "penalty_factors = [1,10,100]\n",
        "bandwidths = [5.,10.,20.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n"
      ],
      "metadata": {
        "id": "93dw0vya6Khr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "54698735-a6e3-49ff-8d16-021f269f5f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* penalty_factor: 1 bandwidth: 5.0 ******************\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ee9ea09d1222>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mattack_params\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m{\u001b[0m\u001b[0;34m'bandwidth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'penalty_factor'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpenalty_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'laplac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'insertion_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minsertion_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'removal_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mremoval_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step_length'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_report_loss_diff'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0madv_predict2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_AT_rFGSM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkde_old2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattack_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mattack_params\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m{\u001b[0m\u001b[0;34m'bandwidth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'penalty_factor'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpenalty_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'laplac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'insertion_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minsertion_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'removal_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mremoval_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step_length'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_report_loss_diff'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-d49f3b3ba210>\u001b[0m in \u001b[0;36madv_predict2\u001b[0;34m(test_loader, model, attack, device, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattack\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgkde_old2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                   \u001b[0mpertb_mal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgkde_old2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmal_y_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_benigns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-406d89ad1df1>\u001b[0m in \u001b[0;36mgkde_old2\u001b[0;34m(x, y, model, bens, bandwidth, penalty_factor, kernel, insertion_array, removal_array, k, step_length, norm, initial_rounding_threshold, round_threshold, random, is_report_loss_diff, is_sample)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m# stop perturbing the examples that are successful to evade the victim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mperturbation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Obl7KqKq7ZYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "70iWYt9Z7ZPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gkde_old(maximize loss & default removal insertion arrays), adv_predict(top benigns), gaussian\n",
        "\n",
        "penalty_factors = [1,10,100,1000,1e4,1e5]\n",
        "bandwidths = [0.1,0.2,0.4,0.6,1.,1.5,2.,5.,10.,20.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n"
      ],
      "metadata": {
        "id": "-6go4nY4ck6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "116f5138-3e86-4176-d361-42ac032e494a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* penalty_factor: 1 bandwidth: 0.1 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.92%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 87.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n",
            "********* penalty_factor: 1 bandwidth: 0.2 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.92%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 87.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n",
            "********* penalty_factor: 1 bandwidth: 0.4 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 84.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 83.01%.\n",
            "********* penalty_factor: 1 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.82%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 79.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 66.11%.\n",
            "********* penalty_factor: 1 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 54.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.5%.\n",
            "********* penalty_factor: 1 bandwidth: 1.5 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.18%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.38%.\n",
            "********* penalty_factor: 1 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.63%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 1 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.53%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.94%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "********* penalty_factor: 1 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "********* penalty_factor: 10 bandwidth: 0.1 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.92%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 87.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n",
            "********* penalty_factor: 10 bandwidth: 0.2 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.92%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 87.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n",
            "********* penalty_factor: 10 bandwidth: 0.4 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 85.13%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 81.15%.\n",
            "********* penalty_factor: 10 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.47%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 75.22%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 63.89%.\n",
            "********* penalty_factor: 10 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.72%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.89%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 51.5%.\n",
            "********* penalty_factor: 10 bandwidth: 1.5 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.89%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.47%.\n",
            "********* penalty_factor: 10 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.78%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 10 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.56%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 10 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.25%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.94%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 10 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100 bandwidth: 0.1 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.92%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 87.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n",
            "********* penalty_factor: 100 bandwidth: 0.2 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.92%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 87.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n",
            "********* penalty_factor: 100 bandwidth: 0.4 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 85.13%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 80.62%.\n",
            "********* penalty_factor: 100 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.47%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 75.93%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 62.83%.\n",
            "********* penalty_factor: 100 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.19%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.88%.\n",
            "********* penalty_factor: 100 bandwidth: 1.5 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.64%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.56%.\n",
            "********* penalty_factor: 100 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.14%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 100 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.56%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 100 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.94%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 0.1 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.92%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 87.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n",
            "********* penalty_factor: 1000 bandwidth: 0.2 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.92%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 87.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n",
            "********* penalty_factor: 1000 bandwidth: 0.4 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 84.16%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 77.35%.\n",
            "********* penalty_factor: 1000 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.56%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 70.97%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 60.8%.\n",
            "********* penalty_factor: 1000 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.36%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.88%.\n",
            "********* penalty_factor: 1000 bandwidth: 1.5 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.14%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.56%.\n",
            "********* penalty_factor: 1000 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.23%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 1000 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.56%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 1000 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.94%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 0.1 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.92%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 87.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 0.2 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.92%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 87.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 92.65%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 0.4 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 82.48%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 76.19%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 68.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 59.47%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 52.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.62%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 1.5 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.14%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.56%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.56%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 10.0 ******************\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-61c3583ca183>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mattack_params\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m{\u001b[0m\u001b[0;34m'bandwidth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'penalty_factor'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpenalty_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'insertion_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minsertion_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'removal_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mremoval_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step_length'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_report_loss_diff'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0madv_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_AT_rFGSM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkde_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattack_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mattack_params\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m{\u001b[0m\u001b[0;34m'bandwidth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'penalty_factor'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpenalty_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'insertion_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minsertion_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'removal_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mremoval_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step_length'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_report_loss_diff'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-d2a3f468a2b5>\u001b[0m in \u001b[0;36madv_predict\u001b[0;34m(test_loader, model, attack, device, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattack\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgkde_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                   \u001b[0mpertb_mal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgkde_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmal_y_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_benigns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattack\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgkde_old2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-87032243fc66>\u001b[0m in \u001b[0;36mgkde_old\u001b[0;34m(x, y, model, bens, bandwidth, penalty_factor, kernel, insertion_array, removal_array, k, step_length, norm, initial_rounding_threshold, round_threshold, random, is_report_loss_diff, is_sample)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss_kde_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;31m#loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Compute gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-406d89ad1df1>\u001b[0m in \u001b[0;36mget_loss_kde_old\u001b[0;34m(adv_x, y, model, benigns, bandwidth, penalty_factor, kernel)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print('ce: ', ce)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKDE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenigns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#print('kde : ', kde)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss_no_reduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mce\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpenalty_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d0c6fc92c747>\u001b[0m in \u001b[0;36mKDE\u001b[0;34m(x, data, bandwidth, kernel)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Calculate standardized distances for all data points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Compute kernel contributions for all data points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gkde_old(maximize loss & default removal insertion arrays), adv_predict2(random benigns), gaussian\n",
        "\n",
        "penalty_factors = [10,100,1000]\n",
        "bandwidths = [10.,20.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old, device, **attack_params)\n"
      ],
      "metadata": {
        "id": "85LtK4b11ycV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74f9c55-e39b-4983-cbcd-14a0f9ed07e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* penalty_factor: 10 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.34%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 10 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.65%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "********* penalty_factor: 100 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gkde_old2(maximize loss & updated removal insertion arrays), adv_predict(top benigns), gaussian\n",
        "\n",
        "penalty_factors = [1,10,100,1000,1e4,1e5]\n",
        "bandwidths = [0.6,0.8,1.,2.,3.,4.,5.,10.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n"
      ],
      "metadata": {
        "id": "50ny1UUT78eY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "715849d3-4d2d-48a6-bf90-00669aeeb985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* penalty_factor: 1 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.0%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.65%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.59%.\n",
            "********* penalty_factor: 1 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.23%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.97%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.89%.\n",
            "********* penalty_factor: 1 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.94%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.82%.\n",
            "********* penalty_factor: 1 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.63%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.4%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.11%.\n",
            "********* penalty_factor: 1 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.98%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.43%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "********* penalty_factor: 1 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.89%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.94%.\n",
            "********* penalty_factor: 1 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.03%.\n",
            "********* penalty_factor: 1 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.53%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.67%.\n",
            "********* penalty_factor: 10 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.65%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.01%.\n",
            "********* penalty_factor: 10 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.03%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.4%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.96%.\n",
            "********* penalty_factor: 10 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.81%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.3%.\n",
            "********* penalty_factor: 10 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.78%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.2%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.94%.\n",
            "********* penalty_factor: 10 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.17%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.47%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.38%.\n",
            "********* penalty_factor: 10 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.38%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 10 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 10 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.25%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.03%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.65%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.26%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.07%.\n",
            "********* penalty_factor: 100 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.76%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.67%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.5%.\n",
            "********* penalty_factor: 100 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.1%.\n",
            "********* penalty_factor: 100 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.14%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.38%.\n",
            "********* penalty_factor: 100 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.32%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 100 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.04%.\n",
            "********* penalty_factor: 1000 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.81%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.88%.\n",
            "********* penalty_factor: 1000 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.45%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.93%.\n",
            "********* penalty_factor: 1000 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.23%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 1000 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 1000 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ab094ca2a76e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mattack_params\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m{\u001b[0m\u001b[0;34m'bandwidth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'penalty_factor'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpenalty_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'insertion_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minsertion_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'removal_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mremoval_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step_length'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'linf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_report_loss_diff'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0madv_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_AT_rFGSM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkde_old2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattack_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-d2a3f468a2b5>\u001b[0m in \u001b[0;36madv_predict\u001b[0;34m(test_loader, model, attack, device, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattack\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgkde_old2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                   \u001b[0mpertb_mal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgkde_old2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmal_y_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_benigns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-406d89ad1df1>\u001b[0m in \u001b[0;36mgkde_old2\u001b[0;34m(x, y, model, bens, bandwidth, penalty_factor, kernel, insertion_array, removal_array, k, step_length, norm, initial_rounding_threshold, round_threshold, random, is_report_loss_diff, is_sample)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m#loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Compute gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mgrad_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         result = _engine_run_backward(\n\u001b[0m\u001b[1;32m    413\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gkde_old2(maximize loss & updated removal insertion arrays), adv_predict2(random benigns), gaussian\n",
        "\n",
        "penalty_factors = [1,10,100,1000,1e4,1e5]\n",
        "bandwidths = [0.6,0.8,1.,2.,3.,4.,5.,10.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict2(test_loader, model_AT_rFGSM, gkde_old2, device, **attack_params)\n"
      ],
      "metadata": {
        "id": "J677NN_j78eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rAkAN5JU778i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor,kernel):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Compute CE loss\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y)\n",
        "    #print('ce ',ce)\n",
        "\n",
        "    # Compute KDE loss\n",
        "    kde = KDE(adv_x, benigns, bandwidth,kernel)\n",
        "    #print('kde ',kde)\n",
        "\n",
        "    # Combine the losses with the penalty factor\n",
        "    loss = ce - penalty_factor * kde\n",
        "    #print('loss ',loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gkde(x, y, model,bens, bandwidth, penalty_factor, kernel, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "        initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "\n",
        "    :param x: Feature vector\n",
        "    :param y: Ground truth labels\n",
        "    :param model: Neural network model\n",
        "    :param RBFModel: Gaussian model for KDE\n",
        "    :param insertion_array: Array for insertion operations\n",
        "    :param removal_array: Array for removal operations\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf', 'l2', 'l1')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    #target's class\n",
        "    traget_labels = torch.zeros_like(y.view(-1).long())\n",
        "\n",
        "    # Compute natural loss and penalty_factor\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), traget_labels)\n",
        "\n",
        "\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    for t in range(k):\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde(x_var,traget_labels,model,bens, bandwidth, penalty_factor, kernel)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "        elif norm == 'l1':\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1', 'l2', or 'linf' norm.\")\n",
        "\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    if random:\n",
        "        round_threshold = torch.rand_like(x_next)\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_adv = criterion(model(x_next), traget_labels).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size(0) * 100:.3f}%.\")\n",
        "\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "xZkNUBSk7zzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fixed penalty factor\n",
        "\n",
        "penalty_factors = [1,10,100,1000,1e4,1e6,1e8,1e10]\n",
        "bandwidths = [1.,2.,3.,5.,10.,15.,20.,30.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n"
      ],
      "metadata": {
        "id": "t9vYJDKg7zzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a5d89d-389d-4dc7-cd66-5ec1d90d966b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* penalty_factor: 1.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.74%.\n",
            "********* penalty_factor: 1.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.21%.\n",
            "********* penalty_factor: 10 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.74%.\n",
            "********* penalty_factor: 10 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.12%.\n",
            "********* penalty_factor: 100 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.3%.\n",
            "********* penalty_factor: 100 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.44%.\n",
            "********* penalty_factor: 100 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.73%.\n",
            "********* penalty_factor: 1000 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.57%.\n",
            "********* penalty_factor: 1000 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.27%.\n",
            "********* penalty_factor: 1000 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.68%.\n",
            "********* penalty_factor: 1000 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.31%.\n",
            "********* penalty_factor: 1000 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.59%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.39%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.94%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.95%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.3%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.83%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.12%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.95%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.49%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.65%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.65%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.56%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.74%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.11%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.65%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.75%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 23.63%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.73%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.01%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.95%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.23%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.15%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.26%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.19%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.61%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.82%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.78%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.11%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.82%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.55%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.72%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.71%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.74%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.16%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.61%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.19%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.02%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.76%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.45%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.23%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.4%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.29%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.13%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.12%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.72%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.0%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.14%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.19%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.99%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.07%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.29%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.76%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.2%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.18%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.18%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.18%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fixed penalty factor\n",
        "\n",
        "penalty_factors = [100,1000,1e4,1e6,1e8]\n",
        "bandwidths = [0.6,0.8,1.,2.,3.,4.,5.,10.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'gaussian','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "id": "LS1hW_l_JQW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2ccae5-abe1-48cf-fe41-c60013663fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* penalty_factor: 100 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 24.78%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.34%.\n",
            "********* penalty_factor: 100 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.29%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.47%.\n",
            "********* penalty_factor: 100 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.93%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "********* penalty_factor: 100 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.67%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.38%.\n",
            "********* penalty_factor: 100 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.67%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.85%.\n",
            "********* penalty_factor: 100 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.08%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.14%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.96%.\n",
            "********* penalty_factor: 1000 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 24.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.9%.\n",
            "********* penalty_factor: 1000 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.8%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 1000 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.18%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 1000 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.47%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 26.64%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.36%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.62%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.28%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.19%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.18%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.19%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.65%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 23.98%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.81%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.22%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.78%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.87%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.55%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.37%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.12%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.36%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.79%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.33%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.69%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.37%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.55%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.0%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.37%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor,kernel,alpha):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Compute CE loss\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y)\n",
        "    #print('ce ',ce)\n",
        "\n",
        "    # Compute KDE loss\n",
        "    kde = KDE(adv_x, benigns, bandwidth,kernel)\n",
        "    #print('kde ',kde)\n",
        "\n",
        "    # Combine the losses with the penalty factor\n",
        "    loss = alpha * ce - penalty_factor * kde\n",
        "    #print('loss ',loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gkde(x, y, model,bens, bandwidth, penalty_factor, kernel,t_threshold, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "        initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "\n",
        "    :param x: Feature vector\n",
        "    :param y: Ground truth labels\n",
        "    :param model: Neural network model\n",
        "    :param RBFModel: Gaussian model for KDE\n",
        "    :param insertion_array: Array for insertion operations\n",
        "    :param removal_array: Array for removal operations\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf', 'l2', 'l1')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    #target's class\n",
        "    traget_labels = torch.zeros_like(y.view(-1).long())\n",
        "\n",
        "    # Compute natural loss and penalty_factor\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), traget_labels)\n",
        "\n",
        "\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    for t in range(k):\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "\n",
        "        if t<t_threshold:\n",
        "          alpha = 0.\n",
        "        else:\n",
        "          alpha = 1.\n",
        "          penalty_factor = 0.\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde(x_var,traget_labels,model,bens, bandwidth, penalty_factor, kernel,alpha)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "        elif norm == 'l1':\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1', 'l2', or 'linf' norm.\")\n",
        "\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    if random:\n",
        "        round_threshold = torch.rand_like(x_next)\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_adv = criterion(model(x_next), traget_labels).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size(0) * 100:.3f}%.\")\n",
        "\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "QRoDHAXrjpgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first t_threshold steps, kde , then ce(penalty factor is meaningless here)\n",
        "\n",
        "t_thresholds = [3,5,10,15,20,25,30]\n",
        "bandwidths = [1.,2.,3.,5.,10.,15.,20.,30.,40.]\n",
        "\n",
        "for t_threshold in t_thresholds:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','t_threshold:',t_threshold,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': 1000,'kernel':'laplac','t_threshold':t_threshold,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': 1000,'kernel':'laplac','t_threshold':t_threshold,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': 1000,'kernel':'laplac','t_threshold':t_threshold,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwm37B4apzFE",
        "outputId": "3fc548cd-4207-4702-f3b2-5aa8f80ad13a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* t_threshold: 3 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.71%.\n",
            "********* t_threshold: 3 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.29%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.94%.\n",
            "********* t_threshold: 3 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.8%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.94%.\n",
            "********* t_threshold: 3 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.71%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.94%.\n",
            "********* t_threshold: 3 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.71%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 24.07%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.35%.\n",
            "********* t_threshold: 3 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.62%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 24.07%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.5%.\n",
            "********* t_threshold: 3 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.53%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.94%.\n",
            "********* t_threshold: 3 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 24.16%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.61%.\n",
            "********* t_threshold: 3 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.61%.\n",
            "********* t_threshold: 5 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.33%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.58%.\n",
            "********* t_threshold: 5 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.53%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.96%.\n",
            "********* t_threshold: 5 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.3%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.96%.\n",
            "********* t_threshold: 5 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.23%.\n",
            "********* t_threshold: 5 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.66%.\n",
            "********* t_threshold: 5 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.0%.\n",
            "********* t_threshold: 5 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.18%.\n",
            "********* t_threshold: 5 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.95%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.18%.\n",
            "********* t_threshold: 5 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.18%.\n",
            "********* t_threshold: 10 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.64%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.94%.\n",
            "********* t_threshold: 10 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.24%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.5%.\n",
            "********* t_threshold: 10 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.02%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 20.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.41%.\n",
            "********* t_threshold: 10 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.66%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.76%.\n",
            "********* t_threshold: 10 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.89%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.67%.\n",
            "********* t_threshold: 10 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.16%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.23%.\n",
            "********* t_threshold: 10 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.63%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.67%.\n",
            "********* t_threshold: 10 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.27%.\n",
            "********* t_threshold: 10 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.01%.\n",
            "********* t_threshold: 15 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.05%.\n",
            "********* t_threshold: 15 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.14%.\n",
            "********* t_threshold: 15 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.78%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.33%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.41%.\n",
            "********* t_threshold: 15 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.47%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.5%.\n",
            "********* t_threshold: 15 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.85%.\n",
            "********* t_threshold: 15 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.03%.\n",
            "********* t_threshold: 15 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.18%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.5%.\n",
            "********* t_threshold: 15 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.23%.\n",
            "********* t_threshold: 15 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.95%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.23%.\n",
            "********* t_threshold: 20 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.41%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.29%.\n",
            "********* t_threshold: 20 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.05%.\n",
            "********* t_threshold: 20 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.99%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.14%.\n",
            "********* t_threshold: 20 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.11%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.24%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.76%.\n",
            "********* t_threshold: 20 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.5%.\n",
            "********* t_threshold: 20 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.75%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.32%.\n",
            "********* t_threshold: 20 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.75%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.85%.\n",
            "********* t_threshold: 20 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.66%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.94%.\n",
            "********* t_threshold: 20 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.3%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.03%.\n",
            "********* t_threshold: 25 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.79%.\n",
            "********* t_threshold: 25 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.32%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.61%.\n",
            "********* t_threshold: 25 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.7%.\n",
            "********* t_threshold: 25 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.37%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.05%.\n",
            "********* t_threshold: 25 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.7%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.05%.\n",
            "********* t_threshold: 25 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.54%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.14%.\n",
            "********* t_threshold: 25 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.62%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.05%.\n",
            "********* t_threshold: 25 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.57%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.58%.\n",
            "********* t_threshold: 25 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.41%.\n",
            "********* t_threshold: 30 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.14%.\n",
            "********* t_threshold: 30 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.17%.\n",
            "********* t_threshold: 30 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 48.14%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.35%.\n",
            "********* t_threshold: 30 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.17%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.52%.\n",
            "********* t_threshold: 30 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.3%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.94%.\n",
            "********* t_threshold: 30 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.56%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.79%.\n",
            "********* t_threshold: 30 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.29%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.41%.\n",
            "********* t_threshold: 30 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.58%.\n",
            "********* t_threshold: 30 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 38.85%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.57%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.58%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ysfPisrTn8n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first t_threshold steps, kde , then ce(penalty factor is meaningless here)\n",
        "\n",
        "t_thresholds = [3,5,10,15,20,25,30]\n",
        "bandwidths = [0.4,0.6,0.8,1.,2.,3.,4.,5.,10.]\n",
        "\n",
        "for t_threshold in t_thresholds:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','t_threshold:',t_threshold,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': 1000,'kernel':'gaussian','t_threshold':t_threshold,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': 1000,'kernel':'gaussian','t_threshold':t_threshold,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': 1000,'kernel':'gaussian','t_threshold':t_threshold,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a04f247-bc40-4e12-c0ee-dbbb1e7967dc",
        "id": "D3fLArOwsQRr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* t_threshold: 3 bandwidth: 0.4 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.05%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.58%.\n",
            "********* t_threshold: 3 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.71%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.6%.\n",
            "********* t_threshold: 3 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.5%.\n",
            "********* t_threshold: 3 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.29%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.33%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.97%.\n",
            "********* t_threshold: 3 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.71%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.18%.\n",
            "********* t_threshold: 3 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.62%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.77%.\n",
            "********* t_threshold: 3 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 24.34%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.3%.\n",
            "********* t_threshold: 3 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 23.89%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.21%.\n",
            "********* t_threshold: 3 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.95%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.89%.\n",
            "********* t_threshold: 5 bandwidth: 0.4 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.58%.\n",
            "********* t_threshold: 5 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.24%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.76%.\n",
            "********* t_threshold: 5 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.43%.\n",
            "********* t_threshold: 5 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.53%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 20.97%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.53%.\n",
            "********* t_threshold: 5 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.0%.\n",
            "********* t_threshold: 5 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.3%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.89%.\n",
            "********* t_threshold: 5 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.16%.\n",
            "********* t_threshold: 5 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.57%.\n",
            "********* t_threshold: 5 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 24.51%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.21%.\n",
            "********* t_threshold: 10 bandwidth: 0.4 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.2%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.0%.\n",
            "********* t_threshold: 10 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.53%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.95%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.23%.\n",
            "********* t_threshold: 10 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.81%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.15%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.29%.\n",
            "********* t_threshold: 10 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.76%.\n",
            "********* t_threshold: 10 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.12%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.77%.\n",
            "********* t_threshold: 10 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.54%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.86%.\n",
            "********* t_threshold: 10 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.24%.\n",
            "********* t_threshold: 10 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.48%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.3%.\n",
            "********* t_threshold: 10 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.74%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.84%.\n",
            "********* t_threshold: 15 bandwidth: 0.4 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.44%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.05%.\n",
            "********* t_threshold: 15 bandwidth: 0.6 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.96%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.32%.\n",
            "********* t_threshold: 15 bandwidth: 0.8 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.08%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.42%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.32%.\n",
            "********* t_threshold: 15 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.14%.\n",
            "********* t_threshold: 15 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.27%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.3%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.77%.\n",
            "********* t_threshold: 15 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.35%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.48%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n",
            "********* t_threshold: 15 bandwidth: 4.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.48%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.01%.\n",
            "********* t_threshold: 15 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.19%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.39%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.48%.\n",
            "********* t_threshold: 15 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.83%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.3%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.01%.\n",
            "********* t_threshold: 20 bandwidth: 0.4 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.44%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3KYqW-o_jo56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor,kernel):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Compute CE loss\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y)\n",
        "    #print('ce ',ce)\n",
        "\n",
        "    # Compute KDE loss\n",
        "    kde = KDE(adv_x, benigns, bandwidth,kernel)\n",
        "    #print('kde ',kde)\n",
        "\n",
        "    # Combine the losses with the penalty factor\n",
        "    loss = ce - penalty_factor * kde\n",
        "    #print('loss ',loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gkde(x, y, model,bens, bandwidth, penalty_factor, kernel, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "        initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "\n",
        "    :param x: Feature vector\n",
        "    :param y: Ground truth labels\n",
        "    :param model: Neural network model\n",
        "    :param RBFModel: Gaussian model for KDE\n",
        "    :param insertion_array: Array for insertion operations\n",
        "    :param removal_array: Array for removal operations\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf', 'l2', 'l1')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    #target's class\n",
        "    traget_labels = torch.zeros_like(y.view(-1).long())\n",
        "\n",
        "    # Compute natural loss and penalty_factor\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), traget_labels)\n",
        "\n",
        "\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    for t in range(k):\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde(x_var,traget_labels,model,bens, bandwidth, decayed_penalty_factor, kernel)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "        elif norm == 'l1':\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1', 'l2', or 'linf' norm.\")\n",
        "\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    if random:\n",
        "        round_threshold = torch.rand_like(x_next)\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_adv = criterion(model(x_next), traget_labels).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size(0) * 100:.3f}%.\")\n",
        "\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "JACMzQSN0xDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "penalty_factors = [1.,10,100,1000,1e4,1e5,1e6,1e7,1e8]\n",
        "bandwidths = [1.,2.,3.,5.,10.,15.,20.,30.,40.]\n",
        "\n",
        "for penalty_factor in penalty_factors:\n",
        "  for bandwidth in bandwidths:\n",
        "    print('*********','penalty_factor:',penalty_factor,'bandwidth:',bandwidth,'******************')\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n",
        "\n",
        "    attack_params =  {'bandwidth': bandwidth,'penalty_factor': penalty_factor,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "    adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669663f6-ccc8-4d93-b0b9-07519f4bba98",
        "id": "zFKmvfGc0xDn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* penalty_factor: 1.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.21%.\n",
            "********* penalty_factor: 100 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.21%.\n",
            "********* penalty_factor: 100 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.12%.\n",
            "********* penalty_factor: 100 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.12%.\n",
            "********* penalty_factor: 100 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.56%.\n",
            "********* penalty_factor: 1000 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.74%.\n",
            "********* penalty_factor: 1000 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.12%.\n",
            "********* penalty_factor: 1000 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.21%.\n",
            "********* penalty_factor: 1000 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.47%.\n",
            "********* penalty_factor: 1000 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.12%.\n",
            "********* penalty_factor: 1000 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.77%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.5%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.19%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.67%.\n",
            "********* penalty_factor: 10000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.59%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.95%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.27%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.68%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.74%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.5%.\n",
            "********* penalty_factor: 100000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.65%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.86%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.59%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.04%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.06%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.95%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.21%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.5%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.57%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.74%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 23.01%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.01%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.91%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 23.19%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.63%.\n",
            "********* penalty_factor: 1000000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.0%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 23.1%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.53%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.86%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.69%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.04%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.31%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.4%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.34%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.01%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.51%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.93%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.0%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.58%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.9%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.29%.\n",
            "********* penalty_factor: 10000000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.46%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.26%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.8%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 1.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 2.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.86%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.86%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 3.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.21%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.83%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 5.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.95%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 27.17%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.72%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 10.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.36%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.7%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 15.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 37.88%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 45.31%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.09%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 20.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.37%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 47.26%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 50.09%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 30.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.73%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 46.46%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.91%.\n",
            "********* penalty_factor: 100000000.0 bandwidth: 40.0 ******************\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.71%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 43.63%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 49.82%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vf0vRQQJ7zQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XoeGnFXncAWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jCxuv-BJ7zMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EozIUaOB7zH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5fWQGqXxb04J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "82Gwm8Epb0zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FAuqOEgCb0u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_done(x, y, model):\n",
        "    # Get the model's predictions\n",
        "    outputs = model(x)\n",
        "\n",
        "    # Use argmax to get the predicted class indices\n",
        "    predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    # Ensure y is in the same shape as predicted for comparison\n",
        "    y = y.view_as(predicted)\n",
        "\n",
        "    # Determine if the predictions are incorrect\n",
        "    done = (predicted != y).bool()\n",
        "\n",
        "    return done\n",
        "\n",
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_ce,penalty_kde):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Compute CE loss\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y)\n",
        "    #print('ce ',ce)\n",
        "\n",
        "    # Compute KDE loss\n",
        "    kde = KDE(adv_x, benigns, bandwidth)\n",
        "    #print('kde ',kde)\n",
        "\n",
        "    # Combine the losses with the penalty factor\n",
        "    loss = (penalty_ce * ce) - (penalty_kde * kde)\n",
        "    #print('loss ',loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gkde(x, y, model,benigns, bandwidth, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "        initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "\n",
        "    :param x: Feature vector\n",
        "    :param y: Ground truth labels\n",
        "    :param model: Neural network model\n",
        "    :param RBFModel: Gaussian model for KDE\n",
        "    :param insertion_array: Array for insertion operations\n",
        "    :param removal_array: Array for removal operations\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf', 'l2', 'l1')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    #target's class\n",
        "    traget_labels = torch.zeros_like(y.view(-1).long())\n",
        "\n",
        "    # Compute natural loss and penalty_factor\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), traget_labels)\n",
        "    kde = KDE(x, benigns, bandwidth)\n",
        "    #penalty_factor = 0.\n",
        "    penalty_factor = 1000.\n",
        "    #print(penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    for t in range(k):\n",
        "        print('*************** t ',t)\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "\n",
        "        if t < 0:\n",
        "          penalty_ce=0.\n",
        "          penalty_kde=1.\n",
        "        else:\n",
        "          penalty_ce=1.\n",
        "          penalty_kde=0.\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "        outputs = model(x_var)\n",
        "        ce_loss = criterion(outputs, traget_labels)\n",
        "        print('ce_loss: ', ce_loss)\n",
        "        kde_loss = KDE(x_var, benigns, bandwidth)\n",
        "        print('kde_loss: ', kde_loss)\n",
        "        ce_grad = torch.autograd.grad(ce_loss.mean(), x_var, retain_graph=True)[0].data\n",
        "        kde_grad = torch.autograd.grad(kde_loss.mean(), x_var)[0].data\n",
        "        print('ce_grad ',torch.abs(ce_grad).sum(dim=-1).detach())\n",
        "        print('kde_grad ',torch.abs(kde_grad).sum(dim=-1).detach())\n",
        "        #impact = torch.abs(ce_grad).sum(dim=-1).detach()/((torch.abs(kde_grad).sum(dim=-1).detach()+ 1e-20)*decayed_penalty_factor)\n",
        "        #print('impact ',impact)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde(x_var,traget_labels,model,benigns, bandwidth, penalty_ce,penalty_kde)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "        elif norm == 'l1':\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1', 'l2', or 'linf' norm.\")\n",
        "\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    if random:\n",
        "        round_threshold = torch.rand_like(x_next)\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, traget_labels).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size(0) * 100:.3f}%.\")\n",
        "\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "2ev1D6s4_Pd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xk6qj8cVhQjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv = gkde(mals.to(torch.float32).to(device), mals_y.to(device), model_AT_rFGSM, top_500_high_confidence_benign_samples,0.6, insertion_array, removal_array, k=100, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903f450c-1f74-4e1e-a25a-a929b4e064e3",
        "id": "yhZTLatx_XpG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************** t  0\n",
            "ce_loss:  tensor([4.1028e+01, 8.6630e+01, 5.8158e+01, 1.8685e+02, 8.6630e+01, 3.6857e+01,\n",
            "        1.5623e+02, 9.2854e+00, 1.8450e+02, 1.0696e+02, 4.1028e+01, 1.2040e-05,\n",
            "        8.6630e+01, 3.8186e+01, 9.1592e+01, 7.5509e+01, 1.2146e+02, 2.8487e+01,\n",
            "        6.3303e+01, 9.9407e+01, 1.4897e+02, 1.9638e+01, 8.6630e+01, 4.9636e+01,\n",
            "        3.4985e+01, 2.0074e+01, 7.7117e+01, 7.5509e+01, 3.8682e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.3344e-05, 2.2177e-10, 1.1448e-15, 0.0000e+00, 2.2177e-10, 3.4137e-18,\n",
            "        1.3935e-26, 6.6971e-06, 1.2336e-39, 1.8229e-36, 1.3344e-05, 5.0246e-11,\n",
            "        2.2177e-10, 5.7728e-08, 3.5037e-15, 4.1197e-12, 1.2445e-38, 3.1590e-40,\n",
            "        8.5677e-20, 2.3542e-38, 7.7047e-27, 2.7702e-10, 2.2177e-10, 4.0407e-39,\n",
            "        1.8901e-17, 1.1674e-15, 2.3014e-07, 4.1197e-12, 7.4781e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.3942e+03, 1.3407e+03, 1.3507e+03, 1.2429e+03, 1.3407e+03, 7.8172e+02,\n",
            "        1.2200e+03, 9.4292e+02, 1.2026e+03, 1.2645e+03, 1.3942e+03, 6.4590e-03,\n",
            "        1.3407e+03, 1.3017e+03, 1.4305e+03, 1.3018e+03, 1.1824e+03, 1.0715e+03,\n",
            "        1.1564e+03, 1.3125e+03, 1.2340e+03, 9.9203e+02, 1.3407e+03, 1.3957e+03,\n",
            "        1.1575e+03, 8.7805e+02, 1.1554e+03, 1.3018e+03, 1.4009e+03])\n",
            "kde_grad  tensor([1.1016e-05, 3.5169e-10, 2.7524e-15, 0.0000e+00, 3.5169e-10, 9.5880e-18,\n",
            "        5.7000e-26, 5.5288e-06, 7.5966e-39, 1.0206e-35, 1.1016e-05, 7.7543e-11,\n",
            "        3.5169e-10, 6.9480e-08, 7.9209e-15, 7.6794e-12, 7.4443e-38, 1.9407e-39,\n",
            "        2.6343e-19, 1.4114e-37, 3.1644e-26, 4.2795e-10, 3.5169e-10, 2.4811e-38,\n",
            "        5.0840e-17, 2.8093e-15, 2.5477e-07, 7.6794e-12, 2.9783e-03])\n",
            "*************** t  1\n",
            "ce_loss:  tensor([3.8942e+01, 8.1252e+01, 5.4561e+01, 1.8050e+02, 8.1252e+01, 3.0279e+01,\n",
            "        1.4982e+02, 6.5895e+00, 1.7741e+02, 1.0231e+02, 3.8942e+01, 7.0333e-06,\n",
            "        8.1252e+01, 3.4357e+01, 8.6054e+01, 7.0332e+01, 1.1706e+02, 2.4853e+01,\n",
            "        6.0047e+01, 9.3228e+01, 1.4309e+02, 1.7637e+01, 8.1252e+01, 4.6975e+01,\n",
            "        3.3508e+01, 1.7785e+01, 6.9806e+01, 7.0332e+01, 3.4755e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.5660e-05, 3.2444e-10, 1.5661e-15, 0.0000e+00, 3.2444e-10, 5.1213e-18,\n",
            "        2.2153e-26, 6.9365e-06, 3.6995e-39, 7.1828e-36, 1.5660e-05, 6.2833e-11,\n",
            "        3.2444e-10, 7.0069e-08, 4.8779e-15, 5.5370e-12, 5.8609e-38, 1.0459e-39,\n",
            "        1.2037e-19, 4.9772e-38, 1.4259e-26, 3.8639e-10, 3.2444e-10, 1.0220e-38,\n",
            "        2.9978e-17, 1.9726e-15, 2.5856e-07, 5.5370e-12, 7.7962e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.4235e+03, 1.1891e+03, 1.2828e+03, 1.2429e+03, 1.1891e+03, 8.8962e+02,\n",
            "        1.2158e+03, 8.5064e+02, 1.2023e+03, 1.2581e+03, 1.4235e+03, 4.3795e-03,\n",
            "        1.1891e+03, 1.2688e+03, 1.4089e+03, 1.2241e+03, 1.1694e+03, 9.9104e+02,\n",
            "        1.1572e+03, 1.2542e+03, 1.2211e+03, 9.9454e+02, 1.1891e+03, 1.3907e+03,\n",
            "        1.1575e+03, 8.7594e+02, 1.1346e+03, 1.2241e+03, 1.2715e+03])\n",
            "kde_grad  tensor([1.6048e-05, 6.3709e-10, 4.4255e-15, 0.0000e+00, 6.3709e-10, 1.7750e-17,\n",
            "        1.0096e-25, 7.5412e-06, 2.4350e-38, 4.2229e-35, 1.6048e-05, 1.0843e-10,\n",
            "        6.3709e-10, 1.0338e-07, 1.2788e-14, 1.2031e-11, 3.6555e-37, 6.7766e-39,\n",
            "        4.0963e-19, 3.2174e-37, 6.4057e-26, 6.6659e-10, 6.3709e-10, 6.4594e-38,\n",
            "        8.3610e-17, 5.2475e-15, 4.2515e-07, 1.2031e-11, 4.9721e-03])\n",
            "*************** t  2\n",
            "ce_loss:  tensor([3.6831e+01, 7.5129e+01, 5.0083e+01, 1.7474e+02, 7.5129e+01, 2.5249e+01,\n",
            "        1.4335e+02, 4.5964e+00, 1.7031e+02, 9.7716e+01, 3.6831e+01, 3.3379e-06,\n",
            "        7.5129e+01, 3.0199e+01, 8.0268e+01, 6.5271e+01, 1.1249e+02, 2.1447e+01,\n",
            "        5.6916e+01, 8.7844e+01, 1.3668e+02, 1.5970e+01, 7.5129e+01, 4.4444e+01,\n",
            "        3.1907e+01, 1.5580e+01, 6.2213e+01, 6.5271e+01, 3.0030e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.8970e-05, 3.8361e-10, 2.0089e-15, 0.0000e+00, 3.8361e-10, 5.7168e-18,\n",
            "        2.6224e-26, 6.5493e-06, 8.1165e-39, 2.0340e-35, 1.8970e-05, 7.2512e-11,\n",
            "        3.8361e-10, 6.9996e-08, 5.4021e-15, 5.9843e-12, 2.2279e-37, 2.1919e-39,\n",
            "        1.3901e-19, 8.4430e-38, 2.0278e-26, 4.7897e-10, 3.8361e-10, 2.1283e-38,\n",
            "        4.3941e-17, 2.5209e-15, 2.0912e-07, 5.9843e-12, 6.7758e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.2642e+03, 1.2799e+03, 1.2845e+03, 1.1585e+03, 1.2799e+03, 7.9543e+02,\n",
            "        1.2113e+03, 7.0616e+02, 1.2023e+03, 1.2581e+03, 1.2642e+03, 1.8475e-03,\n",
            "        1.2799e+03, 1.2114e+03, 1.4061e+03, 1.3432e+03, 1.1632e+03, 9.8969e+02,\n",
            "        1.1525e+03, 1.2595e+03, 1.2044e+03, 8.4584e+02, 1.2799e+03, 1.3203e+03,\n",
            "        1.1159e+03, 8.7464e+02, 1.1262e+03, 1.3432e+03, 1.2023e+03])\n",
            "kde_grad  tensor([2.0599e-05, 9.0564e-10, 6.0731e-15, 0.0000e+00, 9.0564e-10, 2.2511e-17,\n",
            "        1.3190e-25, 8.3880e-06, 5.6871e-38, 1.2557e-34, 2.0599e-05, 1.2869e-10,\n",
            "        9.0564e-10, 1.2878e-07, 1.6222e-14, 1.5340e-11, 1.4500e-36, 1.4372e-38,\n",
            "        5.1593e-19, 5.6705e-37, 9.9912e-26, 9.0794e-10, 9.0564e-10, 1.3852e-37,\n",
            "        1.2702e-16, 7.3776e-15, 4.6555e-07, 1.5340e-11, 6.7630e-03])\n",
            "*************** t  3\n",
            "ce_loss:  tensor([3.4081e+01, 6.8012e+01, 4.6156e+01, 1.6872e+02, 6.8012e+01, 2.1276e+01,\n",
            "        1.3708e+02, 3.6530e+00, 1.6330e+02, 9.2996e+01, 3.4081e+01, 2.0266e-06,\n",
            "        6.8012e+01, 2.5733e+01, 7.4219e+01, 5.9230e+01, 1.0791e+02, 1.8765e+01,\n",
            "        5.3867e+01, 8.3245e+01, 1.3027e+02, 1.3951e+01, 6.8012e+01, 4.1988e+01,\n",
            "        3.0173e+01, 1.3419e+01, 5.5127e+01, 5.9230e+01, 2.5242e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.1560e-05, 3.5571e-10, 2.0376e-15, 0.0000e+00, 3.5571e-10, 7.6090e-18,\n",
            "        2.2872e-26, 5.4613e-06, 1.3032e-38, 4.8171e-35, 2.1560e-05, 8.0726e-11,\n",
            "        3.5571e-10, 5.6350e-08, 4.7640e-15, 5.8324e-12, 6.6298e-37, 5.0324e-39,\n",
            "        1.4140e-19, 1.1735e-37, 2.1743e-26, 5.5507e-10, 3.5571e-10, 5.0171e-38,\n",
            "        5.8801e-17, 2.9546e-15, 1.2476e-07, 5.8324e-12, 4.7858e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.2262e+03, 1.1430e+03, 1.2363e+03, 1.1391e+03, 1.1430e+03, 6.7484e+02,\n",
            "        1.2203e+03, 4.4335e+02, 1.2074e+03, 1.2105e+03, 1.2262e+03, 1.3085e-03,\n",
            "        1.1430e+03, 1.2015e+03, 1.3810e+03, 1.1497e+03, 1.1637e+03, 1.0415e+03,\n",
            "        1.1493e+03, 1.2594e+03, 1.1900e+03, 8.2509e+02, 1.1430e+03, 1.3149e+03,\n",
            "        1.1249e+03, 8.5550e+02, 1.1258e+03, 1.1497e+03, 1.0951e+03])\n",
            "kde_grad  tensor([2.5107e-05, 1.0024e-09, 6.8154e-15, 0.0000e+00, 1.0024e-09, 3.1044e-17,\n",
            "        1.2613e-25, 8.3866e-06, 9.6872e-38, 3.1183e-34, 2.5107e-05, 1.5260e-10,\n",
            "        1.0024e-09, 1.2631e-07, 1.6122e-14, 1.7022e-11, 4.5136e-36, 3.3983e-38,\n",
            "        5.6092e-19, 8.2741e-37, 1.1727e-25, 1.1456e-09, 1.0024e-09, 3.3123e-37,\n",
            "        1.7842e-16, 9.3816e-15, 3.4894e-07, 1.7022e-11, 6.7391e-03])\n",
            "*************** t  4\n",
            "ce_loss:  tensor([3.1758e+01, 6.0436e+01, 4.2251e+01, 1.6281e+02, 6.0436e+01, 1.7927e+01,\n",
            "        1.3122e+02, 3.9063e+00, 1.5689e+02, 8.8479e+01, 3.1758e+01, 1.1921e-06,\n",
            "        6.0436e+01, 2.1159e+01, 6.9034e+01, 5.2443e+01, 1.0354e+02, 1.6370e+01,\n",
            "        5.0637e+01, 7.8845e+01, 1.2464e+02, 1.2020e+01, 6.0436e+01, 3.9746e+01,\n",
            "        2.8391e+01, 1.1675e+01, 4.8368e+01, 5.2443e+01, 2.1526e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.2101e-05, 2.5335e-10, 1.8091e-15, 0.0000e+00, 2.5335e-10, 1.0246e-17,\n",
            "        1.7469e-26, 7.3345e-06, 1.6811e-38, 1.0668e-34, 2.2101e-05, 8.9382e-11,\n",
            "        2.5335e-10, 3.5224e-08, 3.2485e-15, 4.1125e-12, 1.5588e-36, 8.9929e-39,\n",
            "        1.1511e-19, 1.2433e-37, 2.2122e-26, 5.4535e-10, 2.5335e-10, 1.0030e-37,\n",
            "        7.3290e-17, 2.8866e-15, 5.7150e-08, 4.1125e-12, 2.7683e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.1986e+03, 1.2834e+03, 1.2258e+03, 1.1587e+03, 1.2834e+03, 7.4568e+02,\n",
            "        1.2207e+03, 6.4405e+02, 1.2111e+03, 1.1973e+03, 1.1986e+03, 5.9551e-04,\n",
            "        1.2834e+03, 1.0688e+03, 1.1926e+03, 1.2778e+03, 1.1444e+03, 1.0018e+03,\n",
            "        1.1299e+03, 1.2392e+03, 1.1948e+03, 7.6280e+02, 1.2834e+03, 1.3604e+03,\n",
            "        1.1049e+03, 7.2072e+02, 1.1145e+03, 1.2778e+03, 9.1803e+02])\n",
            "kde_grad  tensor([2.8826e-05, 8.2465e-10, 6.6258e-15, 0.0000e+00, 8.2465e-10, 4.1526e-17,\n",
            "        1.0283e-25, 9.6973e-06, 1.3132e-37, 7.2300e-34, 2.8826e-05, 1.7147e-10,\n",
            "        8.2465e-10, 9.3373e-08, 1.2338e-14, 1.3800e-11, 1.1062e-35, 6.1873e-38,\n",
            "        4.8866e-19, 9.2089e-37, 1.2704e-25, 1.2289e-09, 8.2465e-10, 6.7313e-37,\n",
            "        2.3179e-16, 9.9289e-15, 1.8743e-07, 1.3800e-11, 4.9864e-03])\n",
            "*************** t  5\n",
            "ce_loss:  tensor([2.9562e+01, 5.4125e+01, 3.8365e+01, 1.5739e+02, 5.4125e+01, 1.6181e+01,\n",
            "        1.2538e+02, 2.2660e+00, 1.5047e+02, 8.4070e+01, 2.9562e+01, 8.3446e-07,\n",
            "        5.4125e+01, 1.7857e+01, 6.3195e+01, 4.6690e+01, 9.9030e+01, 1.4972e+01,\n",
            "        4.7197e+01, 7.4499e+01, 1.1906e+02, 1.0320e+01, 5.4125e+01, 3.8128e+01,\n",
            "        2.6527e+01, 9.6715e+00, 4.4028e+01, 4.6690e+01, 1.8972e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.0536e-05, 1.3940e-10, 1.3233e-15, 0.0000e+00, 1.3940e-10, 7.8138e-18,\n",
            "        9.8363e-27, 6.2661e-06, 1.7344e-38, 2.0068e-34, 2.0536e-05, 9.1764e-11,\n",
            "        1.3940e-10, 2.4464e-08, 2.1643e-15, 2.5068e-12, 3.3104e-36, 1.7560e-38,\n",
            "        8.3941e-20, 1.3680e-37, 1.7296e-26, 4.8314e-10, 1.3940e-10, 1.5532e-37,\n",
            "        8.0618e-17, 3.1185e-15, 1.9438e-08, 2.5068e-12, 2.5865e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.3251e+03, 9.6291e+02, 1.2236e+03, 1.1391e+03, 9.6291e+02, 6.3379e+02,\n",
            "        1.2206e+03, 3.5627e+02, 1.2114e+03, 1.1145e+03, 1.3251e+03, 5.7977e-04,\n",
            "        9.6291e+02, 8.8006e+02, 1.3182e+03, 1.1284e+03, 1.1207e+03, 7.7541e+02,\n",
            "        1.1289e+03, 1.2345e+03, 1.1949e+03, 8.0959e+02, 9.6291e+02, 1.2840e+03,\n",
            "        1.1304e+03, 5.8165e+02, 1.0450e+03, 1.1284e+03, 1.0401e+03])\n",
            "kde_grad  tensor([2.9695e-05, 5.1541e-10, 5.2547e-15, 0.0000e+00, 5.1541e-10, 3.4368e-17,\n",
            "        6.1609e-26, 9.2616e-06, 1.4148e-37, 1.4152e-33, 2.9695e-05, 1.8486e-10,\n",
            "        5.1541e-10, 7.1726e-08, 9.0654e-15, 9.4632e-12, 2.4250e-35, 1.2198e-37,\n",
            "        3.8444e-19, 1.0537e-36, 1.0517e-25, 1.1941e-09, 5.1541e-10, 1.0697e-36,\n",
            "        2.6856e-16, 1.1327e-14, 7.3284e-08, 9.4632e-12, 4.7594e-03])\n",
            "*************** t  6\n",
            "ce_loss:  tensor([2.8109e+01, 4.8596e+01, 3.4752e+01, 1.5182e+02, 4.8596e+01, 1.3492e+01,\n",
            "        1.1958e+02, 2.8596e+00, 1.4409e+02, 7.9969e+01, 2.8109e+01, 4.7684e-07,\n",
            "        4.8596e+01, 1.7770e+01, 5.7903e+01, 4.0158e+01, 9.4331e+01, 1.2748e+01,\n",
            "        4.3888e+01, 7.0171e+01, 1.1359e+02, 8.8632e+00, 4.8596e+01, 3.6127e+01,\n",
            "        2.4837e+01, 9.4074e+00, 3.9564e+01, 4.0158e+01, 1.8475e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.0231e-05, 1.0158e-10, 7.7744e-16, 0.0000e+00, 1.0158e-10, 9.3283e-18,\n",
            "        4.1493e-27, 7.5743e-06, 1.3102e-38, 4.6153e-34, 2.0231e-05, 1.0265e-10,\n",
            "        1.0158e-10, 1.6464e-08, 1.0008e-15, 1.0983e-12, 5.7929e-36, 5.1872e-38,\n",
            "        4.8253e-20, 1.1814e-37, 1.0012e-26, 3.9555e-10, 1.0158e-10, 2.8090e-37,\n",
            "        8.0780e-17, 4.2774e-15, 1.0306e-08, 1.0983e-12, 1.1931e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.1728e+03, 1.0439e+03, 9.5696e+02, 1.1383e+03, 1.0439e+03, 6.6418e+02,\n",
            "        1.2114e+03, 6.7632e+02, 1.2108e+03, 1.1907e+03, 1.1728e+03, 2.7965e-04,\n",
            "        1.0439e+03, 7.3513e+02, 1.1414e+03, 1.0571e+03, 1.1207e+03, 9.6902e+02,\n",
            "        1.1182e+03, 1.2168e+03, 1.1957e+03, 7.3423e+02, 1.0439e+03, 1.1936e+03,\n",
            "        1.1672e+03, 7.0540e+02, 9.8124e+02, 1.0571e+03, 6.8150e+02])\n",
            "kde_grad  tensor([3.1615e-05, 3.9951e-10, 3.3282e-15, 0.0000e+00, 3.9951e-10, 4.1121e-17,\n",
            "        2.7586e-26, 1.0275e-05, 1.1135e-37, 3.3253e-33, 3.1615e-05, 2.0839e-10,\n",
            "        3.9951e-10, 5.2992e-08, 4.5778e-15, 4.6087e-12, 4.4052e-35, 3.6045e-37,\n",
            "        2.3732e-19, 9.4435e-37, 6.4561e-26, 1.0443e-09, 3.9951e-10, 1.9481e-36,\n",
            "        2.7994e-16, 1.4869e-14, 4.1453e-08, 4.6087e-12, 2.6577e-03])\n",
            "*************** t  7\n",
            "ce_loss:  tensor([2.5491e+01, 4.4087e+01, 3.3239e+01, 1.4629e+02, 4.4087e+01, 1.1476e+01,\n",
            "        1.1361e+02, 2.0232e+00, 1.3775e+02, 7.6312e+01, 2.5491e+01, 2.3842e-07,\n",
            "        4.4087e+01, 1.5543e+01, 5.3609e+01, 3.5886e+01, 8.9677e+01, 1.1759e+01,\n",
            "        4.0825e+01, 6.6155e+01, 1.0816e+02, 7.5149e+00, 4.4087e+01, 3.4263e+01,\n",
            "        2.3218e+01, 7.5782e+00, 3.6068e+01, 3.5886e+01, 1.6438e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.7213e-05, 5.1548e-11, 9.3912e-16, 0.0000e+00, 5.1548e-11, 9.0561e-18,\n",
            "        1.4918e-27, 6.0417e-06, 7.4976e-39, 5.6524e-34, 1.7213e-05, 1.0776e-10,\n",
            "        5.1548e-11, 2.2905e-08, 4.9293e-16, 5.9008e-13, 7.7354e-36, 7.2068e-38,\n",
            "        2.2751e-20, 9.2832e-38, 4.3627e-27, 3.7771e-10, 5.1548e-11, 4.9585e-37,\n",
            "        7.2501e-17, 4.0019e-15, 5.5976e-09, 5.9008e-13, 1.6206e-03],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.1640e+03, 9.4678e+02, 1.1794e+03, 1.1380e+03, 9.4678e+02, 5.7614e+02,\n",
            "        1.1916e+03, 3.9579e+02, 1.2111e+03, 1.1145e+03, 1.1640e+03, 1.6841e-04,\n",
            "        9.4678e+02, 7.7480e+02, 1.2153e+03, 9.6550e+02, 1.1193e+03, 6.9310e+02,\n",
            "        1.0793e+03, 1.2103e+03, 1.1957e+03, 5.6374e+02, 9.4678e+02, 1.1461e+03,\n",
            "        1.0733e+03, 6.5530e+02, 8.8868e+02, 9.6550e+02, 9.0574e+02])\n",
            "kde_grad  tensor([2.8054e-05, 2.1860e-10, 4.0670e-15, 0.0000e+00, 2.1860e-10, 4.0348e-17,\n",
            "        1.0561e-26, 9.4462e-06, 6.6404e-38, 4.2192e-33, 2.8054e-05, 2.2407e-10,\n",
            "        2.1860e-10, 6.9722e-08, 2.3976e-15, 2.6533e-12, 6.1040e-35, 5.0625e-37,\n",
            "        1.1904e-19, 7.6404e-37, 2.9880e-26, 1.0378e-09, 2.1860e-10, 3.4723e-36,\n",
            "        2.6574e-16, 1.4525e-14, 2.3426e-08, 2.6533e-12, 3.3801e-03])\n",
            "*************** t  8\n",
            "ce_loss:  tensor([2.3212e+01, 3.9352e+01, 3.0879e+01, 1.4076e+02, 3.9352e+01, 1.0441e+01,\n",
            "        1.0791e+02, 1.9333e+00, 1.3175e+02, 7.2063e+01, 2.3212e+01, 2.3842e-07,\n",
            "        3.9352e+01, 1.6461e+01, 5.0377e+01, 3.2789e+01, 8.5046e+01, 9.6797e+00,\n",
            "        3.8293e+01, 6.2264e+01, 1.0274e+02, 7.1608e+00, 3.9352e+01, 3.2438e+01,\n",
            "        2.0866e+01, 7.1068e+00, 3.2122e+01, 3.2789e+01, 1.5919e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.2805e-05, 2.4821e-11, 4.7479e-16, 0.0000e+00, 2.4821e-11, 9.8035e-18,\n",
            "        5.4667e-28, 7.0514e-06, 3.1532e-39, 8.7733e-34, 1.2805e-05, 1.1963e-10,\n",
            "        2.4821e-11, 1.7184e-08, 3.1224e-16, 3.4873e-13, 8.1030e-36, 1.9693e-37,\n",
            "        1.0023e-20, 5.7106e-38, 1.4431e-27, 8.3776e-10, 2.4821e-11, 7.4939e-37,\n",
            "        5.7613e-17, 4.1681e-15, 5.7607e-09, 3.4873e-13, 8.7199e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.1518e+03, 9.4206e+02, 9.3987e+02, 1.1380e+03, 9.4206e+02, 4.9388e+02,\n",
            "        1.1900e+03, 4.9764e+02, 1.1916e+03, 1.0144e+03, 1.1518e+03, 1.3267e-04,\n",
            "        9.4206e+02, 7.9255e+02, 1.0062e+03, 9.0969e+02, 1.1171e+03, 7.3961e+02,\n",
            "        9.4230e+02, 1.2056e+03, 1.1957e+03, 7.3282e+02, 9.4206e+02, 1.1390e+03,\n",
            "        1.0498e+03, 6.9032e+02, 8.7272e+02, 9.0969e+02, 6.8076e+02])\n",
            "kde_grad  tensor([2.2856e-05, 1.1112e-10, 2.1807e-15, 0.0000e+00, 1.1112e-10, 4.3327e-17,\n",
            "        4.0594e-27, 9.8756e-06, 2.9068e-38, 6.6897e-33, 2.2856e-05, 2.4872e-10,\n",
            "        1.1112e-10, 5.5517e-08, 1.5637e-15, 1.6263e-12, 6.6201e-35, 1.3849e-36,\n",
            "        5.4864e-20, 4.8408e-37, 1.0468e-26, 2.1213e-09, 1.1112e-10, 5.3050e-36,\n",
            "        2.1929e-16, 1.4845e-14, 2.3780e-08, 1.6263e-12, 2.0150e-03])\n",
            "*************** t  9\n",
            "ce_loss:  tensor([2.1702e+01, 3.5838e+01, 2.8099e+01, 1.3528e+02, 3.5838e+01, 1.0520e+01,\n",
            "        1.0230e+02, 1.1860e+00, 1.2573e+02, 6.8229e+01, 2.1702e+01, 1.1921e-07,\n",
            "        3.5838e+01, 1.3392e+01, 4.6459e+01, 2.9519e+01, 8.0610e+01, 8.0906e+00,\n",
            "        3.6513e+01, 5.9381e+01, 9.8085e+01, 6.1350e+00, 3.5838e+01, 3.0702e+01,\n",
            "        1.8984e+01, 6.2101e+00, 2.9359e+01, 2.9519e+01, 1.3764e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([8.6349e-06, 9.2558e-12, 4.6361e-16, 0.0000e+00, 9.2558e-12, 1.9438e-17,\n",
            "        1.3779e-28, 5.4683e-06, 1.5986e-39, 1.3124e-33, 8.6349e-06, 1.0093e-10,\n",
            "        9.2558e-12, 1.5167e-08, 1.9281e-16, 2.9821e-13, 6.5077e-36, 3.3926e-37,\n",
            "        8.0055e-21, 2.8475e-38, 3.6321e-28, 5.7416e-10, 9.2558e-12, 1.0145e-36,\n",
            "        4.4128e-17, 3.3585e-15, 3.3677e-09, 2.9821e-13, 9.8293e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.0929e+03, 9.4508e+02, 1.0665e+03, 1.1358e+03, 9.4508e+02, 5.7613e+02,\n",
            "        1.1753e+03, 3.1580e+02, 1.1900e+03, 1.0947e+03, 1.0929e+03, 1.0007e-04,\n",
            "        9.4508e+02, 6.8566e+02, 9.0256e+02, 8.9781e+02, 1.1045e+03, 7.4483e+02,\n",
            "        1.0667e+03, 1.1344e+03, 1.0844e+03, 5.5316e+02, 9.4508e+02, 1.2092e+03,\n",
            "        1.0533e+03, 7.0280e+02, 8.8299e+02, 8.9781e+02, 7.8745e+02])\n",
            "kde_grad  tensor([1.6868e-05, 4.3935e-11, 2.1416e-15, 0.0000e+00, 4.3935e-11, 8.6124e-17,\n",
            "        1.0731e-27, 8.6469e-06, 1.5210e-38, 1.0141e-32, 1.6868e-05, 2.1823e-10,\n",
            "        4.3935e-11, 4.8305e-08, 9.8798e-16, 1.3987e-12, 5.5096e-35, 2.3938e-36,\n",
            "        4.4478e-20, 2.4946e-37, 2.7831e-27, 1.5672e-09, 4.3935e-11, 7.2492e-36,\n",
            "        1.7422e-16, 1.2632e-14, 1.4075e-08, 1.3987e-12, 2.1262e-03])\n",
            "*************** t  10\n",
            "ce_loss:  tensor([2.0515e+01, 3.2539e+01, 2.7095e+01, 1.2994e+02, 3.2539e+01, 9.1584e+00,\n",
            "        9.6984e+01, 1.0927e+00, 1.2004e+02, 6.5066e+01, 2.0515e+01, 1.1921e-07,\n",
            "        3.2539e+01, 1.3712e+01, 4.2792e+01, 2.6997e+01, 7.6399e+01, 6.9529e+00,\n",
            "        3.4944e+01, 5.6746e+01, 9.3713e+01, 5.3983e+00, 3.2539e+01, 2.9421e+01,\n",
            "        1.7172e+01, 5.9933e+00, 2.5794e+01, 2.6997e+01, 1.1240e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.0476e-05, 6.5668e-12, 3.0685e-16, 0.0000e+00, 6.5668e-12, 1.8554e-17,\n",
            "        3.1733e-29, 6.0506e-06, 6.2563e-40, 1.3894e-33, 1.0476e-05, 1.3311e-10,\n",
            "        6.5668e-12, 1.1365e-08, 1.3699e-16, 1.6664e-13, 4.6991e-36, 5.2027e-37,\n",
            "        2.2694e-21, 2.6258e-38, 1.5758e-28, 1.2462e-09, 6.5668e-12, 1.2218e-36,\n",
            "        2.9813e-17, 4.2569e-15, 2.2343e-09, 1.6664e-13, 8.5446e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.0442e+03, 8.2512e+02, 9.8790e+02, 1.1257e+03, 8.2512e+02, 4.2787e+02,\n",
            "        1.0984e+03, 4.4903e+02, 1.1105e+03, 9.9787e+02, 1.0442e+03, 7.2240e-05,\n",
            "        8.2512e+02, 7.6757e+02, 9.9164e+02, 8.3129e+02, 1.0882e+03, 6.5855e+02,\n",
            "        8.0754e+02, 9.5469e+02, 1.0079e+03, 6.2732e+02, 8.2512e+02, 1.1390e+03,\n",
            "        1.0265e+03, 6.2579e+02, 8.3849e+02, 8.3129e+02, 6.4887e+02])\n",
            "kde_grad  tensor([2.0543e-05, 3.1848e-11, 1.4638e-15, 0.0000e+00, 3.1848e-11, 8.0110e-17,\n",
            "        2.5684e-28, 8.8442e-06, 6.1288e-39, 1.0930e-32, 2.0543e-05, 2.8039e-10,\n",
            "        3.1848e-11, 3.7605e-08, 7.1196e-16, 7.9738e-13, 4.0942e-35, 3.6696e-36,\n",
            "        1.3033e-20, 2.3435e-37, 1.2512e-27, 3.1494e-09, 3.1848e-11, 8.8701e-36,\n",
            "        1.2239e-16, 1.5281e-14, 9.2440e-09, 7.9738e-13, 1.7698e-03])\n",
            "*************** t  11\n",
            "ce_loss:  tensor([1.8673e+01, 2.9476e+01, 2.4512e+01, 1.2471e+02, 2.9476e+01, 8.7359e+00,\n",
            "        9.2509e+01, 7.7912e-01, 1.1476e+02, 6.1659e+01, 1.8673e+01, 1.1921e-07,\n",
            "        2.9476e+01, 1.1331e+01, 3.9288e+01, 2.3714e+01, 7.2707e+01, 5.6736e+00,\n",
            "        3.2897e+01, 5.3758e+01, 8.9624e+01, 5.0104e+00, 2.9476e+01, 2.7452e+01,\n",
            "        1.5670e+01, 5.1828e+00, 2.4430e+01, 2.3714e+01, 1.2341e+01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([8.6853e-06, 6.5836e-12, 1.9371e-16, 0.0000e+00, 6.5836e-12, 4.0721e-17,\n",
            "        1.3238e-29, 4.5693e-06, 4.4818e-40, 1.4603e-33, 8.6853e-06, 1.1410e-10,\n",
            "        6.5836e-12, 1.0151e-08, 6.0136e-17, 1.3758e-13, 3.0403e-36, 8.8526e-37,\n",
            "        3.0239e-21, 3.7140e-38, 1.1006e-28, 9.6796e-10, 6.5836e-12, 1.2623e-36,\n",
            "        1.8949e-17, 3.2929e-15, 1.8887e-09, 1.3758e-13, 6.3198e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([9.6082e+02, 8.9087e+02, 9.1132e+02, 1.1257e+03, 8.9087e+02, 6.4281e+02,\n",
            "        1.1621e+03, 2.4063e+02, 1.1695e+03, 1.0691e+03, 9.6082e+02, 6.1220e-05,\n",
            "        8.9087e+02, 5.5965e+02, 8.9014e+02, 8.1971e+02, 9.9880e+02, 4.6207e+02,\n",
            "        8.8999e+02, 1.0212e+03, 1.0751e+03, 6.4662e+02, 8.9087e+02, 1.1382e+03,\n",
            "        8.8992e+02, 4.8902e+02, 6.2374e+02, 8.1971e+02, 8.5318e+02])\n",
            "kde_grad  tensor([1.7197e-05, 3.1581e-11, 9.4333e-16, 0.0000e+00, 3.1581e-11, 1.7098e-16,\n",
            "        1.0990e-28, 7.3648e-06, 4.4717e-39, 1.1628e-32, 1.7197e-05, 2.4722e-10,\n",
            "        3.1581e-11, 3.2789e-08, 3.2095e-16, 6.5807e-13, 2.7207e-35, 6.2765e-36,\n",
            "        1.7231e-20, 3.3349e-37, 8.9133e-28, 2.6219e-09, 3.1581e-11, 9.2191e-36,\n",
            "        8.0842e-17, 1.2405e-14, 7.7990e-09, 6.5807e-13, 1.4296e-03])\n",
            "*************** t  12\n",
            "ce_loss:  tensor([ 16.9052,  26.9521,  22.1122, 119.4907,  26.9521,   9.5389,  87.7984,\n",
            "          0.5712, 109.7955,  58.7153,  16.9052,  -0.0000,  26.9521,   9.4457,\n",
            "         36.8351,  21.4333,  68.9813,   4.8317,  31.6250,  51.6934,  86.0300,\n",
            "          5.0110,  26.9521,  25.6979,  14.8255,   3.7228,  22.9212,  21.4333,\n",
            "          9.8910], grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.5157e-06, 2.3624e-12, 1.4023e-16, 0.0000e+00, 2.3624e-12, 2.7602e-17,\n",
            "        2.2904e-30, 5.0651e-06, 1.4820e-40, 1.1573e-33, 7.5157e-06, 1.0979e-10,\n",
            "        2.3624e-12, 1.1950e-08, 2.9125e-17, 7.7540e-14, 2.4236e-36, 2.1854e-36,\n",
            "        2.0070e-21, 2.1498e-38, 3.3468e-29, 1.3985e-09, 2.3624e-12, 1.1834e-36,\n",
            "        2.5482e-17, 3.9978e-15, 2.5228e-09, 7.7540e-14, 4.1304e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.0203e+03, 7.5460e+02, 7.6783e+02, 1.1232e+03, 7.5460e+02, 4.4928e+02,\n",
            "        1.0005e+03, 2.7523e+02, 1.0916e+03, 9.8193e+02, 1.0203e+03, 1.5972e-05,\n",
            "        7.5460e+02, 6.1942e+02, 1.0264e+03, 7.3108e+02, 9.8515e+02, 6.6791e+02,\n",
            "        9.3944e+02, 8.7127e+02, 1.0027e+03, 6.4098e+02, 7.5460e+02, 1.1249e+03,\n",
            "        9.8012e+02, 5.9418e+02, 7.1987e+02, 7.3108e+02, 5.9077e+02])\n",
            "kde_grad  tensor([1.5025e-05, 1.1765e-11, 6.7963e-16, 0.0000e+00, 1.1765e-11, 1.2327e-16,\n",
            "        1.9585e-29, 7.6069e-06, 1.5015e-39, 9.4435e-33, 1.5025e-05, 2.3928e-10,\n",
            "        1.1765e-11, 3.7506e-08, 1.5823e-16, 3.7254e-13, 2.2131e-35, 1.5311e-35,\n",
            "        1.1503e-20, 1.9603e-37, 2.7809e-28, 3.7295e-09, 1.1765e-11, 8.7570e-36,\n",
            "        1.0818e-16, 1.4643e-14, 1.0378e-08, 3.7254e-13, 9.0721e-04])\n",
            "*************** t  13\n",
            "ce_loss:  tensor([ 15.6275,  24.2559,  21.0586, 114.3874,  24.2559,   7.5106,  83.3431,\n",
            "          0.2959, 104.4412,  55.6856,  15.6275,  -0.0000,  24.2559,  10.1047,\n",
            "         35.0822,  22.7208,  65.3089,   4.1872,  29.8677,  49.8927,  81.7691,\n",
            "          3.9591,  24.2559,  24.0554,  13.7271,   3.5677,  20.8505,  22.7208,\n",
            "          9.4574], grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.5674e-06, 2.4888e-12, 1.5264e-16, 0.0000e+00, 2.4888e-12, 5.9678e-17,\n",
            "        1.0077e-30, 3.9094e-06, 8.2241e-41, 8.9597e-34, 5.5674e-06, 1.2047e-10,\n",
            "        2.4888e-12, 1.6284e-08, 2.4968e-17, 4.2783e-14, 1.6511e-36, 2.6825e-36,\n",
            "        9.2691e-22, 5.4920e-38, 1.5752e-29, 1.0306e-09, 2.4888e-12, 9.6559e-37,\n",
            "        1.4052e-17, 3.0484e-15, 2.8285e-09, 4.2783e-14, 4.5059e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([9.3787e+02, 8.1686e+02, 1.1167e+03, 1.0999e+03, 8.1686e+02, 5.2061e+02,\n",
            "        9.8945e+02, 1.1687e+02, 1.0916e+03, 8.4361e+02, 9.3787e+02, 1.1051e-05,\n",
            "        8.1686e+02, 7.3551e+02, 8.3521e+02, 7.4850e+02, 9.8515e+02, 4.3163e+02,\n",
            "        8.0754e+02, 9.4747e+02, 9.9164e+02, 6.5593e+02, 8.1686e+02, 1.1093e+03,\n",
            "        8.4162e+02, 4.6770e+02, 7.0574e+02, 7.4850e+02, 8.2674e+02])\n",
            "kde_grad  tensor([1.1620e-05, 1.2295e-11, 7.3269e-16, 0.0000e+00, 1.2295e-11, 2.4887e-16,\n",
            "        8.7708e-30, 6.1659e-06, 8.4606e-40, 7.3789e-33, 1.1620e-05, 2.6080e-10,\n",
            "        1.2295e-11, 4.8599e-08, 1.3672e-16, 2.1925e-13, 1.5333e-35, 1.8874e-35,\n",
            "        5.4035e-21, 4.9504e-37, 1.3325e-28, 2.8083e-09, 1.2295e-11, 7.2553e-36,\n",
            "        6.1536e-17, 1.1598e-14, 1.1158e-08, 2.1925e-13, 9.6169e-04])\n",
            "*************** t  14\n",
            "ce_loss:  tensor([ 13.9412,  22.1502,  19.9077, 109.4547,  22.1502,   8.0429,  79.4912,\n",
            "          0.2646,  99.5865,  53.3168,  13.9412,  -0.0000,  22.1502,  10.0302,\n",
            "         32.4217,  19.5302,  61.7779,   3.0575,  28.1376,  47.1998,  77.6746,\n",
            "          3.6365,  22.1502,  22.7304,  12.6104,   2.1501,  19.9601,  19.5302,\n",
            "          9.7294], grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.1439e-06, 1.7433e-12, 5.5143e-17, 0.0000e+00, 1.7433e-12, 4.9468e-17,\n",
            "        3.6823e-31, 3.7702e-06, 3.4237e-41, 2.3987e-33, 5.1439e-06, 9.5904e-11,\n",
            "        1.7433e-12, 9.9161e-09, 1.2749e-17, 3.9192e-14, 8.6367e-37, 8.1521e-36,\n",
            "        8.5610e-22, 4.8823e-38, 6.1725e-30, 1.6726e-09, 1.7433e-12, 7.6385e-37,\n",
            "        1.7523e-17, 3.5995e-15, 2.2958e-09, 3.9192e-14, 2.4290e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([9.3554e+02, 7.8518e+02, 5.3706e+02, 1.0999e+03, 7.8518e+02, 4.3104e+02,\n",
            "        1.0505e+03, 1.6587e+02, 1.0563e+03, 9.7777e+02, 9.3554e+02, 1.2565e-05,\n",
            "        7.8518e+02, 6.8565e+02, 8.8230e+02, 6.1935e+02, 9.4825e+02, 6.3666e+02,\n",
            "        1.0015e+03, 8.9848e+02, 9.9164e+02, 5.9159e+02, 7.8518e+02, 1.0423e+03,\n",
            "        7.5689e+02, 5.4301e+02, 7.1606e+02, 6.1935e+02, 5.8718e+02])\n",
            "kde_grad  tensor([1.0657e-05, 8.6820e-12, 2.7703e-16, 0.0000e+00, 8.6820e-12, 2.1228e-16,\n",
            "        3.2533e-30, 5.7556e-06, 3.5987e-40, 1.9468e-32, 1.0657e-05, 2.1377e-10,\n",
            "        8.6820e-12, 3.2508e-08, 6.9834e-17, 1.9154e-13, 8.1667e-36, 5.6674e-35,\n",
            "        4.9908e-21, 4.4157e-37, 5.3083e-29, 4.3475e-09, 8.6820e-12, 5.8131e-36,\n",
            "        7.6034e-17, 1.3307e-14, 9.2501e-09, 1.9154e-13, 5.8059e-04])\n",
            "*************** t  15\n",
            "ce_loss:  tensor([ 12.4796,  21.2791,  19.5081, 104.9971,  21.2791,   6.2354,  75.6469,\n",
            "          0.2634,  95.4829,  51.0064,  12.4796,  -0.0000,  21.2791,   9.1169,\n",
            "         30.2688,  18.8886,  58.7304,   3.1739,  27.5141,  45.7008,  74.1980,\n",
            "          2.9821,  21.2791,  22.0608,  14.9367,   2.3869,  17.9671,  18.8886,\n",
            "          8.0184], grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.2348e-06, 8.5598e-13, 1.3578e-16, 0.0000e+00, 8.5598e-13, 9.3441e-17,\n",
            "        7.0917e-32, 2.7196e-06, 1.2514e-41, 1.4156e-33, 4.2348e-06, 1.2981e-10,\n",
            "        8.5598e-13, 9.4406e-09, 1.0728e-17, 3.9246e-14, 5.6956e-37, 8.7475e-36,\n",
            "        2.5507e-22, 9.0462e-38, 1.7802e-30, 1.0965e-09, 8.5598e-13, 8.3105e-37,\n",
            "        2.2088e-17, 2.5046e-15, 2.1596e-09, 3.9246e-14, 2.5754e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([9.3661e+02, 5.1539e+02, 8.8795e+02, 1.0115e+03, 5.1539e+02, 4.8781e+02,\n",
            "        9.8200e+02, 1.1198e+02, 9.8945e+02, 8.2948e+02, 9.3661e+02, 8.8158e-06,\n",
            "        5.1539e+02, 5.2117e+02, 7.4470e+02, 6.8191e+02, 7.9951e+02, 4.2947e+02,\n",
            "        5.6931e+02, 1.0685e+03, 9.9616e+02, 4.2640e+02, 5.1539e+02, 1.1012e+03,\n",
            "        9.3923e+02, 6.2143e+02, 6.1135e+02, 6.8191e+02, 6.2401e+02])\n",
            "kde_grad  tensor([8.8383e-06, 4.3615e-12, 6.6260e-16, 0.0000e+00, 4.3615e-12, 3.8489e-16,\n",
            "        6.4181e-31, 4.5374e-06, 1.3262e-40, 1.1640e-32, 8.8383e-06, 2.8192e-10,\n",
            "        4.3615e-12, 2.9877e-08, 5.8727e-17, 1.9458e-13, 5.4521e-36, 6.1245e-35,\n",
            "        1.5333e-21, 8.1084e-37, 1.5566e-29, 2.9871e-09, 4.3615e-12, 6.3679e-36,\n",
            "        9.8879e-17, 9.6181e-15, 8.4480e-09, 1.9458e-13, 5.7246e-04])\n",
            "*************** t  16\n",
            "ce_loss:  tensor([ 11.0424,  19.6554,  18.4619, 100.4899,  19.6554,   7.3036,  71.8243,\n",
            "          0.1181,  90.6191,  48.3241,  11.0424,  -0.0000,  19.6554,   9.0514,\n",
            "         28.0987,  17.0803,  56.4606,   1.9973,  26.8649,  43.6090,  70.7324,\n",
            "          1.6490,  19.6554,  20.7097,  12.0411,   1.4656,  17.1410,  17.0803,\n",
            "          6.5541], grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.2732e-06, 3.0480e-12, 8.9182e-17, 0.0000e+00, 3.0480e-12, 8.1178e-17,\n",
            "        1.7466e-32, 2.6190e-06, 6.6800e-42, 3.5487e-33, 3.2732e-06, 1.1017e-10,\n",
            "        3.0480e-12, 8.2046e-09, 1.5783e-17, 3.6753e-14, 2.0194e-36, 2.3217e-35,\n",
            "        5.6135e-22, 3.7848e-38, 4.7865e-31, 2.0036e-09, 3.0480e-12, 6.2851e-37,\n",
            "        2.4554e-17, 3.0089e-15, 2.1214e-09, 3.6753e-14, 2.6444e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([9.1255e+02, 6.9634e+02, 7.5842e+02, 1.0042e+03, 6.9634e+02, 4.3089e+02,\n",
            "        8.4524e+02, 6.4399e+01, 9.8945e+02, 9.6379e+02, 9.1255e+02, 6.0479e-06,\n",
            "        6.9634e+02, 7.3722e+02, 8.6526e+02, 6.0276e+02, 9.2785e+02, 3.9700e+02,\n",
            "        7.7444e+02, 8.1604e+02, 9.2367e+02, 3.3894e+02, 6.9634e+02, 9.7081e+02,\n",
            "        7.5689e+02, 4.3769e+02, 6.3809e+02, 6.0276e+02, 4.7619e+02])\n",
            "kde_grad  tensor([6.8937e-06, 1.4905e-11, 4.3428e-16, 0.0000e+00, 1.4905e-11, 3.4445e-16,\n",
            "        1.6037e-31, 4.1233e-06, 6.7226e-41, 2.8809e-32, 6.8937e-06, 2.4270e-10,\n",
            "        1.4905e-11, 2.7479e-08, 8.4739e-17, 1.7659e-13, 1.9089e-35, 1.6092e-34,\n",
            "        3.3062e-21, 3.4388e-37, 4.2689e-30, 5.1016e-09, 1.4905e-11, 4.8378e-36,\n",
            "        1.0692e-16, 1.1219e-14, 8.4498e-09, 1.7659e-13, 5.6085e-04])\n",
            "*************** t  17\n",
            "ce_loss:  tensor([9.7634e+00, 1.8071e+01, 1.9891e+01, 9.7608e+01, 1.8071e+01, 5.0471e+00,\n",
            "        6.8821e+01, 4.3355e-02, 8.6058e+01, 4.6682e+01, 9.7634e+00, -0.0000e+00,\n",
            "        1.8071e+01, 7.5669e+00, 2.6443e+01, 1.7092e+01, 5.3780e+01, 1.2412e+00,\n",
            "        2.4849e+01, 4.1451e+01, 6.7235e+01, 1.3668e+00, 1.8071e+01, 1.9215e+01,\n",
            "        1.3407e+01, 8.3890e-01, 1.6101e+01, 1.7092e+01, 6.0527e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.6840e-06, 2.3270e-12, 9.1585e-17, 0.0000e+00, 2.3270e-12, 1.4139e-16,\n",
            "        2.5736e-32, 1.9352e-06, 2.7690e-42, 1.8196e-33, 2.6840e-06, 9.9970e-11,\n",
            "        2.3270e-12, 6.5307e-09, 6.2643e-18, 5.3939e-14, 8.9073e-37, 3.7610e-35,\n",
            "        5.4865e-22, 6.6769e-38, 2.1266e-31, 3.1841e-09, 2.3270e-12, 5.6177e-37,\n",
            "        2.7105e-17, 2.7090e-15, 2.6781e-09, 5.3939e-14, 3.2090e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([9.2284e+02, 5.5499e+02, 8.1654e+02, 8.6735e+02, 5.5499e+02, 2.8478e+02,\n",
            "        1.1367e+03, 2.1941e+01, 9.3090e+02, 8.2459e+02, 9.2284e+02, 9.8725e-06,\n",
            "        5.5499e+02, 3.6045e+02, 8.8058e+02, 7.4438e+02, 7.9588e+02, 4.0274e+02,\n",
            "        6.5236e+02, 1.0302e+03, 8.3988e+02, 4.3951e+02, 5.5499e+02, 1.1012e+03,\n",
            "        8.7297e+02, 3.8004e+02, 6.2945e+02, 7.4438e+02, 8.5601e+02])\n",
            "kde_grad  tensor([5.6319e-06, 1.1169e-11, 4.6068e-16, 0.0000e+00, 1.1169e-11, 5.7648e-16,\n",
            "        2.3420e-31, 3.1432e-06, 2.9249e-41, 1.4956e-32, 5.6319e-06, 2.2488e-10,\n",
            "        1.1169e-11, 2.0438e-08, 3.4429e-17, 2.5829e-13, 8.4834e-36, 2.5940e-34,\n",
            "        3.2037e-21, 6.0050e-37, 1.9051e-30, 7.7471e-09, 1.1169e-11, 4.3499e-36,\n",
            "        1.2026e-16, 9.8955e-15, 1.0317e-08, 2.5829e-13, 6.5324e-04])\n",
            "*************** t  18\n",
            "ce_loss:  tensor([8.6303e+00, 1.6773e+01, 1.6994e+01, 9.3360e+01, 1.6773e+01, 5.4467e+00,\n",
            "        6.6223e+01, 2.8719e-02, 8.2025e+01, 4.3745e+01, 8.6303e+00, -0.0000e+00,\n",
            "        1.6773e+01, 5.4207e+00, 2.5578e+01, 1.5793e+01, 5.0919e+01, 1.0557e+00,\n",
            "        2.5027e+01, 3.9658e+01, 6.4660e+01, 1.2929e+00, 1.6773e+01, 1.8592e+01,\n",
            "        9.9354e+00, 5.7871e-01, 1.5482e+01, 1.5793e+01, 6.9163e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.0358e-06, 3.1064e-12, 6.7468e-17, 0.0000e+00, 3.1064e-12, 2.5256e-16,\n",
            "        2.3421e-33, 1.6569e-06, 1.7698e-42, 3.2529e-33, 2.0358e-06, 1.3670e-10,\n",
            "        3.1064e-12, 1.0587e-08, 5.0899e-18, 3.0001e-14, 2.1347e-36, 4.4845e-35,\n",
            "        8.4475e-22, 3.0566e-38, 3.7930e-31, 2.2983e-09, 3.1064e-12, 3.5964e-37,\n",
            "        2.7210e-17, 1.9341e-15, 2.9739e-09, 3.0001e-14, 1.4832e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([9.9940e+02, 7.7087e+02, 5.8642e+02, 8.6735e+02, 7.7087e+02, 5.4557e+02,\n",
            "        7.7681e+02, 1.8740e+01, 1.0505e+03, 8.0390e+02, 9.9940e+02, 5.2541e-06,\n",
            "        7.7087e+02, 3.4037e+02, 7.3747e+02, 4.6415e+02, 9.2785e+02, 2.5582e+02,\n",
            "        9.0636e+02, 8.8166e+02, 9.1680e+02, 2.8130e+02, 7.7087e+02, 9.6399e+02,\n",
            "        6.2021e+02, 1.7518e+02, 7.0425e+02, 4.6415e+02, 5.0060e+02])\n",
            "kde_grad  tensor([4.2946e-06, 1.4955e-11, 3.2922e-16, 0.0000e+00, 1.4955e-11, 1.0182e-15,\n",
            "        2.1811e-32, 2.6957e-06, 1.5168e-41, 2.6438e-32, 4.2946e-06, 2.9873e-10,\n",
            "        1.4955e-11, 3.1763e-08, 2.8109e-17, 1.4384e-13, 2.0147e-35, 3.0905e-34,\n",
            "        4.8975e-21, 2.7693e-37, 3.3484e-30, 5.9884e-09, 1.4955e-11, 2.8081e-36,\n",
            "        1.1625e-16, 7.3323e-15, 1.1455e-08, 1.4384e-13, 3.5145e-04])\n",
            "*************** t  19\n",
            "ce_loss:  tensor([8.0194e+00, 1.5918e+01, 1.6716e+01, 9.0029e+01, 1.5918e+01, 5.1999e+00,\n",
            "        6.3207e+01, 1.3397e-02, 7.8904e+01, 4.2088e+01, 8.0194e+00, -0.0000e+00,\n",
            "        1.5918e+01, 5.2852e+00, 2.3160e+01, 1.3436e+01, 4.9448e+01, 5.8847e-01,\n",
            "        2.2852e+01, 3.8102e+01, 6.1725e+01, 6.0106e-01, 1.5918e+01, 1.7096e+01,\n",
            "        9.7839e+00, 2.7849e-01, 1.4665e+01, 1.3436e+01, 4.0853e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.9893e-06, 1.4460e-12, 9.5575e-17, 0.0000e+00, 1.4460e-12, 1.9964e-16,\n",
            "        4.5558e-33, 1.2424e-06, 3.5313e-43, 5.9003e-33, 1.9893e-06, 1.0787e-10,\n",
            "        1.4460e-12, 1.5262e-08, 5.4618e-18, 7.5676e-14, 6.8760e-37, 9.3766e-35,\n",
            "        2.9113e-22, 3.1284e-38, 1.2031e-31, 3.6483e-09, 1.4460e-12, 2.9233e-37,\n",
            "        4.2729e-17, 1.8455e-15, 2.1779e-09, 7.5676e-14, 1.7455e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([7.7763e+02, 4.6570e+02, 6.9197e+02, 1.0042e+03, 4.6570e+02, 3.3762e+02,\n",
            "        9.0854e+02, 5.4355e+00, 7.8269e+02, 9.3574e+02, 7.7763e+02, 6.6268e-06,\n",
            "        4.6570e+02, 1.0209e+03, 7.3286e+02, 6.7813e+02, 5.5751e+02, 1.9747e+02,\n",
            "        7.8300e+02, 9.6779e+02, 8.4256e+02, 2.1717e+02, 4.6570e+02, 9.6399e+02,\n",
            "        9.6249e+02, 1.0560e+02, 5.7376e+02, 6.7813e+02, 5.7528e+02])\n",
            "kde_grad  tensor([4.2191e-06, 6.9416e-12, 4.6414e-16, 0.0000e+00, 6.9416e-12, 8.2758e-16,\n",
            "        4.1958e-32, 2.0277e-06, 1.9772e-42, 4.7326e-32, 4.2191e-06, 2.4219e-10,\n",
            "        6.9416e-12, 4.5534e-08, 2.9452e-17, 3.5096e-13, 6.5591e-36, 6.4112e-34,\n",
            "        1.7035e-21, 2.8494e-37, 1.0711e-30, 8.8278e-09, 6.9416e-12, 2.2953e-36,\n",
            "        1.8034e-16, 6.8328e-15, 8.4255e-09, 3.5096e-13, 3.6974e-04])\n",
            "*************** t  20\n",
            "ce_loss:  tensor([6.5084e+00, 1.4240e+01, 1.4835e+01, 8.6439e+01, 1.4240e+01, 4.0998e+00,\n",
            "        6.0304e+01, 1.1366e-02, 7.5410e+01, 3.9924e+01, 6.5084e+00, -0.0000e+00,\n",
            "        1.4240e+01, 6.4189e+00, 2.1828e+01, 1.3610e+01, 4.7861e+01, 4.0302e-01,\n",
            "        2.2212e+01, 3.6581e+01, 5.9404e+01, 6.7485e-01, 1.4240e+01, 1.5850e+01,\n",
            "        8.6865e+00, 2.5945e-01, 1.2866e+01, 1.3610e+01, 4.4888e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.8296e-06, 4.1643e-12, 8.5173e-17, 0.0000e+00, 4.1643e-12, 4.6201e-16,\n",
            "        1.7676e-33, 1.1320e-06, 1.4027e-42, 3.1230e-33, 1.8296e-06, 1.7143e-10,\n",
            "        4.1643e-12, 7.6276e-09, 3.2419e-18, 5.0746e-14, 6.6765e-36, 1.2883e-34,\n",
            "        2.1649e-22, 1.8538e-38, 1.3000e-31, 2.9838e-09, 4.1643e-12, 2.0776e-37,\n",
            "        2.2764e-17, 1.2899e-15, 2.6134e-09, 5.0746e-14, 1.5867e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([8.1836e+02, 6.7886e+02, 6.4380e+02, 8.6184e+02, 6.7886e+02, 5.0147e+02,\n",
            "        7.7681e+02, 7.0179e+00, 9.1680e+02, 7.4874e+02, 8.1836e+02, 4.1368e-06,\n",
            "        6.7886e+02, 3.6424e+02, 8.1966e+02, 7.2946e+02, 7.9588e+02, 1.1544e+02,\n",
            "        5.7746e+02, 7.8085e+02, 9.6394e+02, 2.8415e+02, 6.7886e+02, 1.0944e+03,\n",
            "        7.5953e+02, 8.2276e+01, 6.3111e+02, 7.2946e+02, 5.0978e+02])\n",
            "kde_grad  tensor([3.7786e-06, 1.9320e-11, 4.0102e-16, 0.0000e+00, 1.9320e-11, 1.8271e-15,\n",
            "        1.6368e-32, 1.8533e-06, 1.0619e-41, 2.5329e-32, 3.7786e-06, 3.7250e-10,\n",
            "        1.9320e-11, 2.5258e-08, 1.7699e-17, 2.3240e-13, 6.2500e-35, 8.8596e-34,\n",
            "        1.2659e-21, 1.6885e-37, 1.1606e-30, 7.6189e-09, 1.9320e-11, 1.6403e-36,\n",
            "        9.8474e-17, 4.9147e-15, 9.9858e-09, 2.3240e-13, 3.3805e-04])\n",
            "*************** t  21\n",
            "ce_loss:  tensor([5.5210e+00, 1.4344e+01, 1.4716e+01, 8.2429e+01, 1.4344e+01, 5.1285e+00,\n",
            "        5.6939e+01, 5.8135e-03, 7.2113e+01, 3.8089e+01, 5.5210e+00, -0.0000e+00,\n",
            "        1.4344e+01, 3.4935e+00, 2.0137e+01, 1.4417e+01, 4.5695e+01, 2.2342e-01,\n",
            "        2.1870e+01, 3.3889e+01, 5.7013e+01, 3.5400e-01, 1.4344e+01, 1.5034e+01,\n",
            "        8.0217e+00, 1.1194e-01, 1.2213e+01, 1.4417e+01, 3.1547e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.2796e-06, 2.5751e-12, 8.9800e-17, 0.0000e+00, 2.5751e-12, 3.1245e-16,\n",
            "        2.2930e-33, 8.3748e-07, 6.6141e-43, 7.6455e-33, 1.2796e-06, 1.2132e-10,\n",
            "        2.5751e-12, 1.0257e-08, 1.8657e-18, 4.5685e-14, 1.0423e-35, 3.8489e-34,\n",
            "        4.5002e-22, 4.1106e-38, 1.9121e-32, 4.0149e-09, 2.5751e-12, 1.1408e-37,\n",
            "        2.3778e-17, 1.2894e-15, 2.5797e-09, 4.5685e-14, 1.2933e-04],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([5.8351e+02, 5.4585e+02, 7.2395e+02, 9.8558e+02, 5.4585e+02, 4.0872e+02,\n",
            "        9.8575e+02, 2.2614e+00, 7.7681e+02, 9.3574e+02, 5.8351e+02, 3.2014e-06,\n",
            "        5.4585e+02, 4.4911e+02, 4.4897e+02, 6.7419e+02, 6.9159e+02, 6.3671e+01,\n",
            "        7.1543e+02, 8.8166e+02, 7.7301e+02, 1.4357e+02, 5.4585e+02, 9.5028e+02,\n",
            "        5.2221e+02, 2.9963e+01, 4.9075e+02, 6.7419e+02, 5.5082e+02])\n",
            "kde_grad  tensor([2.6574e-06, 1.2118e-11, 4.2376e-16, 0.0000e+00, 1.2118e-11, 1.3095e-15,\n",
            "        2.0956e-32, 1.3706e-06, 5.2198e-42, 6.1209e-32, 2.6574e-06, 2.6893e-10,\n",
            "        1.2118e-11, 3.1040e-08, 1.0186e-17, 2.1995e-13, 9.6222e-35, 2.6084e-33,\n",
            "        2.5993e-21, 3.6934e-37, 1.7271e-31, 9.8772e-09, 1.2118e-11, 9.0809e-37,\n",
            "        1.0155e-16, 4.8206e-15, 9.5333e-09, 2.1995e-13, 2.7337e-04])\n",
            "*************** t  22\n",
            "ce_loss:  tensor([4.8999e+00, 1.1966e+01, 1.4026e+01, 7.9643e+01, 1.1966e+01, 2.9334e+00,\n",
            "        5.5441e+01, 1.0813e-02, 6.8557e+01, 3.6389e+01, 4.8999e+00, -0.0000e+00,\n",
            "        1.1966e+01, 4.5327e+00, 1.9675e+01, 1.3335e+01, 4.6571e+01, 1.6399e-01,\n",
            "        2.1412e+01, 3.3621e+01, 5.3585e+01, 3.0417e-01, 1.1966e+01, 1.3578e+01,\n",
            "        7.6932e+00, 8.9878e-02, 1.0275e+01, 1.3335e+01, 5.0685e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.8285e-06, 4.2906e-12, 7.5003e-17, 0.0000e+00, 4.2906e-12, 4.6089e-16,\n",
            "        4.0105e-34, 8.2960e-07, 2.0417e-42, 3.1086e-33, 1.8285e-06, 1.3200e-10,\n",
            "        4.2906e-12, 7.0889e-09, 7.7742e-18, 2.8883e-14, 1.4200e-35, 8.3001e-34,\n",
            "        5.1630e-22, 3.4159e-38, 3.0460e-32, 3.0092e-09, 4.2906e-12, 8.2443e-38,\n",
            "        5.0444e-17, 1.2127e-15, 4.9138e-09, 2.8883e-14, 8.8770e-05],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([7.7275e+02, 5.6785e+02, 6.9206e+02, 8.5373e+02, 5.6785e+02, 2.4191e+02,\n",
            "        7.7681e+02, 8.1499e+00, 1.0565e+03, 7.4089e+02, 7.7275e+02, 3.3978e-06,\n",
            "        5.6785e+02, 5.1657e+02, 8.0321e+02, 5.3912e+02, 7.6275e+02, 5.7678e+01,\n",
            "        7.1146e+02, 8.3481e+02, 8.3426e+02, 9.6314e+01, 5.6785e+02, 9.4090e+02,\n",
            "        9.2292e+02, 3.8661e+01, 5.3356e+02, 5.3912e+02, 6.1163e+02])\n",
            "kde_grad  tensor([3.6886e-06, 1.9582e-11, 3.5185e-16, 0.0000e+00, 1.9582e-11, 1.8415e-15,\n",
            "        3.7308e-33, 1.3932e-06, 2.0739e-41, 2.5200e-32, 3.6886e-06, 2.9221e-10,\n",
            "        1.9582e-11, 2.2901e-08, 4.1084e-17, 1.3504e-13, 1.3306e-34, 5.5966e-33,\n",
            "        2.9243e-21, 3.0911e-37, 2.7177e-31, 7.7155e-09, 1.9582e-11, 6.5815e-37,\n",
            "        2.1138e-16, 4.4726e-15, 1.7595e-08, 1.3504e-13, 2.0569e-04])\n",
            "*************** t  23\n",
            "ce_loss:  tensor([3.9853e+00, 1.2180e+01, 1.5112e+01, 7.5552e+01, 1.2180e+01, 4.1376e+00,\n",
            "        5.2433e+01, 8.1488e-03, 6.6211e+01, 3.3920e+01, 3.9853e+00, -0.0000e+00,\n",
            "        1.2180e+01, 6.3716e+00, 1.8579e+01, 1.0727e+01, 4.2628e+01, 1.5910e-01,\n",
            "        2.2487e+01, 3.4581e+01, 5.1841e+01, 1.2639e-01, 1.2180e+01, 1.2759e+01,\n",
            "        7.6965e+00, 5.5545e-02, 9.1876e+00, 1.0727e+01, 2.4376e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.2295e-06, 3.6705e-12, 8.2787e-17, 0.0000e+00, 3.6705e-12, 8.7444e-16,\n",
            "        4.1425e-34, 5.9338e-07, 3.1669e-43, 6.9690e-33, 1.2295e-06, 1.4759e-10,\n",
            "        3.6705e-12, 4.5820e-09, 2.9832e-18, 3.7101e-14, 2.1275e-35, 7.2055e-34,\n",
            "        3.5244e-22, 3.9902e-38, 9.5511e-33, 4.7491e-09, 3.6705e-12, 5.2009e-38,\n",
            "        2.4901e-17, 1.0758e-15, 4.3838e-09, 3.7101e-14, 5.8501e-05],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([5.2946e+02, 5.4185e+02, 7.5993e+02, 8.5373e+02, 5.4185e+02, 5.7427e+02,\n",
            "        4.8798e+02, 3.4500e+00, 7.7681e+02, 8.7278e+02, 5.2946e+02, 2.5925e-06,\n",
            "        5.4185e+02, 5.8274e+02, 7.2049e+02, 4.5133e+02, 5.4487e+02, 4.2551e+01,\n",
            "        6.8969e+02, 7.8085e+02, 8.3879e+02, 4.1973e+01, 5.4185e+02, 1.1186e+03,\n",
            "        5.2314e+02, 1.8413e+01, 4.1315e+02, 4.5133e+02, 2.6595e+02])\n",
            "kde_grad  tensor([2.4728e-06, 1.6575e-11, 4.0099e-16, 0.0000e+00, 1.6575e-11, 3.4434e-15,\n",
            "        3.8054e-33, 1.0450e-06, 1.9422e-42, 5.5919e-32, 2.4728e-06, 3.2279e-10,\n",
            "        1.6575e-11, 1.5660e-08, 1.5957e-17, 1.7132e-13, 1.9450e-34, 4.8824e-33,\n",
            "        2.0709e-21, 3.6550e-37, 8.5897e-32, 1.1498e-08, 1.6575e-11, 4.1696e-37,\n",
            "        1.0734e-16, 4.0018e-15, 1.5916e-08, 1.7132e-13, 1.3058e-04])\n",
            "*************** t  24\n",
            "ce_loss:  tensor([3.4977e+00, 1.0495e+01, 1.3032e+01, 7.2154e+01, 1.0495e+01, 4.9132e+00,\n",
            "        5.0659e+01, 3.6728e-03, 6.2259e+01, 3.2701e+01, 3.4977e+00, -0.0000e+00,\n",
            "        1.0495e+01, 3.7731e+00, 2.0377e+01, 1.0060e+01, 3.9933e+01, 9.8363e-02,\n",
            "        1.9971e+01, 3.0088e+01, 4.9081e+01, 7.4359e-02, 1.0495e+01, 1.1994e+01,\n",
            "        6.5052e+00, 3.2479e-02, 8.8223e+00, 1.0060e+01, 2.9041e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.8857e-06, 5.5766e-12, 5.8388e-17, 0.0000e+00, 5.5766e-12, 5.6796e-16,\n",
            "        3.6854e-33, 6.1316e-07, 7.6511e-43, 5.3774e-33, 1.8857e-06, 1.1868e-10,\n",
            "        5.5766e-12, 5.2238e-09, 4.1585e-18, 4.4548e-14, 1.3965e-34, 1.4559e-33,\n",
            "        3.7221e-22, 6.3653e-38, 6.8484e-33, 6.0828e-09, 5.5766e-12, 3.1058e-38,\n",
            "        5.1644e-17, 1.2595e-15, 6.8841e-09, 4.4548e-14, 6.0532e-05],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.5886e+02, 6.2887e+02, 5.5133e+02, 9.8558e+02, 6.2887e+02, 3.5689e+02,\n",
            "        1.1083e+03, 1.9664e+00, 7.7001e+02, 7.3943e+02, 6.5886e+02, 2.0461e-06,\n",
            "        6.2887e+02, 3.1063e+02, 6.7384e+02, 5.0212e+02, 6.0858e+02, 1.6041e+01,\n",
            "        7.1146e+02, 9.1231e+02, 7.0253e+02, 2.8089e+01, 6.2887e+02, 8.1754e+02,\n",
            "        6.7580e+02, 1.0379e+01, 7.8749e+02, 5.0212e+02, 6.5081e+02])\n",
            "kde_grad  tensor([3.7093e-06, 2.4941e-11, 2.7370e-16, 0.0000e+00, 2.4941e-11, 2.4714e-15,\n",
            "        3.2906e-32, 1.0380e-06, 5.2689e-42, 4.3623e-32, 3.7093e-06, 2.6370e-10,\n",
            "        2.4941e-11, 1.6435e-08, 2.2873e-17, 2.0538e-13, 1.2491e-33, 9.7511e-33,\n",
            "        2.1062e-21, 5.6665e-37, 6.1867e-32, 1.4253e-08, 2.4941e-11, 2.5126e-37,\n",
            "        2.1721e-16, 4.5057e-15, 2.4080e-08, 2.0538e-13, 1.2870e-04])\n",
            "*************** t  25\n",
            "ce_loss:  tensor([2.8289e+00, 1.1741e+01, 1.1590e+01, 6.8885e+01, 1.1741e+01, 2.6597e+00,\n",
            "        4.9908e+01, 3.4272e-03, 6.0348e+01, 3.0033e+01, 2.8289e+00, -0.0000e+00,\n",
            "        1.1741e+01, 1.9401e+00, 1.6576e+01, 9.1883e+00, 4.2379e+01, 7.6340e-02,\n",
            "        2.1253e+01, 2.9492e+01, 4.8575e+01, 3.5920e-02, 1.1741e+01, 1.0874e+01,\n",
            "        6.4180e+00, 1.7458e-02, 7.6600e+00, 9.1883e+00, 5.7334e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.5210e-06, 2.7522e-12, 6.9669e-17, 0.0000e+00, 2.7522e-12, 1.1795e-15,\n",
            "        2.6086e-34, 4.9187e-07, 1.4125e-42, 9.7499e-33, 1.5210e-06, 9.9445e-11,\n",
            "        2.7522e-12, 6.2447e-09, 4.0130e-18, 4.9660e-14, 1.3582e-34, 2.3120e-33,\n",
            "        2.2422e-22, 2.9567e-38, 1.0680e-32, 6.2615e-09, 2.7522e-12, 1.7192e-38,\n",
            "        4.8571e-17, 1.0179e-15, 3.4940e-09, 4.9660e-14, 3.0984e-05],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([4.5601e+02, 4.8307e+02, 6.2675e+02, 8.5373e+02, 4.8307e+02, 4.4913e+02,\n",
            "        4.8414e+02, 1.4467e+00, 7.6862e+02, 7.9434e+02, 4.5601e+02, 2.2568e-06,\n",
            "        4.8307e+02, 2.9568e+02, 6.0244e+02, 5.8989e+02, 8.2876e+02, 1.6615e+01,\n",
            "        6.1929e+02, 5.5785e+02, 6.8830e+02, 1.3519e+01, 4.8307e+02, 8.4569e+02,\n",
            "        6.0729e+02, 5.3579e+00, 4.1300e+02, 5.8989e+02, 4.9948e+02])\n",
            "kde_grad  tensor([2.9922e-06, 1.2597e-11, 3.2263e-16, 0.0000e+00, 1.2597e-11, 4.5771e-15,\n",
            "        2.3848e-33, 8.5877e-07, 1.1188e-41, 7.7918e-32, 2.9922e-06, 2.2356e-10,\n",
            "        1.2597e-11, 1.8795e-08, 2.0898e-17, 2.2240e-13, 1.2395e-33, 1.5503e-32,\n",
            "        1.3176e-21, 2.6481e-37, 9.5001e-32, 1.4740e-08, 1.2597e-11, 1.3890e-37,\n",
            "        2.0047e-16, 3.6489e-15, 1.2315e-08, 2.2240e-13, 8.3203e-05])\n",
            "*************** t  26\n",
            "ce_loss:  tensor([2.1981e+00, 8.5219e+00, 1.0903e+01, 6.4947e+01, 8.5219e+00, 3.6707e+00,\n",
            "        4.7012e+01, 1.4973e-03, 6.0341e+01, 2.9155e+01, 2.1981e+00, -0.0000e+00,\n",
            "        8.5219e+00, 2.9299e+00, 1.5813e+01, 8.8044e+00, 3.8916e+01, 5.7303e-02,\n",
            "        1.9466e+01, 2.8537e+01, 4.7324e+01, 2.2672e-02, 8.5219e+00, 1.0342e+01,\n",
            "        7.1414e+00, 9.4348e-03, 6.4595e+00, 8.8044e+00, 1.4137e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.9851e-06, 4.8379e-12, 6.4162e-17, 0.0000e+00, 4.8379e-12, 7.1827e-16,\n",
            "        2.1448e-33, 4.6488e-07, 1.2261e-42, 1.0148e-32, 1.9851e-06, 1.1222e-10,\n",
            "        4.8379e-12, 6.8346e-09, 7.1603e-18, 4.5760e-14, 2.1109e-34, 2.4000e-33,\n",
            "        3.4968e-22, 1.0380e-37, 8.1513e-33, 7.7403e-09, 4.8379e-12, 8.9247e-39,\n",
            "        5.2879e-17, 8.6078e-16, 4.6992e-09, 4.5760e-14, 3.0119e-05],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([5.7243e+02, 3.1597e+02, 5.5321e+02, 9.6496e+02, 3.1597e+02, 3.2322e+02,\n",
            "        7.0152e+02, 7.8826e-01, 8.4256e+02, 6.4930e+02, 5.7243e+02, 2.0053e-06,\n",
            "        3.1597e+02, 5.6049e+02, 7.3168e+02, 5.2507e+02, 4.1910e+02, 9.5108e+00,\n",
            "        5.6547e+02, 7.1027e+02, 7.0253e+02, 1.0150e+01, 3.1597e+02, 5.6624e+02,\n",
            "        7.8126e+02, 3.5205e+00, 7.7866e+02, 5.2507e+02, 3.2604e+02])\n",
            "kde_grad  tensor([3.8212e-06, 2.1142e-11, 2.9017e-16, 0.0000e+00, 2.1142e-11, 3.0338e-15,\n",
            "        1.9096e-32, 7.8799e-07, 1.0710e-41, 8.0278e-32, 3.8212e-06, 2.4922e-10,\n",
            "        2.1142e-11, 2.1392e-08, 3.7028e-17, 2.0084e-13, 1.8941e-33, 1.6062e-32,\n",
            "        1.9714e-21, 9.2122e-37, 7.3353e-32, 1.7255e-08, 2.1142e-11, 7.2358e-38,\n",
            "        2.2634e-16, 3.0929e-15, 1.6199e-08, 2.0084e-13, 6.5756e-05])\n",
            "*************** t  27\n",
            "ce_loss:  tensor([1.7272e+00, 7.8391e+00, 9.8513e+00, 6.2402e+01, 7.8391e+00, 1.6850e+00,\n",
            "        4.6601e+01, 1.0627e-03, 5.6101e+01, 3.0166e+01, 1.7272e+00, -0.0000e+00,\n",
            "        7.8391e+00, 4.3839e+00, 1.5350e+01, 7.3644e+00, 3.6291e+01, 4.3522e-02,\n",
            "        1.7418e+01, 2.7762e+01, 4.4931e+01, 6.7306e-03, 7.8391e+00, 9.8083e+00,\n",
            "        5.2764e+00, 5.0051e-03, 7.5958e+00, 7.3644e+00, 2.3318e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.4457e-06, 1.0141e-11, 6.8842e-17, 0.0000e+00, 1.0141e-11, 1.2028e-15,\n",
            "        2.6078e-33, 3.6704e-07, 1.1743e-42, 1.5095e-32, 1.4457e-06, 8.7466e-11,\n",
            "        1.0141e-11, 4.2558e-09, 3.1024e-18, 4.8063e-14, 3.8043e-33, 3.8146e-33,\n",
            "        4.2782e-22, 1.3980e-37, 1.0502e-32, 7.3281e-09, 1.0141e-11, 1.0149e-38,\n",
            "        3.8288e-17, 8.8940e-16, 1.9928e-09, 4.8063e-14, 2.1667e-05],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([3.7828e+02, 6.8287e+02, 6.8532e+02, 8.3303e+02, 6.8287e+02, 3.4438e+02,\n",
            "        7.3578e+02, 5.0314e-01, 5.5180e+02, 8.5323e+02, 3.7828e+02, 1.6308e-06,\n",
            "        6.8287e+02, 5.2782e+02, 5.1844e+02, 6.2662e+02, 8.9484e+02, 7.2520e+00,\n",
            "        4.0117e+02, 8.4399e+02, 6.5372e+02, 3.1427e+00, 6.8287e+02, 7.3950e+02,\n",
            "        5.9414e+02, 2.1138e+00, 4.1299e+02, 6.2662e+02, 3.8489e+02])\n",
            "kde_grad  tensor([2.7965e-06, 4.3061e-11, 3.1123e-16, 0.0000e+00, 4.3061e-11, 4.6933e-15,\n",
            "        2.2847e-32, 6.2898e-07, 9.6367e-42, 1.2257e-31, 2.7965e-06, 1.9713e-10,\n",
            "        4.3061e-11, 1.4327e-08, 1.6093e-17, 2.1027e-13, 3.2845e-32, 2.5430e-32,\n",
            "        2.3746e-21, 1.2204e-36, 9.2125e-32, 1.6079e-08, 4.3061e-11, 8.2100e-38,\n",
            "        1.5730e-16, 3.1568e-15, 7.2688e-09, 2.1027e-13, 5.1882e-05])\n",
            "*************** t  28\n",
            "ce_loss:  tensor([1.1661e+00, 7.6373e+00, 1.0169e+01, 5.9955e+01, 7.6373e+00, 4.1579e+00,\n",
            "        4.6417e+01, 1.0248e-03, 5.2726e+01, 2.7399e+01, 1.1661e+00, -0.0000e+00,\n",
            "        7.6373e+00, 2.8244e+00, 1.3012e+01, 8.7862e+00, 3.6519e+01, 3.4934e-02,\n",
            "        1.7323e+01, 2.8053e+01, 4.4478e+01, 2.5456e-03, 7.6373e+00, 8.9009e+00,\n",
            "        6.1685e+00, 1.8613e-03, 4.8513e+00, 8.7862e+00, 8.9418e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.6856e-06, 4.0630e-12, 4.7888e-17, 0.0000e+00, 4.0630e-12, 6.7569e-16,\n",
            "        1.7675e-33, 3.0972e-07, 9.5821e-42, 1.2884e-32, 1.6856e-06, 8.4371e-11,\n",
            "        4.0630e-12, 2.6428e-09, 6.9825e-18, 2.2826e-14, 9.1102e-34, 4.1620e-33,\n",
            "        1.3123e-21, 1.1983e-37, 9.2683e-33, 7.7098e-09, 4.0630e-12, 5.3180e-39,\n",
            "        4.0916e-17, 7.6160e-16, 2.5024e-09, 2.2826e-14, 1.6853e-05],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([4.2058e+02, 3.1608e+02, 4.7066e+02, 6.1551e+02, 3.1608e+02, 4.1254e+02,\n",
            "        7.6741e+02, 5.1959e-01, 8.3120e+02, 5.1540e+02, 4.2058e+02, 2.2156e-06,\n",
            "        3.1608e+02, 4.9591e+02, 4.4836e+02, 4.5882e+02, 4.1525e+02, 5.5750e+00,\n",
            "        8.7679e+02, 7.1027e+02, 7.6841e+02, 1.1126e+00, 3.1608e+02, 6.7579e+02,\n",
            "        7.4081e+02, 9.7242e-01, 3.7423e+02, 4.5882e+02, 2.3654e+02])\n",
            "kde_grad  tensor([3.2216e-06, 1.7564e-11, 2.1632e-16, 0.0000e+00, 1.7564e-11, 2.9158e-15,\n",
            "        1.5744e-32, 5.5074e-07, 9.6415e-41, 1.0292e-31, 3.2216e-06, 1.9127e-10,\n",
            "        1.7564e-11, 8.8834e-09, 3.5232e-17, 1.0304e-13, 7.9324e-33, 2.7794e-32,\n",
            "        7.1347e-21, 1.0674e-36, 8.2546e-32, 1.6844e-08, 1.7564e-11, 4.2957e-38,\n",
            "        1.7435e-16, 2.6464e-15, 8.6654e-09, 1.0304e-13, 3.7590e-05])\n",
            "*************** t  29\n",
            "ce_loss:  tensor([9.2156e-01, 5.8384e+00, 8.0544e+00, 5.6255e+01, 5.8384e+00, 1.0837e+00,\n",
            "        4.3904e+01, 6.1850e-04, 5.1982e+01, 2.4985e+01, 9.2156e-01, -0.0000e+00,\n",
            "        5.8384e+00, 2.2137e+00, 1.2820e+01, 5.7877e+00, 3.3960e+01, 2.4265e-02,\n",
            "        1.7137e+01, 2.5890e+01, 4.2889e+01, 1.2254e-03, 5.8384e+00, 9.1140e+00,\n",
            "        4.4160e+00, 7.8480e-04, 4.9363e+00, 5.7877e+00, 2.7000e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.2353e-06, 7.4410e-12, 7.6589e-17, 0.0000e+00, 7.4410e-12, 9.3655e-16,\n",
            "        1.2658e-33, 2.7090e-07, 3.0100e-42, 6.2212e-32, 1.2353e-06, 9.2751e-11,\n",
            "        7.4410e-12, 2.2210e-09, 1.7613e-17, 2.9979e-14, 1.3904e-32, 8.5307e-33,\n",
            "        4.0240e-22, 1.5704e-37, 5.9049e-33, 7.6922e-09, 7.4410e-12, 5.3848e-39,\n",
            "        3.4239e-17, 7.6520e-16, 2.9628e-09, 2.9979e-14, 1.2128e-05],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.9706e+02, 4.0391e+02, 4.1761e+02, 7.7413e+02, 4.0391e+02, 1.0132e+02,\n",
            "        4.4810e+02, 3.1944e-01, 5.5180e+02, 7.9412e+02, 2.9706e+02, 1.3168e-06,\n",
            "        4.0391e+02, 2.6403e+02, 7.2396e+02, 3.0546e+02, 4.1525e+02, 5.1808e+00,\n",
            "        4.2696e+02, 6.8964e+02, 4.4913e+02, 5.7019e-01, 4.0391e+02, 7.4484e+02,\n",
            "        5.7755e+02, 4.1857e-01, 5.4679e+02, 3.0546e+02, 3.9986e+02])\n",
            "kde_grad  tensor([2.3723e-06, 3.1322e-11, 3.3660e-16, 0.0000e+00, 3.1322e-11, 3.6940e-15,\n",
            "        1.1049e-32, 4.6753e-07, 3.0642e-41, 4.8493e-31, 2.3723e-06, 2.0667e-10,\n",
            "        3.1322e-11, 6.9833e-09, 8.6803e-17, 1.2930e-13, 1.1793e-31, 5.6303e-32,\n",
            "        2.2366e-21, 1.3645e-36, 5.1935e-32, 1.7002e-08, 3.1322e-11, 4.3651e-38,\n",
            "        1.4054e-16, 2.6250e-15, 1.0222e-08, 1.2930e-13, 3.0469e-05])\n",
            "*************** t  30\n",
            "ce_loss:  tensor([4.9867e-01, 5.5440e+00, 8.6821e+00, 5.4924e+01, 5.5440e+00, 2.3846e+00,\n",
            "        4.0669e+01, 5.2832e-04, 4.8612e+01, 2.4741e+01, 4.9867e-01, -0.0000e+00,\n",
            "        5.5440e+00, 7.6027e-01, 1.2455e+01, 5.8726e+00, 3.3815e+01, 2.5131e-02,\n",
            "        1.6011e+01, 2.6187e+01, 3.9562e+01, 9.2166e-04, 5.5440e+00, 7.6882e+00,\n",
            "        4.8530e+00, 4.6314e-04, 4.9529e+00, 5.8726e+00, 5.1292e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.4464e-06, 1.0046e-11, 1.1167e-16, 0.0000e+00, 1.0046e-11, 1.4180e-15,\n",
            "        1.1070e-32, 2.3209e-07, 1.8839e-41, 4.2485e-32, 1.4464e-06, 6.9501e-11,\n",
            "        1.0046e-11, 2.2841e-09, 6.8134e-18, 4.6126e-14, 1.5732e-31, 2.1699e-32,\n",
            "        1.0999e-21, 1.9188e-37, 7.1962e-32, 8.7948e-09, 1.0046e-11, 2.3596e-39,\n",
            "        3.2337e-17, 7.8304e-16, 2.1604e-09, 4.6126e-14, 8.8407e-06],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.3849e+02, 5.9635e+02, 9.2003e+02, 7.4513e+02, 5.9635e+02, 4.2255e+02,\n",
            "        6.4595e+02, 2.8843e-01, 5.4639e+02, 5.2244e+02, 1.3849e+02, 1.4369e-06,\n",
            "        5.9635e+02, 9.7580e+01, 7.8920e+02, 6.1045e+02, 8.9102e+02, 7.7773e+00,\n",
            "        7.5584e+02, 7.4544e+02, 6.5372e+02, 3.9873e-01, 5.9635e+02, 6.9466e+02,\n",
            "        6.4508e+02, 2.2368e-01, 5.0403e+02, 6.1045e+02, 6.9844e+01])\n",
            "kde_grad  tensor([2.7170e-06, 4.1621e-11, 4.8930e-16, 0.0000e+00, 4.1621e-11, 5.5130e-15,\n",
            "        9.2753e-32, 4.1285e-07, 1.8856e-40, 3.3011e-31, 2.7170e-06, 1.5847e-10,\n",
            "        4.1621e-11, 6.9205e-09, 3.4260e-17, 1.9760e-13, 1.3053e-30, 1.4283e-31,\n",
            "        5.9706e-21, 1.6980e-36, 6.1142e-31, 1.8884e-08, 4.1621e-11, 1.9044e-38,\n",
            "        1.3625e-16, 2.6468e-15, 7.4341e-09, 1.9760e-13, 2.0090e-05])\n",
            "*************** t  31\n",
            "ce_loss:  tensor([3.6882e-01, 6.6864e+00, 7.9782e+00, 5.2993e+01, 6.6864e+00, 2.6414e+00,\n",
            "        4.1439e+01, 4.1274e-04, 4.6590e+01, 2.2250e+01, 3.6882e-01, -0.0000e+00,\n",
            "        6.6864e+00, 5.3761e-01, 1.3447e+01, 5.9865e+00, 3.2641e+01, 1.9355e-02,\n",
            "        1.7466e+01, 2.3921e+01, 4.0607e+01, 3.5518e-04, 6.6864e+00, 7.6519e+00,\n",
            "        3.3442e+00, 1.9143e-04, 3.8361e+00, 5.9865e+00, 2.4609e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.6341e-06, 4.2372e-12, 4.5532e-17, 0.0000e+00, 4.2372e-12, 1.0005e-15,\n",
            "        1.0515e-32, 1.8149e-07, 1.4010e-40, 2.0097e-31, 1.6341e-06, 7.8369e-11,\n",
            "        4.2372e-12, 2.7865e-09, 7.2752e-18, 2.4182e-14, 4.0488e-32, 1.4545e-32,\n",
            "        9.2172e-22, 2.2902e-37, 5.1996e-32, 7.8825e-09, 4.2372e-12, 2.0959e-39,\n",
            "        2.4583e-17, 7.3112e-16, 1.8790e-09, 2.4182e-14, 9.5602e-06],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.2179e+02, 5.1590e+02, 4.2178e+02, 7.7413e+02, 5.1590e+02, 2.9200e+02,\n",
            "        7.6741e+02, 1.9450e-01, 8.3019e+02, 4.2138e+02, 1.2179e+02, 9.2203e-07,\n",
            "        5.1590e+02, 2.6808e+02, 6.6596e+02, 3.9361e+02, 4.1525e+02, 3.7872e+00,\n",
            "        7.8231e+02, 6.2487e+02, 6.8339e+02, 1.1751e-01, 5.1590e+02, 7.5972e+02,\n",
            "        4.4865e+02, 8.6929e-02, 4.5895e+02, 3.9361e+02, 6.0859e+02])\n",
            "kde_grad  tensor([3.0417e-06, 1.8499e-11, 2.0271e-16, 0.0000e+00, 1.8499e-11, 4.2414e-15,\n",
            "        8.9199e-32, 3.1992e-07, 1.4053e-39, 1.5339e-30, 3.0417e-06, 1.7558e-10,\n",
            "        1.8499e-11, 8.4396e-09, 3.7563e-17, 1.0709e-13, 3.3946e-31, 9.5368e-32,\n",
            "        5.0852e-21, 1.9720e-36, 4.4891e-31, 1.7344e-08, 1.8499e-11, 1.6965e-38,\n",
            "        9.9815e-17, 2.3871e-15, 6.5686e-09, 1.0709e-13, 2.2754e-05])\n",
            "*************** t  32\n",
            "ce_loss:  tensor([2.1936e-01, 4.4800e+00, 6.6056e+00, 5.0166e+01, 4.4800e+00, 7.3508e-01,\n",
            "        3.9132e+01, 3.1585e-04, 4.5876e+01, 2.1857e+01, 2.1936e-01, -0.0000e+00,\n",
            "        4.4800e+00, 1.0501e+00, 1.0730e+01, 3.9075e+00, 3.1078e+01, 1.1133e-02,\n",
            "        1.7139e+01, 2.4838e+01, 3.7923e+01, 1.9060e-04, 4.4800e+00, 6.5686e+00,\n",
            "        2.4609e+00, 1.0943e-04, 4.8885e+00, 3.9075e+00, 3.9411e+00],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.3173e-06, 4.8206e-12, 6.4995e-17, 0.0000e+00, 4.8206e-12, 1.6605e-15,\n",
            "        7.1519e-33, 1.7443e-07, 3.2917e-41, 1.1942e-30, 1.3173e-06, 5.1981e-11,\n",
            "        4.8206e-12, 1.7798e-09, 5.8044e-18, 2.9607e-14, 4.0609e-31, 2.6724e-32,\n",
            "        5.5438e-22, 2.9167e-37, 4.1731e-32, 8.4822e-09, 4.8206e-12, 8.7658e-40,\n",
            "        3.6159e-17, 4.9292e-16, 1.2793e-09, 2.9607e-14, 5.5676e-06],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([7.7450e+01, 5.2524e+02, 6.7263e+02, 6.8999e+02, 5.2524e+02, 3.0783e+02,\n",
            "        5.2403e+02, 2.1441e-01, 4.7631e+02, 8.9549e+02, 7.7450e+01, 1.4695e-06,\n",
            "        5.2524e+02, 1.3861e+02, 5.1137e+02, 2.9465e+02, 7.6979e+02, 1.9156e+00,\n",
            "        6.1929e+02, 7.7461e+02, 4.0941e+02, 9.9343e-02, 5.2524e+02, 6.9400e+02,\n",
            "        5.1146e+02, 5.9622e-02, 3.8017e+02, 2.9465e+02, 5.3123e+02])\n",
            "kde_grad  tensor([2.4564e-06, 2.0268e-11, 2.8374e-16, 0.0000e+00, 2.0268e-11, 6.2637e-15,\n",
            "        5.9398e-32, 3.1097e-07, 3.2748e-40, 8.9370e-30, 2.4564e-06, 1.2014e-10,\n",
            "        2.0268e-11, 5.8053e-09, 2.8300e-17, 1.2677e-13, 3.3174e-30, 1.7318e-31,\n",
            "        3.1273e-21, 2.5487e-36, 3.5099e-31, 1.8697e-08, 2.0268e-11, 7.0576e-39,\n",
            "        1.4453e-16, 1.6455e-15, 4.5169e-09, 1.2677e-13, 1.6200e-05])\n",
            "*************** t  33\n",
            "ce_loss:  tensor([1.4049e-01, 4.7386e+00, 6.1405e+00, 4.8316e+01, 4.7386e+00, 1.9009e+00,\n",
            "        3.6119e+01, 3.8628e-04, 4.2708e+01, 2.1072e+01, 1.4049e-01, -0.0000e+00,\n",
            "        4.7386e+00, 1.7309e-01, 9.0711e+00, 5.2002e+00, 3.1163e+01, 8.5015e-03,\n",
            "        1.5955e+01, 2.3311e+01, 3.5171e+01, 1.3565e-04, 4.7386e+00, 6.3566e+00,\n",
            "        2.9377e+00, 5.7219e-05, 2.4931e+00, 5.2002e+00, 2.1540e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.5935e-06, 3.0556e-12, 4.3166e-17, 0.0000e+00, 3.0556e-12, 1.0637e-15,\n",
            "        2.6882e-32, 1.2956e-07, 3.8868e-40, 4.0756e-31, 1.5935e-06, 7.9124e-11,\n",
            "        3.0556e-12, 2.4421e-09, 1.0040e-17, 3.6078e-14, 8.1547e-31, 4.5243e-32,\n",
            "        6.6490e-22, 2.5044e-37, 5.1018e-31, 9.1743e-09, 3.0556e-12, 6.8583e-40,\n",
            "        2.9771e-17, 5.9839e-16, 1.7638e-09, 3.6078e-14, 4.0378e-06],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.8079e+01, 4.2962e+02, 6.8870e+02, 4.8579e+02, 4.2962e+02, 2.4159e+02,\n",
            "        4.4127e+02, 2.0019e-01, 4.4127e+02, 4.2138e+02, 6.8079e+01, 7.3146e-07,\n",
            "        4.2962e+02, 7.8884e+01, 5.0580e+02, 7.5522e+02, 5.4978e+02, 2.3493e+00,\n",
            "        4.9752e+02, 4.9186e+02, 5.4404e+02, 5.1625e-02, 4.2962e+02, 7.8079e+02,\n",
            "        6.3729e+02, 2.1230e-02, 1.8201e+02, 7.5522e+02, 3.6474e+01])\n",
            "kde_grad  tensor([2.9221e-06, 1.2789e-11, 1.8594e-16, 0.0000e+00, 1.2789e-11, 4.4309e-15,\n",
            "        2.1698e-31, 2.3733e-07, 3.7896e-39, 3.0740e-30, 2.9221e-06, 1.7626e-10,\n",
            "        1.2789e-11, 7.1843e-09, 4.8073e-17, 1.5445e-13, 6.6315e-30, 2.9286e-31,\n",
            "        3.6013e-21, 2.1630e-36, 4.1549e-30, 1.9945e-08, 1.2789e-11, 5.5437e-39,\n",
            "        1.2191e-16, 1.9439e-15, 5.9251e-09, 1.5445e-13, 9.3867e-06])\n",
            "*************** t  34\n",
            "ce_loss:  tensor([7.4901e-02, 3.0193e+00, 8.0543e+00, 4.4719e+01, 3.0193e+00, 3.1581e-01,\n",
            "        3.4001e+01, 1.6676e-04, 4.0802e+01, 1.8953e+01, 7.4901e-02, -0.0000e+00,\n",
            "        3.0193e+00, 5.7405e-02, 7.9534e+00, 6.0331e+00, 3.0757e+01, 6.2645e-03,\n",
            "        1.3999e+01, 2.0465e+01, 3.8563e+01, 6.5801e-05, 3.0193e+00, 5.4370e+00,\n",
            "        1.7562e+00, 1.1741e-04, 2.4880e+00, 6.0331e+00, 2.1215e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.5471e-06, 3.3231e-12, 3.8999e-17, 0.0000e+00, 3.3231e-12, 1.5752e-15,\n",
            "        1.5829e-31, 1.1605e-07, 4.7884e-39, 2.2733e-30, 1.5471e-06, 4.7999e-11,\n",
            "        3.3231e-12, 2.3449e-09, 1.3522e-17, 1.4590e-14, 8.0322e-31, 7.3257e-32,\n",
            "        1.3226e-21, 1.0423e-36, 4.1885e-31, 9.5735e-09, 3.3231e-12, 2.3858e-40,\n",
            "        1.9340e-17, 3.8617e-16, 2.7972e-09, 1.4590e-14, 3.7448e-06],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.9339e+01, 2.4162e+02, 7.2819e+02, 5.2138e+02, 2.4162e+02, 8.6695e+01,\n",
            "        8.3625e+02, 1.0059e-01, 8.8626e+02, 6.3480e+02, 2.9339e+01, 6.0627e-07,\n",
            "        2.4162e+02, 1.7703e+01, 4.4041e+02, 3.6244e+02, 6.3331e+02, 1.2292e+00,\n",
            "        4.0117e+02, 4.8514e+02, 8.0830e+02, 2.8311e-02, 2.4162e+02, 7.2181e+02,\n",
            "        4.2503e+02, 8.9702e-02, 5.1499e+02, 3.6244e+02, 1.1851e+02])\n",
            "kde_grad  tensor([2.8036e-06, 1.3576e-11, 1.7572e-16, 0.0000e+00, 1.3576e-11, 5.9114e-15,\n",
            "        1.2351e-30, 2.0803e-07, 4.5455e-38, 1.6816e-29, 2.8036e-06, 1.1049e-10,\n",
            "        1.3576e-11, 6.9794e-09, 6.4612e-17, 6.8122e-14, 6.5716e-30, 4.7095e-31,\n",
            "        6.9863e-21, 8.7721e-36, 3.4862e-30, 2.0272e-08, 1.3576e-11, 1.9219e-39,\n",
            "        7.7125e-17, 1.3184e-15, 9.3033e-09, 6.8122e-14, 8.8000e-06])\n",
            "*************** t  35\n",
            "ce_loss:  tensor([4.9604e-02, 2.4744e+00, 5.9123e+00, 4.3348e+01, 2.4744e+00, 8.0279e-02,\n",
            "        3.4305e+01, 1.7463e-04, 4.0827e+01, 1.9541e+01, 4.9604e-02, -0.0000e+00,\n",
            "        2.4744e+00, 1.0975e+00, 7.3373e+00, 2.8939e+00, 2.8659e+01, 4.0092e-03,\n",
            "        1.3534e+01, 2.0156e+01, 3.4904e+01, 3.0994e-05, 2.4744e+00, 5.1107e+00,\n",
            "        1.9217e+00, 2.8371e-05, 5.3265e+00, 2.8939e+00, 2.4382e-01],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.4449e-06, 4.0536e-12, 2.3257e-17, 0.0000e+00, 4.0536e-12, 1.7727e-15,\n",
            "        5.8276e-32, 1.0416e-07, 2.2130e-39, 3.0412e-30, 1.4449e-06, 3.6157e-11,\n",
            "        4.0536e-12, 2.2187e-09, 2.3540e-17, 1.9642e-14, 1.8104e-30, 1.0597e-31,\n",
            "        2.9670e-21, 3.7891e-36, 2.3811e-31, 8.3336e-09, 4.0536e-12, 1.5207e-40,\n",
            "        1.5738e-17, 5.5051e-16, 1.5134e-09, 1.9642e-14, 3.2594e-06],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.6596e+01, 3.8148e+02, 5.3993e+02, 6.5599e+02, 3.8148e+02, 4.0784e+01,\n",
            "        4.9151e+02, 8.7905e-02, 5.7539e+02, 6.2177e+02, 1.6596e+01, 5.8787e-07,\n",
            "        3.8148e+02, 6.2950e+02, 6.3903e+02, 4.9537e+02, 4.8572e+02, 9.3453e-01,\n",
            "        9.6972e+02, 1.0432e+03, 4.0941e+02, 1.2438e-02, 3.8148e+02, 7.4574e+02,\n",
            "        5.2469e+02, 1.0868e-02, 5.9522e+02, 4.9537e+02, 7.0391e+01])\n",
            "kde_grad  tensor([2.6148e-06, 1.6381e-11, 1.0129e-16, 0.0000e+00, 1.6381e-11, 6.8396e-15,\n",
            "        4.6178e-31, 1.8604e-07, 2.1101e-38, 2.2068e-29, 2.6148e-06, 8.3914e-11,\n",
            "        1.6381e-11, 7.0895e-09, 1.0914e-16, 8.3029e-14, 1.4231e-29, 6.7635e-31,\n",
            "        1.5498e-20, 3.1450e-35, 1.9508e-30, 1.7915e-08, 1.6381e-11, 1.2182e-39,\n",
            "        6.4599e-17, 1.8256e-15, 5.6061e-09, 8.3029e-14, 8.0444e-06])\n",
            "*************** t  36\n",
            "ce_loss:  tensor([2.7170e-02, 4.5562e+00, 3.8287e+00, 4.1690e+01, 4.5562e+00, 4.8421e-02,\n",
            "        3.1226e+01, 1.0287e-04, 3.9974e+01, 1.8591e+01, 2.7170e-02, -0.0000e+00,\n",
            "        4.5562e+00, 3.9073e-02, 6.8710e+00, 6.7786e+00, 2.6148e+01, 2.8925e-03,\n",
            "        1.4468e+01, 2.0000e+01, 3.1663e+01, 1.6093e-05, 4.5562e+00, 4.5093e+00,\n",
            "        1.2376e+00, 2.6583e-05, 1.8758e+00, 6.7786e+00, 3.6716e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.5658e-06, 1.9916e-12, 2.5807e-17, 0.0000e+00, 1.9916e-12, 1.7584e-15,\n",
            "        2.6014e-31, 8.7060e-08, 2.5113e-39, 3.0960e-30, 1.5658e-06, 4.6498e-11,\n",
            "        1.9916e-12, 1.8514e-09, 1.2513e-17, 8.2475e-15, 9.3738e-30, 1.0526e-31,\n",
            "        9.1198e-22, 9.3413e-37, 2.4182e-30, 7.6743e-09, 1.9916e-12, 8.6967e-41,\n",
            "        9.7569e-18, 3.7147e-16, 1.0745e-09, 8.2475e-15, 3.6228e-06],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.1352e+01, 4.2471e+02, 3.9373e+02, 5.8483e+02, 4.2471e+02, 1.0705e+01,\n",
            "        4.2098e+02, 6.5325e-02, 6.9474e+02, 4.1752e+02, 1.1352e+01, 5.1104e-07,\n",
            "        4.2471e+02, 8.3703e+00, 6.0478e+02, 7.2718e+02, 4.1525e+02, 9.3214e-01,\n",
            "        4.0117e+02, 4.8514e+02, 6.2748e+02, 6.9478e-03, 4.2471e+02, 6.2302e+02,\n",
            "        2.9629e+02, 1.4270e-02, 1.7975e+02, 7.2718e+02, 8.1779e+00])\n",
            "kde_grad  tensor([2.8028e-06, 8.5827e-12, 1.0941e-16, 0.0000e+00, 8.5827e-12, 6.3396e-15,\n",
            "        1.9991e-30, 1.5723e-07, 2.4128e-38, 2.2973e-29, 2.8028e-06, 1.0625e-10,\n",
            "        8.5827e-12, 5.5019e-09, 5.7855e-17, 3.8469e-14, 7.1187e-29, 6.7243e-31,\n",
            "        4.9209e-21, 7.9094e-36, 1.9042e-29, 1.6315e-08, 8.5827e-12, 6.9689e-40,\n",
            "        3.9172e-17, 1.2845e-15, 3.6048e-09, 3.8469e-14, 8.0756e-06])\n",
            "*************** t  37\n",
            "ce_loss:  tensor([1.1964e-02, 1.7368e+00, 3.0148e+00, 4.1442e+01, 1.7368e+00, 1.6917e-02,\n",
            "        3.1129e+01, 1.0585e-04, 3.7407e+01, 1.5842e+01, 1.1964e-02, -0.0000e+00,\n",
            "        1.7368e+00, 1.6227e-02, 5.7654e+00, 3.9140e+00, 2.4994e+01, 2.2121e-03,\n",
            "        1.2597e+01, 1.7842e+01, 3.2357e+01, 8.2254e-06, 1.7368e+00, 3.6060e+00,\n",
            "        6.6441e-01, 1.8477e-05, 7.8095e-01, 3.9140e+00, 2.6211e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.4957e-06, 1.8086e-12, 3.2593e-17, 0.0000e+00, 1.8086e-12, 1.7195e-15,\n",
            "        1.2643e-30, 7.4858e-08, 3.4587e-39, 1.5868e-29, 1.4957e-06, 2.6852e-11,\n",
            "        1.8086e-12, 1.8602e-09, 1.1749e-17, 5.4131e-15, 5.5551e-29, 1.7105e-31,\n",
            "        1.8673e-21, 3.0956e-36, 3.5552e-30, 5.7762e-09, 1.8086e-12, 4.0360e-41,\n",
            "        8.7356e-18, 5.2948e-16, 1.5354e-09, 5.4131e-15, 3.1546e-06],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([7.3819e+00, 1.5213e+02, 6.5451e+02, 6.9130e+02, 1.5213e+02, 2.8160e+00,\n",
            "        1.0530e+03, 4.8505e-02, 4.1323e+02, 4.1752e+02, 7.3819e+00, 3.7090e-07,\n",
            "        1.5213e+02, 1.5427e+01, 7.0684e+02, 4.9067e+02, 7.0177e+02, 5.3127e-01,\n",
            "        5.9523e+02, 6.5970e+02, 6.1454e+02, 3.5754e-03, 1.5213e+02, 6.1715e+02,\n",
            "        2.3780e+02, 6.7010e-03, 1.7188e+02, 4.9067e+02, 9.9439e+00])\n",
            "kde_grad  tensor([2.6367e-06, 7.3141e-12, 1.3496e-16, 0.0000e+00, 7.3141e-12, 6.3050e-15,\n",
            "        9.5186e-30, 1.3486e-07, 3.2229e-38, 1.1334e-28, 2.6367e-06, 6.2586e-11,\n",
            "        7.3141e-12, 5.5514e-09, 5.3951e-17, 2.4971e-14, 4.1122e-28, 1.0835e-30,\n",
            "        9.7797e-21, 2.5600e-35, 2.7454e-29, 1.2515e-08, 7.3141e-12, 3.2304e-40,\n",
            "        3.4989e-17, 1.8209e-15, 5.0328e-09, 2.4971e-14, 7.2256e-06])\n",
            "*************** t  38\n",
            "ce_loss:  tensor([3.6643e-03, 2.0502e+00, 2.9672e+00, 3.7828e+01, 2.0502e+00, 8.8074e-03,\n",
            "        3.0251e+01, 6.7232e-05, 3.4553e+01, 1.6038e+01, 3.6643e-03, -0.0000e+00,\n",
            "        2.0502e+00, 1.3002e-02, 6.3330e+00, 3.6932e+00, 2.6418e+01, 1.4466e-03,\n",
            "        1.2655e+01, 1.9750e+01, 3.1337e+01, 4.1723e-06, 2.0502e+00, 3.4506e+00,\n",
            "        8.2110e-01, 7.6294e-06, 8.0358e-01, 3.6932e+00, 2.4023e-02],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.6528e-06, 2.5143e-12, 2.1350e-17, 0.0000e+00, 2.5143e-12, 1.4233e-15,\n",
            "        2.1743e-31, 6.4018e-08, 2.9669e-38, 5.9875e-29, 1.6528e-06, 2.5553e-11,\n",
            "        2.5143e-12, 1.2027e-09, 3.9921e-18, 4.2269e-15, 3.6300e-29, 1.3939e-31,\n",
            "        1.9492e-21, 3.0014e-36, 2.7126e-30, 5.2588e-09, 2.5143e-12, 5.3106e-41,\n",
            "        7.4123e-18, 4.8418e-16, 1.5613e-09, 4.2269e-15, 2.3053e-06],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([3.0824e+00, 3.6636e+02, 5.4256e+02, 5.7244e+02, 3.6636e+02, 2.0664e+00,\n",
            "        4.0838e+02, 4.2044e-02, 5.0415e+02, 9.3828e+02, 3.0824e+00, 3.5829e-07,\n",
            "        3.6636e+02, 3.0897e+00, 4.5157e+02, 2.6632e+02, 6.9947e+02, 3.7653e-01,\n",
            "        5.9663e+02, 7.0027e+02, 6.8264e+02, 1.7336e-03, 3.6636e+02, 7.2190e+02,\n",
            "        3.4945e+02, 2.9407e-03, 3.1690e+02, 2.6632e+02, 5.8347e+00])\n",
            "kde_grad  tensor([2.9540e-06, 1.0077e-11, 8.8559e-17, 0.0000e+00, 1.0077e-11, 5.3989e-15,\n",
            "        1.6764e-30, 1.1624e-07, 2.6975e-37, 4.2325e-28, 2.9540e-06, 6.0025e-11,\n",
            "        1.0077e-11, 3.5458e-09, 1.8614e-17, 1.8555e-14, 2.7567e-28, 8.8294e-31,\n",
            "        1.0333e-20, 2.5345e-35, 2.1394e-29, 1.1242e-08, 1.0077e-11, 4.1420e-40,\n",
            "        3.0244e-17, 1.6933e-15, 5.0690e-09, 1.8555e-14, 5.4702e-06])\n",
            "*************** t  39\n",
            "ce_loss:  tensor([1.0288e-03, 3.7330e+00, 1.6091e+00, 3.7479e+01, 3.7330e+00, 6.9091e-03,\n",
            "        2.7455e+01, 4.9590e-05, 3.2619e+01, 1.5735e+01, 1.0288e-03, -0.0000e+00,\n",
            "        3.7330e+00, 5.2425e-02, 4.1837e+00, 1.8534e+00, 2.3934e+01, 9.6692e-04,\n",
            "        1.3370e+01, 1.6913e+01, 2.9711e+01, 2.7418e-06, 3.7330e+00, 2.9910e+00,\n",
            "        4.3695e-01, 1.9073e-05, 1.7306e+00, 1.8534e+00, 5.8606e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.6827e-06, 1.2825e-12, 2.2566e-17, 0.0000e+00, 1.2825e-12, 1.4712e-15,\n",
            "        1.2216e-30, 4.5386e-08, 1.3790e-37, 2.0975e-29, 1.6827e-06, 2.1595e-11,\n",
            "        1.2825e-12, 1.0981e-09, 5.1473e-18, 5.4417e-15, 7.1946e-29, 1.4501e-31,\n",
            "        1.7000e-21, 2.6163e-36, 2.4897e-30, 3.8343e-09, 1.2825e-12, 1.5811e-41,\n",
            "        4.5711e-18, 4.0201e-16, 9.4659e-10, 5.4417e-15, 1.8639e-06],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.4296e-01, 4.1427e+02, 4.4644e+02, 6.5599e+02, 4.1427e+02, 1.8229e+00,\n",
            "        4.7404e+02, 2.2977e-02, 6.1254e+02, 4.1064e+02, 6.4296e-01, 4.1270e-07,\n",
            "        4.1427e+02, 5.1279e+01, 4.0048e+02, 1.9277e+02, 4.1384e+02, 2.5926e-01,\n",
            "        6.9824e+02, 4.5033e+02, 4.0877e+02, 1.6584e-03, 4.1427e+02, 5.1026e+02,\n",
            "        1.2403e+02, 1.1565e-02, 2.5781e+02, 1.9277e+02, 1.5981e+00])\n",
            "kde_grad  tensor([2.9479e-06, 5.5779e-12, 9.1502e-17, 0.0000e+00, 5.5779e-12, 5.2803e-15,\n",
            "        9.1505e-30, 8.1680e-08, 1.2262e-36, 1.5135e-28, 2.9479e-06, 5.0473e-11,\n",
            "        5.5779e-12, 3.3802e-09, 2.3268e-17, 2.2953e-14, 5.3116e-28, 9.1410e-31,\n",
            "        8.8397e-21, 2.1416e-35, 1.8979e-29, 8.4260e-09, 5.5779e-12, 1.3527e-40,\n",
            "        1.8222e-17, 1.4872e-15, 3.3566e-09, 2.2953e-14, 4.3303e-06])\n",
            "*************** t  40\n",
            "ce_loss:  tensor([5.6001e-04, 8.7514e-01, 1.0927e+00, 3.4443e+01, 8.7514e-01, 1.0924e-02,\n",
            "        2.7221e+01, 3.8861e-05, 3.3340e+01, 1.3181e+01, 5.6001e-04, -0.0000e+00,\n",
            "        8.7514e-01, 1.9615e-02, 3.0094e+00, 1.1887e+00, 2.1455e+01, 5.9837e-04,\n",
            "        1.3951e+01, 1.5512e+01, 2.7573e+01, 1.4305e-06, 8.7514e-01, 2.3397e+00,\n",
            "        2.5889e-01, 3.3379e-06, 1.3879e-01, 1.1887e+00, 3.5459e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.1124e-06, 1.0613e-12, 1.6150e-17, 0.0000e+00, 1.0613e-12, 9.8479e-16,\n",
            "        3.1632e-30, 3.5755e-08, 1.3218e-37, 6.1097e-29, 2.1124e-06, 2.1753e-11,\n",
            "        1.0613e-12, 7.1786e-10, 6.9174e-18, 6.7700e-15, 3.4055e-28, 1.5288e-31,\n",
            "        8.6679e-22, 8.6900e-36, 1.6199e-29, 3.8757e-09, 1.0613e-12, 2.1586e-41,\n",
            "        3.5350e-18, 5.3906e-16, 1.1433e-09, 6.7700e-15, 1.5059e-06],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([4.4047e-01, 1.2279e+02, 2.6742e+02, 4.3823e+02, 1.2279e+02, 2.9598e+00,\n",
            "        9.5980e+02, 2.6806e-02, 6.5162e+02, 6.4990e+02, 4.4047e-01, 2.1735e-07,\n",
            "        1.2279e+02, 9.4132e+00, 4.2816e+02, 4.5106e+02, 5.2268e+02, 2.1178e-01,\n",
            "        6.6307e+02, 7.0553e+02, 6.0568e+02, 5.9178e-04, 1.2279e+02, 5.3180e+02,\n",
            "        9.0540e+01, 7.8229e-04, 2.9105e+01, 4.5106e+02, 1.2420e+00])\n",
            "kde_grad  tensor([3.7371e-06, 4.1476e-12, 6.4697e-17, 0.0000e+00, 4.1476e-12, 3.6789e-15,\n",
            "        2.3640e-29, 6.5768e-08, 1.2064e-36, 4.2931e-28, 3.7371e-06, 5.0743e-11,\n",
            "        4.1476e-12, 2.2670e-09, 3.0730e-17, 2.8687e-14, 2.4149e-27, 9.5743e-31,\n",
            "        4.6997e-21, 6.9850e-35, 1.1997e-28, 8.1230e-09, 4.1476e-12, 1.7483e-40,\n",
            "        1.4174e-17, 1.8450e-15, 3.6237e-09, 2.8687e-14, 3.5786e-06])\n",
            "*************** t  41\n",
            "ce_loss:  tensor([1.5162e-04, 1.0382e+00, 5.8139e-01, 3.1320e+01, 1.0382e+00, 2.9816e-03,\n",
            "        2.6855e+01, 5.4477e-05, 3.0832e+01, 1.3659e+01, 1.5162e-04, -0.0000e+00,\n",
            "        1.0382e+00, 2.5905e-02, 2.9106e+00, 3.3597e+00, 2.3453e+01, 4.8483e-04,\n",
            "        1.3345e+01, 1.6666e+01, 2.8506e+01, 9.5367e-07, 1.0382e+00, 1.9283e+00,\n",
            "        3.2388e-01, 1.3590e-05, 1.5716e-01, 3.3597e+00, 6.6548e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.3227e-06, 1.1842e-12, 1.9053e-17, 1.4013e-45, 1.1842e-12, 1.2045e-15,\n",
            "        8.3008e-31, 2.3883e-08, 2.1516e-37, 6.8499e-29, 2.3227e-06, 1.2309e-11,\n",
            "        1.1842e-12, 7.2538e-10, 6.8752e-18, 2.5143e-15, 2.2092e-28, 1.7783e-31,\n",
            "        6.0428e-22, 5.4445e-36, 9.7868e-30, 2.6150e-09, 1.1842e-12, 1.0845e-41,\n",
            "        1.7345e-18, 3.9470e-16, 1.1883e-09, 2.5143e-15, 9.9471e-07],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([9.5522e-02, 3.5483e+02, 3.7852e+02, 4.3782e+02, 3.5483e+02, 3.9600e-01,\n",
            "        4.0104e+02, 2.6129e-02, 4.1323e+02, 6.0271e+02, 9.5522e-02, 4.8403e-07,\n",
            "        3.5483e+02, 2.0282e+01, 6.6277e+02, 3.5411e+02, 7.3177e+02, 1.3880e-01,\n",
            "        4.8176e+02, 6.7292e+02, 6.9730e+02, 3.9907e-04, 3.5483e+02, 5.1058e+02,\n",
            "        9.4107e+01, 1.0323e-02, 7.0392e+01, 3.5411e+02, 2.5753e+00])\n",
            "kde_grad  tensor([3.9693e-06, 4.6334e-12, 7.5476e-17, 0.0000e+00, 4.6334e-12, 4.1637e-15,\n",
            "        6.2448e-30, 4.4873e-08, 1.8942e-36, 4.7137e-28, 3.9693e-06, 2.9693e-11,\n",
            "        4.6334e-12, 2.2303e-09, 3.1056e-17, 1.1480e-14, 1.6169e-27, 1.1116e-30,\n",
            "        3.2242e-21, 4.4788e-35, 7.4404e-29, 5.7015e-09, 4.6334e-12, 7.6236e-41,\n",
            "        7.0890e-18, 1.5030e-15, 3.9159e-09, 1.1480e-14, 2.5629e-06])\n",
            "*************** t  42\n",
            "ce_loss:  tensor([7.5695e-05, 2.2363e+00, 3.4986e-01, 2.9451e+01, 2.2363e+00, 2.1406e-03,\n",
            "        2.3975e+01, 2.2411e-05, 2.8064e+01, 1.3383e+01, 7.5695e-05, -0.0000e+00,\n",
            "        2.2363e+00, 8.7176e-04, 3.1837e+00, 6.6820e-01, 2.0616e+01, 2.5615e-04,\n",
            "        1.0789e+01, 1.4550e+01, 2.6851e+01, 3.5763e-07, 2.2363e+00, 2.1788e+00,\n",
            "        1.7533e-01, 1.5497e-06, 6.3442e-01, 6.6820e-01, 1.5973e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.7237e-06, 5.8873e-13, 1.0363e-17, 1.6816e-44, 5.8873e-13, 9.7665e-16,\n",
            "        3.7618e-30, 1.9686e-08, 1.1453e-36, 5.6611e-29, 2.7237e-06, 1.8337e-11,\n",
            "        5.8873e-13, 5.2387e-10, 2.3669e-18, 2.9319e-15, 1.4521e-28, 1.5882e-31,\n",
            "        9.7847e-22, 5.8528e-36, 1.0411e-29, 2.6556e-09, 5.8873e-13, 1.6203e-41,\n",
            "        1.4696e-18, 5.1345e-16, 7.2295e-10, 2.9319e-15, 7.6698e-07],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([4.9305e-02, 2.4847e+02, 1.4409e+02, 5.6504e+02, 2.4847e+02, 4.1461e-01,\n",
            "        3.9329e+02, 9.7500e-03, 4.5899e+02, 4.5814e+02, 4.9305e-02, 1.5930e-07,\n",
            "        2.4847e+02, 1.9404e-01, 3.7114e+02, 1.1645e+02, 3.8026e+02, 8.2796e-02,\n",
            "        3.3863e+02, 5.6012e+02, 4.0040e+02, 1.2300e-04, 2.4847e+02, 6.2891e+02,\n",
            "        4.3844e+01, 4.0674e-04, 1.9551e+02, 1.1645e+02, 3.5532e-01])\n",
            "kde_grad  tensor([4.6599e-06, 2.4971e-12, 4.0651e-17, 0.0000e+00, 2.4971e-12, 3.5904e-15,\n",
            "        2.7482e-29, 3.6362e-08, 9.8158e-36, 3.9812e-28, 4.6599e-06, 4.2525e-11,\n",
            "        2.4971e-12, 1.5305e-09, 1.0761e-17, 1.2008e-14, 1.0272e-27, 9.8764e-31,\n",
            "        4.9909e-21, 4.6842e-35, 7.7523e-29, 5.6354e-09, 2.4971e-12, 1.2566e-40,\n",
            "        5.9520e-18, 1.7401e-15, 2.5185e-09, 1.2008e-14, 1.8357e-06])\n",
            "*************** t  43\n",
            "ce_loss:  tensor([2.7179e-05, 3.0194e-01, 1.1254e-01, 3.0987e+01, 3.0194e-01, 1.3000e-03,\n",
            "        2.3669e+01, 2.2411e-05, 2.7387e+01, 1.1530e+01, 2.7179e-05, -0.0000e+00,\n",
            "        3.0194e-01, 2.4244e-04, 1.7353e+00, 3.9993e-01, 1.8315e+01, 1.4590e-04,\n",
            "        1.0246e+01, 1.5960e+01, 2.4078e+01, 2.3842e-07, 3.0194e-01, 1.5485e+00,\n",
            "        1.7543e-01, 1.3113e-06, 2.9172e-02, 3.9993e-01, 6.9403e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.7791e-06, 7.3709e-13, 1.0722e-17, 2.2421e-44, 7.3709e-13, 7.5565e-16,\n",
            "        1.4779e-29, 1.8140e-08, 3.3349e-36, 1.5076e-28, 2.7791e-06, 9.8972e-12,\n",
            "        7.3709e-13, 4.9242e-10, 2.7665e-18, 2.8583e-15, 6.0011e-28, 2.2247e-31,\n",
            "        1.8151e-21, 4.9457e-36, 5.9817e-29, 2.0311e-09, 7.3709e-13, 7.8192e-42,\n",
            "        9.0827e-19, 3.2678e-16, 7.9933e-10, 2.8583e-15, 5.0225e-07],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.8594e-02, 4.2260e+01, 5.3656e+01, 6.5512e+02, 4.2260e+01, 1.7076e-01,\n",
            "        8.6429e+02, 1.4216e-02, 6.6615e+02, 3.6387e+02, 1.8594e-02, 4.5563e-07,\n",
            "        4.2260e+01, 1.0176e-01, 2.2381e+02, 1.8874e+02, 3.7603e+02, 4.4418e-02,\n",
            "        7.5982e+02, 8.2165e+02, 5.2753e+02, 9.3073e-05, 4.2260e+01, 4.1352e+02,\n",
            "        7.0677e+01, 7.7777e-04, 3.5160e+00, 1.8874e+02, 1.7317e-01])\n",
            "kde_grad  tensor([4.7038e-06, 2.8350e-12, 4.1654e-17, 0.0000e+00, 2.8350e-12, 2.7006e-15,\n",
            "        1.0621e-28, 3.4668e-08, 2.8543e-35, 1.0323e-27, 4.7038e-06, 2.3974e-11,\n",
            "        2.8350e-12, 1.4736e-09, 1.2269e-17, 1.1889e-14, 4.1221e-27, 1.3762e-30,\n",
            "        9.1281e-21, 4.0239e-35, 4.2875e-28, 4.4127e-09, 2.8350e-12, 5.8381e-41,\n",
            "        3.7361e-18, 1.2105e-15, 2.5056e-09, 1.1889e-14, 1.2999e-06])\n",
            "*************** t  44\n",
            "ce_loss:  tensor([1.2159e-05, 1.1757e+01, 5.0511e-02, 2.6657e+01, 1.1757e+01, 1.3333e-03,\n",
            "        2.3040e+01, 1.7762e-05, 2.7944e+01, 9.6109e+00, 1.2159e-05, -0.0000e+00,\n",
            "        1.1757e+01, 5.6504e-05, 1.2608e+00, 1.3940e+00, 1.7790e+01, 1.1324e-04,\n",
            "        1.0920e+01, 1.4304e+01, 2.6028e+01, 2.3842e-07, 1.1757e+01, 1.1026e+00,\n",
            "        1.5291e-01, 1.0729e-06, 6.1518e-01, 1.3940e+00, 7.6944e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.7886e-06, 6.5128e-13, 8.8440e-18, 4.4842e-44, 6.5128e-13, 4.7590e-16,\n",
            "        5.5016e-30, 1.5393e-08, 2.2411e-36, 4.3764e-28, 2.7886e-06, 1.2581e-11,\n",
            "        6.5128e-13, 3.6727e-10, 3.8247e-18, 1.0507e-15, 1.9968e-27, 2.0831e-31,\n",
            "        8.1431e-22, 2.2512e-36, 3.6632e-29, 1.3426e-09, 6.5128e-13, 3.6434e-42,\n",
            "        4.9500e-19, 3.1180e-16, 9.4382e-10, 1.0507e-15, 3.5663e-07],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([5.2835e-03, 8.6820e+02, 3.5969e+01, 4.2319e+02, 8.6820e+02, 2.7532e-01,\n",
            "        3.9329e+02, 8.5579e-03, 6.1142e+02, 4.0869e+02, 5.2835e-03, 1.4198e-07,\n",
            "        8.6820e+02, 1.1498e-02, 2.8077e+02, 1.8988e+02, 8.3810e+02, 4.7908e-02,\n",
            "        3.9302e+02, 4.5190e+02, 6.9071e+02, 1.0274e-04, 8.6820e+02, 3.0712e+02,\n",
            "        4.1602e+01, 3.0683e-04, 4.7216e+02, 1.8988e+02, 3.0722e-01])\n",
            "kde_grad  tensor([4.6222e-06, 2.8030e-12, 3.3844e-17, 0.0000e+00, 2.8030e-12, 1.8148e-15,\n",
            "        4.0253e-29, 2.8544e-08, 1.9397e-35, 2.9104e-27, 4.6222e-06, 2.9303e-11,\n",
            "        2.8030e-12, 1.0143e-09, 1.6901e-17, 4.6540e-15, 1.3444e-26, 1.2871e-30,\n",
            "        4.1860e-21, 1.8141e-35, 2.7132e-28, 2.9740e-09, 2.8030e-12, 2.2997e-41,\n",
            "        2.0476e-18, 1.1056e-15, 3.2358e-09, 4.6540e-15, 9.1783e-07])\n",
            "*************** t  45\n",
            "ce_loss:  tensor([1.4186e-05, 1.3911e+00, 2.6095e-02, 2.3745e+01, 1.3911e+00, 7.3072e-04,\n",
            "        2.0374e+01, 1.0371e-05, 2.5204e+01, 8.9671e+00, 1.4186e-05, -0.0000e+00,\n",
            "        1.3911e+00, 3.0398e-05, 1.7359e+00, 1.5431e-01, 1.8074e+01, 8.9761e-05,\n",
            "        9.3604e+00, 1.2066e+01, 2.3796e+01, 1.1921e-07, 1.3911e+00, 8.5435e-01,\n",
            "        1.1739e-01, 4.7684e-07, 5.7710e-02, 1.5431e-01, 5.5262e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.0236e-06, 3.2267e-13, 6.3700e-18, 2.9147e-43, 3.2267e-13, 5.8684e-16,\n",
            "        1.9878e-29, 1.3736e-08, 3.7643e-36, 8.2332e-28, 3.0236e-06, 7.0331e-12,\n",
            "        3.2267e-13, 2.5146e-10, 1.6977e-18, 1.4029e-15, 7.5630e-28, 2.8392e-31,\n",
            "        1.4907e-21, 5.2866e-36, 3.0824e-29, 1.2120e-09, 3.2267e-13, 3.0352e-42,\n",
            "        3.1951e-19, 2.3566e-16, 4.4368e-10, 1.4029e-15, 2.1092e-07],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.0374e-02, 1.4744e+02, 1.3002e+01, 5.5742e+02, 1.4744e+02, 1.7191e-01,\n",
            "        6.1142e+02, 4.7870e-03, 3.9329e+02, 4.8892e+02, 1.0374e-02, 1.6572e-07,\n",
            "        1.4744e+02, 1.4233e-02, 3.3769e+02, 2.6910e+01, 3.8801e+02, 2.7846e-02,\n",
            "        3.5555e+02, 4.1498e+02, 3.9265e+02, 3.5867e-05, 1.4744e+02, 3.2854e+02,\n",
            "        3.9857e+01, 2.0407e-04, 1.6535e+01, 2.6910e+01, 1.6230e-01])\n",
            "kde_grad  tensor([5.1838e-06, 1.3467e-12, 2.4127e-17, 3.1053e-42, 1.3467e-12, 2.1132e-15,\n",
            "        1.4123e-28, 2.5638e-08, 3.1286e-35, 5.3655e-27, 5.1838e-06, 1.6861e-11,\n",
            "        1.3467e-12, 7.7063e-10, 7.6075e-18, 5.8032e-15, 5.2256e-27, 1.7481e-30,\n",
            "        7.4515e-21, 4.1541e-35, 2.2317e-28, 2.5953e-09, 1.3467e-12, 1.9331e-41,\n",
            "        1.3333e-18, 8.7806e-16, 1.4832e-09, 5.8032e-15, 5.6899e-07])\n",
            "*************** t  46\n",
            "ce_loss:  tensor([5.3644e-06, 1.3394e-01, 1.4914e-02, 2.5551e+01, 1.3394e-01, 2.0862e-03,\n",
            "        2.0856e+01, 1.1325e-05, 2.2396e+01, 1.0505e+01, 5.3644e-06, -0.0000e+00,\n",
            "        1.3394e-01, 1.0729e-05, 9.5280e-01, 1.1030e+00, 1.5439e+01, 5.1378e-05,\n",
            "        9.3933e+00, 1.1663e+01, 2.0773e+01, -0.0000e+00, 1.3394e-01, 8.9196e-01,\n",
            "        8.1850e-02, 2.3842e-07, 1.4457e-02, 1.1030e+00, 1.5353e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.8071e-06, 3.6044e-13, 7.3234e-18, 2.6485e-43, 3.6044e-13, 3.2312e-16,\n",
            "        2.5778e-29, 1.2220e-08, 2.1903e-35, 1.0198e-27, 2.8071e-06, 7.2056e-12,\n",
            "        3.6044e-13, 1.7107e-10, 1.5293e-18, 1.3612e-15, 2.2862e-27, 2.7455e-31,\n",
            "        1.8307e-21, 1.3558e-35, 1.2478e-28, 8.0228e-10, 3.6044e-13, 1.2163e-42,\n",
            "        1.3610e-19, 1.7939e-16, 4.4086e-10, 1.3612e-15, 1.4321e-07],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.5907e-03, 1.2729e+01, 1.4123e+01, 6.4052e+02, 1.2729e+01, 6.0607e-01,\n",
            "        6.8168e+02, 7.5640e-03, 3.9329e+02, 5.7308e+02, 2.5907e-03, 9.4105e-08,\n",
            "        1.2729e+01, 2.2417e-03, 1.2219e+02, 5.4218e+02, 5.4961e+02, 1.7546e-02,\n",
            "        7.4646e+02, 8.0951e+02, 3.9362e+02, 8.9599e-06, 1.2729e+01, 2.2523e+02,\n",
            "        1.9923e+01, 6.8532e-05, 1.4418e+00, 5.4218e+02, 2.5132e-02])\n",
            "kde_grad  tensor([4.6556e-06, 1.3371e-12, 2.7628e-17, 2.4341e-42, 1.3371e-12, 1.2492e-15,\n",
            "        1.7998e-28, 2.3332e-08, 1.7694e-34, 6.8465e-27, 4.6556e-06, 1.7001e-11,\n",
            "        1.3371e-12, 4.7756e-10, 6.7374e-18, 5.7441e-15, 1.5120e-26, 1.6758e-30,\n",
            "        9.0991e-21, 1.0506e-34, 8.7108e-28, 1.7487e-09, 1.3371e-12, 7.8249e-42,\n",
            "        5.6430e-19, 6.5947e-16, 1.4166e-09, 5.7441e-15, 3.6670e-07])\n",
            "*************** t  47\n",
            "ce_loss:  tensor([2.8610e-06, 2.6433e+00, 5.8116e-03, 2.1754e+01, 2.6433e+00, 5.7299e-04,\n",
            "        2.0248e+01, 1.5616e-05, 2.1201e+01, 8.0831e+00, 2.8610e-06, -0.0000e+00,\n",
            "        2.6433e+00, 6.1989e-06, 6.1613e-01, 1.4081e+00, 1.8404e+01, 3.9934e-05,\n",
            "        1.0182e+01, 1.1951e+01, 2.0562e+01, -0.0000e+00, 2.6433e+00, 6.0096e-01,\n",
            "        5.1611e-02, 1.3113e-06, 3.5468e-02, 1.4081e+00, 7.2915e-03],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.0314e-06, 4.3594e-13, 4.0898e-18, 4.8065e-43, 4.3594e-13, 3.0884e-16,\n",
            "        1.3302e-29, 8.9280e-09, 9.5519e-35, 1.0215e-27, 3.0314e-06, 3.9600e-12,\n",
            "        4.3594e-13, 9.7515e-11, 1.9551e-18, 6.9022e-16, 1.4852e-27, 3.3198e-31,\n",
            "        7.9618e-22, 4.1905e-36, 3.7715e-28, 5.9034e-10, 4.3594e-13, 1.1435e-42,\n",
            "        8.1654e-20, 1.2175e-16, 3.8608e-10, 6.9022e-16, 6.3786e-08],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.4447e-03, 6.4879e+02, 3.3934e+00, 4.1125e+02, 6.4879e+02, 6.9016e-02,\n",
            "        6.7772e+02, 8.4532e-03, 5.9295e+02, 3.3530e+02, 1.4447e-03, 1.5296e-07,\n",
            "        6.4879e+02, 2.7665e-03, 1.5134e+02, 1.9797e+02, 6.3668e+02, 1.1778e-02,\n",
            "        4.6220e+02, 4.1498e+02, 8.7354e+02, 4.4396e-06, 6.4879e+02, 1.8710e+02,\n",
            "        1.2497e+01, 1.0319e-03, 1.4210e+01, 1.9797e+02, 7.9493e+00])\n",
            "kde_grad  tensor([4.9917e-06, 1.8043e-12, 1.5259e-17, 4.5836e-42, 1.8043e-12, 1.0954e-15,\n",
            "        9.5425e-29, 1.7381e-08, 7.6020e-34, 6.5285e-27, 4.9917e-06, 9.5707e-12,\n",
            "        1.8043e-12, 3.0320e-10, 8.5701e-18, 3.1674e-15, 1.0197e-26, 2.0136e-30,\n",
            "        4.1081e-21, 3.3040e-35, 2.5962e-27, 1.2772e-09, 1.8043e-12, 7.7800e-42,\n",
            "        3.4296e-19, 4.7632e-16, 1.4024e-09, 3.1674e-15, 1.9083e-07])\n",
            "*************** t  48\n",
            "ce_loss:  tensor([1.5497e-06, 4.3684e-01, 2.5664e-03, 1.8784e+01, 4.3684e-01, 3.7151e-04,\n",
            "        1.9519e+01, 6.1989e-06, 2.2067e+01, 6.4566e+00, 1.5497e-06, -0.0000e+00,\n",
            "        4.3684e-01, 2.8610e-06, 7.9996e-01, 6.3883e-02, 1.6194e+01, 2.4199e-05,\n",
            "        8.2748e+00, 9.6899e+00, 1.9982e+01, -0.0000e+00, 4.3684e-01, 5.8374e-01,\n",
            "        4.2797e-02, 1.1921e-07, 5.9895e-03, 6.3883e-02, 1.4960e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.0652e-06, 2.3281e-13, 3.8342e-18, 2.4369e-42, 2.3281e-13, 2.1577e-16,\n",
            "        1.6081e-29, 6.8646e-09, 6.3319e-35, 1.8879e-27, 3.0652e-06, 5.5277e-12,\n",
            "        2.3281e-13, 9.3570e-11, 8.9315e-19, 7.9152e-16, 2.2904e-27, 1.6953e-31,\n",
            "        9.1823e-22, 9.9205e-36, 6.3606e-29, 3.9227e-10, 2.3281e-13, 8.6320e-43,\n",
            "        6.9982e-20, 1.0950e-16, 3.2502e-10, 7.9152e-16, 4.1164e-08],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([8.4728e-04, 1.0240e+02, 2.1078e+00, 4.1125e+02, 1.0240e+02, 8.2233e-02,\n",
            "        3.9329e+02, 3.3531e-03, 6.1142e+02, 4.1045e+02, 8.4728e-04, 7.7470e-08,\n",
            "        1.0240e+02, 5.8452e-04, 1.6045e+02, 8.3987e+00, 3.4374e+02, 7.4796e-03,\n",
            "        4.9565e+02, 5.1336e+02, 3.9362e+02, 5.1850e-06, 1.0240e+02, 2.7485e+02,\n",
            "        1.6766e+01, 3.8907e-05, 8.7927e-01, 8.3987e+00, 3.5639e-02])\n",
            "kde_grad  tensor([5.0287e-06, 9.2395e-13, 1.4351e-17, 2.1608e-41, 9.2395e-13, 8.1830e-16,\n",
            "        1.1205e-28, 1.3081e-08, 5.2126e-34, 1.1765e-26, 5.0287e-06, 1.2963e-11,\n",
            "        9.2395e-13, 2.6650e-10, 3.9733e-18, 3.2313e-15, 1.5316e-26, 1.0302e-30,\n",
            "        4.5221e-21, 7.6304e-35, 4.4523e-28, 8.7706e-10, 9.2395e-13, 5.1147e-42,\n",
            "        2.9675e-19, 4.0027e-16, 1.0067e-09, 3.2313e-15, 1.1546e-07])\n",
            "*************** t  49\n",
            "ce_loss:  tensor([9.5367e-07, 7.4897e-02, 9.0963e-04, 1.7914e+01, 7.4897e-02, 3.5542e-04,\n",
            "        1.6537e+01, 5.8412e-06, 1.9473e+01, 9.2550e+00, 9.5367e-07, -0.0000e+00,\n",
            "        7.4897e-02, 2.3842e-06, 2.8926e-01, 5.1430e+00, 1.3285e+01, 1.6212e-05,\n",
            "        9.4689e+00, 1.2538e+01, 1.7569e+01, -0.0000e+00, 7.4897e-02, 4.8088e-01,\n",
            "        3.0286e-02, 1.1921e-07, 1.2639e-01, 5.1430e+00, 6.5563e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.4015e-06, 2.1586e-13, 2.8278e-18, 9.5765e-42, 2.1586e-13, 1.8969e-16,\n",
            "        4.7540e-29, 5.1415e-09, 8.5829e-35, 1.5018e-27, 3.4015e-06, 2.5132e-12,\n",
            "        2.1586e-13, 4.7737e-11, 1.1159e-18, 5.4751e-16, 6.7208e-27, 1.2960e-31,\n",
            "        6.5497e-22, 8.2071e-36, 1.7612e-28, 3.1865e-10, 2.1586e-13, 3.1529e-43,\n",
            "        3.0221e-20, 6.6095e-17, 2.4484e-10, 5.4751e-16, 2.4808e-08],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([3.5534e-04, 3.2633e+00, 4.7973e-01, 7.4635e+02, 3.2633e+00, 4.2550e-02,\n",
            "        3.7325e+02, 2.8945e-03, 3.9329e+02, 6.4706e+02, 3.5534e-04, 1.9560e-07,\n",
            "        3.2633e+00, 1.2415e-03, 8.2478e+01, 8.3098e+02, 3.9851e+02, 4.4871e-03,\n",
            "        6.1100e+02, 6.9195e+02, 6.6208e+02, 2.7245e-06, 3.2633e+00, 1.4652e+02,\n",
            "        1.0003e+01, 4.8606e-05, 1.5588e+02, 8.3098e+02, 1.4309e-02])\n",
            "kde_grad  tensor([5.4007e-06, 7.8559e-13, 1.0380e-17, 8.5932e-41, 7.8559e-13, 7.0373e-16,\n",
            "        3.2080e-28, 9.7862e-09, 6.7374e-34, 9.8983e-27, 5.4007e-06, 6.1518e-12,\n",
            "        7.8559e-13, 1.5276e-10, 4.8289e-18, 2.6661e-15, 4.2898e-26, 7.8481e-31,\n",
            "        3.2849e-21, 6.4237e-35, 1.2003e-27, 7.0714e-10, 7.8559e-13, 1.2135e-42,\n",
            "        1.2780e-19, 2.5414e-16, 8.6400e-10, 2.6661e-15, 7.2178e-08])\n",
            "*************** t  50\n",
            "ce_loss:  tensor([2.9802e-06, 1.2121e+00, 5.8133e-04, 1.6697e+01, 1.2121e+00, 2.3696e-04,\n",
            "        1.4717e+01, 3.5763e-06, 1.6875e+01, 6.7465e+00, 2.9802e-06, -0.0000e+00,\n",
            "        1.2121e+00, 9.5367e-07, 1.1806e-01, 1.9963e-01, 1.1944e+01, 1.1921e-05,\n",
            "        1.0141e+01, 9.7113e+00, 1.9536e+01, -0.0000e+00, 1.2121e+00, 3.6733e-01,\n",
            "        2.3205e-02, 1.1921e-07, 1.3168e-03, 1.9963e-01, 8.6423e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.9148e-06, 2.0393e-13, 2.5872e-18, 4.5332e-42, 2.0393e-13, 1.1261e-16,\n",
            "        1.4037e-28, 5.5111e-09, 2.9746e-34, 1.1665e-27, 2.9148e-06, 4.0580e-12,\n",
            "        2.0393e-13, 3.0514e-11, 1.4841e-18, 2.9437e-16, 1.2421e-26, 9.5905e-32,\n",
            "        3.5800e-22, 4.5090e-36, 1.1613e-28, 2.8445e-10, 2.0393e-13, 2.1019e-43,\n",
            "        1.7634e-20, 4.9201e-17, 1.4122e-10, 2.9437e-16, 1.2251e-08],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.4759e-03, 4.3421e+02, 5.0828e-01, 4.0608e+02, 4.3421e+02, 6.4158e-02,\n",
            "        5.0778e+02, 1.9252e-03, 3.5183e+02, 2.9707e+02, 2.4759e-03, 5.6651e-08,\n",
            "        4.3421e+02, 2.0934e-04, 4.9865e+01, 4.2445e+01, 3.1543e+02, 4.9749e-03,\n",
            "        5.9997e+02, 4.0007e+02, 5.9940e+02, 1.1289e-06, 4.3421e+02, 1.4966e+02,\n",
            "        7.9769e+00, 1.8386e-05, 1.9447e-01, 4.2445e+01, 5.6485e-02])\n",
            "kde_grad  tensor([5.1043e-06, 9.0802e-13, 9.5758e-18, 3.9985e-41, 9.0802e-13, 4.4154e-16,\n",
            "        9.3335e-28, 1.0360e-08, 2.2786e-33, 7.3966e-27, 5.1043e-06, 9.4863e-12,\n",
            "        9.0802e-13, 9.1664e-11, 6.3619e-18, 1.2415e-15, 7.7567e-26, 5.8406e-31,\n",
            "        1.8521e-21, 3.4778e-35, 7.9791e-28, 6.3002e-10, 9.0802e-13, 1.2219e-42,\n",
            "        7.5790e-20, 1.7856e-16, 4.3163e-10, 1.2415e-15, 3.6785e-08])\n",
            "*************** t  51\n",
            "ce_loss:  tensor([5.9605e-07, 1.6974e-01, 2.8320e-04, 1.5458e+01, 1.6974e-01, 3.5649e-04,\n",
            "        1.8997e+01, 4.2915e-06, 1.7899e+01, 4.7905e+00, 5.9605e-07, -0.0000e+00,\n",
            "        1.6974e-01, 8.3446e-07, 6.8670e-02, 2.7911e-02, 1.2990e+01, 1.0133e-05,\n",
            "        1.0139e+01, 8.5150e+00, 1.8476e+01, -0.0000e+00, 1.6974e-01, 3.5476e-01,\n",
            "        1.8689e-02, 1.7881e-06, 3.7662e-02, 2.7911e-02, 6.3179e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.2794e-06, 1.1285e-13, 1.7649e-18, 1.8983e-41, 1.1285e-13, 6.7884e-17,\n",
            "        1.0370e-28, 4.1597e-09, 9.3213e-34, 2.0249e-27, 3.2794e-06, 1.8260e-12,\n",
            "        1.1285e-13, 1.5909e-11, 1.8619e-18, 3.6988e-16, 2.5818e-26, 8.9733e-32,\n",
            "        2.3604e-22, 9.1454e-36, 7.6778e-29, 1.7109e-10, 1.1285e-13, 1.2472e-43,\n",
            "        9.4276e-21, 2.6802e-17, 9.3317e-11, 3.6988e-16, 8.4367e-09],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.5151e-04, 3.5768e+01, 1.5554e-01, 6.7566e+02, 3.5768e+01, 8.4555e-02,\n",
            "        8.0446e+02, 2.2479e-03, 7.7641e+02, 2.6381e+02, 2.5151e-04, 4.3472e-07,\n",
            "        3.5768e+01, 5.8310e-04, 3.8516e+01, 4.5308e+00, 8.5846e+02, 2.5029e-03,\n",
            "        4.4081e+02, 7.0874e+02, 6.1545e+02, 2.8655e-06, 3.5768e+01, 1.4801e+02,\n",
            "        5.9783e+00, 1.8316e-03, 4.0126e+01, 4.5308e+00, 1.1632e-02])\n",
            "kde_grad  tensor([5.0795e-06, 4.4229e-13, 6.4425e-18, 1.6704e-40, 4.4229e-13, 2.6561e-16,\n",
            "        7.1930e-28, 7.8343e-09, 7.0732e-33, 1.2458e-26, 5.0795e-06, 4.5710e-12,\n",
            "        4.4229e-13, 5.2414e-11, 7.9414e-18, 1.4873e-15, 1.5864e-25, 5.4440e-31,\n",
            "        1.2153e-21, 6.8825e-35, 5.3174e-28, 3.9498e-10, 4.4229e-13, 0.0000e+00,\n",
            "        4.0301e-20, 1.0993e-16, 3.3048e-10, 1.4873e-15, 2.5287e-08])\n",
            "*************** t  52\n",
            "ce_loss:  tensor([5.9605e-07, 6.0739e-02, 3.5816e-04, 1.6893e+01, 6.0739e-02, 5.7967e-04,\n",
            "        1.6219e+01, 3.0994e-06, 1.7682e+01, 4.7661e+00, 5.9605e-07, -0.0000e+00,\n",
            "        6.0739e-02, 5.9605e-07, 3.9877e-02, 3.2007e-02, 1.2870e+01, 1.3709e-05,\n",
            "        7.8504e+00, 8.9780e+00, 1.7868e+01, -0.0000e+00, 6.0739e-02, 4.3767e-01,\n",
            "        1.5577e-02, -0.0000e+00, 7.7933e-04, 3.2007e-02, 8.9284e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.5453e-06, 1.1723e-13, 1.6425e-18, 1.8777e-41, 1.1723e-13, 1.0153e-16,\n",
            "        8.1260e-29, 4.0798e-09, 4.0634e-34, 3.1286e-27, 3.5453e-06, 2.8212e-12,\n",
            "        1.1723e-13, 1.5528e-11, 1.1181e-18, 4.3440e-16, 1.3459e-26, 5.2467e-32,\n",
            "        2.7645e-22, 4.2106e-36, 6.9618e-29, 2.0937e-10, 1.1723e-13, 1.1351e-43,\n",
            "        7.6497e-21, 3.5975e-17, 6.8400e-11, 4.3440e-16, 3.6792e-09],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([3.4784e-04, 0.0000e+00, 3.0016e-01, 5.3983e+02, 0.0000e+00, 1.5219e-01,\n",
            "        3.7746e+02, 1.2774e-03, 4.4805e+02, 4.8686e+02, 3.4784e-04, 5.2899e-08,\n",
            "        0.0000e+00, 1.3097e-04, 1.5812e+01, 2.0126e+01, 3.3561e+02, 6.4832e-03,\n",
            "        2.8424e+02, 4.6070e+02, 3.9362e+02, 1.1509e-06, 0.0000e+00, 1.7221e+02,\n",
            "        5.6704e+00, 5.7889e-06, 1.3583e-01, 2.0126e+01, 5.4590e-02])\n",
            "kde_grad  tensor([5.8118e-06, 4.5100e-13, 6.0594e-18, 1.6447e-40, 4.5100e-13, 4.0496e-16,\n",
            "        5.5122e-28, 7.6663e-09, 3.1734e-33, 1.9081e-26, 5.8118e-06, 6.6227e-12,\n",
            "        4.5100e-13, 4.6829e-11, 4.7263e-18, 1.8168e-15, 8.5645e-26, 3.2214e-31,\n",
            "        1.3590e-21, 3.1914e-35, 4.6549e-28, 4.6780e-10, 4.5100e-13, 0.0000e+00,\n",
            "        3.3301e-20, 1.2951e-16, 2.1178e-10, 1.8168e-15, 1.1645e-08])\n",
            "*************** t  53\n",
            "ce_loss:  tensor([4.7684e-07, 6.0739e-02, 1.7069e-04, 1.7541e+01, 6.0739e-02, 5.4654e-04,\n",
            "        1.3705e+01, 1.4067e-05, 1.6576e+01, 8.4663e+00, 4.7684e-07, -0.0000e+00,\n",
            "        6.0739e-02, 5.9605e-07, 3.5602e-02, 4.3850e-03, 1.2742e+01, 9.1791e-06,\n",
            "        8.0773e+00, 8.0802e+00, 1.6412e+01, -0.0000e+00, 6.0739e-02, 2.8948e-01,\n",
            "        1.4052e-02, 4.7684e-07, 4.4217e-04, 4.3850e-03, 2.8967e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.5449e-06, 1.1723e-13, 1.0557e-18, 1.5902e-41, 1.1723e-13, 8.9811e-17,\n",
            "        1.9146e-28, 3.3124e-09, 8.9980e-34, 2.5041e-27, 3.5449e-06, 1.3922e-12,\n",
            "        1.1723e-13, 8.8516e-12, 1.2078e-18, 3.5535e-16, 2.9536e-26, 5.6050e-32,\n",
            "        4.0493e-22, 4.6772e-36, 2.3093e-28, 1.2604e-10, 1.1723e-13, 4.9045e-44,\n",
            "        4.5019e-21, 1.7207e-17, 4.5621e-11, 3.5535e-16, 3.6698e-09],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.2630e-04, 0.0000e+00, 9.7669e-02, 6.1323e+02, 0.0000e+00, 1.4913e-01,\n",
            "        5.9191e+02, 8.6917e-03, 7.7641e+02, 7.2333e+02, 2.2630e-04, 1.8942e-07,\n",
            "        0.0000e+00, 4.5830e-04, 2.0623e+01, 7.1215e-01, 9.4118e+02, 2.5033e-03,\n",
            "        6.9735e+02, 6.5140e+02, 5.7803e+02, 1.8199e-06, 0.0000e+00, 8.8751e+01,\n",
            "        4.5286e+00, 4.2061e-04, 2.2086e-01, 7.1215e-01, 4.7681e-03])\n",
            "kde_grad  tensor([5.4655e-06, 4.5100e-13, 3.8812e-18, 1.3939e-40, 4.5100e-13, 3.5150e-16,\n",
            "        1.2537e-27, 6.5938e-09, 6.7586e-33, 1.6070e-26, 5.4655e-06, 3.4454e-12,\n",
            "        4.5100e-13, 2.9584e-11, 5.1158e-18, 1.3540e-15, 1.8025e-25, 3.4022e-31,\n",
            "        1.9804e-21, 3.5028e-35, 1.5106e-27, 2.9143e-10, 4.5100e-13, 0.0000e+00,\n",
            "        1.9554e-20, 6.9827e-17, 1.5306e-10, 1.3540e-15, 1.0738e-08])\n",
            "*************** t  54\n",
            "ce_loss:  tensor([3.5763e-07, 6.0739e-02, 2.5698e-04, 1.5385e+01, 6.0739e-02, 2.6425e-04,\n",
            "        1.5358e+01, 3.3379e-06, 1.7517e+01, 5.2954e+00, 3.5763e-07, -0.0000e+00,\n",
            "        6.0739e-02, 3.5763e-07, 3.4866e-02, 1.6247e-02, 1.2717e+01, 8.5830e-06,\n",
            "        9.0831e+00, 9.2945e+00, 1.9612e+01, -0.0000e+00, 6.0739e-02, 2.1984e-01,\n",
            "        1.3313e-02, -0.0000e+00, 2.6354e-04, 1.6247e-02, 8.6008e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.1517e-06, 1.1723e-13, 1.1208e-18, 2.2501e-41, 1.1723e-13, 9.3450e-17,\n",
            "        1.7469e-28, 3.2505e-09, 3.6917e-34, 1.6228e-27, 3.1517e-06, 2.1604e-12,\n",
            "        1.1723e-13, 7.1147e-12, 5.4857e-19, 3.0814e-16, 1.2742e-26, 2.8126e-32,\n",
            "        1.8989e-22, 2.2468e-36, 1.6059e-28, 1.2019e-10, 1.1723e-13, 5.3249e-44,\n",
            "        3.0217e-21, 2.2489e-17, 4.6592e-11, 3.0814e-16, 1.2720e-09],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.0075e-04, 0.0000e+00, 2.1167e-01, 5.3192e+02, 0.0000e+00, 3.9369e-02,\n",
            "        7.2770e+02, 1.3709e-03, 3.7746e+02, 2.6540e+02, 2.0075e-04, 5.0685e-08,\n",
            "        0.0000e+00, 8.0037e-05, 1.5222e+01, 1.6947e+01, 3.2787e+02, 2.9445e-03,\n",
            "        3.5513e+02, 6.0464e+02, 7.3834e+02, 1.1606e-06, 0.0000e+00, 8.5951e+01,\n",
            "        4.8178e+00, 4.0404e-06, 3.8964e-02, 1.6947e+01, 1.0717e+00])\n",
            "kde_grad  tensor([5.1137e-06, 4.5100e-13, 4.1403e-18, 1.9245e-40, 4.5100e-13, 3.5527e-16,\n",
            "        1.1673e-27, 6.1516e-09, 2.8569e-33, 1.0125e-26, 5.1137e-06, 5.0967e-12,\n",
            "        4.5100e-13, 2.1843e-11, 2.3619e-18, 1.2718e-15, 8.0970e-26, 1.7254e-31,\n",
            "        9.6858e-22, 1.6988e-35, 1.0938e-27, 2.7325e-10, 4.5100e-13, 0.0000e+00,\n",
            "        1.3443e-20, 8.0236e-17, 1.4082e-10, 1.2718e-15, 4.2157e-09])\n",
            "*************** t  55\n",
            "ce_loss:  tensor([5.9605e-07, 6.0739e-02, 1.1396e-04, 1.7242e+01, 6.0739e-02, 1.6128e-04,\n",
            "        1.4670e+01, 1.2994e-05, 1.6131e+01, 3.6132e+00, 5.9605e-07, -0.0000e+00,\n",
            "        6.0739e-02, 3.5763e-07, 2.2581e-02, 2.8277e-03, 1.2332e+01, 6.7949e-06,\n",
            "        7.1968e+00, 9.8078e+00, 1.7413e+01, -0.0000e+00, 6.0739e-02, 3.9468e-01,\n",
            "        1.0452e-02, 3.5763e-07, 1.2424e-02, 2.8277e-03, 2.9206e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.8198e-06, 1.1723e-13, 7.9649e-19, 1.7708e-41, 1.1723e-13, 5.2012e-17,\n",
            "        1.1657e-28, 2.5768e-09, 1.3174e-33, 2.5441e-27, 2.8198e-06, 1.2172e-12,\n",
            "        1.1723e-13, 3.5188e-12, 7.0352e-19, 2.1895e-16, 2.5302e-26, 2.0406e-32,\n",
            "        3.2353e-22, 1.6875e-36, 1.1023e-28, 8.8234e-11, 1.1723e-13, 4.7644e-44,\n",
            "        1.6217e-21, 1.1410e-17, 3.0298e-11, 2.1895e-16, 1.3029e-09],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([3.2810e-04, 0.0000e+00, 8.2477e-02, 6.6459e+02, 0.0000e+00, 2.0278e-02,\n",
            "        3.7746e+02, 8.2591e-03, 7.7641e+02, 3.2523e+02, 3.2810e-04, 6.9962e-08,\n",
            "        0.0000e+00, 2.3122e-04, 1.1306e+01, 6.7559e-01, 8.5846e+02, 1.9277e-03,\n",
            "        5.5269e+02, 6.9829e+02, 3.7192e+02, 6.8289e-07, 0.0000e+00, 1.6346e+02,\n",
            "        3.8610e+00, 2.5105e-04, 1.6656e+01, 6.7559e-01, 4.8050e-03])\n",
            "kde_grad  tensor([4.5000e-06, 4.5100e-13, 2.9355e-18, 1.5462e-40, 4.5100e-13, 2.0064e-16,\n",
            "        7.7479e-28, 5.1691e-09, 9.8366e-33, 1.5431e-26, 4.5000e-06, 2.9543e-12,\n",
            "        4.5100e-13, 1.2005e-11, 2.9946e-18, 8.5090e-16, 1.5416e-25, 1.2459e-31,\n",
            "        1.5607e-21, 1.2926e-35, 7.3786e-28, 2.0073e-10, 4.5100e-13, 0.0000e+00,\n",
            "        7.1802e-21, 4.6197e-17, 1.0803e-10, 8.5090e-16, 3.9251e-09])\n",
            "*************** t  56\n",
            "ce_loss:  tensor([3.5763e-07, 6.0739e-02, 1.0514e-04, 1.4929e+01, 6.0739e-02, 1.7284e-04,\n",
            "        1.4052e+01, 2.8610e-06, 1.7238e+01, 4.6120e+00, 3.5763e-07, -0.0000e+00,\n",
            "        6.0739e-02, 2.3842e-07, 3.7778e-02, 8.7044e-04, 1.2434e+01, 6.0797e-06,\n",
            "        8.2190e+00, 8.8176e+00, 1.5999e+01, -0.0000e+00, 6.0739e-02, 2.0694e-01,\n",
            "        8.1808e-03, -0.0000e+00, 1.5961e-04, 8.7044e-04, 4.4527e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.5207e-06, 1.1723e-13, 9.0518e-19, 2.4497e-41, 1.1723e-13, 3.5686e-17,\n",
            "        2.5228e-28, 2.1668e-09, 5.6285e-34, 3.3791e-27, 2.5207e-06, 1.1867e-12,\n",
            "        1.1723e-13, 2.4230e-12, 3.7559e-19, 1.9204e-16, 1.2250e-26, 1.1544e-32,\n",
            "        2.3263e-22, 8.7429e-37, 3.1239e-28, 6.8212e-11, 1.1723e-13, 2.2421e-44,\n",
            "        9.5246e-22, 1.3236e-17, 2.6647e-11, 1.9204e-16, 4.7643e-10],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.1992e-04, 0.0000e+00, 7.6168e-02, 5.3192e+02, 0.0000e+00, 6.4646e-02,\n",
            "        7.0549e+02, 8.7202e-04, 3.7746e+02, 6.3611e+02, 2.1992e-04, 4.2898e-08,\n",
            "        0.0000e+00, 5.3657e-05, 2.0057e+01, 2.2160e-01, 3.2737e+02, 1.8395e-03,\n",
            "        4.6164e+02, 5.3714e+02, 8.5214e+02, 1.5986e-06, 0.0000e+00, 6.6813e+01,\n",
            "        3.0703e+00, 3.5819e-06, 3.0294e-02, 2.2160e-01, 5.2118e-01])\n",
            "kde_grad  tensor([4.0790e-06, 4.5100e-13, 3.3303e-18, 2.0750e-40, 4.5100e-13, 1.4442e-16,\n",
            "        1.6328e-27, 4.1173e-09, 4.3342e-33, 2.0290e-26, 4.0790e-06, 2.8103e-12,\n",
            "        4.5100e-13, 7.6767e-12, 1.6250e-18, 7.4062e-16, 7.7367e-26, 7.1301e-32,\n",
            "        1.1473e-21, 6.6520e-36, 2.0164e-27, 1.6020e-10, 4.5100e-13, 0.0000e+00,\n",
            "        4.2772e-21, 4.8080e-17, 8.0304e-11, 7.4062e-16, 1.6081e-09])\n",
            "*************** t  57\n",
            "ce_loss:  tensor([2.3842e-07, 6.0739e-02, 7.4503e-05, 1.7005e+01, 6.0739e-02, 1.3696e-04,\n",
            "        1.5750e+01, 1.8120e-05, 1.6107e+01, 5.1721e+00, 2.3842e-07, -0.0000e+00,\n",
            "        6.0739e-02, 4.7684e-07, 4.5119e-02, 5.1247e-04, 1.2117e+01, 6.1989e-06,\n",
            "        7.3989e+00, 9.5768e+00, 1.6726e+01, -0.0000e+00, 6.0739e-02, 2.0349e-01,\n",
            "        5.5235e-03, 2.3842e-07, 7.9867e-05, 5.1247e-04, 1.9669e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.0034e-06, 1.1723e-13, 5.7092e-19, 1.8852e-41, 1.1723e-13, 4.0018e-17,\n",
            "        2.1586e-28, 1.9837e-09, 1.8723e-33, 1.7329e-27, 2.0034e-06, 6.8971e-13,\n",
            "        1.1723e-13, 1.1769e-12, 5.4657e-19, 2.0081e-16, 2.4413e-26, 6.4976e-33,\n",
            "        3.0729e-22, 5.5000e-37, 7.9739e-29, 6.2506e-11, 1.1723e-13, 2.3822e-44,\n",
            "        5.0654e-22, 7.9504e-18, 1.9938e-11, 2.0081e-16, 5.8612e-10],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.1518e-04, 0.0000e+00, 5.9489e-02, 6.7566e+02, 0.0000e+00, 1.8767e-02,\n",
            "        6.7358e+02, 1.5221e-02, 8.7208e+02, 3.9198e+02, 1.1518e-04, 4.3680e-08,\n",
            "        0.0000e+00, 3.7943e-04, 2.4701e+01, 1.4461e-01, 7.9265e+02, 2.0806e-03,\n",
            "        5.6341e+02, 6.1632e+02, 3.7192e+02, 8.6025e-07, 0.0000e+00, 9.6095e+01,\n",
            "        1.6058e+00, 1.7955e-04, 2.9179e-02, 1.4461e-01, 4.2592e-03])\n",
            "kde_grad  tensor([3.1165e-06, 4.5100e-13, 2.1087e-18, 1.6513e-40, 4.5100e-13, 1.5521e-16,\n",
            "        1.4281e-27, 4.1094e-09, 1.3920e-32, 1.0811e-26, 3.1165e-06, 1.6662e-12,\n",
            "        4.5100e-13, 4.1363e-12, 2.3587e-18, 7.8156e-16, 1.4822e-25, 4.0140e-32,\n",
            "        1.4831e-21, 4.2381e-36, 5.2655e-28, 1.4344e-10, 4.5100e-13, 0.0000e+00,\n",
            "        2.2796e-21, 3.2069e-17, 6.5255e-11, 7.8156e-16, 1.7577e-09])\n",
            "*************** t  58\n",
            "ce_loss:  tensor([3.5763e-07, 6.0739e-02, 5.1259e-05, 1.5167e+01, 6.0739e-02, 1.0597e-04,\n",
            "        1.6984e+01, 3.3379e-06, 1.6589e+01, 3.6952e+00, 3.5763e-07, -0.0000e+00,\n",
            "        6.0739e-02, 1.1921e-07, 2.6315e-02, 4.3109e-04, 1.1853e+01, 5.9604e-06,\n",
            "        9.6222e+00, 7.9456e+00, 1.5822e+01, -0.0000e+00, 6.0739e-02, 2.0364e-01,\n",
            "        5.8833e-03, -0.0000e+00, 5.0663e-05, 4.3109e-04, 1.3590e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.5675e-06, 1.1723e-13, 5.4601e-19, 1.7285e-41, 1.1723e-13, 2.4948e-17,\n",
            "        1.2732e-28, 1.6454e-09, 8.4480e-34, 1.8145e-27, 1.5675e-06, 6.8697e-13,\n",
            "        1.1723e-13, 9.7877e-13, 3.3826e-19, 1.3813e-16, 1.1074e-26, 5.1422e-33,\n",
            "        1.7583e-22, 4.2367e-37, 2.1966e-28, 5.6197e-11, 1.1723e-13, 1.1210e-44,\n",
            "        3.7523e-22, 1.0353e-17, 1.8046e-11, 1.3813e-16, 2.3459e-10],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.3049e-04, 0.0000e+00, 4.4772e-02, 5.3192e+02, 0.0000e+00, 3.6042e-02,\n",
            "        6.6875e+02, 1.0830e-03, 3.7746e+02, 5.6052e+02, 2.3049e-04, 2.9068e-08,\n",
            "        0.0000e+00, 3.3095e-05, 1.1598e+01, 1.9664e-01, 3.2737e+02, 2.1681e-03,\n",
            "        6.3318e+02, 5.7503e+02, 7.3389e+02, 7.6278e-07, 0.0000e+00, 6.5853e+01,\n",
            "        2.5410e+00, 3.7924e-06, 9.6106e-03, 1.9664e-01, 4.0659e-03])\n",
            "kde_grad  tensor([2.6031e-06, 4.5100e-13, 1.9904e-18, 1.4815e-40, 4.5100e-13, 9.9891e-17,\n",
            "        8.5900e-28, 3.1756e-09, 6.4453e-33, 1.0857e-26, 2.6031e-06, 1.6426e-12,\n",
            "        4.5100e-13, 3.1606e-12, 1.4497e-18, 5.4004e-16, 6.9183e-26, 3.2138e-32,\n",
            "        8.8614e-22, 3.2010e-36, 1.4145e-27, 1.2815e-10, 4.5100e-13, 0.0000e+00,\n",
            "        1.7125e-21, 3.7410e-17, 5.4452e-11, 5.4004e-16, 7.5516e-10])\n",
            "*************** t  59\n",
            "ce_loss:  tensor([2.3842e-07, 6.0739e-02, 4.5537e-05, 1.7159e+01, 6.0739e-02, 2.1634e-04,\n",
            "        1.5198e+01, 9.1791e-06, 1.6308e+01, 4.8022e+00, 2.3842e-07, -0.0000e+00,\n",
            "        6.0739e-02, 3.5763e-07, 1.1622e-02, 5.5334e-04, 1.2324e+01, 4.8876e-06,\n",
            "        9.3524e+00, 9.6656e+00, 1.7499e+01, -0.0000e+00, 6.0739e-02, 1.7517e-01,\n",
            "        4.7569e-03, -0.0000e+00, 3.5166e-05, 5.5334e-04, 1.1921e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.3820e-06, 1.1723e-13, 4.6397e-19, 1.2373e-41, 1.1723e-13, 1.2906e-17,\n",
            "        1.4228e-28, 1.8704e-09, 2.4691e-33, 1.1351e-27, 1.3820e-06, 4.1180e-13,\n",
            "        1.1723e-13, 4.2654e-13, 3.1894e-19, 1.1977e-16, 2.0662e-26, 4.1403e-33,\n",
            "        1.1645e-22, 3.5937e-37, 1.3037e-28, 3.8998e-11, 1.1723e-13, 9.8091e-45,\n",
            "        2.0958e-22, 5.1511e-18, 1.1195e-11, 1.1977e-16, 1.7428e-10],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.1342e-04, 0.0000e+00, 3.8279e-02, 6.6459e+02, 0.0000e+00, 7.0564e-02,\n",
            "        3.7746e+02, 7.2645e-03, 7.7926e+02, 3.0331e+02, 1.1342e-04, 8.3990e-08,\n",
            "        0.0000e+00, 2.7133e-04, 5.6053e+00, 1.8589e-01, 8.1904e+02, 1.5461e-03,\n",
            "        5.7013e+02, 6.9828e+02, 5.7803e+02, 1.3175e-06, 0.0000e+00, 8.3864e+01,\n",
            "        1.3813e+00, 4.2123e-06, 1.3718e-02, 1.8589e-01, 2.7469e-03])\n",
            "kde_grad  tensor([2.1740e-06, 4.5100e-13, 1.7074e-18, 1.0791e-40, 4.5100e-13, 5.2179e-17,\n",
            "        9.3750e-28, 3.8170e-09, 1.8277e-32, 6.9690e-27, 2.1740e-06, 1.0172e-12,\n",
            "        4.5100e-13, 1.5312e-12, 1.3541e-18, 4.8056e-16, 1.2535e-25, 2.5592e-32,\n",
            "        5.9641e-22, 2.7622e-36, 8.5225e-28, 9.1324e-11, 4.5100e-13, 0.0000e+00,\n",
            "        9.6052e-22, 1.9861e-17, 3.7254e-11, 4.8056e-16, 5.4950e-10])\n",
            "*************** t  60\n",
            "ce_loss:  tensor([2.3842e-07, 6.0739e-02, 3.7193e-05, 1.4372e+01, 6.0739e-02, 1.1062e-04,\n",
            "        1.3153e+01, 2.9802e-06, 1.7487e+01, 3.3862e+00, 2.3842e-07, -0.0000e+00,\n",
            "        6.0739e-02, 1.1921e-07, 2.6075e-02, 6.2232e-04, 1.2706e+01, 6.1989e-06,\n",
            "        9.4422e+00, 8.2915e+00, 1.8733e+01, -0.0000e+00, 6.0739e-02, 1.8780e-01,\n",
            "        4.1310e-03, -0.0000e+00, 2.6583e-05, 6.2232e-04, 1.6928e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.2159e-06, 1.1723e-13, 3.5436e-19, 1.7540e-41, 1.1723e-13, 2.2111e-17,\n",
            "        3.2374e-28, 1.6248e-09, 2.2743e-33, 1.6221e-27, 1.2159e-06, 6.9027e-13,\n",
            "        1.1723e-13, 4.0363e-13, 1.7194e-19, 1.2740e-16, 1.0479e-26, 3.9625e-33,\n",
            "        8.1562e-23, 1.7661e-37, 9.4651e-29, 3.9682e-11, 1.1723e-13, 5.6052e-45,\n",
            "        1.3880e-22, 4.6756e-18, 1.0896e-11, 1.2740e-16, 6.4705e-11],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.8233e-04, 0.0000e+00, 2.8580e-02, 4.0608e+02, 0.0000e+00, 1.3908e-02,\n",
            "        7.6374e+02, 1.1698e-03, 5.1245e+02, 4.4053e+02, 1.8233e-04, 2.7936e-08,\n",
            "        0.0000e+00, 2.6817e-05, 1.4548e+01, 2.9583e-01, 4.7117e+02, 2.8449e-03,\n",
            "        4.9873e+02, 4.6962e+02, 7.3834e+02, 8.8983e-07, 0.0000e+00, 6.1197e+01,\n",
            "        1.6857e+00, 1.4279e-06, 5.0474e-03, 2.9583e-01, 8.1109e-03])\n",
            "kde_grad  tensor([2.0315e-06, 4.5100e-13, 1.3061e-18, 1.4807e-40, 4.5100e-13, 8.3980e-17,\n",
            "        2.0552e-27, 3.1403e-09, 1.7160e-32, 9.6641e-27, 2.0315e-06, 1.6433e-12,\n",
            "        4.5100e-13, 1.3362e-12, 7.4321e-19, 4.9673e-16, 6.6092e-26, 2.4849e-32,\n",
            "        4.1657e-22, 1.3488e-36, 6.3304e-28, 9.1635e-11, 4.5100e-13, 0.0000e+00,\n",
            "        6.4119e-22, 1.7617e-17, 3.3595e-11, 4.9673e-16, 2.1543e-10])\n",
            "*************** t  61\n",
            "ce_loss:  tensor([2.3842e-07, 6.0739e-02, 7.9033e-05, 1.3947e+01, 6.0739e-02, 1.0240e-04,\n",
            "        1.4646e+01, 3.5763e-06, 1.9458e+01, 5.1992e+00, 2.3842e-07, -0.0000e+00,\n",
            "        6.0739e-02, 3.5763e-07, 1.6113e-02, 2.6485e-04, 1.6238e+01, 5.1260e-06,\n",
            "        7.4134e+00, 7.0363e+00, 1.6995e+01, -0.0000e+00, 6.0739e-02, 1.6373e-01,\n",
            "        3.3660e-03, -0.0000e+00, 2.6703e-05, 2.6485e-04, 3.5018e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.2487e-06, 1.1723e-13, 2.9726e-19, 5.3960e-41, 1.1723e-13, 1.2416e-17,\n",
            "        1.7857e-28, 1.3258e-09, 1.8668e-33, 1.3398e-27, 1.2487e-06, 3.8075e-13,\n",
            "        1.1723e-13, 1.7313e-13, 2.1359e-19, 9.0245e-17, 5.9665e-27, 2.8347e-33,\n",
            "        9.2325e-23, 1.8372e-37, 5.5171e-29, 2.8879e-11, 1.1723e-13, 4.2039e-45,\n",
            "        6.8497e-23, 2.1527e-18, 5.9388e-12, 9.0245e-17, 4.7688e-11],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([9.7759e-05, 0.0000e+00, 7.1286e-02, 7.1689e+02, 0.0000e+00, 2.3715e-02,\n",
            "        3.7746e+02, 2.6215e-03, 8.0366e+02, 5.1117e+02, 9.7759e-05, 7.8246e-08,\n",
            "        0.0000e+00, 2.8709e-04, 8.7542e+00, 5.5426e-02, 7.7289e+02, 1.7196e-03,\n",
            "        4.9454e+02, 6.9756e+02, 5.7803e+02, 6.4732e-07, 0.0000e+00, 6.4765e+01,\n",
            "        1.0822e+00, 5.0685e-06, 1.3679e-02, 5.5426e-02, 2.7045e-01])\n",
            "kde_grad  tensor([1.9530e-06, 4.5100e-13, 1.1167e-18, 4.5209e-40, 4.5100e-13, 5.0133e-17,\n",
            "        1.1640e-27, 2.6729e-09, 1.4265e-32, 8.0857e-27, 1.9530e-06, 9.4412e-13,\n",
            "        4.5100e-13, 6.3646e-13, 9.1679e-19, 3.5618e-16, 3.8315e-26, 1.7626e-32,\n",
            "        4.6027e-22, 1.3824e-36, 3.6297e-28, 6.7906e-11, 4.5100e-13, 0.0000e+00,\n",
            "        3.1840e-22, 8.6240e-18, 2.0110e-11, 3.5618e-16, 1.6900e-10])\n",
            "*************** t  62\n",
            "ce_loss:  tensor([2.3842e-07, 6.0739e-02, 3.7550e-05, 1.4109e+01, 6.0739e-02, 7.8317e-05,\n",
            "        1.3063e+01, 2.9802e-06, 1.6610e+01, 5.9270e+00, 2.3842e-07, -0.0000e+00,\n",
            "        6.0739e-02, 1.1921e-07, 1.1870e-02, 8.1470e-04, 1.2649e+01, 5.1260e-06,\n",
            "        8.4673e+00, 7.7370e+00, 1.8596e+01, -0.0000e+00, 6.0739e-02, 1.8053e-01,\n",
            "        3.5638e-03, -0.0000e+00, 1.7285e-05, 8.1470e-04, 1.4186e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.1252e-06, 1.1723e-13, 2.9084e-19, 2.3470e-41, 1.1723e-13, 6.8520e-18,\n",
            "        3.9765e-28, 1.2979e-09, 1.2689e-33, 9.0269e-28, 1.1252e-06, 7.1757e-13,\n",
            "        1.1723e-13, 1.5502e-13, 1.2904e-19, 6.4343e-17, 3.5798e-27, 3.4067e-33,\n",
            "        6.9697e-23, 1.0286e-37, 4.1796e-29, 2.9634e-11, 1.1723e-13, 2.8026e-45,\n",
            "        5.7670e-23, 3.2749e-18, 6.6395e-12, 6.4343e-17, 6.9952e-11],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.4860e-04, 0.0000e+00, 2.5980e-02, 4.0608e+02, 0.0000e+00, 1.1963e-02,\n",
            "        7.8421e+02, 1.3368e-03, 3.7746e+02, 5.0405e+02, 1.4860e-04, 2.4406e-08,\n",
            "        0.0000e+00, 2.2829e-05, 5.2312e+00, 7.5351e-01, 3.4389e+02, 1.6674e-03,\n",
            "        5.2301e+02, 4.2089e+02, 6.7054e+02, 6.4374e-07, 0.0000e+00, 7.3096e+01,\n",
            "        1.5727e+00, 1.0952e-06, 3.3499e-03, 7.5351e-01, 2.3341e-03])\n",
            "kde_grad  tensor([1.8567e-06, 4.5100e-13, 1.0695e-18, 1.9698e-40, 4.5100e-13, 2.7223e-17,\n",
            "        2.5015e-27, 2.5534e-09, 9.5891e-33, 5.6296e-27, 1.8567e-06, 1.6903e-12,\n",
            "        4.5100e-13, 5.2395e-13, 5.4882e-19, 2.5912e-16, 2.2778e-26, 2.1190e-32,\n",
            "        3.4765e-22, 7.7988e-37, 2.8113e-28, 6.9772e-11, 4.5100e-13, 0.0000e+00,\n",
            "        2.7038e-22, 1.2369e-17, 2.0888e-11, 2.5912e-16, 2.1853e-10])\n",
            "*************** t  63\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 1.0931e-04, 1.3700e+01, 6.0739e-02, 7.5337e-05,\n",
            "        1.4982e+01, 2.1458e-06, 1.5427e+01, 4.2700e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, 3.5763e-07, 5.2628e-03, 3.8938e-04, 1.1351e+01, 3.9339e-06,\n",
            "        9.0458e+00, 7.3302e+00, 1.6264e+01, -0.0000e+00, 6.0739e-02, 2.2317e-01,\n",
            "        1.9979e-03, 1.1921e-07, 1.2994e-05, 3.8938e-04, 1.8011e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.0806e-06, 1.1723e-13, 2.0703e-19, 6.6961e-41, 1.1723e-13, 4.4104e-18,\n",
            "        2.7736e-28, 1.3029e-09, 3.7178e-33, 7.2203e-28, 1.0806e-06, 3.5315e-13,\n",
            "        1.1723e-13, 6.2968e-14, 1.5243e-19, 3.8981e-17, 8.1980e-27, 2.0932e-33,\n",
            "        7.5093e-23, 1.9563e-37, 3.0414e-29, 2.0481e-11, 1.1723e-13, 2.8026e-45,\n",
            "        2.4133e-23, 1.6135e-18, 3.1327e-12, 3.8981e-17, 2.1879e-11],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.5416e-05, 0.0000e+00, 1.0220e-01, 7.6838e+02, 0.0000e+00, 1.8441e-02,\n",
            "        5.1245e+02, 1.1184e-03, 8.7589e+02, 4.1952e+02, 6.5416e-05, 5.0081e-08,\n",
            "        0.0000e+00, 2.5935e-04, 2.1700e+00, 1.4193e-01, 5.8102e+02, 1.1750e-03,\n",
            "        5.7043e+02, 7.0317e+02, 4.4405e+02, 4.0816e-07, 0.0000e+00, 9.5767e+01,\n",
            "        7.7008e-01, 1.1384e-04, 6.4487e-03, 1.4193e-01, 2.1095e-01])\n",
            "kde_grad  tensor([1.6838e-06, 4.5100e-13, 7.9353e-19, 5.5341e-40, 4.5100e-13, 1.8006e-17,\n",
            "        1.7953e-27, 2.5518e-09, 2.7168e-32, 4.3408e-27, 1.6838e-06, 8.6467e-13,\n",
            "        4.5100e-13, 2.3639e-13, 6.4727e-19, 1.5665e-16, 4.9862e-26, 1.3024e-32,\n",
            "        3.8537e-22, 1.4641e-36, 1.9782e-28, 4.7372e-11, 4.5100e-13, 0.0000e+00,\n",
            "        1.1246e-22, 6.6910e-18, 1.0737e-11, 1.5665e-16, 7.7184e-11])\n",
            "*************** t  64\n",
            "ce_loss:  tensor([3.5763e-07, 6.0739e-02, 3.5047e-05, 1.3791e+01, 6.0739e-02, 5.4940e-04,\n",
            "        1.6414e+01, 1.7881e-06, 1.5883e+01, 6.1409e+00, 3.5763e-07, -0.0000e+00,\n",
            "        6.0739e-02, 1.1921e-07, 2.1248e-02, 1.1646e-04, 1.1424e+01, 3.9339e-06,\n",
            "        8.3320e+00, 8.0336e+00, 1.4657e+01, -0.0000e+00, 6.0739e-02, 1.5883e-01,\n",
            "        1.8632e-03, -0.0000e+00, 1.2398e-05, 1.1646e-04, 1.2040e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.8192e-07, 1.1723e-13, 2.0127e-19, 2.3889e-41, 1.1723e-13, 5.2080e-18,\n",
            "        2.3934e-28, 1.2280e-09, 1.6833e-33, 5.3597e-28, 9.8192e-07, 5.0219e-13,\n",
            "        1.1723e-13, 4.7730e-14, 6.5434e-20, 2.5793e-17, 7.2841e-27, 1.4488e-33,\n",
            "        6.0869e-23, 8.4246e-38, 6.8791e-29, 1.8016e-11, 1.1723e-13, 1.4013e-45,\n",
            "        1.7345e-23, 2.7156e-18, 3.7253e-12, 2.5793e-17, 2.6041e-11],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.5865e-04, 0.0000e+00, 2.7711e-02, 4.0608e+02, 0.0000e+00, 2.8089e-01,\n",
            "        8.8005e+02, 8.1531e-04, 3.5603e+02, 6.2672e+02, 2.5865e-04, 2.6384e-08,\n",
            "        0.0000e+00, 2.4160e-05, 1.1182e+01, 2.5562e-02, 3.2786e+02, 1.5531e-03,\n",
            "        4.8479e+02, 5.3230e+02, 5.9398e+02, 5.0691e-07, 0.0000e+00, 6.4144e+01,\n",
            "        7.6057e-01, 1.2968e-06, 2.5644e-03, 2.5562e-02, 2.3879e-03])\n",
            "kde_grad  tensor([1.6485e-06, 4.5100e-13, 7.4358e-19, 1.9804e-40, 4.5100e-13, 2.1916e-17,\n",
            "        1.5810e-27, 2.3925e-09, 1.2594e-32, 3.3631e-27, 1.6485e-06, 1.2001e-12,\n",
            "        4.5100e-13, 1.6641e-13, 2.8687e-19, 1.0003e-16, 4.4705e-26, 9.0999e-33,\n",
            "        3.0220e-22, 6.3892e-37, 4.3799e-28, 4.1573e-11, 4.5100e-13, 0.0000e+00,\n",
            "        8.1191e-23, 1.0158e-17, 1.2228e-11, 1.0003e-16, 8.2660e-11])\n",
            "*************** t  65\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 4.2795e-05, 1.3568e+01, 6.0739e-02, 9.3098e-05,\n",
            "        1.5122e+01, 1.9073e-06, 1.5553e+01, 4.7941e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, 1.1921e-07, 3.9831e-03, 9.1310e-05, 1.1027e+01, 3.4571e-06,\n",
            "        7.3548e+00, 9.0522e+00, 1.6665e+01, -0.0000e+00, 6.0739e-02, 1.9146e-01,\n",
            "        1.9670e-03, -0.0000e+00, 1.1206e-05, 9.1310e-05, 9.8943e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.2418e-07, 1.1723e-13, 1.4768e-19, 6.3419e-41, 1.1723e-13, 6.0945e-18,\n",
            "        1.0898e-28, 1.1699e-09, 4.7465e-33, 3.7222e-28, 9.2418e-07, 2.7247e-13,\n",
            "        1.1723e-13, 2.4303e-14, 6.8123e-20, 1.8502e-17, 1.2934e-26, 1.0955e-33,\n",
            "        6.7995e-23, 7.9334e-38, 5.4598e-29, 1.5213e-11, 1.1723e-13, 1.4013e-45,\n",
            "        9.5605e-24, 1.2741e-18, 2.0955e-12, 1.8502e-17, 9.6774e-12],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.3789e-05, 0.0000e+00, 3.9552e-02, 7.7895e+02, 0.0000e+00, 1.6429e-02,\n",
            "        3.7746e+02, 1.1691e-03, 8.0440e+02, 3.1986e+02, 6.3789e-05, 3.1495e-08,\n",
            "        0.0000e+00, 5.0830e-05, 1.4371e+00, 4.6778e-02, 7.9264e+02, 1.1789e-03,\n",
            "        3.5734e+02, 6.7624e+02, 5.7803e+02, 7.0393e-07, 0.0000e+00, 8.7746e+01,\n",
            "        9.0702e-01, 2.8708e-06, 5.0388e-03, 4.6778e-02, 3.6987e-03])\n",
            "kde_grad  tensor([1.4476e-06, 4.5100e-13, 5.6028e-19, 5.2244e-40, 4.5100e-13, 2.4004e-17,\n",
            "        7.1540e-28, 2.3094e-09, 3.4461e-32, 2.2938e-27, 1.4476e-06, 6.6451e-13,\n",
            "        4.5100e-13, 9.0352e-14, 2.9031e-19, 7.4892e-17, 7.7167e-26, 6.8545e-33,\n",
            "        3.3826e-22, 6.0903e-37, 3.4524e-28, 3.6076e-11, 4.5100e-13, 0.0000e+00,\n",
            "        4.5521e-23, 5.0909e-18, 7.2023e-12, 7.4892e-17, 3.3471e-11])\n",
            "*************** t  66\n",
            "ce_loss:  tensor([2.3842e-07, 6.0739e-02, 3.1590e-05, 1.3965e+01, 6.0739e-02, 6.2106e-05,\n",
            "        1.2803e+01, 1.4305e-06, 1.6521e+01, 2.8180e+00, 2.3842e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 5.6364e-03, 9.1429e-05, 1.1279e+01, 3.9339e-06,\n",
            "        7.4278e+00, 7.8834e+00, 1.7929e+01, -0.0000e+00, 6.0739e-02, 1.3682e-01,\n",
            "        1.2629e-03, -0.0000e+00, 6.7949e-06, 9.1429e-05, 1.7524e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.2206e-07, 1.1723e-13, 1.5535e-19, 2.4133e-41, 1.1723e-13, 3.7249e-18,\n",
            "        2.4890e-28, 1.0941e-09, 2.4570e-33, 5.3730e-28, 9.2206e-07, 4.1062e-13,\n",
            "        1.1723e-13, 1.4530e-14, 5.2340e-20, 1.4290e-17, 6.1089e-27, 7.4292e-34,\n",
            "        1.0927e-22, 4.2705e-38, 3.9193e-29, 1.9388e-11, 1.1723e-13, 0.0000e+00,\n",
            "        5.8360e-24, 1.4942e-18, 2.7498e-12, 1.4290e-17, 6.0722e-12],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.8167e-04, 0.0000e+00, 2.1155e-02, 4.5759e+02, 0.0000e+00, 1.3142e-02,\n",
            "        5.7933e+02, 7.4505e-04, 4.9142e+02, 2.4404e+02, 1.8167e-04, 2.2732e-08,\n",
            "        0.0000e+00, 5.4284e-06, 3.0677e+00, 2.3717e-02, 3.6099e+02, 1.2971e-03,\n",
            "        5.3456e+02, 5.7502e+02, 7.3834e+02, 3.0385e-07, 0.0000e+00, 4.7243e+01,\n",
            "        5.8266e-01, 1.0014e-06, 1.3107e-03, 2.3717e-02, 7.8905e-03])\n",
            "kde_grad  tensor([1.5308e-06, 4.5100e-13, 5.7845e-19, 2.0095e-40, 4.5100e-13, 1.5066e-17,\n",
            "        1.5789e-27, 2.1281e-09, 1.8197e-32, 3.2129e-27, 1.5308e-06, 9.8313e-13,\n",
            "        4.5100e-13, 5.2648e-14, 2.2933e-19, 5.6501e-17, 3.7559e-26, 4.7038e-33,\n",
            "        5.4778e-22, 3.2525e-37, 2.5773e-28, 4.4335e-11, 4.5100e-13, 0.0000e+00,\n",
            "        2.7754e-23, 5.7447e-18, 8.8716e-12, 5.6501e-17, 2.1365e-11])\n",
            "*************** t  67\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 1.0514e-04, 1.3134e+01, 6.0739e-02, 5.9960e-05,\n",
            "        1.3999e+01, 2.1458e-06, 1.9636e+01, 3.7130e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, 1.1921e-07, 3.3208e-03, 3.5405e-05, 1.0902e+01, 3.0994e-06,\n",
            "        9.8563e+00, 8.7286e+00, 1.6794e+01, -0.0000e+00, 6.0739e-02, 1.6470e-01,\n",
            "        1.3679e-03, -0.0000e+00, 3.4451e-05, 3.5405e-05, 1.2994e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.5904e-07, 1.1723e-13, 1.2412e-19, 6.5295e-41, 1.1723e-13, 3.1233e-18,\n",
            "        2.6200e-28, 1.2863e-09, 1.9573e-33, 8.1116e-28, 9.5904e-07, 2.1257e-13,\n",
            "        1.1723e-13, 6.6076e-15, 4.2684e-20, 9.0092e-18, 1.2171e-26, 5.2646e-34,\n",
            "        7.9922e-23, 3.5724e-38, 2.2709e-29, 1.3718e-11, 1.1723e-13, 0.0000e+00,\n",
            "        2.6017e-24, 7.8408e-19, 1.1120e-12, 9.0092e-18, 6.8001e-12],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.1349e-05, 0.0000e+00, 1.0995e-01, 7.1689e+02, 0.0000e+00, 1.0524e-02,\n",
            "        6.6607e+02, 1.4060e-03, 7.8769e+02, 6.9490e+02, 6.1349e-05, 2.6286e-08,\n",
            "        0.0000e+00, 6.2740e-05, 1.4164e+00, 1.0043e-02, 7.0313e+02, 1.2747e-03,\n",
            "        5.3782e+02, 6.2567e+02, 5.0650e+02, 6.9091e-07, 0.0000e+00, 6.9189e+01,\n",
            "        6.5305e-01, 4.3939e-06, 3.2912e-02, 1.0043e-02, 2.5349e-03])\n",
            "kde_grad  tensor([1.4929e-06, 4.5100e-13, 4.7834e-19, 5.3337e-40, 4.5100e-13, 1.2432e-17,\n",
            "        1.6563e-27, 2.5341e-09, 1.4804e-32, 4.8410e-27, 1.4929e-06, 5.2128e-13,\n",
            "        4.5100e-13, 2.5405e-14, 1.8314e-19, 3.6285e-17, 7.2352e-26, 3.3251e-33,\n",
            "        4.1070e-22, 2.7534e-37, 1.4690e-28, 3.2592e-11, 4.5100e-13, 0.0000e+00,\n",
            "        1.2602e-23, 3.1489e-18, 3.9049e-12, 3.6285e-17, 2.3319e-11])\n",
            "*************** t  68\n",
            "ce_loss:  tensor([2.3842e-07, 6.0739e-02, 2.9563e-05, 1.3415e+01, 6.0739e-02, 7.6053e-05,\n",
            "        1.6009e+01, 1.6689e-06, 1.6014e+01, 3.9892e+00, 2.3842e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 3.0251e-03, 8.2244e-04, 1.2243e+01, 3.9339e-06,\n",
            "        7.6887e+00, 6.9208e+00, 1.8094e+01, -0.0000e+00, 6.0739e-02, 1.2910e-01,\n",
            "        9.3226e-04, -0.0000e+00, 7.2717e-06, 8.2244e-04, 1.7166e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([8.1564e-07, 1.1723e-13, 1.2289e-19, 2.3343e-41, 1.1723e-13, 1.7654e-18,\n",
            "        1.4473e-28, 1.0700e-09, 1.4574e-33, 4.4827e-28, 8.1564e-07, 2.9206e-13,\n",
            "        1.1723e-13, 5.7310e-15, 3.6478e-20, 8.2194e-18, 8.7597e-27, 4.5078e-34,\n",
            "        7.1327e-23, 2.5959e-38, 1.7337e-29, 1.4648e-11, 1.1723e-13, 0.0000e+00,\n",
            "        1.7001e-24, 9.5482e-19, 1.1068e-12, 8.2194e-18, 2.7879e-12],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.7324e-04, 0.0000e+00, 2.1573e-02, 4.0608e+02, 0.0000e+00, 3.1563e-02,\n",
            "        6.6212e+02, 7.2281e-04, 3.5603e+02, 3.4124e+02, 1.7324e-04, 2.4500e-08,\n",
            "        0.0000e+00, 4.1204e-06, 1.4340e+00, 8.9619e-01, 5.0504e+02, 1.6318e-03,\n",
            "        4.7300e+02, 5.7394e+02, 8.4450e+02, 4.5226e-07, 0.0000e+00, 4.4747e+01,\n",
            "        4.4552e-01, 1.7157e-06, 1.8983e-03, 8.9619e-01, 1.0794e-02])\n",
            "kde_grad  tensor([1.3570e-06, 4.5100e-13, 4.5562e-19, 1.9112e-40, 4.5100e-13, 7.2556e-18,\n",
            "        9.5170e-28, 2.0970e-09, 1.0854e-32, 2.7687e-27, 1.3570e-06, 7.0624e-13,\n",
            "        4.5100e-13, 2.0908e-14, 1.5916e-19, 3.4554e-17, 5.3994e-26, 2.8729e-33,\n",
            "        3.5085e-22, 1.9582e-37, 1.1522e-28, 3.4392e-11, 4.5100e-13, 0.0000e+00,\n",
            "        8.2156e-24, 3.7260e-18, 3.6476e-12, 3.4554e-17, 9.9708e-12])\n",
            "*************** t  69\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 4.4941e-05, 1.2697e+01, 6.0739e-02, 8.0940e-05,\n",
            "        1.4707e+01, 2.0266e-06, 1.5174e+01, 3.4931e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 3.5738e-03, 1.1515e-04, 1.4432e+01, 4.7684e-06,\n",
            "        7.3545e+00, 8.4274e+00, 1.6651e+01, -0.0000e+00, 6.0739e-02, 1.4700e-01,\n",
            "        1.0367e-03, -0.0000e+00, 4.1723e-06, 1.1515e-04, 9.6559e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.0068e-06, 1.1723e-13, 8.8349e-20, 5.5535e-41, 1.1723e-13, 1.5017e-18,\n",
            "        1.4047e-28, 9.9177e-10, 4.1698e-33, 6.2519e-28, 1.0068e-06, 2.4032e-13,\n",
            "        1.1723e-13, 3.3293e-15, 2.8219e-20, 5.7412e-18, 4.9354e-27, 3.5268e-34,\n",
            "        8.5874e-23, 1.8341e-38, 7.6802e-30, 1.0401e-11, 1.1723e-13, 0.0000e+00,\n",
            "        9.4391e-25, 8.0712e-19, 7.3350e-13, 5.7412e-18, 3.8241e-12],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([5.9471e-05, 0.0000e+00, 3.9934e-02, 6.5347e+02, 0.0000e+00, 2.6721e-02,\n",
            "        4.4805e+02, 1.5689e-03, 8.1025e+02, 5.0489e+02, 5.9471e-05, 3.3299e-08,\n",
            "        0.0000e+00, 4.3548e-06, 2.1039e+00, 4.9406e-02, 6.8215e+02, 1.6536e-03,\n",
            "        5.4483e+02, 6.7709e+02, 3.9265e+02, 3.3719e-07, 0.0000e+00, 5.5938e+01,\n",
            "        5.6703e-01, 1.2909e-06, 1.5003e-03, 4.9406e-02, 3.2769e-03])\n",
            "kde_grad  tensor([1.5498e-06, 4.5100e-13, 3.3860e-19, 4.5156e-40, 4.5100e-13, 6.1103e-18,\n",
            "        9.0594e-28, 1.9805e-09, 3.0010e-32, 3.7325e-27, 1.5498e-06, 5.8426e-13,\n",
            "        4.5100e-13, 1.2719e-14, 1.2247e-19, 2.3884e-17, 3.1011e-26, 2.2569e-33,\n",
            "        4.2248e-22, 1.4199e-37, 5.0295e-29, 2.4670e-11, 4.5100e-13, 0.0000e+00,\n",
            "        4.6137e-24, 3.1712e-18, 2.4938e-12, 2.3884e-17, 1.3036e-11])\n",
            "*************** t  70\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 2.1934e-05, 1.4217e+01, 6.0739e-02, 5.6861e-05,\n",
            "        1.2417e+01, 1.6689e-06, 1.5349e+01, 4.0409e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 7.0033e-03, 5.1974e-05, 1.1922e+01, 3.9339e-06,\n",
            "        9.1735e+00, 6.7555e+00, 1.4431e+01, -0.0000e+00, 6.0739e-02, 1.1514e-01,\n",
            "        6.8486e-04, -0.0000e+00, 3.5763e-06, 5.1974e-05, 2.7895e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.0119e-06, 1.1723e-13, 9.1581e-20, 3.7692e-41, 1.1723e-13, 1.3896e-18,\n",
            "        2.1747e-28, 1.0712e-09, 2.1489e-33, 4.2627e-28, 1.0119e-06, 2.0501e-13,\n",
            "        1.1723e-13, 2.3560e-15, 2.5121e-20, 5.1387e-18, 4.2414e-27, 4.2559e-34,\n",
            "        5.4879e-23, 1.3451e-38, 2.0721e-29, 1.0129e-11, 1.1723e-13, 0.0000e+00,\n",
            "        7.9849e-25, 5.6663e-19, 5.0117e-13, 5.1387e-18, 2.1406e-12],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([8.2896e-05, 0.0000e+00, 1.7848e-02, 5.7890e+02, 0.0000e+00, 8.4188e-03,\n",
            "        3.7745e+02, 7.9087e-04, 3.7746e+02, 4.1837e+02, 8.2896e-05, 1.4577e-08,\n",
            "        0.0000e+00, 1.3785e-06, 4.3373e+00, 1.6070e-02, 3.4337e+02, 1.5154e-03,\n",
            "        6.8424e+02, 4.0707e+02, 6.3307e+02, 2.9193e-07, 0.0000e+00, 3.2667e+01,\n",
            "        2.8703e-01, 1.5787e-06, 8.7666e-04, 1.6070e-02, 1.1330e-02])\n",
            "kde_grad  tensor([1.6255e-06, 4.5100e-13, 3.4099e-19, 3.0725e-40, 4.5100e-13, 5.5267e-18,\n",
            "        1.3570e-27, 2.1163e-09, 1.5738e-32, 2.5845e-27, 1.6255e-06, 4.9344e-13,\n",
            "        4.5100e-13, 8.8295e-15, 1.1234e-19, 2.0923e-17, 2.6352e-26, 2.7065e-33,\n",
            "        2.7920e-22, 1.0177e-37, 1.3130e-28, 2.3737e-11, 4.5100e-13, 0.0000e+00,\n",
            "        3.8891e-24, 2.2570e-18, 1.6792e-12, 2.0923e-17, 7.5750e-12])\n",
            "*************** t  71\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 2.5510e-05, 1.5082e+01, 6.0739e-02, 6.1987e-05,\n",
            "        1.4114e+01, 1.7881e-06, 1.5056e+01, 6.4101e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 1.7644e-03, 2.6092e-04, 1.0723e+01, 3.2186e-06,\n",
            "        8.4984e+00, 6.3412e+00, 1.7901e+01, -0.0000e+00, 6.0739e-02, 9.3886e-02,\n",
            "        7.2953e-04, -0.0000e+00, 3.0994e-06, 2.6092e-04, 7.6294e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.4407e-07, 1.1723e-13, 6.3495e-20, 2.3113e-41, 1.1723e-13, 5.6731e-19,\n",
            "        3.8852e-28, 9.1559e-10, 4.9896e-33, 3.4230e-28, 9.4407e-07, 1.0212e-13,\n",
            "        1.1723e-13, 1.1952e-15, 1.9348e-20, 3.6743e-18, 8.5774e-27, 2.6866e-34,\n",
            "        4.0190e-23, 2.5539e-38, 1.0736e-29, 8.2821e-12, 1.1723e-13, 0.0000e+00,\n",
            "        4.0644e-25, 6.1636e-19, 3.0585e-13, 3.6743e-18, 1.6571e-12],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.0324e-05, 0.0000e+00, 2.2692e-02, 6.1323e+02, 0.0000e+00, 2.1383e-02,\n",
            "        1.0037e+03, 1.1646e-03, 8.7984e+02, 6.4300e+02, 6.0324e-05, 4.9576e-08,\n",
            "        0.0000e+00, 4.7816e-06, 6.2216e-01, 1.5976e-01, 7.1892e+02, 1.2255e-03,\n",
            "        5.0305e+02, 8.2244e+02, 6.1614e+02, 1.4577e-07, 0.0000e+00, 3.3914e+01,\n",
            "        3.8790e-01, 2.3032e-06, 1.3976e-03, 1.5976e-01, 1.2522e-03])\n",
            "kde_grad  tensor([1.4442e-06, 4.5100e-13, 2.4198e-19, 1.9097e-40, 4.5100e-13, 2.3608e-18,\n",
            "        2.4074e-27, 1.8267e-09, 3.5645e-32, 2.1387e-27, 1.4442e-06, 2.5380e-13,\n",
            "        4.5100e-13, 4.7046e-15, 8.3677e-20, 1.5491e-17, 5.1174e-26, 1.7137e-33,\n",
            "        2.0681e-22, 1.9146e-37, 7.1141e-29, 1.9287e-11, 4.5100e-13, 0.0000e+00,\n",
            "        2.0123e-24, 2.4488e-18, 1.0679e-12, 1.5491e-17, 5.5430e-12])\n",
            "*************** t  72\n",
            "ce_loss:  tensor([2.3842e-07, 6.0739e-02, 2.0504e-05, 1.3138e+01, 6.0739e-02, 4.2557e-05,\n",
            "        1.3872e+01, 1.3113e-06, 1.5607e+01, 3.3667e+00, 2.3842e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 1.7455e-03, 3.8981e-05, 1.1318e+01, 3.4571e-06,\n",
            "        8.0341e+00, 7.3334e+00, 1.5193e+01, -0.0000e+00, 6.0739e-02, 1.5796e-01,\n",
            "        4.9007e-04, -0.0000e+00, 5.2452e-06, 3.8981e-05, 3.8981e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.7897e-07, 1.1723e-13, 5.7094e-20, 2.2810e-41, 1.1723e-13, 6.7104e-19,\n",
            "        1.7619e-28, 9.9156e-10, 2.0508e-33, 2.3990e-28, 9.7897e-07, 1.6639e-13,\n",
            "        1.1723e-13, 1.2165e-15, 1.4035e-20, 4.0952e-18, 4.6024e-27, 2.3073e-34,\n",
            "        3.9280e-23, 9.0870e-39, 8.3919e-30, 6.6011e-12, 1.1723e-13, 0.0000e+00,\n",
            "        3.1474e-25, 4.6868e-19, 4.7237e-13, 4.0952e-18, 5.0760e-13],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.8454e-04, 0.0000e+00, 1.4965e-02, 5.1208e+02, 0.0000e+00, 6.2844e-03,\n",
            "        3.7746e+02, 5.8056e-04, 3.9004e+02, 2.8099e+02, 1.8454e-04, 2.4121e-08,\n",
            "        0.0000e+00, 1.1663e-06, 9.5553e-01, 6.7022e-03, 3.3564e+02, 1.1328e-03,\n",
            "        4.1039e+02, 4.2080e+02, 4.4405e+02, 2.1116e-07, 0.0000e+00, 6.5347e+01,\n",
            "        2.5312e-01, 3.1461e-06, 2.2138e-03, 6.7022e-03, 4.0496e-02])\n",
            "kde_grad  tensor([1.5911e-06, 4.5100e-13, 2.1444e-19, 1.8383e-40, 4.5100e-13, 2.6636e-18,\n",
            "        1.1380e-27, 1.9420e-09, 1.5098e-32, 1.4411e-27, 1.5911e-06, 4.0447e-13,\n",
            "        4.5100e-13, 4.5848e-15, 6.1820e-20, 1.6022e-17, 2.8125e-26, 1.4768e-33,\n",
            "        1.9593e-22, 6.9617e-38, 5.3493e-29, 1.5718e-11, 4.5100e-13, 0.0000e+00,\n",
            "        1.5505e-24, 1.8861e-18, 1.6127e-12, 1.6022e-17, 1.8937e-12])\n",
            "*************** t  73\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 4.2676e-05, 1.5477e+01, 6.0739e-02, 3.7312e-05,\n",
            "        1.4050e+01, 2.6226e-06, 1.5053e+01, 2.8120e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 3.2597e-03, 1.5603e-03, 1.0484e+01, 2.6226e-06,\n",
            "        6.3145e+00, 6.3619e+00, 1.4149e+01, -0.0000e+00, 6.0739e-02, 9.3440e-02,\n",
            "        6.0087e-04, -0.0000e+00, 2.5674e-04, 1.5603e-03, 6.4373e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.0936e-06, 1.1723e-13, 4.9633e-20, 1.6405e-41, 1.1723e-13, 4.4964e-19,\n",
            "        3.1009e-28, 7.6434e-10, 4.9741e-33, 3.6890e-28, 1.0936e-06, 1.6977e-13,\n",
            "        1.1723e-13, 6.5891e-16, 6.9002e-21, 2.5483e-18, 8.1218e-27, 1.2607e-34,\n",
            "        5.5272e-23, 1.6513e-38, 1.6160e-29, 7.2199e-12, 1.1723e-13, 0.0000e+00,\n",
            "        2.4713e-25, 3.7738e-19, 4.3264e-13, 2.5483e-18, 4.5058e-13],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([4.8506e-05, 0.0000e+00, 4.6208e-02, 8.2684e+02, 0.0000e+00, 1.1977e-02,\n",
            "        8.4733e+02, 2.0759e-03, 1.0239e+03, 4.6973e+02, 4.8506e-05, 1.1500e-08,\n",
            "        0.0000e+00, 2.4460e-06, 1.9761e+00, 2.0171e+00, 7.3779e+02, 9.8439e-04,\n",
            "        2.8429e+02, 6.5407e+02, 6.4674e+02, 1.6341e-07, 0.0000e+00, 2.4183e+01,\n",
            "        3.4502e-01, 1.8867e-06, 2.2611e-01, 2.0171e+00, 1.0894e-03])\n",
            "kde_grad  tensor([1.6460e-06, 4.5100e-13, 1.9148e-19, 1.3521e-40, 4.5100e-13, 1.8836e-18,\n",
            "        1.9255e-27, 1.5615e-09, 3.5557e-32, 2.1954e-27, 1.6460e-06, 4.0733e-13,\n",
            "        4.5100e-13, 2.5856e-15, 3.0771e-20, 1.0841e-17, 4.8041e-26, 8.0960e-34,\n",
            "        2.6872e-22, 1.2439e-37, 1.0166e-28, 1.6978e-11, 4.5100e-13, 0.0000e+00,\n",
            "        1.2297e-24, 1.5013e-18, 1.5967e-12, 1.0841e-17, 1.5400e-12])\n",
            "*************** t  74\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 1.5497e-05, 1.3533e+01, 6.0739e-02, 2.5749e-05,\n",
            "        1.3586e+01, 1.4305e-06, 1.5710e+01, 4.1855e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 1.7571e-03, 3.2901e-05, 1.1232e+01, 3.2186e-06,\n",
            "        6.8870e+00, 7.6255e+00, 1.6670e+01, -0.0000e+00, 6.0739e-02, 8.5987e-02,\n",
            "        3.5089e-04, -0.0000e+00, 5.6028e-06, 3.2901e-05, 3.2663e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([8.6534e-07, 1.1723e-13, 4.6595e-20, 9.0748e-42, 1.1723e-13, 3.3999e-19,\n",
            "        1.6954e-28, 7.2792e-10, 2.0099e-33, 2.6366e-28, 8.6534e-07, 1.3524e-13,\n",
            "        1.1723e-13, 7.2434e-16, 9.9963e-21, 1.5034e-18, 3.7972e-27, 1.2352e-34,\n",
            "        8.4402e-23, 6.7074e-39, 1.0334e-29, 5.8823e-12, 1.1723e-13, 0.0000e+00,\n",
            "        1.1479e-25, 2.8782e-19, 6.5596e-13, 1.5034e-18, 1.2724e-13],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([9.1393e-05, 0.0000e+00, 1.2060e-02, 5.3192e+02, 0.0000e+00, 4.8948e-03,\n",
            "        3.7746e+02, 6.8567e-04, 3.7746e+02, 5.3028e+02, 9.1393e-05, 5.8223e-08,\n",
            "        0.0000e+00, 8.0593e-07, 9.3018e-01, 7.8222e-03, 3.4337e+02, 1.0056e-03,\n",
            "        7.0676e+02, 6.1654e+02, 6.0587e+02, 2.3191e-07, 0.0000e+00, 3.1291e+01,\n",
            "        2.0751e-01, 1.3737e-06, 1.1234e-03, 7.8222e-03, 2.9907e-02])\n",
            "kde_grad  tensor([1.3966e-06, 4.5100e-13, 1.7373e-19, 7.3609e-41, 4.5100e-13, 1.3978e-18,\n",
            "        1.0892e-27, 1.4613e-09, 1.4828e-32, 1.5842e-27, 1.3966e-06, 3.3228e-13,\n",
            "        4.5100e-13, 2.7089e-15, 4.4046e-20, 5.9357e-18, 2.3333e-26, 7.9493e-34,\n",
            "        4.0814e-22, 5.1239e-38, 6.6617e-29, 1.3905e-11, 4.5100e-13, 0.0000e+00,\n",
            "        5.6985e-25, 1.1532e-18, 2.1230e-12, 5.9357e-18, 4.8434e-13])\n",
            "*************** t  75\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 1.5020e-05, 1.5331e+01, 6.0739e-02, 2.9802e-05,\n",
            "        1.4096e+01, 1.7881e-06, 1.4970e+01, 5.2091e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 2.5556e-03, 1.8358e-05, 1.0480e+01, 2.6226e-06,\n",
            "        7.9924e+00, 7.5466e+00, 1.6674e+01, -0.0000e+00, 6.0739e-02, 9.3538e-02,\n",
            "        2.9905e-04, -0.0000e+00, 4.2915e-06, 1.8358e-05, 5.4836e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.8856e-07, 1.1723e-13, 3.3121e-20, 5.7902e-42, 1.1723e-13, 2.5539e-19,\n",
            "        3.0595e-28, 6.3393e-10, 4.3489e-33, 1.9480e-28, 9.8856e-07, 2.1390e-13,\n",
            "        1.1723e-13, 2.7425e-16, 6.4439e-21, 8.7238e-19, 7.3419e-27, 7.9760e-35,\n",
            "        4.6861e-23, 4.7235e-39, 6.3421e-30, 5.0730e-12, 1.1723e-13, 0.0000e+00,\n",
            "        7.1214e-26, 2.4707e-19, 3.0329e-13, 8.7238e-19, 2.3423e-13],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([5.3225e-05, 0.0000e+00, 1.3273e-02, 6.4656e+02, 0.0000e+00, 9.5678e-03,\n",
            "        1.0074e+03, 1.2227e-03, 7.4714e+02, 5.0563e+02, 5.3225e-05, 1.7197e-08,\n",
            "        0.0000e+00, 1.1991e-06, 1.5379e+00, 7.7235e-03, 5.2908e+02, 8.8919e-04,\n",
            "        4.9892e+02, 6.7963e+02, 6.4977e+02, 1.2011e-07, 0.0000e+00, 2.6821e+01,\n",
            "        1.7166e-01, 4.4609e-06, 1.9664e-03, 7.7235e-03, 8.9839e-04])\n",
            "kde_grad  tensor([1.5063e-06, 4.5100e-13, 1.2608e-19, 4.7612e-41, 4.5100e-13, 1.0840e-18,\n",
            "        1.8933e-27, 1.2830e-09, 3.1027e-32, 1.2088e-27, 1.5063e-06, 5.0855e-13,\n",
            "        4.5100e-13, 1.0755e-15, 2.8658e-20, 3.5661e-18, 4.3469e-26, 5.1342e-34,\n",
            "        2.3644e-22, 3.6420e-38, 4.1499e-29, 1.2051e-11, 4.5100e-13, 0.0000e+00,\n",
            "        3.5462e-25, 1.0033e-18, 1.0636e-12, 3.5661e-18, 8.0049e-13])\n",
            "*************** t  76\n",
            "ce_loss:  tensor([3.5763e-07, 6.0739e-02, 1.0967e-05, 1.2593e+01, 6.0739e-02, 2.0504e-05,\n",
            "        1.3643e+01, 1.0729e-06, 1.6051e+01, 3.8934e+00, 3.5763e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 8.3817e-04, 1.6689e-05, 1.1666e+01, 3.0994e-06,\n",
            "        9.1573e+00, 7.2156e+00, 1.5017e+01, -0.0000e+00, 6.0739e-02, 7.9438e-02,\n",
            "        2.5305e-04, -0.0000e+00, 2.8610e-06, 1.6689e-05, 4.2557e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.4802e-07, 1.1723e-13, 2.9207e-20, 6.1531e-42, 1.1723e-13, 2.4891e-19,\n",
            "        1.3683e-28, 6.8537e-10, 2.9729e-33, 1.6353e-28, 9.4802e-07, 1.0739e-13,\n",
            "        1.1723e-13, 2.5438e-16, 9.1629e-21, 6.8541e-19, 6.2527e-27, 1.0808e-34,\n",
            "        4.4324e-23, 2.6866e-39, 4.4006e-30, 4.1160e-12, 1.1723e-13, 0.0000e+00,\n",
            "        3.6795e-26, 2.7196e-19, 2.2316e-13, 6.8541e-19, 6.3781e-14],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.8293e-04, 0.0000e+00, 6.7780e-03, 5.3192e+02, 0.0000e+00, 6.5769e-03,\n",
            "        3.7746e+02, 5.4324e-04, 5.0381e+02, 4.6858e+02, 2.8293e-04, 2.1346e-08,\n",
            "        0.0000e+00, 5.8190e-07, 4.4789e-01, 3.7141e-03, 5.0504e+02, 1.1262e-03,\n",
            "        5.9951e+02, 5.7482e+02, 3.7124e+02, 1.1166e-07, 0.0000e+00, 2.7636e+01,\n",
            "        1.2789e-01, 9.3282e-07, 5.6770e-04, 3.7141e-03, 4.4101e-02])\n",
            "kde_grad  tensor([1.5568e-06, 4.5100e-13, 1.0999e-19, 4.9759e-41, 4.5100e-13, 1.0470e-18,\n",
            "        8.8318e-28, 1.3581e-09, 2.1576e-32, 9.8234e-28, 1.5568e-06, 2.6177e-13,\n",
            "        4.5100e-13, 9.7900e-16, 3.9789e-20, 2.7801e-18, 3.7788e-26, 6.9643e-34,\n",
            "        2.2465e-22, 2.0598e-38, 2.7927e-29, 9.7996e-12, 4.5100e-13, 0.0000e+00,\n",
            "        1.8415e-25, 1.0636e-18, 7.3258e-13, 2.7801e-18, 2.4628e-13])\n",
            "*************** t  77\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 7.4265e-05, 1.5250e+01, 6.0739e-02, 5.5312e-05,\n",
            "        1.4006e+01, 2.6226e-06, 1.9314e+01, 5.3801e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 2.5852e-03, 3.1590e-05, 1.4237e+01, 3.5763e-06,\n",
            "        7.3039e+00, 7.9665e+00, 1.3892e+01, -0.0000e+00, 6.0739e-02, 8.6903e-02,\n",
            "        2.8153e-04, -0.0000e+00, 5.3644e-06, 3.1590e-05, 5.0068e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.2289e-07, 1.1723e-13, 2.3322e-20, 3.6364e-42, 1.1723e-13, 1.6608e-19,\n",
            "        2.3057e-28, 5.1243e-10, 2.2476e-33, 1.0470e-28, 9.2289e-07, 1.4471e-13,\n",
            "        1.1723e-13, 9.9487e-17, 4.1455e-21, 4.1363e-19, 3.2839e-27, 7.6122e-35,\n",
            "        2.5610e-23, 2.2213e-39, 1.0384e-29, 2.7884e-12, 1.1723e-13, 0.0000e+00,\n",
            "        2.1330e-26, 1.4936e-19, 9.2272e-14, 4.1363e-19, 8.9879e-14],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([4.9526e-05, 0.0000e+00, 7.7158e-02, 7.1322e+02, 0.0000e+00, 2.9673e-02,\n",
            "        7.1477e+02, 2.0725e-03, 8.6085e+02, 5.6195e+02, 4.9526e-05, 2.9106e-08,\n",
            "        0.0000e+00, 4.9241e-07, 1.7577e+00, 2.0061e-02, 7.0851e+02, 1.4762e-03,\n",
            "        3.6099e+02, 6.2556e+02, 8.4898e+02, 3.2103e-07, 0.0000e+00, 2.4055e+01,\n",
            "        1.6321e-01, 1.7040e-06, 4.3003e-03, 2.0061e-02, 8.2075e-04])\n",
            "kde_grad  tensor([1.4013e-06, 4.5100e-13, 9.1205e-20, 2.9985e-41, 4.5100e-13, 7.1682e-19,\n",
            "        1.4307e-27, 1.0518e-09, 1.6699e-32, 6.5711e-28, 1.4013e-06, 3.5114e-13,\n",
            "        4.5100e-13, 3.9286e-16, 1.8538e-20, 1.7281e-18, 2.0464e-26, 4.9323e-34,\n",
            "        1.2762e-22, 1.7247e-38, 6.4889e-29, 6.8579e-12, 4.5100e-13, 0.0000e+00,\n",
            "        1.0830e-25, 6.0423e-19, 3.3051e-13, 1.7281e-18, 3.1341e-13])\n",
            "*************** t  78\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 1.3590e-05, 1.2417e+01, 6.0739e-02, 1.6570e-05,\n",
            "        1.4133e+01, 1.4305e-06, 1.5571e+01, 3.4129e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 6.5353e-04, 1.1444e-05, 1.1601e+01, 3.0994e-06,\n",
            "        6.5266e+00, 6.3244e+00, 1.5458e+01, -0.0000e+00, 6.0739e-02, 7.0812e-02,\n",
            "        2.2897e-04, -0.0000e+00, 2.3842e-06, 1.1444e-05, 3.5524e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([8.3642e-07, 1.1723e-13, 2.4485e-20, 2.5237e-42, 1.1723e-13, 2.0112e-19,\n",
            "        1.5770e-28, 4.8074e-10, 1.2480e-33, 7.2620e-29, 8.3642e-07, 1.5773e-13,\n",
            "        1.1723e-13, 5.4090e-17, 6.2702e-21, 4.7918e-19, 3.0746e-27, 6.3308e-35,\n",
            "        4.1211e-23, 1.5804e-39, 3.1183e-30, 3.9413e-12, 1.1723e-13, 0.0000e+00,\n",
            "        1.2419e-26, 1.4967e-19, 1.1167e-13, 4.7918e-19, 2.4931e-14],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([8.0083e-05, 0.0000e+00, 1.0152e-02, 3.8596e+02, 0.0000e+00, 2.7769e-03,\n",
            "        6.7371e+02, 6.6980e-04, 3.6863e+02, 2.7633e+02, 8.0083e-05, 1.3948e-08,\n",
            "        0.0000e+00, 2.2795e-07, 2.4505e-01, 3.6784e-03, 3.6974e+02, 9.1602e-04,\n",
            "        5.9198e+02, 5.9137e+02, 3.9329e+02, 9.3641e-08, 0.0000e+00, 2.4267e+01,\n",
            "        1.1160e-01, 6.8435e-07, 6.0974e-04, 3.6784e-03, 3.3309e-02])\n",
            "kde_grad  tensor([1.3176e-06, 4.5100e-13, 9.2022e-20, 1.9966e-41, 4.5100e-13, 8.3888e-19,\n",
            "        1.0063e-27, 9.7290e-10, 9.1434e-33, 4.3688e-28, 1.3176e-06, 3.7400e-13,\n",
            "        4.5100e-13, 2.1411e-16, 2.7160e-20, 1.9215e-18, 1.9016e-26, 4.0969e-34,\n",
            "        1.9852e-22, 1.2025e-38, 2.0219e-29, 9.2962e-12, 4.5100e-13, 0.0000e+00,\n",
            "        6.3274e-26, 5.9364e-19, 3.6621e-13, 1.9215e-18, 9.7593e-14])\n",
            "*************** t  79\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 1.8835e-05, 1.2286e+01, 6.0739e-02, 1.9908e-05,\n",
            "        1.6520e+01, 1.3113e-06, 1.4702e+01, 2.2485e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 1.1030e-03, 8.7022e-06, 1.0157e+01, 2.3842e-06,\n",
            "        8.2546e+00, 7.8352e+00, 1.3815e+01, -0.0000e+00, 6.0739e-02, 8.9538e-02,\n",
            "        2.5019e-04, 2.3842e-07, 1.5497e-06, 8.7022e-06, 4.5299e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.0667e-07, 1.1723e-13, 1.7663e-20, 6.0816e-42, 1.1723e-13, 1.3827e-19,\n",
            "        9.1885e-29, 4.3983e-10, 2.9085e-33, 1.0414e-28, 7.0667e-07, 8.4478e-14,\n",
            "        1.1723e-13, 1.9085e-17, 4.9307e-21, 2.8989e-19, 5.5687e-27, 3.0196e-35,\n",
            "        2.5128e-23, 1.2083e-39, 8.1051e-30, 2.6026e-12, 1.1723e-13, 0.0000e+00,\n",
            "        1.0618e-26, 1.0720e-19, 9.6528e-14, 2.8989e-19, 4.6902e-14],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.4680e-05, 0.0000e+00, 1.8001e-02, 7.1549e+02, 0.0000e+00, 7.2431e-03,\n",
            "        6.7455e+02, 7.6272e-04, 6.0407e+02, 2.5490e+02, 1.4680e-05, 5.3341e-08,\n",
            "        0.0000e+00, 1.3205e-06, 5.9499e-01, 2.8962e-03, 6.1525e+02, 7.9274e-04,\n",
            "        6.3752e+02, 6.7972e+02, 7.0567e+02, 8.0205e-08, 0.0000e+00, 2.8267e+01,\n",
            "        1.4668e-01, 2.4556e-04, 4.5832e-04, 2.8962e-03, 7.4522e-04])\n",
            "kde_grad  tensor([1.0732e-06, 4.5100e-13, 6.8322e-20, 4.8727e-41, 4.5100e-13, 5.9431e-19,\n",
            "        5.9463e-28, 8.8340e-10, 2.0721e-32, 6.2166e-28, 1.0732e-06, 2.1056e-13,\n",
            "        4.5100e-13, 7.8119e-17, 2.1837e-20, 1.1862e-18, 3.2934e-26, 1.9638e-34,\n",
            "        1.2686e-22, 9.3831e-39, 5.0757e-29, 6.2420e-12, 4.5100e-13, 0.0000e+00,\n",
            "        5.4545e-26, 4.5318e-19, 3.3137e-13, 1.1862e-18, 1.6443e-13])\n",
            "*************** t  80\n",
            "ce_loss:  tensor([1.1921e-07, 6.0739e-02, 1.1444e-05, 1.2573e+01, 6.0739e-02, 1.3828e-05,\n",
            "        1.3735e+01, 1.5497e-06, 1.5645e+01, 4.0973e+00, 1.1921e-07, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 1.4935e-03, 1.5020e-05, 1.1465e+01, 2.3842e-06,\n",
            "        8.5531e+00, 6.8366e+00, 1.5048e+01, -0.0000e+00, 6.0739e-02, 6.5681e-02,\n",
            "        1.6974e-04, -0.0000e+00, 1.1921e-06, 1.5020e-05, 3.3616e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.7399e-07, 1.1723e-13, 1.4538e-20, 2.1636e-42, 1.1723e-13, 9.9349e-20,\n",
            "        8.2302e-29, 4.1303e-10, 3.2612e-33, 1.0820e-28, 5.7399e-07, 1.4332e-13,\n",
            "        1.1723e-13, 1.9099e-17, 2.4404e-21, 2.4934e-19, 3.3971e-27, 2.7867e-35,\n",
            "        1.7419e-23, 8.4926e-40, 3.3705e-30, 2.9827e-12, 1.1723e-13, 0.0000e+00,\n",
            "        6.4073e-27, 1.7341e-19, 4.9310e-14, 2.4934e-19, 1.2662e-14],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.2757e-05, 0.0000e+00, 9.6789e-03, 4.0608e+02, 0.0000e+00, 3.0772e-03,\n",
            "        4.5584e+02, 9.4102e-04, 6.6504e+02, 7.3051e+02, 6.2757e-05, 1.8240e-08,\n",
            "        0.0000e+00, 1.3170e-07, 9.7952e-01, 6.2948e-03, 4.7169e+02, 9.8753e-04,\n",
            "        5.6262e+02, 4.7107e+02, 5.0710e+02, 1.8517e-07, 0.0000e+00, 1.7770e+01,\n",
            "        9.1478e-02, 7.3945e-07, 2.5454e-04, 6.2948e-03, 3.4103e-02])\n",
            "kde_grad  tensor([9.1497e-07, 4.5100e-13, 5.5150e-20, 1.7205e-41, 4.5100e-13, 4.2330e-19,\n",
            "        5.2549e-28, 8.4184e-10, 2.3206e-32, 6.5197e-28, 9.1497e-07, 3.4431e-13,\n",
            "        4.5100e-13, 7.5522e-17, 1.0979e-20, 1.0287e-18, 2.0426e-26, 1.8129e-34,\n",
            "        8.9050e-23, 6.5366e-39, 2.1352e-29, 7.2886e-12, 4.5100e-13, 0.0000e+00,\n",
            "        3.2877e-26, 6.7417e-19, 1.6908e-13, 1.0287e-18, 5.0009e-14])\n",
            "*************** t  81\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 7.8678e-06, 1.2190e+01, 6.0739e-02, 3.5643e-05,\n",
            "        1.2633e+01, 1.4305e-06, 1.8322e+01, 3.7643e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 6.0957e-04, 1.6332e-05, 1.4262e+01, 2.3842e-06,\n",
            "        8.6121e+00, 5.4691e+00, 1.7880e+01, -0.0000e+00, 6.0739e-02, 1.0901e-01,\n",
            "        2.3148e-04, -0.0000e+00, 1.0848e-05, 1.6332e-05, 4.4107e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([6.5773e-07, 1.1723e-13, 9.5352e-21, 5.0755e-42, 1.1723e-13, 6.9179e-20,\n",
            "        1.0730e-28, 3.6372e-10, 1.8712e-33, 6.4405e-29, 6.5773e-07, 7.2861e-14,\n",
            "        1.1723e-13, 8.0543e-18, 2.8769e-21, 1.5174e-19, 2.0770e-27, 2.2883e-35,\n",
            "        1.2636e-23, 1.0844e-39, 2.2564e-30, 2.5329e-12, 1.1723e-13, 0.0000e+00,\n",
            "        5.1428e-27, 9.3036e-20, 2.7860e-14, 1.5174e-19, 1.5210e-14],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.2720e-05, 0.0000e+00, 6.3211e-03, 8.1903e+02, 0.0000e+00, 1.9674e-02,\n",
            "        5.5818e+02, 7.2405e-04, 6.8909e+02, 3.4011e+02, 1.2720e-05, 2.9956e-08,\n",
            "        0.0000e+00, 1.2690e-06, 2.9305e-01, 5.9055e-03, 8.1355e+02, 1.0129e-03,\n",
            "        5.6067e+02, 6.1078e+02, 8.0173e+02, 8.5668e-08, 0.0000e+00, 4.0948e+01,\n",
            "        1.1181e-01, 8.6676e-07, 1.0071e-02, 5.9055e-03, 7.4385e-04])\n",
            "kde_grad  tensor([9.9507e-07, 4.5100e-13, 3.6642e-20, 4.0687e-41, 4.5100e-13, 3.0345e-19,\n",
            "        6.6334e-28, 7.3611e-10, 1.3809e-32, 4.0437e-28, 9.9507e-07, 1.8033e-13,\n",
            "        4.5100e-13, 3.3434e-17, 1.2658e-20, 6.3876e-19, 1.2960e-26, 1.4896e-34,\n",
            "        6.4759e-23, 8.2377e-39, 1.4866e-29, 6.0176e-12, 4.5100e-13, 0.0000e+00,\n",
            "        2.6596e-26, 3.7246e-19, 1.0159e-13, 6.3876e-19, 5.4809e-14])\n",
            "*************** t  82\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 1.0490e-05, 1.2669e+01, 6.0739e-02, 1.1086e-05,\n",
            "        1.3138e+01, 1.0729e-06, 1.6046e+01, 3.3031e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 2.1689e-03, 1.0490e-05, 1.1322e+01, 2.6226e-06,\n",
            "        6.6583e+00, 6.8347e+00, 1.5369e+01, -0.0000e+00, 6.0739e-02, 6.8252e-02,\n",
            "        1.6688e-04, -0.0000e+00, 1.3113e-06, 1.0490e-05, 2.7179e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.2937e-07, 1.1723e-13, 7.8523e-21, 1.8988e-42, 1.1723e-13, 5.3771e-20,\n",
            "        1.1561e-28, 3.7957e-10, 1.2484e-33, 6.8435e-29, 5.2937e-07, 1.2592e-13,\n",
            "        1.1723e-13, 7.8818e-18, 1.5104e-21, 1.0172e-19, 1.1574e-27, 2.5284e-35,\n",
            "        1.4557e-23, 7.6628e-40, 8.5807e-31, 1.7426e-12, 1.1723e-13, 0.0000e+00,\n",
            "        3.3898e-27, 7.8816e-20, 4.6005e-14, 1.0172e-19, 4.2552e-15],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.2247e-05, 0.0000e+00, 8.9645e-03, 4.1286e+02, 0.0000e+00, 2.3369e-03,\n",
            "        7.3094e+02, 5.9466e-04, 5.0381e+02, 6.9429e+02, 2.2247e-05, 1.3785e-08,\n",
            "        0.0000e+00, 1.3872e-07, 1.4291e+00, 5.9570e-03, 3.1181e+02, 8.3797e-04,\n",
            "        5.0290e+02, 6.4545e+02, 3.7922e+02, 7.2749e-08, 0.0000e+00, 2.2400e+01,\n",
            "        1.1528e-01, 5.6161e-07, 3.1165e-04, 5.9570e-03, 2.0587e-02])\n",
            "kde_grad  tensor([8.4084e-07, 4.5100e-13, 3.0301e-20, 1.5184e-41, 4.5100e-13, 2.3007e-19,\n",
            "        7.1417e-28, 7.6351e-10, 9.0382e-33, 4.1196e-28, 8.4084e-07, 2.9985e-13,\n",
            "        4.5100e-13, 3.1375e-17, 6.8647e-21, 4.2058e-19, 7.1415e-27, 1.6463e-34,\n",
            "        7.2263e-23, 5.8460e-39, 5.5728e-30, 4.1904e-12, 4.5100e-13, 0.0000e+00,\n",
            "        1.7601e-26, 3.1393e-19, 1.5487e-13, 4.2058e-19, 1.6998e-14])\n",
            "*************** t  83\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 7.0333e-06, 1.2258e+01, 6.0739e-02, 1.8477e-05,\n",
            "        1.5682e+01, 1.4305e-06, 1.8268e+01, 3.4275e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 5.5822e-04, 9.2983e-06, 1.0080e+01, 2.1458e-06,\n",
            "        7.4965e+00, 7.0863e+00, 1.3407e+01, -0.0000e+00, 6.0739e-02, 8.8089e-02,\n",
            "        1.1741e-04, -0.0000e+00, 2.1458e-06, 9.2983e-06, 4.4107e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.8201e-07, 1.1723e-13, 4.5895e-21, 5.2381e-42, 1.1723e-13, 4.1230e-20,\n",
            "        5.9828e-29, 3.2547e-10, 9.3013e-34, 3.4315e-29, 5.8201e-07, 6.6289e-14,\n",
            "        1.1723e-13, 2.5408e-18, 1.9317e-21, 8.6537e-20, 2.6490e-27, 1.1229e-35,\n",
            "        1.2200e-23, 4.9125e-40, 2.3978e-30, 2.1124e-12, 1.1723e-13, 0.0000e+00,\n",
            "        1.7700e-27, 4.3095e-20, 2.2874e-14, 8.6537e-20, 7.7222e-15],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.5963e-05, 0.0000e+00, 5.8026e-03, 8.2955e+02, 0.0000e+00, 8.8787e-03,\n",
            "        6.6875e+02, 7.8527e-04, 8.5048e+02, 2.9934e+02, 1.5963e-05, 3.1722e-08,\n",
            "        0.0000e+00, 4.4411e-07, 3.0605e-01, 2.9092e-03, 5.6590e+02, 7.1425e-04,\n",
            "        4.1030e+02, 6.3839e+02, 6.9958e+02, 8.0009e-08, 0.0000e+00, 3.0331e+01,\n",
            "        7.0585e-02, 1.0059e-06, 1.6849e-03, 2.9092e-03, 7.7322e-04])\n",
            "kde_grad  tensor([8.9171e-07, 4.5100e-13, 1.7694e-20, 4.1790e-41, 4.5100e-13, 1.8117e-19,\n",
            "        3.8434e-28, 6.5247e-10, 6.8997e-33, 2.1370e-28, 8.9171e-07, 1.6483e-13,\n",
            "        4.5100e-13, 1.0532e-17, 8.5420e-21, 3.5304e-19, 1.5745e-26, 7.3643e-35,\n",
            "        6.0679e-23, 3.8335e-39, 1.5135e-29, 5.0112e-12, 4.5100e-13, 0.0000e+00,\n",
            "        9.1940e-27, 1.7498e-19, 8.1345e-14, 3.5304e-19, 2.8298e-14])\n",
            "*************** t  84\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 8.5830e-06, 1.2889e+01, 6.0739e-02, 9.7751e-06,\n",
            "        1.3561e+01, 2.3842e-06, 1.5930e+01, 3.1959e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 1.9001e-03, 5.1260e-06, 1.1415e+01, 2.3842e-06,\n",
            "        5.7497e+00, 6.2826e+00, 1.4882e+01, -0.0000e+00, 6.0739e-02, 6.8215e-02,\n",
            "        1.1241e-04, -0.0000e+00, 1.6689e-06, 5.1260e-06, 1.3709e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.1271e-07, 1.1723e-13, 3.3328e-21, 1.6409e-42, 1.1723e-13, 4.9922e-20,\n",
            "        5.1023e-29, 3.1569e-10, 4.5866e-34, 3.7821e-29, 5.1271e-07, 1.2578e-13,\n",
            "        1.1723e-13, 2.4633e-18, 8.5017e-22, 5.3653e-20, 1.9981e-27, 1.1150e-35,\n",
            "        1.6099e-23, 4.3358e-40, 9.3978e-31, 1.2247e-12, 1.1723e-13, 0.0000e+00,\n",
            "        1.2866e-27, 6.8367e-20, 3.2126e-14, 5.3653e-20, 2.3130e-15],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.3034e-05, 0.0000e+00, 8.0195e-03, 4.0608e+02, 0.0000e+00, 2.1693e-03,\n",
            "        3.7746e+02, 1.4840e-03, 3.9004e+02, 6.5817e+02, 1.3034e-05, 1.4249e-08,\n",
            "        0.0000e+00, 2.1211e-07, 1.2612e+00, 2.2354e-03, 5.6797e+02, 1.1094e-03,\n",
            "        2.8277e+02, 5.9133e+02, 5.0710e+02, 1.7782e-07, 0.0000e+00, 2.0149e+01,\n",
            "        5.5635e-02, 4.6080e-07, 4.7236e-04, 2.2354e-03, 9.0290e-03])\n",
            "kde_grad  tensor([7.9883e-07, 4.5100e-13, 1.2969e-20, 1.2715e-41, 4.5100e-13, 2.1417e-19,\n",
            "        3.2245e-28, 6.5280e-10, 3.3540e-33, 2.2849e-28, 7.9883e-07, 3.0000e-13,\n",
            "        4.5100e-13, 1.0006e-17, 3.8954e-21, 2.1730e-19, 1.1975e-26, 7.3099e-35,\n",
            "        7.8029e-23, 3.3055e-39, 6.0035e-30, 3.0234e-12, 4.5100e-13, 0.0000e+00,\n",
            "        6.7277e-27, 2.6786e-19, 1.1024e-13, 2.1730e-19, 9.2939e-15])\n",
            "*************** t  85\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 6.3181e-06, 1.2174e+01, 6.0739e-02, 1.8358e-05,\n",
            "        1.2069e+01, 1.4305e-06, 1.4130e+01, 3.9965e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 5.5488e-04, 8.3446e-06, 1.2834e+01, 2.7418e-06,\n",
            "        6.6673e+00, 7.3477e+00, 1.7390e+01, -0.0000e+00, 6.0739e-02, 5.5724e-02,\n",
            "        1.2981e-04, -0.0000e+00, 1.1921e-06, 8.3446e-06, 3.6955e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([3.8782e-07, 1.1723e-13, 2.7949e-21, 3.7471e-42, 1.1723e-13, 3.1099e-20,\n",
            "        8.6966e-29, 2.9271e-10, 1.0954e-33, 2.0255e-29, 3.8782e-07, 6.6289e-14,\n",
            "        1.1723e-13, 1.4594e-18, 1.2864e-21, 4.4110e-20, 1.4339e-27, 1.0806e-35,\n",
            "        2.9803e-23, 3.4888e-40, 6.4507e-31, 1.6972e-12, 1.1723e-13, 0.0000e+00,\n",
            "        9.2995e-28, 3.8965e-20, 1.9262e-14, 4.4110e-20, 3.5175e-15],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.9807e-06, 0.0000e+00, 4.2597e-03, 8.1903e+02, 0.0000e+00, 1.0467e-02,\n",
            "        8.3180e+02, 8.6041e-04, 5.7458e+02, 4.2410e+02, 6.9807e-06, 3.1722e-08,\n",
            "        0.0000e+00, 5.8218e-07, 3.1224e-01, 4.0326e-03, 6.2876e+02, 1.2739e-03,\n",
            "        7.2902e+02, 6.9266e+02, 7.5246e+02, 8.5855e-08, 0.0000e+00, 1.5150e+01,\n",
            "        7.9914e-02, 6.0016e-07, 5.8636e-04, 4.0326e-03, 6.8209e-04])\n",
            "kde_grad  tensor([6.0095e-07, 4.5100e-13, 1.0730e-20, 2.9500e-41, 4.5100e-13, 1.3716e-19,\n",
            "        5.3376e-28, 5.8958e-10, 7.8039e-33, 1.2653e-28, 6.0095e-07, 1.6483e-13,\n",
            "        4.5100e-13, 6.0965e-18, 5.7220e-21, 1.8199e-19, 8.8433e-27, 7.1000e-35,\n",
            "        1.4300e-22, 2.7165e-39, 4.2903e-30, 4.0297e-12, 4.5100e-13, 0.0000e+00,\n",
            "        4.9179e-27, 1.5669e-19, 6.7552e-14, 1.8199e-19, 1.3139e-14])\n",
            "*************** t  86\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 3.3259e-05, 1.2565e+01, 6.0739e-02, 7.0333e-06,\n",
            "        1.3636e+01, 2.2650e-06, 1.5130e+01, 6.0645e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 9.0880e-04, 1.9431e-05, 1.1345e+01, 2.0266e-06,\n",
            "        7.3090e+00, 6.7435e+00, 1.5472e+01, -0.0000e+00, 6.0739e-02, 9.5303e-02,\n",
            "        9.2979e-05, -0.0000e+00, 2.3842e-06, 1.9431e-05, 1.0967e-05],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.6721e-07, 1.1723e-13, 2.2365e-21, 1.4700e-42, 1.1723e-13, 3.6023e-20,\n",
            "        4.5626e-29, 2.7082e-10, 1.2929e-33, 1.3747e-29, 2.6721e-07, 1.2578e-13,\n",
            "        1.1723e-13, 1.4880e-18, 4.9500e-22, 3.6948e-20, 1.4559e-27, 1.0672e-35,\n",
            "        1.4390e-23, 2.2674e-40, 3.4762e-31, 8.0820e-13, 1.1723e-13, 0.0000e+00,\n",
            "        6.6080e-28, 3.9351e-20, 1.8306e-14, 3.6948e-20, 1.2994e-15],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([8.8376e-06, 0.0000e+00, 3.5512e-02, 4.0608e+02, 0.0000e+00, 1.5354e-03,\n",
            "        3.7746e+02, 1.4530e-03, 5.7436e+02, 6.5254e+02, 8.8376e-06, 1.4249e-08,\n",
            "        0.0000e+00, 1.7033e-07, 5.3607e-01, 1.1141e-02, 5.3088e+02, 6.3438e-04,\n",
            "        4.9476e+02, 6.0741e+02, 3.9329e+02, 1.4871e-07, 0.0000e+00, 3.8676e+01,\n",
            "        4.7318e-02, 7.8164e-07, 1.1768e-03, 1.1141e-02, 7.0222e-03])\n",
            "kde_grad  tensor([4.3172e-07, 4.5100e-13, 8.9585e-21, 1.1376e-41, 4.5100e-13, 1.5424e-19,\n",
            "        2.8978e-28, 5.6622e-10, 9.1455e-33, 8.7273e-29, 4.3172e-07, 3.0000e-13,\n",
            "        4.5100e-13, 6.0353e-18, 2.2648e-21, 1.5477e-19, 8.8686e-27, 6.9493e-35,\n",
            "        7.2042e-23, 1.7486e-39, 2.2722e-30, 1.9948e-12, 4.5100e-13, 0.0000e+00,\n",
            "        3.4831e-27, 1.5959e-19, 6.4792e-14, 1.5477e-19, 5.2401e-15])\n",
            "*************** t  87\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 5.6028e-06, 1.2292e+01, 6.0739e-02, 1.0610e-05,\n",
            "        1.2138e+01, 1.5497e-06, 1.7255e+01, 2.8779e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 4.3538e-04, 4.8876e-06, 1.0068e+01, 1.7881e-06,\n",
            "        8.7673e+00, 7.2396e+00, 1.3455e+01, -0.0000e+00, 6.0739e-02, 5.8598e-02,\n",
            "        1.0967e-04, -0.0000e+00, 1.9073e-06, 4.8876e-06, 6.5565e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.4158e-07, 1.1723e-13, 1.6969e-21, 3.8354e-42, 1.1723e-13, 2.2420e-20,\n",
            "        8.1510e-29, 2.6648e-10, 1.0010e-33, 8.3117e-30, 2.4158e-07, 6.6289e-14,\n",
            "        1.1723e-13, 6.4311e-19, 7.7199e-22, 3.6844e-20, 1.6837e-27, 5.7367e-36,\n",
            "        1.2784e-23, 1.8427e-40, 8.7468e-31, 7.8355e-13, 1.1723e-13, 0.0000e+00,\n",
            "        4.6043e-28, 3.9198e-20, 1.8117e-14, 3.6844e-20, 1.0895e-15],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([8.7231e-06, 0.0000e+00, 4.4396e-03, 7.8992e+02, 0.0000e+00, 4.4672e-03,\n",
            "        7.0461e+02, 7.9091e-04, 7.4424e+02, 2.7255e+02, 8.7231e-06, 3.1722e-08,\n",
            "        0.0000e+00, 2.1727e-07, 1.8828e-01, 1.1721e-03, 5.1818e+02, 6.3907e-04,\n",
            "        7.5779e+02, 6.4210e+02, 4.8214e+02, 7.3829e-08, 0.0000e+00, 1.5429e+01,\n",
            "        6.7371e-02, 4.9557e-07, 7.4261e-04, 1.1721e-03, 2.7727e-03])\n",
            "kde_grad  tensor([3.9375e-07, 4.5100e-13, 6.5408e-21, 2.9451e-41, 4.5100e-13, 9.8813e-20,\n",
            "        4.9934e-28, 5.4134e-10, 7.3098e-33, 5.0938e-29, 3.9375e-07, 1.6483e-13,\n",
            "        4.5100e-13, 2.6984e-18, 3.4551e-21, 1.4976e-19, 1.0066e-26, 3.7581e-35,\n",
            "        6.4065e-23, 1.4402e-39, 5.5690e-30, 1.8824e-12, 4.5100e-13, 0.0000e+00,\n",
            "        2.4649e-27, 1.5694e-19, 6.3532e-14, 1.4976e-19, 4.2944e-15])\n",
            "*************** t  88\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 5.4836e-06, 1.3267e+01, 6.0739e-02, 6.9141e-06,\n",
            "        1.3134e+01, 1.0729e-06, 1.5752e+01, 2.6991e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 1.3854e-03, 6.9141e-06, 1.1518e+01, 1.9073e-06,\n",
            "        7.2033e+00, 5.9564e+00, 1.4550e+01, -0.0000e+00, 6.0739e-02, 5.4306e-02,\n",
            "        7.4741e-05, -0.0000e+00, 1.9073e-06, 6.9141e-06, 4.2915e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([2.2635e-07, 1.1723e-13, 1.1751e-21, 2.2281e-42, 1.1723e-13, 1.8693e-20,\n",
            "        6.5559e-29, 2.8218e-10, 6.9819e-34, 1.0335e-29, 2.2635e-07, 1.2578e-13,\n",
            "        1.1723e-13, 4.8154e-19, 4.6808e-22, 2.4852e-20, 1.5836e-27, 5.6984e-36,\n",
            "        6.7291e-24, 1.2988e-40, 1.6039e-30, 3.8016e-13, 1.1723e-13, 0.0000e+00,\n",
            "        3.0624e-28, 2.9638e-20, 1.5911e-14, 2.4852e-20, 1.0314e-15],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.6844e-06, 0.0000e+00, 5.7706e-03, 5.3865e+02, 0.0000e+00, 2.3860e-03,\n",
            "        5.9518e+02, 5.1916e-04, 4.0588e+02, 4.4831e+02, 6.6844e-06, 1.4249e-08,\n",
            "        0.0000e+00, 1.0239e-07, 1.0397e+00, 4.6430e-03, 4.9460e+02, 7.2079e-04,\n",
            "        3.7799e+02, 5.4520e+02, 7.9120e+02, 1.1712e-07, 0.0000e+00, 2.0226e+01,\n",
            "        3.4151e-02, 1.4298e-06, 5.2909e-04, 4.6430e-03, 1.2432e-03])\n",
            "kde_grad  tensor([3.6270e-07, 4.5100e-13, 4.6399e-21, 1.7925e-41, 4.5100e-13, 8.1705e-20,\n",
            "        4.0463e-28, 5.7810e-10, 5.0263e-33, 6.2615e-29, 3.6270e-07, 3.0000e-13,\n",
            "        4.5100e-13, 1.9666e-18, 2.1477e-21, 1.0408e-19, 9.4575e-27, 3.7325e-35,\n",
            "        3.4039e-23, 9.9741e-40, 1.0212e-29, 9.4969e-13, 4.5100e-13, 0.0000e+00,\n",
            "        1.6301e-27, 1.2092e-19, 5.6086e-14, 1.0408e-19, 4.0672e-15])\n",
            "*************** t  89\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 4.2915e-06, 1.5135e+01, 6.0739e-02, 8.4638e-06,\n",
            "        1.5778e+01, 1.3113e-06, 1.3832e+01, 3.8973e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 4.6969e-04, 3.4571e-06, 1.2214e+01, 2.0266e-06,\n",
            "        5.7628e+00, 7.7688e+00, 1.4934e+01, -0.0000e+00, 6.0739e-02, 6.2189e-02,\n",
            "        8.8807e-05, -0.0000e+00, 1.6689e-06, 3.4571e-06, 3.0994e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.7495e-07, 1.1723e-13, 9.5114e-22, 1.8637e-42, 1.1723e-13, 1.2311e-20,\n",
            "        3.5998e-29, 2.4959e-10, 1.6713e-33, 6.6919e-30, 1.7495e-07, 6.6289e-14,\n",
            "        1.1723e-13, 2.1096e-19, 8.0055e-22, 2.0803e-20, 8.9639e-28, 4.9004e-36,\n",
            "        1.2075e-23, 1.0950e-40, 4.5855e-31, 6.8810e-13, 1.1723e-13, 0.0000e+00,\n",
            "        2.1060e-28, 3.8439e-20, 1.2369e-14, 2.0803e-20, 8.2616e-16],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([4.3723e-06, 0.0000e+00, 3.1083e-03, 7.4469e+02, 0.0000e+00, 2.9640e-03,\n",
            "        6.9564e+02, 7.7332e-04, 6.4491e+02, 5.4722e+02, 4.3723e-06, 3.1722e-08,\n",
            "        0.0000e+00, 2.1028e-07, 2.1591e-01, 1.1532e-03, 6.8777e+02, 7.2293e-04,\n",
            "        5.2802e+02, 8.4102e+02, 4.0104e+02, 4.2603e-08, 0.0000e+00, 1.6935e+01,\n",
            "        5.8238e-02, 3.4489e-07, 6.4994e-04, 1.1532e-03, 1.0031e-03])\n",
            "kde_grad  tensor([2.8014e-07, 4.5100e-13, 3.7031e-21, 1.4770e-41, 4.5100e-13, 5.4310e-20,\n",
            "        2.3188e-28, 5.0892e-10, 1.1721e-32, 4.1282e-29, 2.8014e-07, 1.6483e-13,\n",
            "        4.5100e-13, 8.9425e-19, 3.5618e-21, 8.4622e-20, 5.5336e-27, 3.2356e-35,\n",
            "        5.8362e-23, 8.5832e-40, 3.0009e-30, 1.6378e-12, 4.5100e-13, 0.0000e+00,\n",
            "        1.1395e-27, 1.5270e-19, 4.4459e-14, 8.4622e-20, 3.1972e-15])\n",
            "*************** t  90\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 7.9870e-06, 1.1919e+01, 6.0739e-02, 9.7751e-06,\n",
            "        1.3473e+01, 1.5497e-06, 1.4915e+01, 5.1603e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 3.1196e-03, 2.5034e-06, 1.1496e+01, 1.6689e-06,\n",
            "        6.4270e+00, 6.6778e+00, 1.4013e+01, -0.0000e+00, 6.0739e-02, 5.1317e-02,\n",
            "        5.8172e-05, -0.0000e+00, 8.3446e-07, 2.5034e-06, 1.6689e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.5168e-07, 1.1723e-13, 6.5385e-22, 1.3060e-42, 1.1723e-13, 8.4650e-21,\n",
            "        2.0856e-29, 2.3886e-10, 1.4710e-33, 5.1300e-30, 1.5168e-07, 1.2578e-13,\n",
            "        1.1723e-13, 1.7059e-19, 3.8228e-22, 9.7326e-21, 7.2084e-28, 3.9337e-36,\n",
            "        8.0252e-24, 4.1904e-41, 1.4843e-30, 4.7778e-13, 1.1723e-13, 0.0000e+00,\n",
            "        9.7133e-29, 1.9840e-20, 8.9866e-15, 9.7326e-21, 5.7597e-16],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([5.6963e-06, 0.0000e+00, 7.7366e-03, 5.1207e+02, 0.0000e+00, 4.1481e-03,\n",
            "        3.7746e+02, 8.4045e-04, 5.0381e+02, 5.8792e+02, 5.6963e-06, 1.4249e-08,\n",
            "        0.0000e+00, 5.4778e-08, 2.7385e+00, 7.7743e-04, 3.6318e+02, 5.5849e-04,\n",
            "        4.6274e+02, 4.2785e+02, 7.3057e+02, 7.4201e-08, 0.0000e+00, 1.6637e+01,\n",
            "        2.9768e-02, 4.2481e-06, 2.1264e-04, 7.7743e-04, 3.8671e-04])\n",
            "kde_grad  tensor([2.4907e-07, 4.5100e-13, 2.6137e-21, 9.8679e-42, 4.5100e-13, 3.7770e-20,\n",
            "        1.3218e-28, 5.0216e-10, 1.0298e-32, 3.2232e-29, 2.4907e-07, 3.0000e-13,\n",
            "        4.5100e-13, 6.9619e-19, 1.7721e-21, 4.0658e-20, 4.3919e-27, 2.5864e-35,\n",
            "        3.9419e-23, 3.2789e-40, 9.3653e-30, 1.1775e-12, 4.5100e-13, 0.0000e+00,\n",
            "        5.2390e-28, 8.2861e-20, 3.1027e-14, 4.0658e-20, 2.2353e-15])\n",
            "*************** t  91\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 4.0531e-06, 1.5541e+01, 6.0739e-02, 6.6757e-06,\n",
            "        1.1931e+01, 1.6689e-06, 1.8265e+01, 3.6106e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 2.9917e-04, 3.3379e-06, 9.3006e+00, 1.6689e-06,\n",
            "        6.1918e+00, 5.1693e+00, 1.4372e+01, -0.0000e+00, 6.0739e-02, 5.6408e-02,\n",
            "        7.2238e-05, -0.0000e+00, 7.1526e-07, 3.3379e-06, 2.3842e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([1.2571e-07, 1.1723e-13, 5.3724e-22, 8.5479e-43, 1.1723e-13, 6.1356e-21,\n",
            "        3.6542e-29, 2.0570e-10, 9.8855e-34, 4.2036e-30, 1.2571e-07, 6.6289e-14,\n",
            "        1.1723e-13, 7.7288e-20, 6.0263e-22, 5.9822e-21, 1.2919e-27, 2.5435e-36,\n",
            "        9.7027e-24, 8.4165e-41, 4.7641e-31, 3.9880e-13, 1.1723e-13, 0.0000e+00,\n",
            "        7.6778e-29, 3.4839e-20, 5.3448e-15, 5.9822e-21, 2.7046e-16],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.6757e-06, 0.0000e+00, 3.0371e-03, 8.3356e+02, 0.0000e+00, 1.9911e-03,\n",
            "        8.8195e+02, 9.3573e-04, 8.3773e+02, 3.8789e+02, 2.6757e-06, 3.1722e-08,\n",
            "        0.0000e+00, 4.7524e-08, 1.4833e-01, 1.4282e-03, 3.8692e+02, 6.1275e-04,\n",
            "        5.3711e+02, 5.6864e+02, 3.7188e+02, 8.6043e-08, 0.0000e+00, 1.9001e+01,\n",
            "        4.9629e-02, 3.1512e-07, 3.0403e-04, 1.4282e-03, 1.1937e-03])\n",
            "kde_grad  tensor([2.0368e-07, 4.5100e-13, 2.1025e-21, 6.9322e-42, 4.5100e-13, 2.7236e-20,\n",
            "        2.2498e-28, 4.2732e-10, 7.1963e-33, 2.6243e-29, 2.0368e-07, 1.6483e-13,\n",
            "        4.5100e-13, 3.2455e-19, 2.6920e-21, 2.5447e-20, 7.5763e-27, 1.6883e-35,\n",
            "        4.7065e-23, 6.4759e-40, 3.0834e-30, 9.8156e-13, 4.5100e-13, 0.0000e+00,\n",
            "        4.2118e-28, 1.3607e-19, 1.9076e-14, 2.5447e-20, 1.0884e-15])\n",
            "*************** t  92\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 1.1086e-05, 1.2587e+01, 6.0739e-02, 3.5763e-06,\n",
            "        1.3511e+01, 1.6689e-06, 1.5686e+01, 2.0657e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 2.4113e-04, 7.6294e-06, 1.0238e+01, 1.6689e-06,\n",
            "        7.8049e+00, 6.5966e+00, 1.4063e+01, -0.0000e+00, 6.0739e-02, 6.4857e-02,\n",
            "        4.8636e-05, -0.0000e+00, 1.3113e-06, 7.6294e-06, 2.0266e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.8873e-08, 1.1723e-13, 4.9940e-22, 6.1097e-43, 1.1723e-13, 2.8149e-21,\n",
            "        1.8359e-29, 2.0582e-10, 4.0448e-34, 3.2290e-30, 9.8873e-08, 1.2578e-13,\n",
            "        1.1723e-13, 4.3009e-20, 2.8401e-22, 5.2188e-21, 1.5907e-27, 1.9329e-36,\n",
            "        6.0127e-24, 5.8396e-41, 1.0643e-30, 4.4982e-13, 1.1723e-13, 0.0000e+00,\n",
            "        4.3768e-29, 1.7862e-20, 6.9126e-15, 5.2188e-21, 2.9983e-16],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([8.0329e-06, 0.0000e+00, 1.0728e-02, 4.0608e+02, 0.0000e+00, 1.0401e-03,\n",
            "        3.7746e+02, 1.0739e-03, 4.0588e+02, 3.9217e+02, 8.0329e-06, 1.4249e-08,\n",
            "        0.0000e+00, 4.7531e-08, 1.1287e-01, 5.2096e-03, 5.2546e+02, 6.5420e-04,\n",
            "        6.4764e+02, 5.9542e+02, 7.0122e+02, 3.9245e-08, 0.0000e+00, 2.2589e+01,\n",
            "        2.4003e-02, 9.3111e-07, 5.4866e-04, 5.2096e-03, 5.1811e-04])\n",
            "kde_grad  tensor([1.6805e-07, 4.5100e-13, 2.0167e-21, 4.5346e-42, 4.5100e-13, 1.2621e-20,\n",
            "        1.1688e-28, 4.3742e-10, 2.9158e-33, 1.9672e-29, 1.6805e-07, 3.0000e-13,\n",
            "        4.5100e-13, 1.8294e-19, 1.2857e-21, 2.2594e-20, 9.3947e-27, 1.2801e-35,\n",
            "        3.0146e-23, 4.5187e-40, 6.7191e-30, 1.0756e-12, 4.5100e-13, 0.0000e+00,\n",
            "        2.3800e-28, 7.2515e-20, 2.4376e-14, 2.2594e-20, 1.1886e-15])\n",
            "*************** t  93\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 3.6955e-06, 1.2227e+01, 6.0739e-02, 4.1723e-06,\n",
            "        1.1952e+01, 1.1921e-06, 1.3753e+01, 3.8522e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 2.4852e-04, 3.5763e-06, 1.0972e+01, 2.1458e-06,\n",
            "        7.5636e+00, 6.9719e+00, 1.5602e+01, -0.0000e+00, 6.0739e-02, 5.6963e-02,\n",
            "        5.0663e-05, -0.0000e+00, 6.4490e-05, 3.5763e-06, 1.7881e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([8.8925e-08, 1.1723e-13, 4.5065e-22, 1.3144e-42, 1.1723e-13, 1.9813e-21,\n",
            "        3.1831e-29, 2.1939e-10, 9.5937e-34, 2.6144e-30, 8.8925e-08, 6.6289e-14,\n",
            "        1.1723e-13, 3.9566e-20, 3.1884e-22, 6.4684e-21, 1.3153e-27, 1.5958e-36,\n",
            "        5.4240e-24, 5.3656e-41, 4.9564e-31, 3.8225e-13, 1.1723e-13, 0.0000e+00,\n",
            "        3.3095e-29, 2.4742e-20, 6.2906e-15, 6.4684e-21, 1.2534e-16],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.6453e-06, 0.0000e+00, 2.7743e-03, 5.5626e+02, 0.0000e+00, 1.2375e-03,\n",
            "        8.5338e+02, 6.5866e-04, 6.4106e+02, 4.3211e+02, 2.6453e-06, 3.1722e-08,\n",
            "        0.0000e+00, 2.7386e-08, 1.4502e-01, 1.2244e-03, 5.0463e+02, 1.1008e-03,\n",
            "        5.8705e+02, 6.9607e+02, 6.9648e+02, 2.4622e-08, 0.0000e+00, 2.0550e+01,\n",
            "        3.4746e-02, 3.5936e-07, 4.7912e-02, 1.2244e-03, 6.7194e-04])\n",
            "kde_grad  tensor([1.4541e-07, 4.5100e-13, 1.7626e-21, 9.8679e-42, 4.5100e-13, 8.9737e-21,\n",
            "        1.9594e-28, 4.5073e-10, 6.7411e-33, 1.6062e-29, 1.4541e-07, 1.6483e-13,\n",
            "        4.5100e-13, 1.6706e-19, 1.4391e-21, 2.7388e-20, 7.7724e-27, 1.0665e-35,\n",
            "        2.7430e-23, 4.2011e-40, 3.2281e-30, 9.1892e-13, 4.5100e-13, 0.0000e+00,\n",
            "        1.8206e-28, 9.7582e-20, 2.3913e-14, 2.7388e-20, 5.0653e-16])\n",
            "*************** t  94\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 1.0014e-05, 1.2595e+01, 6.0739e-02, 2.7418e-06,\n",
            "        1.4078e+01, 8.3446e-07, 1.5912e+01, 5.0770e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 6.1040e-04, 1.9073e-06, 1.2254e+01, 1.5497e-06,\n",
            "        7.1712e+00, 6.6193e+00, 1.6466e+01, -0.0000e+00, 6.0739e-02, 6.1111e-02,\n",
            "        3.0040e-05, -0.0000e+00, 1.1921e-06, 1.9073e-06, 1.0729e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([8.9519e-08, 1.1723e-13, 3.8955e-22, 1.5428e-42, 1.1723e-13, 8.9086e-22,\n",
            "        1.4729e-29, 2.2164e-10, 8.5335e-34, 1.4217e-30, 8.9519e-08, 1.2578e-13,\n",
            "        1.1723e-13, 1.8236e-20, 1.7356e-22, 2.7650e-21, 6.6919e-28, 2.6010e-36,\n",
            "        3.7923e-24, 3.3710e-41, 3.6224e-31, 2.4566e-13, 1.1723e-13, 0.0000e+00,\n",
            "        1.4546e-29, 1.3865e-20, 9.0687e-15, 2.7650e-21, 8.4846e-17],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([6.5206e-06, 0.0000e+00, 9.6845e-03, 5.8555e+02, 0.0000e+00, 1.4479e-03,\n",
            "        5.2009e+02, 3.6819e-04, 7.4959e+02, 5.7211e+02, 6.5206e-06, 1.4249e-08,\n",
            "        0.0000e+00, 3.8982e-08, 4.0979e-01, 8.2346e-04, 6.5081e+02, 5.4897e-04,\n",
            "        4.8916e+02, 5.8076e+02, 7.1001e+02, 1.0692e-07, 0.0000e+00, 1.9299e+01,\n",
            "        1.5143e-02, 7.1444e-07, 2.3252e-04, 8.2346e-04, 1.7887e-04])\n",
            "kde_grad  tensor([1.5175e-07, 4.5100e-13, 1.5744e-21, 1.1793e-41, 4.5100e-13, 4.0749e-21,\n",
            "        9.4277e-29, 4.5702e-10, 6.0848e-33, 9.0752e-30, 1.5175e-07, 3.0000e-13,\n",
            "        4.5100e-13, 7.8317e-20, 8.0046e-22, 1.1850e-20, 4.0960e-27, 1.7191e-35,\n",
            "        1.9101e-23, 2.6210e-40, 2.3913e-30, 6.2022e-13, 4.5100e-13, 0.0000e+00,\n",
            "        7.9569e-29, 5.6233e-20, 3.0898e-14, 1.1850e-20, 3.3557e-16])\n",
            "*************** t  95\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 3.4571e-06, 1.4684e+01, 6.0739e-02, 2.3842e-06,\n",
            "        1.5613e+01, 1.1921e-06, 1.6303e+01, 2.9628e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 1.5532e-04, 2.1458e-06, 1.1371e+01, 1.4305e-06,\n",
            "        5.6466e+00, 7.1336e+00, 1.4845e+01, -0.0000e+00, 6.0739e-02, 5.3017e-02,\n",
            "        3.7550e-05, -0.0000e+00, 2.8610e-06, 2.1458e-06, 6.1660e-04],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([9.0181e-08, 1.1723e-13, 3.6796e-22, 8.0995e-43, 1.1723e-13, 1.0220e-21,\n",
            "        1.1746e-29, 1.6699e-10, 3.8656e-34, 1.2493e-30, 9.0181e-08, 6.6289e-14,\n",
            "        1.1723e-13, 2.1173e-20, 2.6047e-22, 2.4493e-21, 5.3127e-28, 2.2048e-36,\n",
            "        4.1893e-24, 3.1811e-41, 2.4494e-31, 2.8827e-13, 1.1723e-13, 0.0000e+00,\n",
            "        1.5871e-29, 9.7931e-21, 3.7403e-15, 2.4493e-21, 2.7533e-17],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([2.1036e-06, 0.0000e+00, 2.4396e-03, 7.0465e+02, 0.0000e+00, 5.9508e-04,\n",
            "        7.4424e+02, 8.0410e-04, 6.6212e+02, 3.0520e+02, 2.1036e-06, 3.1722e-08,\n",
            "        0.0000e+00, 1.9498e-08, 6.2399e-02, 9.3523e-04, 6.5758e+02, 5.0526e-04,\n",
            "        4.7691e+02, 6.4205e+02, 3.9329e+02, 4.6185e-08, 0.0000e+00, 1.8659e+01,\n",
            "        2.5395e-02, 8.1514e-07, 2.4592e-03, 9.3523e-04, 9.0443e-01])\n",
            "kde_grad  tensor([1.4743e-07, 4.5100e-13, 1.4426e-21, 6.8706e-42, 4.5100e-13, 4.5693e-21,\n",
            "        7.6515e-29, 3.5010e-10, 2.8155e-33, 7.6389e-30, 1.4743e-07, 1.6483e-13,\n",
            "        4.5100e-13, 8.9203e-20, 1.1617e-21, 1.0534e-20, 3.2271e-27, 1.4589e-35,\n",
            "        2.0502e-23, 2.5145e-40, 1.5927e-30, 7.0417e-13, 4.5100e-13, 0.0000e+00,\n",
            "        8.7457e-29, 4.0158e-20, 1.3812e-14, 1.0534e-20, 1.1931e-16])\n",
            "*************** t  96\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 1.0371e-05, 1.1848e+01, 6.0739e-02, 6.4373e-06,\n",
            "        1.3778e+01, 9.5367e-07, 1.5805e+01, 1.8100e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 2.6735e-04, 7.7486e-06, 1.1211e+01, 1.7881e-06,\n",
            "        6.5510e+00, 5.8741e+00, 1.3427e+01, -0.0000e+00, 6.0739e-02, 5.9885e-02,\n",
            "        2.3007e-05, -0.0000e+00, 8.3446e-07, 7.7486e-06, 1.3113e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([7.6265e-08, 1.1723e-13, 2.8088e-22, 8.2957e-43, 1.1723e-13, 5.4988e-22,\n",
            "        7.2997e-30, 1.8063e-10, 3.2205e-34, 1.9050e-30, 7.6265e-08, 1.2578e-13,\n",
            "        1.1723e-13, 9.5746e-21, 1.8522e-22, 2.1443e-21, 3.1422e-28, 2.0255e-36,\n",
            "        4.5851e-24, 2.3309e-41, 5.6629e-31, 1.6868e-13, 1.1723e-13, 0.0000e+00,\n",
            "        8.4145e-30, 1.0255e-20, 4.4193e-15, 2.1443e-21, 3.7018e-17],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([4.8636e-06, 0.0000e+00, 1.0052e-02, 5.1879e+02, 0.0000e+00, 4.2239e-03,\n",
            "        3.8521e+02, 4.1985e-04, 4.7643e+02, 3.7670e+02, 4.8636e-06, 1.4249e-08,\n",
            "        0.0000e+00, 5.4071e-08, 1.9955e-01, 4.9775e-03, 5.5401e+02, 6.5882e-04,\n",
            "        5.9368e+02, 5.3004e+02, 7.2714e+02, 2.7714e-08, 0.0000e+00, 1.8863e+01,\n",
            "        9.9766e-03, 3.6802e-07, 1.6645e-04, 4.9775e-03, 3.1633e-04])\n",
            "kde_grad  tensor([1.2906e-07, 4.5100e-13, 1.1422e-21, 6.5651e-42, 4.5100e-13, 2.5698e-21,\n",
            "        4.6799e-29, 3.7662e-10, 2.3100e-33, 1.1502e-29, 1.2906e-07, 3.0000e-13,\n",
            "        4.5100e-13, 4.1536e-20, 8.5255e-22, 9.4531e-21, 1.9176e-27, 1.3449e-35,\n",
            "        2.2524e-23, 1.8118e-40, 3.5871e-30, 4.1701e-13, 4.5100e-13, 0.0000e+00,\n",
            "        4.6223e-29, 4.1012e-20, 1.4993e-14, 9.4531e-21, 1.4828e-16])\n",
            "*************** t  97\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 3.3379e-06, 1.5128e+01, 6.0739e-02, 2.1458e-06,\n",
            "        1.1594e+01, 1.1921e-06, 1.3687e+01, 3.7241e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 1.0299e-04, 4.7684e-06, 1.0500e+01, 1.6689e-06,\n",
            "        7.6681e+00, 7.5492e+00, 1.4612e+01, -0.0000e+00, 6.0739e-02, 5.0008e-02,\n",
            "        4.2438e-05, -0.0000e+00, 2.0266e-06, 4.7684e-06, 2.0266e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([6.5886e-08, 1.1723e-13, 2.8570e-22, 5.4090e-43, 1.1723e-13, 7.3684e-22,\n",
            "        1.1447e-29, 1.3379e-10, 5.2284e-34, 1.6461e-30, 6.5886e-08, 6.6289e-14,\n",
            "        1.1723e-13, 8.3111e-21, 2.2339e-22, 2.8907e-21, 2.6747e-28, 2.1793e-36,\n",
            "        3.3064e-24, 1.8871e-41, 2.6576e-31, 1.7238e-13, 1.1723e-13, 0.0000e+00,\n",
            "        7.6742e-30, 6.8688e-21, 1.9323e-15, 2.8907e-21, 1.6661e-17],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.6443e-06, 0.0000e+00, 2.4656e-03, 8.2684e+02, 0.0000e+00, 5.0898e-04,\n",
            "        6.2853e+02, 8.0327e-04, 3.5603e+02, 4.6678e+02, 1.6443e-06, 3.1722e-08,\n",
            "        0.0000e+00, 1.7258e-08, 4.5020e-02, 2.4376e-03, 3.5158e+02, 6.3886e-04,\n",
            "        6.0219e+02, 8.2696e+02, 5.2814e+02, 2.0367e-08, 0.0000e+00, 1.5831e+01,\n",
            "        3.2500e-02, 4.7427e-06, 1.5452e-03, 2.4376e-03, 1.3058e-03])\n",
            "kde_grad  tensor([1.0746e-07, 4.5100e-13, 1.1243e-21, 3.8858e-42, 4.5100e-13, 3.2840e-21,\n",
            "        7.1002e-29, 2.8280e-10, 3.6701e-33, 1.0054e-29, 1.0746e-07, 1.6483e-13,\n",
            "        4.5100e-13, 3.5210e-20, 9.9716e-22, 1.2502e-20, 1.5850e-27, 1.4519e-35,\n",
            "        1.6797e-23, 1.4968e-40, 1.7054e-30, 4.2050e-13, 4.5100e-13, 0.0000e+00,\n",
            "        4.2787e-29, 2.8941e-20, 7.1842e-15, 1.2502e-20, 6.9805e-17])\n",
            "*************** t  98\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 6.3181e-06, 1.2534e+01, 6.0739e-02, 1.1921e-06,\n",
            "        1.2746e+01, 7.1526e-07, 1.4803e+01, 4.5225e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 2.0621e-04, 6.5565e-06, 8.9167e+00, 1.4305e-06,\n",
            "        6.7271e+00, 6.3392e+00, 1.6927e+01, -0.0000e+00, 6.0739e-02, 4.1950e-02,\n",
            "        2.1219e-05, -0.0000e+00, 8.3446e-07, 6.5565e-06, 1.7881e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([4.9385e-08, 1.1723e-13, 2.0422e-22, 3.5173e-43, 1.1723e-13, 3.8772e-22,\n",
            "        1.0189e-29, 1.6677e-10, 1.1395e-33, 1.0298e-30, 4.9385e-08, 1.2578e-13,\n",
            "        1.1723e-13, 3.9748e-21, 1.3335e-22, 2.5123e-21, 4.8971e-28, 1.6127e-36,\n",
            "        2.4535e-24, 9.8904e-42, 2.1490e-31, 1.0495e-13, 1.1723e-13, 0.0000e+00,\n",
            "        5.3578e-30, 1.0805e-20, 3.0045e-15, 2.5123e-21, 1.7876e-17],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([3.4348e-06, 0.0000e+00, 6.4674e-03, 5.3864e+02, 0.0000e+00, 3.7025e-04,\n",
            "        5.1245e+02, 2.5538e-04, 8.3180e+02, 6.2508e+02, 3.4348e-06, 1.4249e-08,\n",
            "        0.0000e+00, 3.8462e-08, 1.1454e-01, 4.4177e-03, 3.3816e+02, 4.3116e-04,\n",
            "        5.1612e+02, 4.2860e+02, 8.6431e+02, 3.8266e-08, 0.0000e+00, 1.1767e+01,\n",
            "        1.0838e-02, 2.9937e-07, 1.7399e-04, 4.4177e-03, 7.7378e-04])\n",
            "kde_grad  tensor([8.4238e-08, 4.5100e-13, 8.2546e-22, 2.6204e-42, 4.5100e-13, 1.7656e-21,\n",
            "        6.3569e-29, 3.4260e-10, 7.9512e-33, 6.5520e-30, 8.4238e-08, 3.0000e-13,\n",
            "        4.5100e-13, 1.7338e-20, 6.1265e-22, 1.1010e-20, 2.8493e-27, 1.0704e-35,\n",
            "        1.2313e-23, 7.9391e-41, 1.4250e-30, 2.6473e-13, 4.5100e-13, 0.0000e+00,\n",
            "        2.9554e-29, 4.2507e-20, 1.0323e-14, 1.1010e-20, 7.2871e-17])\n",
            "*************** t  99\n",
            "ce_loss:  tensor([-0.0000e+00, 6.0739e-02, 2.8610e-06, 1.4799e+01, 6.0739e-02, 1.3113e-06,\n",
            "        1.5295e+01, 2.5034e-06, 1.4968e+01, 2.7837e+00, -0.0000e+00, -0.0000e+00,\n",
            "        6.0739e-02, -0.0000e+00, 8.1297e-05, 3.2186e-06, 9.3950e+00, 1.7881e-06,\n",
            "        5.4443e+00, 5.0777e+00, 1.5164e+01, -0.0000e+00, 6.0739e-02, 6.4237e-02,\n",
            "        3.7073e-05, -0.0000e+00, 1.7881e-06, 3.2186e-06, 4.5299e-06],\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "kde_loss:  tensor([5.2200e-08, 1.1723e-13, 1.6308e-22, 2.6625e-43, 1.1723e-13, 1.3729e-22,\n",
            "        7.6119e-30, 1.2302e-10, 5.4178e-34, 7.4133e-31, 5.2200e-08, 6.6289e-14,\n",
            "        1.1723e-13, 2.7449e-21, 7.9936e-23, 2.2176e-21, 8.2115e-28, 8.3784e-37,\n",
            "        2.4493e-24, 2.0777e-41, 1.0287e-31, 1.2621e-13, 1.1723e-13, 0.0000e+00,\n",
            "        3.5654e-30, 5.5248e-21, 1.4101e-15, 2.2176e-21, 1.9149e-17],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "ce_grad  tensor([1.4001e-06, 0.0000e+00, 2.3295e-03, 7.6463e+02, 0.0000e+00, 4.0337e-04,\n",
            "        7.5150e+02, 2.1436e-03, 3.9004e+02, 3.4020e+02, 1.4001e-06, 3.1722e-08,\n",
            "        0.0000e+00, 1.3410e-08, 4.0850e-02, 1.1010e-03, 5.9446e+02, 8.1722e-04,\n",
            "        4.9501e+02, 5.6202e+02, 3.9329e+02, 2.0859e-08, 0.0000e+00, 3.1562e+01,\n",
            "        2.6155e-02, 6.3916e-07, 1.6213e-03, 1.1010e-03, 2.4455e-03])\n",
            "kde_grad  tensor([8.7139e-08, 4.5100e-13, 6.4809e-22, 2.0095e-42, 4.5100e-13, 6.3029e-22,\n",
            "        4.9392e-29, 2.6783e-10, 3.8922e-33, 4.5069e-30, 8.7139e-08, 1.6483e-13,\n",
            "        4.5100e-13, 1.1813e-20, 3.6354e-22, 9.4910e-21, 4.7478e-27, 5.6538e-36,\n",
            "        1.2024e-23, 1.6196e-40, 6.7566e-31, 3.1177e-13, 4.5100e-13, 0.0000e+00,\n",
            "        2.0022e-29, 2.2638e-20, 5.2136e-15, 9.4910e-21, 8.0271e-17])\n",
            "PGD linf: Attack effectiveness 72.414%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_done(x, y, model):\n",
        "    # Get the model's predictions\n",
        "    outputs = model(x)\n",
        "\n",
        "    # Use argmax to get the predicted class indices\n",
        "    predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    # Ensure y is in the same shape as predicted for comparison\n",
        "    y = y.view_as(predicted)\n",
        "\n",
        "    # Determine if the predictions are incorrect\n",
        "    done = (predicted != y).bool()\n",
        "\n",
        "    return done\n",
        "\n",
        "\n",
        "def pgd_min(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack (loss based on goal's class, which we have to minimize the loss).\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), torch.zeros_like(y.view(-1).long()))\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, torch.zeros_like(y.view(-1).long()))\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "        #print('loss : ',criterion(y_model, y.view(-1).long()))\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "            #print(torch.abs(perturbation).sum())\n",
        "            #print('torch.abs(perturbation).sum(dim=-1) : ',torch.abs(perturbation).sum(dim=-1))\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            #print('l2norm ; ',l2norm)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        #print(torch.abs(x_next - torch.clamp(x_next + perturbation * step_length, min=0., max=1.)).sum())\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), torch.zeros_like(y.view(-1).long())).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        done = get_done(x_next, y, model)\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "UYtPqOObSYCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y.view(-1).long())\n",
        "    print('ce: ', ce)\n",
        "    kde = KDE(adv_x, benigns, bandwidth)\n",
        "    print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done\n",
        "\n",
        "\n",
        "def gkde(x, y, model,bens, bandwidth, penalty_factor, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural, _ = get_loss_kde(x,y,model,bens, bandwidth, penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        #y_model = model(x_var)\n",
        "        if t > 20:\n",
        "          decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "        else:\n",
        "          decayed_penalty_factor = penalty_factor\n",
        "\n",
        "        # Compute loss\n",
        "        loss, _ = get_loss_kde(x_var,y,model,bens, bandwidth, decayed_penalty_factor)\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        #pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            perturbation[torch.isnan(perturbation)] = 0.\n",
        "            perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            _, done = get_loss_kde(x_next,y,model,bens, bandwidth, penalty_factor)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, y.view(-1).long())\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "fBG8j2GvbXNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "default GKDE with 500 centers"
      ],
      "metadata": {
        "id": "jnK2GlF8Tluo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    if (attack ==  gkde) or (attack ==  mimicry):\n",
        "      # Pre-select benign samples\n",
        "      benign_samples = []\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "      ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "      # Forward pass to get logits for benign samples\n",
        "      with torch.no_grad():  # No need for gradients\n",
        "          outputs = model(ben_x.to(torch.float32))\n",
        "\n",
        "      # Calculate softmax probabilities\n",
        "      probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "      # Sort indices based on probabilities of class 1 (assuming class 1 is the \"positive\" class)\n",
        "      sorted_indices = torch.argsort(probabilities[:, 1], descending=False)\n",
        "\n",
        "      # Select the top 500 high confidence benign samples\n",
        "      top_500_high_confidence_benign_samples = ben_x[sorted_indices[:500]]\n",
        "\n",
        "      del benign_samples, outputs, probabilities, ben_x  # Free up memory\n",
        "\n",
        "    model.eval()\n",
        "    n_samples = 0\n",
        "    cor_test = 0\n",
        "    cor_ad_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            #outputs = model(x_test)\n",
        "            #predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            #acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            #avg_acc_test.append(acc_test)\n",
        "\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "            n_samples += len(mal_y_batch)\n",
        "\n",
        "            outputs = model(mal_x_batch)\n",
        "            predicted = outputs.argmax(1)\n",
        "            cor_test += (predicted == 1).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            if attack == mimicry:\n",
        "                pertb_mal_x = mimicry(top_500_high_confidence_benign_samples, mal_x_batch, model, **kwargs)\n",
        "            elif attack == gkde:\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde(mal_x_batch, mal_y_batch, model, top_500_high_confidence_benign_samples, **kwargs)\n",
        "            else :\n",
        "                with torch.enable_grad():\n",
        "                    pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_test += (y_pred == 1).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Accuracy of just malwares (without attack): {(cor_test / n_samples) * 100:.4}% | Under attack: {(cor_ad_test / n_samples) * 100:.4}%.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9QZ9I07UcXzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wydbPkuuU6pz",
        "outputId": "d31cc20b-c49b-435e-fd69-5bbc21f1ed26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8394b3-7e7b-44a7-e0bc-937de7d7c7fa",
        "id": "Q4YobjklUj8s"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.82%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va30PtoJVF6n",
        "outputId": "c25e0cab-d27d-4d4d-ba0a-51d6e5d7b7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfWO7OA1Uq5g",
        "outputId": "bbe95afe-b646-49c6-85f9-6d03d98bc55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 26.19%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': .02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDMFXlV6VKb8",
        "outputId": "4fc1759b-2711-41bd-a060-082190022cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GPiZrKUUw0e",
        "outputId": "efe977ad-1720-4545-8261-032c1cac5564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.63%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0wNlRcUMWZ-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gSQehpHvgQSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c45ade-a9cf-4a41-dbd3-4b3e3a2a19b5",
        "id": "2Ixn6t-9gRl-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7dac27c-8a8e-48b8-991e-531dfedb88a8",
        "id": "sHoVNHLygRl_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.73%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4fe1c8a-528f-4716-f684-3168459768d4",
        "id": "-dgwSspQgRl_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34aee256-e4f0-4bc1-b06a-0eaa54b8be2e",
        "id": "kp5Cx-dngRmA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.54%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': .02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7783cd49-2b0d-45c9-a09a-41b5f96a33ba",
        "id": "z1G3RXDbgRmA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9a4f29-fbb4-47ed-d0ff-9a8cc9dfde89",
        "id": "XIn4TPPZgRmA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 60.35%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NpehYej7gQ6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "default GKDE with 1000 centers"
      ],
      "metadata": {
        "id": "Hd7zLZP-Wdej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    if (attack ==  gkde) or (attack ==  mimicry):\n",
        "      # Pre-select benign samples\n",
        "      benign_samples = []\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "      ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "      # Forward pass to get logits for benign samples\n",
        "      with torch.no_grad():  # No need for gradients\n",
        "          outputs = model(ben_x.to(torch.float32))\n",
        "\n",
        "      # Calculate softmax probabilities\n",
        "      probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "      # Sort indices based on probabilities of class 1 (assuming class 1 is the \"positive\" class)\n",
        "      sorted_indices = torch.argsort(probabilities[:, 1], descending=False)\n",
        "\n",
        "      # Select the top 1000 high confidence benign samples\n",
        "      top_1000_high_confidence_benign_samples = ben_x[sorted_indices[:1000]]\n",
        "\n",
        "      del benign_samples, outputs, probabilities, ben_x  # Free up memory\n",
        "\n",
        "    model.eval()\n",
        "    n_samples = 0\n",
        "    cor_test = 0\n",
        "    cor_ad_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            #outputs = model(x_test)\n",
        "            #predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            #acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            #avg_acc_test.append(acc_test)\n",
        "\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "            n_samples += len(mal_y_batch)\n",
        "\n",
        "            outputs = model(mal_x_batch)\n",
        "            predicted = outputs.argmax(1)\n",
        "            cor_test += (predicted == 1).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            if attack == mimicry:\n",
        "                pertb_mal_x = mimicry(top_500_high_confidence_benign_samples, mal_x_batch, model, **kwargs)\n",
        "            elif attack == gkde:\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde(mal_x_batch, mal_y_batch, model, top_1000_high_confidence_benign_samples, **kwargs)\n",
        "            else :\n",
        "                with torch.enable_grad():\n",
        "                    pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_test += (y_pred == 1).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Accuracy of just malwares (without attack): {(cor_test / n_samples) * 100:.4}% | Under attack: {(cor_ad_test / n_samples) * 100:.4}%.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "V71KgezuW2Ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86437ff0-b8f0-4cce-92bf-c6dc9d8c8a31",
        "id": "xK8JGFRkWt6L"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1886dad-2944-4f97-f61d-97a220bbcb24",
        "id": "yYmmANnVWt6Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.18%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78fFYFwLWt6Z",
        "outputId": "de6dbf2a-6b6f-4fe4-d15d-78358d7a40de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBcPY67SWt6Z",
        "outputId": "9bba3114-159b-4660-8603-d5869c3d0df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.62%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': .02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfXtr22RWt6Z",
        "outputId": "5246598d-7450-47e1-ac4e-386a9bc61018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvqVuimXWt6a",
        "outputId": "d715d14a-0d4a-4766-df41-559d5495a61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 54.16%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rOzTmK7mgqCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AEGxKIKDXaU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c202a7c6-0e93-454b-be37-dff52aca3b49",
        "id": "nSf7rZELgrFi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 40.18%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1127b6cb-7a1f-4a36-b1c7-922a7e078ead",
        "id": "WBafTuWzgrFi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.99%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af552ac6-0b66-4f9e-9700-5793985168d0",
        "id": "4Wt3YAQjgrFj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 60.18%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2dT2UCWggqiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "default GKDE with 200 centers"
      ],
      "metadata": {
        "id": "fIInHgOVZFvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    if (attack ==  gkde) or (attack ==  mimicry):\n",
        "      # Pre-select benign samples\n",
        "      benign_samples = []\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "      ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "      # Forward pass to get logits for benign samples\n",
        "      with torch.no_grad():  # No need for gradients\n",
        "          outputs = model(ben_x.to(torch.float32))\n",
        "\n",
        "      # Calculate softmax probabilities\n",
        "      probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "      # Sort indices based on probabilities of class 1 (assuming class 1 is the \"positive\" class)\n",
        "      sorted_indices = torch.argsort(probabilities[:, 1], descending=False)\n",
        "\n",
        "      # Select the top 200 high confidence benign samples\n",
        "      top_200_high_confidence_benign_samples = ben_x[sorted_indices[:200]]\n",
        "\n",
        "      del benign_samples, outputs, probabilities, ben_x  # Free up memory\n",
        "\n",
        "    model.eval()\n",
        "    n_samples = 0\n",
        "    cor_test = 0\n",
        "    cor_ad_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            #outputs = model(x_test)\n",
        "            #predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            #acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            #avg_acc_test.append(acc_test)\n",
        "\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "            n_samples += len(mal_y_batch)\n",
        "\n",
        "            outputs = model(mal_x_batch)\n",
        "            predicted = outputs.argmax(1)\n",
        "            cor_test += (predicted == 1).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            if attack == mimicry:\n",
        "                pertb_mal_x = mimicry(top_500_high_confidence_benign_samples, mal_x_batch, model, **kwargs)\n",
        "            elif attack == gkde:\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde(mal_x_batch, mal_y_batch, model, top_200_high_confidence_benign_samples, **kwargs)\n",
        "            else :\n",
        "                with torch.enable_grad():\n",
        "                    pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_test += (y_pred == 1).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Accuracy of just malwares (without attack): {(cor_test / n_samples) * 100:.4}% | Under attack: {(cor_ad_test / n_samples) * 100:.4}%.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "H_q5fx8MZFv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86437ff0-b8f0-4cce-92bf-c6dc9d8c8a31",
        "id": "mLBjBOzFZFwA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c8617c-66e9-4943-8beb-5c6584556302",
        "id": "t3HKxWBRZFwB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.73%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6dbf2a-6b6f-4fe4-d15d-78358d7a40de",
        "id": "5AnYOp5qZFwC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4b80c7-31b9-40ac-91e2-8051bda6001a",
        "id": "mP5vQvEgZFwD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 17.52%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': .02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5246598d-7450-47e1-ac4e-386a9bc61018",
        "id": "USGew-x6ZFwD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByMCOoIaZFwD",
        "outputId": "7ca3ba8b-a99b-46f1-859a-97ebfd823366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 53.54%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-jtf4DlXaJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602b0885-5e51-49ab-c5b4-776a9dd3ed1d",
        "id": "mLqDMu-Mi6_z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.73%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ff61b5-89f3-40af-c50c-9c91c219f193",
        "id": "QoWFyjjIi6_0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 24.16%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c720b7cc-20a2-43c8-8d2e-fd95e4d3775b",
        "id": "3Vxr2jQ8i6_1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 61.59%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzRmVuVCi6E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "updated gkde"
      ],
      "metadata": {
        "id": "u-gv7N3MaCPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Compute CE loss\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y)\n",
        "    #print('ce ',ce)\n",
        "\n",
        "    # Compute KDE loss\n",
        "    kde = KDE(adv_x, benigns, bandwidth)\n",
        "    #print('kde ',kde)\n",
        "\n",
        "    # Combine the losses with the penalty factor\n",
        "    loss = ce + penalty_factor * kde\n",
        "    #print('loss ',loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gkde(x, y, model,benigns, bandwidth, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "        initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "\n",
        "    :param x: Feature vector\n",
        "    :param y: Ground truth labels\n",
        "    :param model: Neural network model\n",
        "    :param RBFModel: Gaussian model for KDE\n",
        "    :param insertion_array: Array for insertion operations\n",
        "    :param removal_array: Array for removal operations\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf', 'l2', 'l1')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    #target's class\n",
        "    traget_labels = torch.zeros_like(y.view(-1).long())\n",
        "\n",
        "    # Compute natural loss and penalty_factor\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), traget_labels)\n",
        "    kde = KDE(x, benigns, bandwidth)\n",
        "    #penalty_factor = 0.\n",
        "    penalty_factor = 1000.\n",
        "    #print(penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    for t in range(k):\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde(x_var,traget_labels,model,benigns, bandwidth, decayed_penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "        elif norm == 'l1':\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1', 'l2', or 'linf' norm.\")\n",
        "\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    if random:\n",
        "        round_threshold = torch.rand_like(x_next)\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, traget_labels).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size(0) * 100:.3f}%.\")\n",
        "\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "YMpzn3inYPmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JAjBaCRrm0Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86437ff0-b8f0-4cce-92bf-c6dc9d8c8a31",
        "id": "yht_rh0haMRs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e60816d-7ca0-456d-fa5b-cd1e7d1c532f",
        "id": "FzaJb7PzaMRt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6dbf2a-6b6f-4fe4-d15d-78358d7a40de",
        "id": "k2NOquP7aMRv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff3e607-d4a9-426b-f61b-582bb502d698",
        "id": "cfOihLOQaMRv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': .02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5246598d-7450-47e1-ac4e-386a9bc61018",
        "id": "BZjyCQi_aMRw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa46c09-8e01-4810-cb82-9c916e239297",
        "id": "gcOafwy-aMRx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2YAFU6TIaLvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RMKozYLJpsTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ubO6Bzxps10",
        "outputId": "6449bc8b-c8d1-4f15-8080-98e64cdd74cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeFrA79Yps11",
        "outputId": "355c1f5b-11bc-459f-8f5a-3984b80f8d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.77%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgQ4GYK3ps11",
        "outputId": "9582c08f-b0c5-4340-a2df-91a35e2b8b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.04%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UwGzVxYGaLr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G3zCWcqTbLDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "penalty factor = 50000"
      ],
      "metadata": {
        "id": "aS0yJigrbTUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Compute CE loss\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y)\n",
        "    #print('ce ',ce)\n",
        "\n",
        "    # Compute KDE loss\n",
        "    kde = KDE(adv_x, benigns, bandwidth)\n",
        "    #print('kde ',kde)\n",
        "\n",
        "    # Combine the losses with the penalty factor\n",
        "    loss = ce + penalty_factor * kde\n",
        "    #print('loss ',loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gkde(x, y, model,benigns, bandwidth, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "        initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "\n",
        "    :param x: Feature vector\n",
        "    :param y: Ground truth labels\n",
        "    :param model: Neural network model\n",
        "    :param RBFModel: Gaussian model for KDE\n",
        "    :param insertion_array: Array for insertion operations\n",
        "    :param removal_array: Array for removal operations\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf', 'l2', 'l1')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    #target's class\n",
        "    traget_labels = torch.zeros_like(y.view(-1).long())\n",
        "\n",
        "    # Compute natural loss and penalty_factor\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), traget_labels)\n",
        "    kde = KDE(x, benigns, bandwidth)\n",
        "    #penalty_factor = 0.\n",
        "    penalty_factor = 50000.\n",
        "    #print(penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    for t in range(k):\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde(x_var,traget_labels,model,benigns, bandwidth, decayed_penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "        elif norm == 'l1':\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1', 'l2', or 'linf' norm.\")\n",
        "\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    if random:\n",
        "        round_threshold = torch.rand_like(x_next)\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, traget_labels).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size(0) * 100:.3f}%.\")\n",
        "\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "41Nq90DVbQmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86437ff0-b8f0-4cce-92bf-c6dc9d8c8a31",
        "id": "hCalTv1xbLUB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 50000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fcf9604-539c-406b-8522-1e597987d4aa",
        "id": "5yoOK9udbLUB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.86%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6dbf2a-6b6f-4fe4-d15d-78358d7a40de",
        "id": "pfVjIYlnbLUC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 50000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6ad00c-1036-416a-860b-ece1e25bac8c",
        "id": "6uZhtdSfbLUC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 22.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': .02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5246598d-7450-47e1-ac4e-386a9bc61018",
        "id": "NH1AGmAEbLUC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 50000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8c0894-b262-48f6-a0f9-b9a33ba44232",
        "id": "LU5blXrQbLUD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.58%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ioMX8VsQb5DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 50000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Czz2BHLorFDl",
        "outputId": "5379f449-7977-48e0-8472-93639f4f6140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.65%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 50000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdyVHqOirFDm",
        "outputId": "9dd719ea-2ec5-4684-d582-501ac9ee6b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.06%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 50000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrSTOITnrFDm",
        "outputId": "d84eade7-3788-42ee-b99d-b137be031181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.33%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hcg6wQ4Sb5ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "penalty_factor = (loss_natural / (kde+ 1e-20)).detach()"
      ],
      "metadata": {
        "id": "mgTpuzwRcIRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Compute CE loss\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y)\n",
        "    #print('ce ',ce)\n",
        "\n",
        "    # Compute KDE loss\n",
        "    kde = KDE(adv_x, benigns, bandwidth)\n",
        "    #print('kde ',kde)\n",
        "\n",
        "    # Combine the losses with the penalty factor\n",
        "    loss = ce + penalty_factor * kde\n",
        "    #print('loss ',loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gkde(x, y, model,benigns, bandwidth, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "        initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "\n",
        "    :param x: Feature vector\n",
        "    :param y: Ground truth labels\n",
        "    :param model: Neural network model\n",
        "    :param RBFModel: Gaussian model for KDE\n",
        "    :param insertion_array: Array for insertion operations\n",
        "    :param removal_array: Array for removal operations\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf', 'l2', 'l1')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    #target's class\n",
        "    traget_labels = torch.zeros_like(y.view(-1).long())\n",
        "\n",
        "    # Compute natural loss and penalty_factor\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), traget_labels)\n",
        "    kde = KDE(x, benigns, bandwidth)\n",
        "    #penalty_factor = 0.\n",
        "    penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "    print('loss_natural ',loss_natural)\n",
        "    print('kde ',kde)\n",
        "    print('penalty_factor ',penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    for t in range(k):\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde(x_var,traget_labels,model,benigns, bandwidth, decayed_penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "        elif norm == 'l1':\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1', 'l2', or 'linf' norm.\")\n",
        "\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    if random:\n",
        "        round_threshold = torch.rand_like(x_next)\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, traget_labels).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size(0) * 100:.3f}%.\")\n",
        "\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "CAw4ok8-b6CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86437ff0-b8f0-4cce-92bf-c6dc9d8c8a31",
        "id": "RmcnJF5Kb6CK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0789b8d-dce6-4854-c389-3692eea8c6bf",
        "id": "WFmA-sRnb6CL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.31%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6dbf2a-6b6f-4fe4-d15d-78358d7a40de",
        "id": "8cLo66Znb6CM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e89e5fa-dfa4-42fb-f955-a62dfeb994e2",
        "id": "SUlfHewTb6CM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 23.01%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': .02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5246598d-7450-47e1-ac4e-386a9bc61018",
        "id": "JxI0rdIEb6CM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e60b4f-4558-42b8-e787-fab998826f69",
        "id": "W7_ars6Db6CN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.75%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O7WkkKQAb45Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr3SSPbQsKka",
        "outputId": "7155378e-e55c-4679-e4fc-52251121a1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.42%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYHhNyAVsKkb",
        "outputId": "cf86ff03-d02c-4ed2-9bce-d3b3838267b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 21.24%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1vLt6yGsKkb",
        "outputId": "2f1636c4-4b7b-4de1-f584-050edfd104bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.81%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kE-n-zYPsHfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv = gkde(mals[:2].to(torch.float32).to(device), mals_y[:2].to(device), model_AT_rFGSM, top_500_high_confidence_benign_samples,0.6, insertion_array, removal_array, k=100, step_length=1., norm='l1', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE8cjKblNmQe",
        "outputId": "196b9f48-24a0-423c-ac81-d0241b9ec2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss_natural  tensor([41.0281, 86.6297], device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "kde  tensor([6.8584e-06, 1.0497e-10], device='cuda:0')\n",
            "penalty_factor  tensor([5.9821e+06, 8.2526e+11], device='cuda:0')\n",
            "PGD l1: Attack effectiveness 100.000%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_500_high_confidence_benign_samples.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X0BDBGYuPvU",
        "outputId": "1df57b29-77eb-4ef1-e06f-05e658faa071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KDE(top_500_high_confidence_benign_samples[:1], top_500_high_confidence_benign_samples, 0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gJueUFQuM0P",
        "outputId": "4292279c-76f7-4aef-939f-e378ab1ebe6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3498], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KDE(adv, top_500_high_confidence_benign_samples, 0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu7ye-j5unRu",
        "outputId": "de99f996-9b5b-477e-8a3b-2ae37ff3816e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.7102e-06, 1.0120e-13], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "default GKDE with 1000 centers , penalty_factor = (loss_natural / (kde+ 1e-20)).detach()"
      ],
      "metadata": {
        "id": "GwSo9ou_NmzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    if (attack ==  gkde) or (attack ==  mimicry):\n",
        "      # Pre-select benign samples\n",
        "      benign_samples = []\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "      ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "      # Forward pass to get logits for benign samples\n",
        "      with torch.no_grad():  # No need for gradients\n",
        "          outputs = model(ben_x.to(torch.float32))\n",
        "\n",
        "      # Calculate softmax probabilities\n",
        "      probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "      # Sort indices based on probabilities of class 1 (assuming class 1 is the \"positive\" class)\n",
        "      sorted_indices = torch.argsort(probabilities[:, 1], descending=False)\n",
        "\n",
        "      # Select the top 1000 high confidence benign samples\n",
        "      top_1000_high_confidence_benign_samples = ben_x[sorted_indices[:1000]]\n",
        "\n",
        "      del benign_samples, outputs, probabilities, ben_x  # Free up memory\n",
        "\n",
        "    model.eval()\n",
        "    n_samples = 0\n",
        "    cor_test = 0\n",
        "    cor_ad_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            #outputs = model(x_test)\n",
        "            #predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            #acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            #avg_acc_test.append(acc_test)\n",
        "\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "            n_samples += len(mal_y_batch)\n",
        "\n",
        "            outputs = model(mal_x_batch)\n",
        "            predicted = outputs.argmax(1)\n",
        "            cor_test += (predicted == 1).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            if attack == mimicry:\n",
        "                pertb_mal_x = mimicry(top_500_high_confidence_benign_samples, mal_x_batch, model, **kwargs)\n",
        "            elif attack == gkde:\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde(mal_x_batch, mal_y_batch, model, top_1000_high_confidence_benign_samples, **kwargs)\n",
        "            else :\n",
        "                with torch.enable_grad():\n",
        "                    pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_test += (y_pred == 1).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Accuracy of just malwares (without attack): {(cor_test / n_samples) * 100:.4}% | Under attack: {(cor_ad_test / n_samples) * 100:.4}%.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oR9XJAYMNmzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Compute CE loss\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y)\n",
        "    #print('ce ',ce)\n",
        "\n",
        "    # Compute KDE loss\n",
        "    kde = KDE(adv_x, benigns, bandwidth)\n",
        "    #print('kde ',kde)\n",
        "\n",
        "    # Combine the losses with the penalty factor\n",
        "    loss = ce + penalty_factor * kde\n",
        "    #print('loss ',loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gkde(x, y, model,benigns, bandwidth, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "        initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "\n",
        "    :param x: Feature vector\n",
        "    :param y: Ground truth labels\n",
        "    :param model: Neural network model\n",
        "    :param RBFModel: Gaussian model for KDE\n",
        "    :param insertion_array: Array for insertion operations\n",
        "    :param removal_array: Array for removal operations\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf', 'l2', 'l1')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    #target's class\n",
        "    traget_labels = torch.zeros_like(y.view(-1).long())\n",
        "\n",
        "    # Compute natural loss and penalty_factor\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), traget_labels)\n",
        "    kde = KDE(x, benigns, bandwidth)\n",
        "    #penalty_factor = 0.\n",
        "    penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "    #print(penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    for t in range(k):\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde(x_var,traget_labels,model,benigns, bandwidth, decayed_penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "        elif norm == 'l1':\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1', 'l2', or 'linf' norm.\")\n",
        "\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    if random:\n",
        "        round_threshold = torch.rand_like(x_next)\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, traget_labels).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size(0) * 100:.3f}%.\")\n",
        "\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "IgAUst4hNmzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86437ff0-b8f0-4cce-92bf-c6dc9d8c8a31",
        "id": "of3JHlhjNmzX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f021f949-41cc-45f2-8a52-a521bd017c8c",
        "id": "LUW05D1xNmzY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 34.87%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6dbf2a-6b6f-4fe4-d15d-78358d7a40de",
        "id": "K6XhBMrWNmzY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b75657-1e30-4595-dd47-b74ff9520c17",
        "id": "i-2weOwbNmzY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 23.01%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': .02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5246598d-7450-47e1-ac4e-386a9bc61018",
        "id": "lCClNvLTNmzZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 42.48%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09250ce-da69-4f83-f95f-2c0a06b666d0",
        "id": "50YUGbXiNmzZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 36.11%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9602YXnLNmDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aCJYfE6YP8R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J3IpGebgR1Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "default GKDE with 200 centers , penalty_factor = (loss_natural / (kde+ 1e-20)).detach()"
      ],
      "metadata": {
        "id": "O4Pqgv1KR2TN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    if (attack ==  gkde) or (attack ==  mimicry):\n",
        "      # Pre-select benign samples\n",
        "      benign_samples = []\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "      ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "      # Forward pass to get logits for benign samples\n",
        "      with torch.no_grad():  # No need for gradients\n",
        "          outputs = model(ben_x.to(torch.float32))\n",
        "\n",
        "      # Calculate softmax probabilities\n",
        "      probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "      # Sort indices based on probabilities of class 1 (assuming class 1 is the \"positive\" class)\n",
        "      sorted_indices = torch.argsort(probabilities[:, 1], descending=False)\n",
        "\n",
        "      # Select the top 1000 high confidence benign samples\n",
        "      top_1000_high_confidence_benign_samples = ben_x[sorted_indices[:200]]\n",
        "\n",
        "      del benign_samples, outputs, probabilities, ben_x  # Free up memory\n",
        "\n",
        "    model.eval()\n",
        "    n_samples = 0\n",
        "    cor_test = 0\n",
        "    cor_ad_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            #outputs = model(x_test)\n",
        "            #predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            #acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            #avg_acc_test.append(acc_test)\n",
        "\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "            n_samples += len(mal_y_batch)\n",
        "\n",
        "            outputs = model(mal_x_batch)\n",
        "            predicted = outputs.argmax(1)\n",
        "            cor_test += (predicted == 1).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            if attack == mimicry:\n",
        "                pertb_mal_x = mimicry(top_500_high_confidence_benign_samples, mal_x_batch, model, **kwargs)\n",
        "            elif attack == gkde:\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde(mal_x_batch, mal_y_batch, model, top_1000_high_confidence_benign_samples, **kwargs)\n",
        "            else :\n",
        "                with torch.enable_grad():\n",
        "                    pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_test += (y_pred == 1).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Accuracy of just malwares (without attack): {(cor_test / n_samples) * 100:.4}% | Under attack: {(cor_ad_test / n_samples) * 100:.4}%.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Y5rY74asR2TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Compute CE loss\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y)\n",
        "    #print('ce ',ce)\n",
        "\n",
        "    # Compute KDE loss\n",
        "    kde = KDE(adv_x, benigns, bandwidth)\n",
        "    #print('kde ',kde)\n",
        "\n",
        "    # Combine the losses with the penalty factor\n",
        "    loss = ce + penalty_factor * kde\n",
        "    #print('loss ',loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gkde(x, y, model,benigns, bandwidth, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "        initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "\n",
        "    :param x: Feature vector\n",
        "    :param y: Ground truth labels\n",
        "    :param model: Neural network model\n",
        "    :param RBFModel: Gaussian model for KDE\n",
        "    :param insertion_array: Array for insertion operations\n",
        "    :param removal_array: Array for removal operations\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf', 'l2', 'l1')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    #target's class\n",
        "    traget_labels = torch.zeros_like(y.view(-1).long())\n",
        "\n",
        "    # Compute natural loss and penalty_factor\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), traget_labels)\n",
        "    kde = KDE(x, benigns, bandwidth)\n",
        "    #penalty_factor = 0.\n",
        "    penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "    #print(penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    for t in range(k):\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_kde(x_var,traget_labels,model,benigns, bandwidth, decayed_penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        #pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "        elif norm == 'l1':\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1', 'l2', or 'linf' norm.\")\n",
        "\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    if random:\n",
        "        round_threshold = torch.rand_like(x_next)\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, traget_labels).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size(0) * 100:.3f}%.\")\n",
        "\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "mtFTE9foR2TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd2690f-0ec1-49b2-bb21-bff2ffe39712",
        "id": "H6CIbgOeR2TP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 72.414%.\n",
            "PGD l1: Attack effectiveness 64.000%.\n",
            "PGD l1: Attack effectiveness 46.154%.\n",
            "PGD l1: Attack effectiveness 71.429%.\n",
            "PGD l1: Attack effectiveness 72.000%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 64.706%.\n",
            "PGD l1: Attack effectiveness 63.636%.\n",
            "PGD l1: Attack effectiveness 64.286%.\n",
            "PGD l1: Attack effectiveness 62.069%.\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "PGD l1: Attack effectiveness 55.882%.\n",
            "PGD l1: Attack effectiveness 45.000%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 74.194%.\n",
            "PGD l1: Attack effectiveness 63.333%.\n",
            "PGD l1: Attack effectiveness 84.000%.\n",
            "PGD l1: Attack effectiveness 64.516%.\n",
            "PGD l1: Attack effectiveness 62.963%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 70.000%.\n",
            "PGD l1: Attack effectiveness 36.364%.\n",
            "PGD l1: Attack effectiveness 58.621%.\n",
            "PGD l1: Attack effectiveness 59.091%.\n",
            "PGD l1: Attack effectiveness 57.692%.\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "PGD l1: Attack effectiveness 67.568%.\n",
            "PGD l1: Attack effectiveness 56.250%.\n",
            "PGD l1: Attack effectiveness 56.250%.\n",
            "PGD l1: Attack effectiveness 69.444%.\n",
            "PGD l1: Attack effectiveness 72.973%.\n",
            "PGD l1: Attack effectiveness 63.158%.\n",
            "PGD l1: Attack effectiveness 67.742%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 60.714%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 40.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.31%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 1.,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpNro2fYSErd",
        "outputId": "69ec5baa-47f6-42d5-efd2-d69275f07e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 68.966%.\n",
            "PGD l1: Attack effectiveness 56.000%.\n",
            "PGD l1: Attack effectiveness 38.462%.\n",
            "PGD l1: Attack effectiveness 68.571%.\n",
            "PGD l1: Attack effectiveness 56.000%.\n",
            "PGD l1: Attack effectiveness 48.000%.\n",
            "PGD l1: Attack effectiveness 58.824%.\n",
            "PGD l1: Attack effectiveness 48.485%.\n",
            "PGD l1: Attack effectiveness 54.762%.\n",
            "PGD l1: Attack effectiveness 58.621%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 44.118%.\n",
            "PGD l1: Attack effectiveness 40.000%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 56.000%.\n",
            "PGD l1: Attack effectiveness 58.065%.\n",
            "PGD l1: Attack effectiveness 56.667%.\n",
            "PGD l1: Attack effectiveness 64.000%.\n",
            "PGD l1: Attack effectiveness 45.161%.\n",
            "PGD l1: Attack effectiveness 48.148%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 56.667%.\n",
            "PGD l1: Attack effectiveness 31.818%.\n",
            "PGD l1: Attack effectiveness 55.172%.\n",
            "PGD l1: Attack effectiveness 52.273%.\n",
            "PGD l1: Attack effectiveness 50.000%.\n",
            "PGD l1: Attack effectiveness 71.429%.\n",
            "PGD l1: Attack effectiveness 59.459%.\n",
            "PGD l1: Attack effectiveness 25.000%.\n",
            "PGD l1: Attack effectiveness 46.875%.\n",
            "PGD l1: Attack effectiveness 52.778%.\n",
            "PGD l1: Attack effectiveness 64.865%.\n",
            "PGD l1: Attack effectiveness 50.000%.\n",
            "PGD l1: Attack effectiveness 58.065%.\n",
            "PGD l1: Attack effectiveness 71.429%.\n",
            "PGD l1: Attack effectiveness 60.714%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 40.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 44.78%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 2.,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xDXSyhyR1Fu",
        "outputId": "199fc374-25ed-40e8-a3a5-0c8c470fc09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 62.069%.\n",
            "PGD l1: Attack effectiveness 52.000%.\n",
            "PGD l1: Attack effectiveness 34.615%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 48.000%.\n",
            "PGD l1: Attack effectiveness 32.000%.\n",
            "PGD l1: Attack effectiveness 35.294%.\n",
            "PGD l1: Attack effectiveness 33.333%.\n",
            "PGD l1: Attack effectiveness 40.476%.\n",
            "PGD l1: Attack effectiveness 41.379%.\n",
            "PGD l1: Attack effectiveness 45.000%.\n",
            "PGD l1: Attack effectiveness 41.176%.\n",
            "PGD l1: Attack effectiveness 30.000%.\n",
            "PGD l1: Attack effectiveness 59.259%.\n",
            "PGD l1: Attack effectiveness 40.000%.\n",
            "PGD l1: Attack effectiveness 45.161%.\n",
            "PGD l1: Attack effectiveness 50.000%.\n",
            "PGD l1: Attack effectiveness 48.000%.\n",
            "PGD l1: Attack effectiveness 38.710%.\n",
            "PGD l1: Attack effectiveness 44.444%.\n",
            "PGD l1: Attack effectiveness 46.667%.\n",
            "PGD l1: Attack effectiveness 50.000%.\n",
            "PGD l1: Attack effectiveness 27.273%.\n",
            "PGD l1: Attack effectiveness 44.828%.\n",
            "PGD l1: Attack effectiveness 50.000%.\n",
            "PGD l1: Attack effectiveness 42.308%.\n",
            "PGD l1: Attack effectiveness 67.857%.\n",
            "PGD l1: Attack effectiveness 48.649%.\n",
            "PGD l1: Attack effectiveness 21.875%.\n",
            "PGD l1: Attack effectiveness 40.625%.\n",
            "PGD l1: Attack effectiveness 38.889%.\n",
            "PGD l1: Attack effectiveness 48.649%.\n",
            "PGD l1: Attack effectiveness 39.474%.\n",
            "PGD l1: Attack effectiveness 41.935%.\n",
            "PGD l1: Attack effectiveness 60.714%.\n",
            "PGD l1: Attack effectiveness 35.714%.\n",
            "PGD l1: Attack effectiveness 70.588%.\n",
            "PGD l1: Attack effectiveness 20.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 55.31%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnTYMOvcR1Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef177ab-d4fe-463f-f1af-a369a0585b0f",
        "id": "MhVcJCFFSbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l2: Attack effectiveness 72.414%.\n",
            "PGD l2: Attack effectiveness 76.000%.\n",
            "PGD l2: Attack effectiveness 57.692%.\n",
            "PGD l2: Attack effectiveness 85.714%.\n",
            "PGD l2: Attack effectiveness 72.000%.\n",
            "PGD l2: Attack effectiveness 76.000%.\n",
            "PGD l2: Attack effectiveness 79.412%.\n",
            "PGD l2: Attack effectiveness 72.727%.\n",
            "PGD l2: Attack effectiveness 73.810%.\n",
            "PGD l2: Attack effectiveness 79.310%.\n",
            "PGD l2: Attack effectiveness 95.000%.\n",
            "PGD l2: Attack effectiveness 67.647%.\n",
            "PGD l2: Attack effectiveness 70.000%.\n",
            "PGD l2: Attack effectiveness 85.185%.\n",
            "PGD l2: Attack effectiveness 72.000%.\n",
            "PGD l2: Attack effectiveness 80.645%.\n",
            "PGD l2: Attack effectiveness 73.333%.\n",
            "PGD l2: Attack effectiveness 92.000%.\n",
            "PGD l2: Attack effectiveness 77.419%.\n",
            "PGD l2: Attack effectiveness 77.778%.\n",
            "PGD l2: Attack effectiveness 83.333%.\n",
            "PGD l2: Attack effectiveness 90.000%.\n",
            "PGD l2: Attack effectiveness 54.545%.\n",
            "PGD l2: Attack effectiveness 75.862%.\n",
            "PGD l2: Attack effectiveness 77.273%.\n",
            "PGD l2: Attack effectiveness 65.385%.\n",
            "PGD l2: Attack effectiveness 85.714%.\n",
            "PGD l2: Attack effectiveness 75.676%.\n",
            "PGD l2: Attack effectiveness 62.500%.\n",
            "PGD l2: Attack effectiveness 78.125%.\n",
            "PGD l2: Attack effectiveness 83.333%.\n",
            "PGD l2: Attack effectiveness 75.676%.\n",
            "PGD l2: Attack effectiveness 84.211%.\n",
            "PGD l2: Attack effectiveness 77.419%.\n",
            "PGD l2: Attack effectiveness 78.571%.\n",
            "PGD l2: Attack effectiveness 85.714%.\n",
            "PGD l2: Attack effectiveness 82.353%.\n",
            "PGD l2: Attack effectiveness 60.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 23.01%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 1.,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKIHNUqiSgqt",
        "outputId": "19f37121-67f4-4758-cae4-66c86a9dbab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l2: Attack effectiveness 72.414%.\n",
            "PGD l2: Attack effectiveness 76.000%.\n",
            "PGD l2: Attack effectiveness 57.692%.\n",
            "PGD l2: Attack effectiveness 82.857%.\n",
            "PGD l2: Attack effectiveness 80.000%.\n",
            "PGD l2: Attack effectiveness 76.000%.\n",
            "PGD l2: Attack effectiveness 79.412%.\n",
            "PGD l2: Attack effectiveness 66.667%.\n",
            "PGD l2: Attack effectiveness 73.810%.\n",
            "PGD l2: Attack effectiveness 75.862%.\n",
            "PGD l2: Attack effectiveness 95.000%.\n",
            "PGD l2: Attack effectiveness 67.647%.\n",
            "PGD l2: Attack effectiveness 70.000%.\n",
            "PGD l2: Attack effectiveness 77.778%.\n",
            "PGD l2: Attack effectiveness 72.000%.\n",
            "PGD l2: Attack effectiveness 77.419%.\n",
            "PGD l2: Attack effectiveness 70.000%.\n",
            "PGD l2: Attack effectiveness 92.000%.\n",
            "PGD l2: Attack effectiveness 77.419%.\n",
            "PGD l2: Attack effectiveness 74.074%.\n",
            "PGD l2: Attack effectiveness 83.333%.\n",
            "PGD l2: Attack effectiveness 86.667%.\n",
            "PGD l2: Attack effectiveness 54.545%.\n",
            "PGD l2: Attack effectiveness 75.862%.\n",
            "PGD l2: Attack effectiveness 75.000%.\n",
            "PGD l2: Attack effectiveness 61.538%.\n",
            "PGD l2: Attack effectiveness 85.714%.\n",
            "PGD l2: Attack effectiveness 78.378%.\n",
            "PGD l2: Attack effectiveness 56.250%.\n",
            "PGD l2: Attack effectiveness 81.250%.\n",
            "PGD l2: Attack effectiveness 75.000%.\n",
            "PGD l2: Attack effectiveness 75.676%.\n",
            "PGD l2: Attack effectiveness 81.579%.\n",
            "PGD l2: Attack effectiveness 77.419%.\n",
            "PGD l2: Attack effectiveness 78.571%.\n",
            "PGD l2: Attack effectiveness 85.714%.\n",
            "PGD l2: Attack effectiveness 79.412%.\n",
            "PGD l2: Attack effectiveness 60.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 24.34%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  {'bandwidth': 2.,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQgJk06uSgnm",
        "outputId": "6dbeabc0-22f5-4643-9d75-627153e1bab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l2: Attack effectiveness 72.414%.\n",
            "PGD l2: Attack effectiveness 68.000%.\n",
            "PGD l2: Attack effectiveness 46.154%.\n",
            "PGD l2: Attack effectiveness 71.429%.\n",
            "PGD l2: Attack effectiveness 60.000%.\n",
            "PGD l2: Attack effectiveness 60.000%.\n",
            "PGD l2: Attack effectiveness 70.588%.\n",
            "PGD l2: Attack effectiveness 57.576%.\n",
            "PGD l2: Attack effectiveness 69.048%.\n",
            "PGD l2: Attack effectiveness 58.621%.\n",
            "PGD l2: Attack effectiveness 80.000%.\n",
            "PGD l2: Attack effectiveness 64.706%.\n",
            "PGD l2: Attack effectiveness 55.000%.\n",
            "PGD l2: Attack effectiveness 74.074%.\n",
            "PGD l2: Attack effectiveness 68.000%.\n",
            "PGD l2: Attack effectiveness 70.968%.\n",
            "PGD l2: Attack effectiveness 66.667%.\n",
            "PGD l2: Attack effectiveness 84.000%.\n",
            "PGD l2: Attack effectiveness 61.290%.\n",
            "PGD l2: Attack effectiveness 74.074%.\n",
            "PGD l2: Attack effectiveness 70.000%.\n",
            "PGD l2: Attack effectiveness 73.333%.\n",
            "PGD l2: Attack effectiveness 45.455%.\n",
            "PGD l2: Attack effectiveness 68.966%.\n",
            "PGD l2: Attack effectiveness 68.182%.\n",
            "PGD l2: Attack effectiveness 57.692%.\n",
            "PGD l2: Attack effectiveness 75.000%.\n",
            "PGD l2: Attack effectiveness 75.676%.\n",
            "PGD l2: Attack effectiveness 50.000%.\n",
            "PGD l2: Attack effectiveness 62.500%.\n",
            "PGD l2: Attack effectiveness 63.889%.\n",
            "PGD l2: Attack effectiveness 67.568%.\n",
            "PGD l2: Attack effectiveness 73.684%.\n",
            "PGD l2: Attack effectiveness 67.742%.\n",
            "PGD l2: Attack effectiveness 78.571%.\n",
            "PGD l2: Attack effectiveness 71.429%.\n",
            "PGD l2: Attack effectiveness 76.471%.\n",
            "PGD l2: Attack effectiveness 46.667%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 33.01%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_n99n_3WSgjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    if (attack ==  gkde) or (attack ==  mimicry):\n",
        "      print('ok')\n",
        "      # Pre-select benign samples\n",
        "      benign_samples = []\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "      ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "      # Forward pass to get logits for benign samples\n",
        "      with torch.no_grad():  # No need for gradients\n",
        "          outputs = model(ben_x.to(torch.float32))\n",
        "\n",
        "      # Calculate softmax probabilities\n",
        "      probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "      # Sort indices based on probabilities of class 1 (assuming class 1 is the \"positive\" class)\n",
        "      sorted_indices = torch.argsort(probabilities[:, 1], descending=False)\n",
        "\n",
        "      # Select the top 500 high confidence benign samples\n",
        "      top_500_high_confidence_benign_samples = ben_x[sorted_indices[:500]]\n",
        "\n",
        "      del benign_samples, outputs, probabilities, ben_x  # Free up memory\n",
        "\n",
        "    model.eval()\n",
        "    n_samples = 0\n",
        "    cor_test = 0\n",
        "    cor_ad_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            #outputs = model(x_test)\n",
        "            #predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            #acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            #avg_acc_test.append(acc_test)\n",
        "\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "            n_samples += len(mal_y_batch)\n",
        "\n",
        "            outputs = model(mal_x_batch)\n",
        "            predicted = outputs.argmax(1)\n",
        "            cor_test += (predicted == 1).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            if attack == mimicry:\n",
        "                pertb_mal_x = mimicry(top_500_high_confidence_benign_samples, mal_x_batch, model, **kwargs)\n",
        "            elif attack == gkde:\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde(mal_x_batch, mal_y_batch, model, top_500_high_confidence_benign_samples, **kwargs)\n",
        "            else :\n",
        "                with torch.enable_grad():\n",
        "                    pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_test += (y_pred == 1).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Accuracy of just malwares (without attack): {(cor_test / n_samples) * 100:.4}% | Under attack: {(cor_ad_test / n_samples) * 100:.4}%.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "B2S5U28YIGzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = (loss_natural / (kde+ 1e-20)).detach()\n",
        "attack_params =  gkde,{'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqzXO5sCkeIv",
        "outputId": "c099ad36-e382-40ab-f1f9-029728b8a5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ok\n",
            "PGD l1: Attack effectiveness 72.414%.\n",
            "PGD l1: Attack effectiveness 64.000%.\n",
            "PGD l1: Attack effectiveness 50.000%.\n",
            "PGD l1: Attack effectiveness 74.286%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 64.000%.\n",
            "PGD l1: Attack effectiveness 64.706%.\n",
            "PGD l1: Attack effectiveness 57.576%.\n",
            "PGD l1: Attack effectiveness 61.905%.\n",
            "PGD l1: Attack effectiveness 62.069%.\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "PGD l1: Attack effectiveness 55.882%.\n",
            "PGD l1: Attack effectiveness 45.000%.\n",
            "PGD l1: Attack effectiveness 70.370%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 64.516%.\n",
            "PGD l1: Attack effectiveness 63.333%.\n",
            "PGD l1: Attack effectiveness 80.000%.\n",
            "PGD l1: Attack effectiveness 67.742%.\n",
            "PGD l1: Attack effectiveness 62.963%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 73.333%.\n",
            "PGD l1: Attack effectiveness 36.364%.\n",
            "PGD l1: Attack effectiveness 58.621%.\n",
            "PGD l1: Attack effectiveness 59.091%.\n",
            "PGD l1: Attack effectiveness 57.692%.\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "PGD l1: Attack effectiveness 67.568%.\n",
            "PGD l1: Attack effectiveness 53.125%.\n",
            "PGD l1: Attack effectiveness 62.500%.\n",
            "PGD l1: Attack effectiveness 69.444%.\n",
            "PGD l1: Attack effectiveness 72.973%.\n",
            "PGD l1: Attack effectiveness 63.158%.\n",
            "PGD l1: Attack effectiveness 67.742%.\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "PGD l1: Attack effectiveness 64.286%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 46.667%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.49%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3856fba6-090e-4a42-8fbe-f435c533c705",
        "id": "B40_ZyWzn7Vf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ok\n",
            "PGD l1: Attack effectiveness 72.414%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 42.308%.\n",
            "PGD l1: Attack effectiveness 80.000%.\n",
            "PGD l1: Attack effectiveness 72.000%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 70.588%.\n",
            "PGD l1: Attack effectiveness 60.606%.\n",
            "PGD l1: Attack effectiveness 69.048%.\n",
            "PGD l1: Attack effectiveness 62.069%.\n",
            "PGD l1: Attack effectiveness 85.000%.\n",
            "PGD l1: Attack effectiveness 61.765%.\n",
            "PGD l1: Attack effectiveness 55.000%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 64.000%.\n",
            "PGD l1: Attack effectiveness 77.419%.\n",
            "PGD l1: Attack effectiveness 70.000%.\n",
            "PGD l1: Attack effectiveness 88.000%.\n",
            "PGD l1: Attack effectiveness 61.290%.\n",
            "PGD l1: Attack effectiveness 70.370%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 73.333%.\n",
            "PGD l1: Attack effectiveness 45.455%.\n",
            "PGD l1: Attack effectiveness 65.517%.\n",
            "PGD l1: Attack effectiveness 63.636%.\n",
            "PGD l1: Attack effectiveness 61.538%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 70.270%.\n",
            "PGD l1: Attack effectiveness 56.250%.\n",
            "PGD l1: Attack effectiveness 59.375%.\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "PGD l1: Attack effectiveness 72.973%.\n",
            "PGD l1: Attack effectiveness 76.316%.\n",
            "PGD l1: Attack effectiveness 70.968%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 64.286%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 46.667%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 31.86%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_kde(adv_x,y,model,benigns, bandwidth, penalty_factor):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y.view(-1).long())\n",
        "    #print('ce: ', ce)\n",
        "    kde = KDE(adv_x, benigns, bandwidth)\n",
        "    #print('kde : ', kde)\n",
        "    loss_no_reduction = ce + penalty_factor * kde\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss_no_reduction, done\n",
        "\n",
        "def gkde(x, y, model,bens, bandwidth, penalty_factor, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural, _ = get_loss_kde(x,y,model,bens, bandwidth, penalty_factor)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        #y_model = model(x_var)\n",
        "        if t > 20:\n",
        "          decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "        else:\n",
        "          decayed_penalty_factor = penalty_factor\n",
        "\n",
        "        # Compute loss\n",
        "        loss, _ = get_loss_kde(x_var,y,model,bens, bandwidth, decayed_penalty_factor)\n",
        "        #loss,_ = get_loss_kde(x_var,y,model,bens, bandwidth, penalty_factor)\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "        #pos_insertion = (x_var <= 0.5) * 1 * insertion_array\n",
        "        pos_insertion = (x_var <= 0.5) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.5) * 1 * removal_array\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / l2norm).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x_next - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "\n",
        "            val, _ = torch.topk(torch.abs(gradients), 1)\n",
        "            perturbation = (torch.abs(gradients) >= val.expand_as(gradients)).float() * torch.sign(gradients).float()\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            _, done = get_loss_kde(x_next,y,model,bens, bandwidth, penalty_factor)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv, done = get_loss_kde(x_next,y,model,bens, bandwidth, penalty_factor)\n",
        "    loss_adv = loss_adv.data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "rBy2t9Kc5DA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# penalty_factor = 1000.\n",
        "attack_params =  {'bandwidth': 0.6,'penalty_factor': 1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, gkde, device, **attack_params)"
      ],
      "metadata": {
        "id": "gAWNQW7u5LKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81167f8-8130-4d38-f266-3b5069758624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ok\n",
            "PGD l1: Attack effectiveness 65.517%.\n",
            "PGD l1: Attack effectiveness 64.000%.\n",
            "PGD l1: Attack effectiveness 42.308%.\n",
            "PGD l1: Attack effectiveness 74.286%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 55.882%.\n",
            "PGD l1: Attack effectiveness 48.485%.\n",
            "PGD l1: Attack effectiveness 61.905%.\n",
            "PGD l1: Attack effectiveness 58.621%.\n",
            "PGD l1: Attack effectiveness 70.000%.\n",
            "PGD l1: Attack effectiveness 58.824%.\n",
            "PGD l1: Attack effectiveness 40.000%.\n",
            "PGD l1: Attack effectiveness 70.370%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 64.516%.\n",
            "PGD l1: Attack effectiveness 56.667%.\n",
            "PGD l1: Attack effectiveness 72.000%.\n",
            "PGD l1: Attack effectiveness 54.839%.\n",
            "PGD l1: Attack effectiveness 59.259%.\n",
            "PGD l1: Attack effectiveness 63.333%.\n",
            "PGD l1: Attack effectiveness 56.667%.\n",
            "PGD l1: Attack effectiveness 31.818%.\n",
            "PGD l1: Attack effectiveness 58.621%.\n",
            "PGD l1: Attack effectiveness 59.091%.\n",
            "PGD l1: Attack effectiveness 57.692%.\n",
            "PGD l1: Attack effectiveness 67.857%.\n",
            "PGD l1: Attack effectiveness 64.865%.\n",
            "PGD l1: Attack effectiveness 40.625%.\n",
            "PGD l1: Attack effectiveness 53.125%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 72.973%.\n",
            "PGD l1: Attack effectiveness 68.421%.\n",
            "PGD l1: Attack effectiveness 64.516%.\n",
            "PGD l1: Attack effectiveness 71.429%.\n",
            "PGD l1: Attack effectiveness 53.571%.\n",
            "PGD l1: Attack effectiveness 70.588%.\n",
            "PGD l1: Attack effectiveness 40.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 39.65%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PGD_min VS RBF"
      ],
      "metadata": {
        "id": "No0B0LWHxde5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVCkiKb7xiqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_min(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack (loss based on goal's class, which we have to minimize the loss).\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), torch.zeros_like(y.view(-1).long()))\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, torch.zeros_like(y.view(-1).long()))\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "        #print('loss : ',criterion(y_model, y.view(-1).long()))\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "            #print(torch.abs(perturbation).sum())\n",
        "            #print('torch.abs(perturbation).sum(dim=-1) : ',torch.abs(perturbation).sum(dim=-1))\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            #print('l2norm ; ',l2norm)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        #print(torch.abs(x_next - torch.clamp(x_next + perturbation * step_length, min=0., max=1.)).sum())\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), torch.zeros_like(y.view(-1).long())).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        done = get_done(x_next, y, model)\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "frsaxe7U8t7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_done(x, y, model):\n",
        "    # Get the model's predictions\n",
        "    outputs = model(x)\n",
        "\n",
        "    # Use argmax to get the predicted class indices\n",
        "    predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    # Ensure y is in the same shape as predicted for comparison\n",
        "    y = y.view_as(predicted)\n",
        "\n",
        "    # Determine if the predictions are incorrect\n",
        "    done = (predicted != y).bool()\n",
        "\n",
        "    return done\n",
        "\n",
        "def get_loss_rbf(adv_x: torch.Tensor, y: torch.Tensor, model: nn.Module, RBFModel: nn.Module, penalty_factor: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Compute CE loss\n",
        "    outputs = model(adv_x)\n",
        "    ce = criterion(outputs, y)\n",
        "    #print('ce ',ce)\n",
        "\n",
        "    # Compute KDE loss\n",
        "    outputs_rbf = RBFModel(adv_x)\n",
        "    kde = criterion(outputs_rbf, y)\n",
        "    #print('kde ',kde)\n",
        "\n",
        "    # Combine the losses with the penalty factor\n",
        "    loss = ce + penalty_factor * kde\n",
        "    #print('loss ',loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "def rbf(x, y, model, RBFModel, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "        initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "\n",
        "    :param x: Feature vector\n",
        "    :param y: Ground truth labels\n",
        "    :param model: Neural network model\n",
        "    :param RBFModel: Gaussian model for KDE\n",
        "    :param insertion_array: Array for insertion operations\n",
        "    :param removal_array: Array for removal operations\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf', 'l2', 'l1')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    #target's class\n",
        "    traget_labels = torch.zeros_like(y.view(-1).long())\n",
        "\n",
        "    # Compute natural loss and penalty_factor\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), traget_labels)\n",
        "    kde = criterion(RBFModel(x), traget_labels)\n",
        "    #penalty_factor = 0.\n",
        "    penalty_factor = (loss_natural / kde).detach()\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = get_x0(x.clone(), initial_rounding_threshold, is_sample)\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    for t in range(k):\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        decayed_penalty_factor = penalty_factor * (1 - t / k)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = get_loss_rbf(x_var, traget_labels, model, RBFModel, decayed_penalty_factor)\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        pos_insertion = (x_var <= 0.999) * 1 * insertion_array_updated\n",
        "        #pos_insertion = (x_var <= 0.999) * 1\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "\n",
        "        pos_removal = (x_var > 0.001) * 1 * removal_array_updated\n",
        "        grad4removal = (gradients < 0) * pos_removal * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "        elif norm == 'l1':\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1', 'l2', or 'linf' norm.\")\n",
        "\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    if random:\n",
        "        round_threshold = torch.rand_like(x_next)\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    outputs = model(x_next)\n",
        "    loss_adv = criterion(outputs, traget_labels).data\n",
        "    done = get_done(x_next, y, model)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size(0) * 100:.3f}%.\")\n",
        "\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next\n"
      ],
      "metadata": {
        "id": "A33nGhZDzOF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# when penalty_factor = 0\n",
        "attack_params =  {'RBFModel':model_gaussian_1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, rbf, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUH6bf-X4im3",
        "outputId": "181db644-6de1-4a17-b701-8a43a2cd0fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 72.414%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 46.154%.\n",
            "PGD l1: Attack effectiveness 77.143%.\n",
            "PGD l1: Attack effectiveness 72.000%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 70.588%.\n",
            "PGD l1: Attack effectiveness 60.606%.\n",
            "PGD l1: Attack effectiveness 69.048%.\n",
            "PGD l1: Attack effectiveness 65.517%.\n",
            "PGD l1: Attack effectiveness 85.000%.\n",
            "PGD l1: Attack effectiveness 61.765%.\n",
            "PGD l1: Attack effectiveness 55.000%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 77.419%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 88.000%.\n",
            "PGD l1: Attack effectiveness 64.516%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 70.000%.\n",
            "PGD l1: Attack effectiveness 76.667%.\n",
            "PGD l1: Attack effectiveness 45.455%.\n",
            "PGD l1: Attack effectiveness 65.517%.\n",
            "PGD l1: Attack effectiveness 63.636%.\n",
            "PGD l1: Attack effectiveness 61.538%.\n",
            "PGD l1: Attack effectiveness 82.143%.\n",
            "PGD l1: Attack effectiveness 70.270%.\n",
            "PGD l1: Attack effectiveness 56.250%.\n",
            "PGD l1: Attack effectiveness 62.500%.\n",
            "PGD l1: Attack effectiveness 72.222%.\n",
            "PGD l1: Attack effectiveness 72.973%.\n",
            "PGD l1: Attack effectiveness 78.947%.\n",
            "PGD l1: Attack effectiveness 74.194%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 71.429%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 53.333%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl4c1lyu0h3H",
        "outputId": "fac3d9f9-32f5-4ce9-bf26-8f0e72791e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 72.414%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 46.154%.\n",
            "PGD l1: Attack effectiveness 77.143%.\n",
            "PGD l1: Attack effectiveness 72.000%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 70.588%.\n",
            "PGD l1: Attack effectiveness 60.606%.\n",
            "PGD l1: Attack effectiveness 69.048%.\n",
            "PGD l1: Attack effectiveness 65.517%.\n",
            "PGD l1: Attack effectiveness 85.000%.\n",
            "PGD l1: Attack effectiveness 61.765%.\n",
            "PGD l1: Attack effectiveness 55.000%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 77.419%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 88.000%.\n",
            "PGD l1: Attack effectiveness 64.516%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 70.000%.\n",
            "PGD l1: Attack effectiveness 76.667%.\n",
            "PGD l1: Attack effectiveness 45.455%.\n",
            "PGD l1: Attack effectiveness 65.517%.\n",
            "PGD l1: Attack effectiveness 63.636%.\n",
            "PGD l1: Attack effectiveness 61.538%.\n",
            "PGD l1: Attack effectiveness 82.143%.\n",
            "PGD l1: Attack effectiveness 70.270%.\n",
            "PGD l1: Attack effectiveness 56.250%.\n",
            "PGD l1: Attack effectiveness 62.500%.\n",
            "PGD l1: Attack effectiveness 72.222%.\n",
            "PGD l1: Attack effectiveness 72.973%.\n",
            "PGD l1: Attack effectiveness 78.947%.\n",
            "PGD l1: Attack effectiveness 74.194%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 71.429%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 53.333%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.88%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# when penalty_factor = (loss_natural / kde).detach()\n",
        "attack_params =  {'RBFModel':model_gaussian_1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, rbf, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzZWr19C-SYp",
        "outputId": "ce8faf41-ec53-4bd3-b02e-188a19f01316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 68.966%.\n",
            "PGD l1: Attack effectiveness 76.000%.\n",
            "PGD l1: Attack effectiveness 53.846%.\n",
            "PGD l1: Attack effectiveness 82.857%.\n",
            "PGD l1: Attack effectiveness 76.000%.\n",
            "PGD l1: Attack effectiveness 76.000%.\n",
            "PGD l1: Attack effectiveness 70.588%.\n",
            "PGD l1: Attack effectiveness 63.636%.\n",
            "PGD l1: Attack effectiveness 71.429%.\n",
            "PGD l1: Attack effectiveness 75.862%.\n",
            "PGD l1: Attack effectiveness 90.000%.\n",
            "PGD l1: Attack effectiveness 64.706%.\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "PGD l1: Attack effectiveness 77.778%.\n",
            "PGD l1: Attack effectiveness 72.000%.\n",
            "PGD l1: Attack effectiveness 77.419%.\n",
            "PGD l1: Attack effectiveness 70.000%.\n",
            "PGD l1: Attack effectiveness 88.000%.\n",
            "PGD l1: Attack effectiveness 70.968%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 80.000%.\n",
            "PGD l1: Attack effectiveness 83.333%.\n",
            "PGD l1: Attack effectiveness 50.000%.\n",
            "PGD l1: Attack effectiveness 68.966%.\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "PGD l1: Attack effectiveness 65.385%.\n",
            "PGD l1: Attack effectiveness 85.714%.\n",
            "PGD l1: Attack effectiveness 72.973%.\n",
            "PGD l1: Attack effectiveness 62.500%.\n",
            "PGD l1: Attack effectiveness 78.125%.\n",
            "PGD l1: Attack effectiveness 83.333%.\n",
            "PGD l1: Attack effectiveness 75.676%.\n",
            "PGD l1: Attack effectiveness 81.579%.\n",
            "PGD l1: Attack effectiveness 74.194%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.84%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSMxrhlx13T2",
        "outputId": "247a1367-9cb9-4e3c-ed76-86f6385db1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l2: Attack effectiveness 72.414%.\n",
            "PGD l2: Attack effectiveness 72.000%.\n",
            "PGD l2: Attack effectiveness 53.846%.\n",
            "PGD l2: Attack effectiveness 85.714%.\n",
            "PGD l2: Attack effectiveness 72.000%.\n",
            "PGD l2: Attack effectiveness 68.000%.\n",
            "PGD l2: Attack effectiveness 76.471%.\n",
            "PGD l2: Attack effectiveness 72.727%.\n",
            "PGD l2: Attack effectiveness 71.429%.\n",
            "PGD l2: Attack effectiveness 68.966%.\n",
            "PGD l2: Attack effectiveness 90.000%.\n",
            "PGD l2: Attack effectiveness 64.706%.\n",
            "PGD l2: Attack effectiveness 65.000%.\n",
            "PGD l2: Attack effectiveness 81.481%.\n",
            "PGD l2: Attack effectiveness 68.000%.\n",
            "PGD l2: Attack effectiveness 83.871%.\n",
            "PGD l2: Attack effectiveness 70.000%.\n",
            "PGD l2: Attack effectiveness 92.000%.\n",
            "PGD l2: Attack effectiveness 77.419%.\n",
            "PGD l2: Attack effectiveness 77.778%.\n",
            "PGD l2: Attack effectiveness 80.000%.\n",
            "PGD l2: Attack effectiveness 90.000%.\n",
            "PGD l2: Attack effectiveness 50.000%.\n",
            "PGD l2: Attack effectiveness 68.966%.\n",
            "PGD l2: Attack effectiveness 72.727%.\n",
            "PGD l2: Attack effectiveness 65.385%.\n",
            "PGD l2: Attack effectiveness 85.714%.\n",
            "PGD l2: Attack effectiveness 75.676%.\n",
            "PGD l2: Attack effectiveness 62.500%.\n",
            "PGD l2: Attack effectiveness 75.000%.\n",
            "PGD l2: Attack effectiveness 80.556%.\n",
            "PGD l2: Attack effectiveness 72.973%.\n",
            "PGD l2: Attack effectiveness 81.579%.\n",
            "PGD l2: Attack effectiveness 74.194%.\n",
            "PGD l2: Attack effectiveness 78.571%.\n",
            "PGD l2: Attack effectiveness 82.143%.\n",
            "PGD l2: Attack effectiveness 82.353%.\n",
            "PGD l2: Attack effectiveness 53.333%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 25.4%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'RBFModel':model_gaussian_1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, rbf, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czJU9XFM-2mv",
        "outputId": "2cc001dc-f491-414e-d263-6b5cae5d1cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l2: Attack effectiveness 72.414%.\n",
            "PGD l2: Attack effectiveness 72.000%.\n",
            "PGD l2: Attack effectiveness 53.846%.\n",
            "PGD l2: Attack effectiveness 85.714%.\n",
            "PGD l2: Attack effectiveness 72.000%.\n",
            "PGD l2: Attack effectiveness 68.000%.\n",
            "PGD l2: Attack effectiveness 79.412%.\n",
            "PGD l2: Attack effectiveness 66.667%.\n",
            "PGD l2: Attack effectiveness 76.190%.\n",
            "PGD l2: Attack effectiveness 68.966%.\n",
            "PGD l2: Attack effectiveness 90.000%.\n",
            "PGD l2: Attack effectiveness 64.706%.\n",
            "PGD l2: Attack effectiveness 70.000%.\n",
            "PGD l2: Attack effectiveness 85.185%.\n",
            "PGD l2: Attack effectiveness 72.000%.\n",
            "PGD l2: Attack effectiveness 83.871%.\n",
            "PGD l2: Attack effectiveness 73.333%.\n",
            "PGD l2: Attack effectiveness 92.000%.\n",
            "PGD l2: Attack effectiveness 77.419%.\n",
            "PGD l2: Attack effectiveness 77.778%.\n",
            "PGD l2: Attack effectiveness 83.333%.\n",
            "PGD l2: Attack effectiveness 90.000%.\n",
            "PGD l2: Attack effectiveness 50.000%.\n",
            "PGD l2: Attack effectiveness 72.414%.\n",
            "PGD l2: Attack effectiveness 75.000%.\n",
            "PGD l2: Attack effectiveness 65.385%.\n",
            "PGD l2: Attack effectiveness 85.714%.\n",
            "PGD l2: Attack effectiveness 72.973%.\n",
            "PGD l2: Attack effectiveness 62.500%.\n",
            "PGD l2: Attack effectiveness 71.875%.\n",
            "PGD l2: Attack effectiveness 83.333%.\n",
            "PGD l2: Attack effectiveness 72.973%.\n",
            "PGD l2: Attack effectiveness 81.579%.\n",
            "PGD l2: Attack effectiveness 77.419%.\n",
            "PGD l2: Attack effectiveness 78.571%.\n",
            "PGD l2: Attack effectiveness 82.143%.\n",
            "PGD l2: Attack effectiveness 82.353%.\n",
            "PGD l2: Attack effectiveness 53.333%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 24.69%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GCx0_k-sDjcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R8N1KkEy19rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, pgd_min, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hLhT6VX1_V1",
        "outputId": "2c79f354-895a-4e6b-88fd-0a6250b80b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 72.414%.\n",
            "PGD linf: Attack effectiveness 64.000%.\n",
            "PGD linf: Attack effectiveness 38.462%.\n",
            "PGD linf: Attack effectiveness 74.286%.\n",
            "PGD linf: Attack effectiveness 68.000%.\n",
            "PGD linf: Attack effectiveness 60.000%.\n",
            "PGD linf: Attack effectiveness 70.588%.\n",
            "PGD linf: Attack effectiveness 60.606%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 62.069%.\n",
            "PGD linf: Attack effectiveness 85.000%.\n",
            "PGD linf: Attack effectiveness 55.882%.\n",
            "PGD linf: Attack effectiveness 45.000%.\n",
            "PGD linf: Attack effectiveness 74.074%.\n",
            "PGD linf: Attack effectiveness 60.000%.\n",
            "PGD linf: Attack effectiveness 61.290%.\n",
            "PGD linf: Attack effectiveness 63.333%.\n",
            "PGD linf: Attack effectiveness 76.000%.\n",
            "PGD linf: Attack effectiveness 67.742%.\n",
            "PGD linf: Attack effectiveness 70.370%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 70.000%.\n",
            "PGD linf: Attack effectiveness 40.909%.\n",
            "PGD linf: Attack effectiveness 58.621%.\n",
            "PGD linf: Attack effectiveness 61.364%.\n",
            "PGD linf: Attack effectiveness 61.538%.\n",
            "PGD linf: Attack effectiveness 71.429%.\n",
            "PGD linf: Attack effectiveness 67.568%.\n",
            "PGD linf: Attack effectiveness 43.750%.\n",
            "PGD linf: Attack effectiveness 59.375%.\n",
            "PGD linf: Attack effectiveness 69.444%.\n",
            "PGD linf: Attack effectiveness 72.973%.\n",
            "PGD linf: Attack effectiveness 65.789%.\n",
            "PGD linf: Attack effectiveness 64.516%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 60.714%.\n",
            "PGD linf: Attack effectiveness 79.412%.\n",
            "PGD linf: Attack effectiveness 40.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 35.58%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'RBFModel':model_gaussian_1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, rbf, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4916de19-0231-48bf-a16b-77420f16b486",
        "id": "d5BJy7BG1_WE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 68.966%.\n",
            "PGD linf: Attack effectiveness 52.000%.\n",
            "PGD linf: Attack effectiveness 38.462%.\n",
            "PGD linf: Attack effectiveness 65.714%.\n",
            "PGD linf: Attack effectiveness 60.000%.\n",
            "PGD linf: Attack effectiveness 48.000%.\n",
            "PGD linf: Attack effectiveness 61.765%.\n",
            "PGD linf: Attack effectiveness 57.576%.\n",
            "PGD linf: Attack effectiveness 54.762%.\n",
            "PGD linf: Attack effectiveness 62.069%.\n",
            "PGD linf: Attack effectiveness 70.000%.\n",
            "PGD linf: Attack effectiveness 55.882%.\n",
            "PGD linf: Attack effectiveness 35.000%.\n",
            "PGD linf: Attack effectiveness 70.370%.\n",
            "PGD linf: Attack effectiveness 48.000%.\n",
            "PGD linf: Attack effectiveness 58.065%.\n",
            "PGD linf: Attack effectiveness 60.000%.\n",
            "PGD linf: Attack effectiveness 68.000%.\n",
            "PGD linf: Attack effectiveness 54.839%.\n",
            "PGD linf: Attack effectiveness 62.963%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 40.909%.\n",
            "PGD linf: Attack effectiveness 51.724%.\n",
            "PGD linf: Attack effectiveness 54.545%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 71.429%.\n",
            "PGD linf: Attack effectiveness 59.459%.\n",
            "PGD linf: Attack effectiveness 37.500%.\n",
            "PGD linf: Attack effectiveness 53.125%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 54.054%.\n",
            "PGD linf: Attack effectiveness 63.158%.\n",
            "PGD linf: Attack effectiveness 61.290%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 57.143%.\n",
            "PGD linf: Attack effectiveness 79.412%.\n",
            "PGD linf: Attack effectiveness 33.333%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 41.59%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'RBFModel':model_gaussian_1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 200, 'step_length': 0.01, 'norm': 'linf', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, rbf, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBDplVFa2Xzi",
        "outputId": "396cfc92-d78a-4f8f-c754-f6fe45a60494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 72.414%.\n",
            "PGD linf: Attack effectiveness 72.000%.\n",
            "PGD linf: Attack effectiveness 46.154%.\n",
            "PGD linf: Attack effectiveness 80.000%.\n",
            "PGD linf: Attack effectiveness 68.000%.\n",
            "PGD linf: Attack effectiveness 60.000%.\n",
            "PGD linf: Attack effectiveness 70.588%.\n",
            "PGD linf: Attack effectiveness 60.606%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 62.069%.\n",
            "PGD linf: Attack effectiveness 85.000%.\n",
            "PGD linf: Attack effectiveness 58.824%.\n",
            "PGD linf: Attack effectiveness 40.000%.\n",
            "PGD linf: Attack effectiveness 81.481%.\n",
            "PGD linf: Attack effectiveness 68.000%.\n",
            "PGD linf: Attack effectiveness 67.742%.\n",
            "PGD linf: Attack effectiveness 66.667%.\n",
            "PGD linf: Attack effectiveness 84.000%.\n",
            "PGD linf: Attack effectiveness 64.516%.\n",
            "PGD linf: Attack effectiveness 70.370%.\n",
            "PGD linf: Attack effectiveness 73.333%.\n",
            "PGD linf: Attack effectiveness 76.667%.\n",
            "PGD linf: Attack effectiveness 45.455%.\n",
            "PGD linf: Attack effectiveness 62.069%.\n",
            "PGD linf: Attack effectiveness 68.182%.\n",
            "PGD linf: Attack effectiveness 57.692%.\n",
            "PGD linf: Attack effectiveness 71.429%.\n",
            "PGD linf: Attack effectiveness 67.568%.\n",
            "PGD linf: Attack effectiveness 50.000%.\n",
            "PGD linf: Attack effectiveness 62.500%.\n",
            "PGD linf: Attack effectiveness 72.222%.\n",
            "PGD linf: Attack effectiveness 72.973%.\n",
            "PGD linf: Attack effectiveness 68.421%.\n",
            "PGD linf: Attack effectiveness 67.742%.\n",
            "PGD linf: Attack effectiveness 75.000%.\n",
            "PGD linf: Attack effectiveness 67.857%.\n",
            "PGD linf: Attack effectiveness 79.412%.\n",
            "PGD linf: Attack effectiveness 40.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 32.92%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# when penalty_factor = (loss_natural / kde).detach()/2.\n",
        "attack_params =  {'RBFModel':model_gaussian_1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, rbf, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkn64rNd--PM",
        "outputId": "243e5f6f-7f90-42b3-dc60-84516f1e8a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 68.966%.\n",
            "PGD l1: Attack effectiveness 76.000%.\n",
            "PGD l1: Attack effectiveness 46.154%.\n",
            "PGD l1: Attack effectiveness 80.000%.\n",
            "PGD l1: Attack effectiveness 76.000%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 60.606%.\n",
            "PGD l1: Attack effectiveness 69.048%.\n",
            "PGD l1: Attack effectiveness 72.414%.\n",
            "PGD l1: Attack effectiveness 90.000%.\n",
            "PGD l1: Attack effectiveness 61.765%.\n",
            "PGD l1: Attack effectiveness 55.000%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 64.000%.\n",
            "PGD l1: Attack effectiveness 77.419%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 88.000%.\n",
            "PGD l1: Attack effectiveness 70.968%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 73.333%.\n",
            "PGD l1: Attack effectiveness 80.000%.\n",
            "PGD l1: Attack effectiveness 50.000%.\n",
            "PGD l1: Attack effectiveness 68.966%.\n",
            "PGD l1: Attack effectiveness 68.182%.\n",
            "PGD l1: Attack effectiveness 65.385%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 72.973%.\n",
            "PGD l1: Attack effectiveness 56.250%.\n",
            "PGD l1: Attack effectiveness 68.750%.\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "PGD l1: Attack effectiveness 75.676%.\n",
            "PGD l1: Attack effectiveness 73.684%.\n",
            "PGD l1: Attack effectiveness 70.968%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 71.429%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.03%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# when penalty_factor = (loss_natural / kde).detach()  fixed\n",
        "attack_params =  {'RBFModel':model_gaussian_1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, rbf, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybfmw4np_24q",
        "outputId": "451f0adc-3c4f-456f-ef60-f660a24ed5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 68.966%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 42.308%.\n",
            "PGD l1: Attack effectiveness 82.857%.\n",
            "PGD l1: Attack effectiveness 76.000%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 76.471%.\n",
            "PGD l1: Attack effectiveness 54.545%.\n",
            "PGD l1: Attack effectiveness 69.048%.\n",
            "PGD l1: Attack effectiveness 65.517%.\n",
            "PGD l1: Attack effectiveness 90.000%.\n",
            "PGD l1: Attack effectiveness 58.824%.\n",
            "PGD l1: Attack effectiveness 65.000%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 64.000%.\n",
            "PGD l1: Attack effectiveness 77.419%.\n",
            "PGD l1: Attack effectiveness 70.000%.\n",
            "PGD l1: Attack effectiveness 88.000%.\n",
            "PGD l1: Attack effectiveness 67.742%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 70.000%.\n",
            "PGD l1: Attack effectiveness 80.000%.\n",
            "PGD l1: Attack effectiveness 45.455%.\n",
            "PGD l1: Attack effectiveness 68.966%.\n",
            "PGD l1: Attack effectiveness 68.182%.\n",
            "PGD l1: Attack effectiveness 65.385%.\n",
            "PGD l1: Attack effectiveness 85.714%.\n",
            "PGD l1: Attack effectiveness 67.568%.\n",
            "PGD l1: Attack effectiveness 62.500%.\n",
            "PGD l1: Attack effectiveness 59.375%.\n",
            "PGD l1: Attack effectiveness 77.778%.\n",
            "PGD l1: Attack effectiveness 75.676%.\n",
            "PGD l1: Attack effectiveness 73.684%.\n",
            "PGD l1: Attack effectiveness 67.742%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 64.286%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 53.333%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 30.09%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# when penalty_factor = (loss_natural / kde).detach()  decrease by /2\n",
        "attack_params =  {'RBFModel':model_gaussian_1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, rbf, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN_8pD9wALwe",
        "outputId": "8bb71b0f-2eb4-4033-8df1-ce871ba9b326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 72.414%.\n",
            "PGD l1: Attack effectiveness 72.000%.\n",
            "PGD l1: Attack effectiveness 50.000%.\n",
            "PGD l1: Attack effectiveness 80.000%.\n",
            "PGD l1: Attack effectiveness 76.000%.\n",
            "PGD l1: Attack effectiveness 76.000%.\n",
            "PGD l1: Attack effectiveness 76.471%.\n",
            "PGD l1: Attack effectiveness 60.606%.\n",
            "PGD l1: Attack effectiveness 69.048%.\n",
            "PGD l1: Attack effectiveness 75.862%.\n",
            "PGD l1: Attack effectiveness 90.000%.\n",
            "PGD l1: Attack effectiveness 64.706%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 80.645%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 88.000%.\n",
            "PGD l1: Attack effectiveness 67.742%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 73.333%.\n",
            "PGD l1: Attack effectiveness 73.333%.\n",
            "PGD l1: Attack effectiveness 50.000%.\n",
            "PGD l1: Attack effectiveness 68.966%.\n",
            "PGD l1: Attack effectiveness 65.909%.\n",
            "PGD l1: Attack effectiveness 57.692%.\n",
            "PGD l1: Attack effectiveness 82.143%.\n",
            "PGD l1: Attack effectiveness 75.676%.\n",
            "PGD l1: Attack effectiveness 62.500%.\n",
            "PGD l1: Attack effectiveness 71.875%.\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "PGD l1: Attack effectiveness 75.676%.\n",
            "PGD l1: Attack effectiveness 78.947%.\n",
            "PGD l1: Attack effectiveness 70.968%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 71.429%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 28.32%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# when penalty_factor = (loss_natural / kde).detach()  penalty_factor /(2**(t-1))\n",
        "attack_params =  {'RBFModel':model_gaussian_1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 50, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, rbf, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1037d2-c97f-4414-accc-c0f0f20fb11f",
        "id": "EciUXJgpBhG5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 72.414%.\n",
            "PGD l1: Attack effectiveness 72.000%.\n",
            "PGD l1: Attack effectiveness 53.846%.\n",
            "PGD l1: Attack effectiveness 74.286%.\n",
            "PGD l1: Attack effectiveness 72.000%.\n",
            "PGD l1: Attack effectiveness 76.000%.\n",
            "PGD l1: Attack effectiveness 76.471%.\n",
            "PGD l1: Attack effectiveness 60.606%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 75.862%.\n",
            "PGD l1: Attack effectiveness 85.000%.\n",
            "PGD l1: Attack effectiveness 64.706%.\n",
            "PGD l1: Attack effectiveness 55.000%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 74.194%.\n",
            "PGD l1: Attack effectiveness 63.333%.\n",
            "PGD l1: Attack effectiveness 88.000%.\n",
            "PGD l1: Attack effectiveness 67.742%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 73.333%.\n",
            "PGD l1: Attack effectiveness 80.000%.\n",
            "PGD l1: Attack effectiveness 50.000%.\n",
            "PGD l1: Attack effectiveness 65.517%.\n",
            "PGD l1: Attack effectiveness 65.909%.\n",
            "PGD l1: Attack effectiveness 61.538%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 75.676%.\n",
            "PGD l1: Attack effectiveness 59.375%.\n",
            "PGD l1: Attack effectiveness 71.875%.\n",
            "PGD l1: Attack effectiveness 75.000%.\n",
            "PGD l1: Attack effectiveness 75.676%.\n",
            "PGD l1: Attack effectiveness 76.316%.\n",
            "PGD l1: Attack effectiveness 70.968%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 71.429%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 29.29%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# when penalty_factor = (loss_natural / kde).detach()\n",
        "attack_params =  {'RBFModel':model_gaussian_1000,'insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 1., 'norm': 'l1', 'is_report_loss_diff' : True}\n",
        "adv_predict(test_loader, model_AT_rFGSM, rbf, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhvM7ueGCpqR",
        "outputId": "d9edecc2-810d-4eed-eac6-65859a74c32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD l1: Attack effectiveness 68.966%.\n",
            "PGD l1: Attack effectiveness 72.000%.\n",
            "PGD l1: Attack effectiveness 46.154%.\n",
            "PGD l1: Attack effectiveness 80.000%.\n",
            "PGD l1: Attack effectiveness 76.000%.\n",
            "PGD l1: Attack effectiveness 76.000%.\n",
            "PGD l1: Attack effectiveness 67.647%.\n",
            "PGD l1: Attack effectiveness 63.636%.\n",
            "PGD l1: Attack effectiveness 66.667%.\n",
            "PGD l1: Attack effectiveness 75.862%.\n",
            "PGD l1: Attack effectiveness 95.000%.\n",
            "PGD l1: Attack effectiveness 64.706%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "PGD l1: Attack effectiveness 85.185%.\n",
            "PGD l1: Attack effectiveness 68.000%.\n",
            "PGD l1: Attack effectiveness 77.419%.\n",
            "PGD l1: Attack effectiveness 70.000%.\n",
            "PGD l1: Attack effectiveness 88.000%.\n",
            "PGD l1: Attack effectiveness 74.194%.\n",
            "PGD l1: Attack effectiveness 74.074%.\n",
            "PGD l1: Attack effectiveness 83.333%.\n",
            "PGD l1: Attack effectiveness 90.000%.\n",
            "PGD l1: Attack effectiveness 54.545%.\n",
            "PGD l1: Attack effectiveness 72.414%.\n",
            "PGD l1: Attack effectiveness 70.455%.\n",
            "PGD l1: Attack effectiveness 65.385%.\n",
            "PGD l1: Attack effectiveness 85.714%.\n",
            "PGD l1: Attack effectiveness 72.973%.\n",
            "PGD l1: Attack effectiveness 59.375%.\n",
            "PGD l1: Attack effectiveness 78.125%.\n",
            "PGD l1: Attack effectiveness 77.778%.\n",
            "PGD l1: Attack effectiveness 75.676%.\n",
            "PGD l1: Attack effectiveness 84.211%.\n",
            "PGD l1: Attack effectiveness 74.194%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 78.571%.\n",
            "PGD l1: Attack effectiveness 79.412%.\n",
            "PGD l1: Attack effectiveness 60.000%.\n",
            "Accuracy of just malwares (without attack): 94.69% | Under attack: 26.37%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vRkMRmST4QDI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}