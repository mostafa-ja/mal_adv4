{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/mal_adv4/blob/main/PGD_max.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzlso6a2ls-W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading data"
      ],
      "metadata": {
        "id": "f_I3TDVL-SAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RBF_models\n",
        "\n",
        "download_links = [\n",
        "                  'https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f',\n",
        "                  'https://drive.google.com/uc?id=1-OHACrNCt0yKBbdqQPVfNZcjKt5_jxKD',\n",
        "                  'https://drive.google.com/uc?id=1-KeXJXtU1_6m9JOhormeVwigy0myX3HL',\n",
        "                  'https://drive.google.com/uc?id=1-13RDdZqnrNkdHg3D8PC5KI0CZREwlsz',\n",
        "                  'https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP',\n",
        "\n",
        "]\n",
        "\n",
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM_3KjraHnkn",
        "outputId": "d8ba39ef-55a0-486d-8f91-847a84825489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f\n",
            "From (redirected): https://drive.google.com/uc?id=1-8lJXLdAl_4NdDwzw9kFML0aiOCTrI9f&confirm=t&uuid=497b95c1-c3d8-4cb2-bbe5-abca8fe07f0f\n",
            "To: /content/best_model_gaussian_400.pth\n",
            "100%|██████████| 32.0M/32.0M [00:00<00:00, 38.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-OHACrNCt0yKBbdqQPVfNZcjKt5_jxKD\n",
            "To: /content/best_model_gaussian_600_nonremoval.pth\n",
            "100%|██████████| 5.50M/5.50M [00:00<00:00, 24.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-KeXJXtU1_6m9JOhormeVwigy0myX3HL\n",
            "To: /content/best_model_gaussian_600.pth\n",
            "100%|██████████| 24.0M/24.0M [00:00<00:00, 31.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-13RDdZqnrNkdHg3D8PC5KI0CZREwlsz\n",
            "To: /content/best_model_gaussian_1000_nonremoval.pth\n",
            "100%|██████████| 9.16M/9.16M [00:00<00:00, 24.5MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP\n",
            "From (redirected): https://drive.google.com/uc?id=1-8LjsCdzKh6asxCFsYLiQZbSEXXKSQBP&confirm=t&uuid=20ab1a63-83b3-4df3-b15e-c6cfb0ddfebd\n",
            "To: /content/best_model_gaussian_1000.pth\n",
            "100%|██████████| 40.0M/40.0M [00:00<00:00, 46.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "download_links = ['https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl',\n",
        "                  'https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py'\n",
        "]"
      ],
      "metadata": {
        "id": "1IW4pHac9VLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "output_filepath = '/content/'\n",
        "for link in download_links:\n",
        "  gdown.download(link, output_filepath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kzSbjaXGVeG",
        "outputId": "86a07e8d-f6ef-4fca-81e5-13e77e26c01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_0.npz\n",
            "To: /content/sparse_matrix_0.npz\n",
            "100%|██████████| 461k/461k [00:00<00:00, 4.22MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_1.npz\n",
            "To: /content/sparse_matrix_1.npz\n",
            "100%|██████████| 148k/148k [00:00<00:00, 8.68MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_2.npz\n",
            "To: /content/sparse_matrix_2.npz\n",
            "100%|██████████| 150k/150k [00:00<00:00, 7.53MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y0.npz\n",
            "To: /content/sparse_matrix_y0.npz\n",
            "100%|██████████| 5.79k/5.79k [00:00<00:00, 4.80MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y1.npz\n",
            "To: /content/sparse_matrix_y1.npz\n",
            "100%|██████████| 2.64k/2.64k [00:00<00:00, 6.85MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/sparse_matrix_y2.npz\n",
            "To: /content/sparse_matrix_y2.npz\n",
            "100%|██████████| 2.71k/2.71k [00:00<00:00, 5.22MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_DNN_drebin_best.pth\n",
            "To: /content/model_DNN_drebin_best.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 37.6MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM_weightedLoss.pth\n",
            "To: /content/model_AT_rFGSM_weightedLoss.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 37.4MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv3/raw/main/drebin/model_AT_rFGSM.pth\n",
            "To: /content/model_AT_rFGSM.pth\n",
            "100%|██████████| 8.17M/8.17M [00:00<00:00, 36.0MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/insertion_array.pkl\n",
            "To: /content/insertion_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 3.51MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/removal_array.pkl\n",
            "To: /content/removal_array.pkl\n",
            "100%|██████████| 80.2k/80.2k [00:00<00:00, 3.99MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/mostafa-ja/mal_adv4/raw/main/dataset/adverserial_attacks_functions.py\n",
            "To: /content/adverserial_attacks_functions.py\n",
            "67.1kB [00:00, 68.3MB/s]                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,balanced_accuracy_score\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "from adverserial_attacks_functions import *\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "JKDdI3K9LrlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68b1d97-2bcf-4151-ac31-22f2434948b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b5806751510>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    #os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX4ncRLLFDnN",
        "outputId": "037c106f-b02d-4aba-e2b7-109c8d67c586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the .pkl file\n",
        "with open('/content/insertion_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    insertion_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "insertion_array = torch.tensor(insertion_array, dtype=torch.uint8).to(device)\n",
        "print(len(insertion_array))\n",
        "\n",
        "# Open the .pkl file\n",
        "with open('/content/removal_array.pkl', 'rb') as f:\n",
        "    # Load the object\n",
        "    removal_array = pickle.load(f)\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "removal_array = torch.tensor(removal_array, dtype=torch.uint8).to(device)\n",
        "print(len(removal_array))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXV0WIjsJG_F",
        "outputId": "9399e522-7c3f-4d42-ea0d-50d4bef1a034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load dataset\n",
        "X_train = sparse.load_npz(\"/content/sparse_matrix_0.npz\").toarray()\n",
        "X_val = sparse.load_npz(\"/content/sparse_matrix_1.npz\").toarray()\n",
        "X_test = sparse.load_npz(\"/content/sparse_matrix_2.npz\").toarray()\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.int8)\n",
        "X_val = torch.tensor(X_val, dtype=torch.int8)\n",
        "X_test = torch.tensor(X_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "y_train = sparse.load_npz(\"/content/sparse_matrix_y0.npz\").toarray().reshape((-1, 1))\n",
        "y_val = sparse.load_npz(\"/content/sparse_matrix_y1.npz\").toarray().reshape((-1, 1))\n",
        "y_test = sparse.load_npz(\"/content/sparse_matrix_y2.npz\").toarray().reshape((-1, 1))\n",
        "\n",
        "y_train = torch.tensor(y_train, dtype=torch.int8)\n",
        "y_val = torch.tensor(y_val, dtype=torch.int8)\n",
        "y_test = torch.tensor(y_test, dtype=torch.int8)\n",
        "\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"x_train:\", X_train.shape)\n",
        "print(\"x_val:\", X_val.shape)\n",
        "print(\"x_test:\", X_test.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"y_val:\", y_val.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5blmEg4h-GKy",
        "outputId": "c99776a7-12f1-4b85-b4f5-24179477b78c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:\n",
            "x_train: torch.Size([28683, 10000])\n",
            "x_val: torch.Size([9562, 10000])\n",
            "x_test: torch.Size([9562, 10000])\n",
            "y_train: torch.Size([28683, 1])\n",
            "y_val: torch.Size([9562, 1])\n",
            "y_test: torch.Size([9562, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of benigns and malicious sample in training dataset\n",
        "n_ben = (y_train.squeeze()== 0).sum().item()\n",
        "n_mal = (y_train.squeeze()== 1).sum().item()\n",
        "print('the proportion of malwares : ', n_mal/(n_mal+n_ben))\n",
        "\n",
        "# Combine features and labels into datasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Define the DataLoader for training, validation, and test sets\n",
        "batch_size = 1024\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Clear unnecessary variables\n",
        "del train_dataset, val_dataset, test_dataset, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81AZSXOV-HoW",
        "outputId": "a8b232ba-bd7a-41cd-904a-df486ff3ec6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the proportion of malwares :  0.11386535578565701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4SfV6ct5Gfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN = MalwareDetectionModel().to(device)\n",
        "# Load model parameters\n",
        "model_DNN.load_state_dict(torch.load('model_DNN_drebin_best.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "id": "0MavlKAt6mb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a446d4-d6a4-4e02-dc89-a8cac20c9f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM.load_state_dict(torch.load('model_AT_rFGSM.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26137b8-f373-4214-c98e-2b546083d513",
        "id": "ga4V4Pek-b_D"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_rFGSM_weightedLoss = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_rFGSM_weightedLoss.load_state_dict(torch.load('model_AT_rFGSM_weightedLoss.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGs5E9_2SDbJ",
        "outputId": "860df325-6aa5-4a96-d3ad-e119ea95cb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(model_DNN, test_loader, device)"
      ],
      "metadata": {
        "id": "xk78RQCW-V9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c3f574-8f4c-4a5a-8c22-e42a6209b6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9912\n",
            "Test balanced Accuracy: 0.9785\n",
            "Precision: 0.9637\n",
            "Recall: 0.9619\n",
            "F1-score: 0.9628\n",
            "True Positives (TP): 1087\n",
            "True Negatives (TN): 8391\n",
            "False Positives (FP): 41\n",
            "False Negatives (FN): 43\n",
            "False Negative Rate (FNR): 3.8053\n",
            "False Positive Rate (FPR): 0.4862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(model_AT_rFGSM,test_loader,device)"
      ],
      "metadata": {
        "id": "rbnXfFVsg5Qd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a52418-1586-45bd-9e12-eadb27380198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9893\n",
            "Test balanced Accuracy: 0.9710\n",
            "Precision: 0.9622\n",
            "Recall: 0.9469\n",
            "F1-score: 0.9545\n",
            "True Positives (TP): 1070\n",
            "True Negatives (TN): 8390\n",
            "False Positives (FP): 42\n",
            "False Negatives (FN): 60\n",
            "False Negative Rate (FNR): 5.3097\n",
            "False Positive Rate (FPR): 0.4981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(model_AT_rFGSM_weightedLoss,test_loader,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "909EV2TTSJ8t",
        "outputId": "f2a56ada-f5a2-4889-91e4-f29bbcfaabb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9872\n",
            "Test balanced Accuracy: 0.9782\n",
            "Precision: 0.9286\n",
            "Recall: 0.9664\n",
            "F1-score: 0.9471\n",
            "True Positives (TP): 1092\n",
            "True Negatives (TN): 8348\n",
            "False Positives (FP): 84\n",
            "False Negatives (FN): 38\n",
            "False Negative Rate (FNR): 3.3628\n",
            "False Positive Rate (FPR): 0.9962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RBFModel(nn.Module):\n",
        "    def __init__(self, hidden_dim, output_dim, init_centers, init_sigmas, kernel):\n",
        "        super(RBFModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.centers = nn.Parameter(torch.Tensor(init_centers))\n",
        "        self.sigmas = nn.Parameter(torch.Tensor(init_sigmas))\n",
        "        self.kernel = kernel\n",
        "        # Linear layer for output\n",
        "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def gaussian(self, x, c, sigma):\n",
        "        return torch.exp(-torch.sum((x[:, None, :] - c) ** 2, dim=-1) / (2 * sigma ** 2))\n",
        "\n",
        "    def laplacian(self, x, c, sigma):\n",
        "        return torch.exp(-torch.sum(torch.abs(x[:, None, :] - c) , dim=-1) / sigma)\n",
        "\n",
        "    def forward(self, x):\n",
        "      if self.kernel == 'gaussian':\n",
        "        radial_out = self.gaussian(x, self.centers, self.sigmas)\n",
        "      elif self.kernel == 'laplacian':\n",
        "        radial_out = self.laplacian(x, self.centers, self.sigmas)\n",
        "      else:\n",
        "        raise ValueError(\"Invalid kernel type. Choose 'gaussian' or 'laplacian'.\")\n",
        "\n",
        "      output = self.linear(radial_out.to(torch.float32))\n",
        "      return output\n"
      ],
      "metadata": {
        "id": "WHAI-VGJSGa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_removal_features = False\n",
        "non_removal_mask = torch.logical_not(removal_array).to('cpu')\n",
        "sigma = 4.15\n",
        "kernel = 'gaussian'\n",
        "all_centers = torch.rand((1000, 10000))\n",
        "model_gaussian_1000 = RBFModel(1000, 2, all_centers, [sigma], kernel)\n",
        "model_gaussian_1000 = model_gaussian_1000.to(device)\n",
        "\n",
        "# Load the model state dictionary\n",
        "model_gaussian_1000.load_state_dict(torch.load('/content/best_model_gaussian_1000.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "id": "W9qJYeK0bbnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc6e90b-fd74-4453-adaa-fbd9e5bae43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_removal_features = True\n",
        "non_removal_mask = torch.logical_not(removal_array).to('cpu')\n",
        "sigma = 4.15\n",
        "kernel = 'gaussian'\n",
        "all_centers = torch.rand((1000, 1144))\n",
        "model_gaussian_1000_nonremoval = RBFModel(1000, 2, all_centers, [sigma], kernel)\n",
        "model_gaussian_1000_nonremoval = model_gaussian_1000_nonremoval.to(device)\n",
        "\n",
        "# Load the model state dictionary\n",
        "model_gaussian_1000_nonremoval.load_state_dict(torch.load('/content/best_model_gaussian_1000_nonremoval.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMA7rzpTPhv7",
        "outputId": "7575fcc4-cb69-43fb-8f25-ceef8ae83d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in test_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break\n",
        "\n",
        "bens = x[y.squeeze()==0]\n",
        "bens_y = y[y.squeeze()==0]\n",
        "print(bens.shape)\n",
        "\n",
        "mals = x[y.squeeze()==1]\n",
        "mals_y = y[y.squeeze()==1]\n",
        "print(mals.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StL135L1JUiE",
        "outputId": "1d26c0af-b2f1-41c1-c432-278e451eaa20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1024, 10000])\n",
            "torch.Size([1024, 1])\n",
            "torch.Size([909, 10000])\n",
            "torch.Size([115, 10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o3ia6BEnBWux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "JWm66EMNBX3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_done(x, y, model):\n",
        "    # Get the model's predictions\n",
        "    outputs = model(x)\n",
        "\n",
        "    # Use argmax to get the predicted class indices\n",
        "    predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    # Ensure y is in the same shape as predicted for comparison\n",
        "    y = y.view_as(predicted)\n",
        "\n",
        "    # Determine if the predictions are incorrect\n",
        "    done = (predicted != y).bool()\n",
        "\n",
        "    return done"
      ],
      "metadata": {
        "id": "575llJ__CHFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd2(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack.\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), y.view(-1).long())\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "\n",
        "    #insertion_array_updated = torch.bitwise_or(insertion_array.to(torch.uint8), x.squeeze().to(torch.uint8) )\n",
        "    #removal_array_updated = torch.bitwise_or(removal_array.to(torch.uint8), (1 - x.squeeze().to(torch.uint8)) )\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, y.view(-1).long())\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "        #print('loss : ',criterion(y_model, y.view(-1).long()))\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = grad_vars[0].data\n",
        "\n",
        "        grad4insertion = (gradients >= 0) *(x_var < 1.)* insertion_array_updated * gradients\n",
        "        grad4removal = (gradients < 0) * (x_var > 0.) * removal_array_updated * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #gradients =  grad4insertion\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "            #perturbation = torch.minimum(torch.tensor(1., dtype=x.dtype, device=x.device), gradients / l2norm).float()\n",
        "            #perturbation = torch.maximum(torch.tensor(-1., dtype=x.dtype, device=x.device), perturbation).float()\n",
        "            #perturbation[torch.isnan(perturbation)] = 0.\n",
        "            #perturbation[torch.isinf(perturbation)] = 1.\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Feasible projection\n",
        "    #x_next = or_float_tensors(x_next, x)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), y.view(-1).long()).data\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        outputs = model(x_next)\n",
        "        _, predicted = torch.topk(outputs, k=1)\n",
        "        done = (predicted != y).squeeze()\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv < loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    return x_next"
      ],
      "metadata": {
        "id": "ljfazeC6MOcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_min2(x, y, model, insertion_array, removal_array, k=25, step_length=0.02, norm='linf', initial_rounding_threshold=0.5, round_threshold=0.5, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack (loss based on goal's class, which we have to minimize the loss).\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), torch.zeros_like(y.view(-1).long()))\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    loss_steps_i = []\n",
        "    loss_steps_d = []\n",
        "\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        y_model = model(x_var)\n",
        "        loss = criterion(y_model, torch.zeros_like(y.view(-1).long()))\n",
        "        #print(loss)\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "        loss_steps_i.append(criterion(y_model, y.view(-1).long()).mean().detach().item())\n",
        "        loss_steps_d.append(loss.mean().detach().item())\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        grad4insertion = (gradients >= 0) *(x_var < 1.)* insertion_array_updated * gradients\n",
        "        grad4removal = (gradients < 0) * (x_var > 0.) * removal_array_updated * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #print(torch.abs(gradients).sum())\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'free':\n",
        "            perturbation = gradients\n",
        "\n",
        "        elif norm == 'max':\n",
        "            max_values, _ = torch.max(torch.abs(gradients), dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (max_values+ 1e-20))\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), torch.zeros_like(y.view(-1).long())).data\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    diff = torch.abs(x_next - x).sum(dim=-1)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        done = get_done(x_next, y, model)\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "        print('mean of differnce featres',torch.mean(diff))\n",
        "\n",
        "    return x_next\n"
      ],
      "metadata": {
        "id": "ZTSII1-50VHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss(x,y,model):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y.view(-1).long())\n",
        "    _, predicted = torch.topk(outputs, k=1)\n",
        "    done = (predicted != y).squeeze()\n",
        "\n",
        "    return loss, done\n",
        "\n",
        "def PGD_Max2(x,y, model, insertion_array, removal_array, attack_list = ['linf', 'l2', 'l1'],steps_max=5, is_sample = False, varepsilon = 1e-20, is_report_loss_diff = False):\n",
        "    \"\"\"\n",
        "    PGD_Max adversarial attack.\n",
        "\n",
        "    Args:\n",
        "        x: Input data tensor (shape: [samples, features])\n",
        "        y: Ground truth labels tensor (shape: [samples])\n",
        "        model: Neural network model\n",
        "        attack_list: List of norms for attacks (default: ['linf', 'l2', 'l1'])\n",
        "        steps_max: Maximum number of steps (default: 5)\n",
        "        is_sample: Flag to sample randomly from the feasible area (default: False)\n",
        "        vaρεpsilon: Tolerance for stopping condition (default: 1e-20)\n",
        "\n",
        "    Returns:\n",
        "        Adversarial version of input data (tensor)\n",
        "    \"\"\"\n",
        "    batch_size = x.shape[0]\n",
        "    norm_params = {\n",
        "        'l1': {'k': 50, 'step_length': 1.0, 'is_report_loss_diff':is_report_loss_diff},\n",
        "        'l2': {'k': 50, 'step_length': 0.5, 'is_report_loss_diff':is_report_loss_diff},\n",
        "        'linf': {'k': 50, 'step_length': 0.02, 'is_report_loss_diff':is_report_loss_diff}\n",
        "    }\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        loss, done = get_loss(x,y,model) #shape:[samples],[samples]\n",
        "\n",
        "    pre_loss = loss\n",
        "    n = x.shape[0]\n",
        "    adv_x = x.detach().clone().to(x.device)\n",
        "    stop_flag = torch.zeros(n, dtype=torch.bool).to(x.device) #[samples]\n",
        "\n",
        "    for t in range(steps_max):\n",
        "      num_remaining  = (~stop_flag).sum().item()\n",
        "      #print('number of remaining samples : ',num_remaining )\n",
        "      if num_remaining  <= 0:\n",
        "          break\n",
        "\n",
        "      remaining_label = y[~stop_flag]\n",
        "      pertbx = []\n",
        "\n",
        "      for norm in attack_list:\n",
        "          if norm in norm_params:\n",
        "              params = norm_params[norm]\n",
        "              perturbation = pgd_min2(adv_x[~stop_flag], remaining_label, model, insertion_array, removal_array, norm=norm, is_sample=is_sample, **params)\n",
        "              #print(\"the number of added features : \", (perturbation.sum() - adv_x[~stop_flag].sum())/len(adv_x[~stop_flag]))\n",
        "              pertbx.append(perturbation)\n",
        "          else:\n",
        "              raise ValueError(\"Expected 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "\n",
        "      # here pertbx.shape = a list of (number of attacks  ,(num_remaining ,features))\n",
        "      pertbx = torch.vstack(pertbx)\n",
        "      # here pertbx.shape = a tensor (num_remaining *number of attacks samples, features)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        remaining_label_ext = torch.cat([remaining_label] * len(attack_list)) #(labels*number of attacks )\n",
        "        loss, done = get_loss(pertbx, remaining_label_ext,model) #(labels*number of attacks )\n",
        "\n",
        "        # for a sample, if there is at least one successful attack, we will select the one with maximum loss;\n",
        "        # while if no attacks evade the victim successful, all perturbed examples are reminded for selection\n",
        "        max_v = loss.amax()\n",
        "        loss[done] += max_v\n",
        "\n",
        "        loss = loss.reshape(len(attack_list), num_remaining ).permute(1, 0) #(num_remaining ,number of attacks)\n",
        "        done = done.reshape(len(attack_list), num_remaining ).permute(1, 0) #(num_remaining ,number of attacks)\n",
        "\n",
        "        success_flag = torch.any(done, dim=-1) #(num_remaining )\n",
        "\n",
        "        pertbx = pertbx.reshape(len(attack_list), num_remaining , x.shape[1]).permute([1, 0, 2])#(num_remaining ,attacks,features)\n",
        "        _, indices = loss.max(dim=-1) # ans:(samples), max loss among attacks which worked, and max loss among all attacks for sample , none of them worked\n",
        "        adv_x[~stop_flag] = pertbx[torch.arange(num_remaining ), indices]\n",
        "        a_loss = loss[torch.arange(num_remaining ), indices]\n",
        "        pre_stop_flag = stop_flag.clone()\n",
        "        stop_flag[~stop_flag] = (torch.abs(pre_loss[~stop_flag] - a_loss) < varepsilon) | success_flag\n",
        "        pre_loss[~pre_stop_flag] = a_loss\n",
        "\n",
        "    return adv_x"
      ],
      "metadata": {
        "id": "xC7ui_bLbHXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##pgd2\n",
        "adv_x = PGD_Max2(mals.to(torch.float32).to(device),mals_y.to(device), model_AT_rFGSM, insertion_array, removal_array, attack_list = ['linf', 'l2', 'l1'],steps_max=5, is_sample = False, varepsilon = 1e-20, is_report_loss_diff = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvuGOwt0C_HQ",
        "outputId": "64306695-fc61-45aa-d121-7941493eede6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 73.333%.\n",
            "PGD l2: Attack effectiveness 40.000%.\n",
            "PGD l1: Attack effectiveness 73.333%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##pgd2\n",
        "loss, done = get_loss(adv_x.to(torch.float32).to(device),mals_y.to(device), model_AT_rFGSM)\n",
        "print(done.sum()/len(done))\n",
        "print(torch.abs(adv_x - mals.to(device)).sum(dim=-1).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK-BvUihDbbS",
        "outputId": "cabaa520-9403-451a-9056-7fdec07529cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7333, device='cuda:0')\n",
            "tensor(11.0667, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pgd_min2\n",
        "adv_x = PGD_Max2(mals.to(torch.float32).to(device),mals_y.to(device), model_AT_rFGSM, insertion_array, removal_array, attack_list = ['linf', 'l2', 'l1'],steps_max=5, is_sample = False, varepsilon = 1e-20, is_report_loss_diff = True)"
      ],
      "metadata": {
        "outputId": "ad6053ed-c82d-4fc0-b3af-d764f429a325",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYrVWxYIEslt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD linf: Attack effectiveness 66.667%.\n",
            "mean of differnce featres tensor(25.2000, device='cuda:0')\n",
            "PGD l2: Attack effectiveness 73.333%.\n",
            "mean of differnce featres tensor(25.6667, device='cuda:0')\n",
            "PGD l1: Attack effectiveness 73.333%.\n",
            "mean of differnce featres tensor(17.3333, device='cuda:0')\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "mean of differnce featres tensor(10.2500, device='cuda:0')\n",
            "PGD l2: Attack effectiveness 0.000%.\n",
            "mean of differnce featres tensor(6.2500, device='cuda:0')\n",
            "PGD l1: Attack effectiveness 0.000%.\n",
            "mean of differnce featres tensor(12.5000, device='cuda:0')\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "mean of differnce featres tensor(4.5000, device='cuda:0')\n",
            "PGD l2: Attack effectiveness 0.000%.\n",
            "mean of differnce featres tensor(4.5000, device='cuda:0')\n",
            "PGD l1: Attack effectiveness 0.000%.\n",
            "mean of differnce featres tensor(0., device='cuda:0')\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "mean of differnce featres tensor(1.7500, device='cuda:0')\n",
            "PGD l2: Attack effectiveness 25.000%.\n",
            "mean of differnce featres tensor(2.5000, device='cuda:0')\n",
            "PGD l1: Attack effectiveness 0.000%.\n",
            "mean of differnce featres tensor(0., device='cuda:0')\n",
            "PGD linf: Attack effectiveness 0.000%.\n",
            "mean of differnce featres tensor(2.5000, device='cuda:0')\n",
            "PGD l2: Attack effectiveness 0.000%.\n",
            "mean of differnce featres tensor(0., device='cuda:0')\n",
            "PGD l1: Attack effectiveness 0.000%.\n",
            "mean of differnce featres tensor(0., device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##pgd_min2\n",
        "loss, done = get_loss(adv_x.to(torch.float32).to(device),mals_y.to(device), model_AT_rFGSM)\n",
        "print(done.sum()/len(done))\n",
        "print(torch.abs(adv_x - mals).sum(dim=-1).mean())"
      ],
      "metadata": {
        "outputId": "55b70c91-e1c6-43a5-8a3e-dbf4b69a9cc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPWW874hEslu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8000)\n",
            "tensor(30.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UqSErykJHw36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_AT_max.parameters(), lr=0.001, weight_decay=0)\n",
        "\n",
        "total_time = 0.\n",
        "nbatches = len(train_loader)\n",
        "best_acc_val = 0.\n",
        "acc_val_adv_be = 0.\n",
        "best_epoch = 0\n",
        "\n",
        "for epoch in range(50):\n",
        "    epoch_losses = []\n",
        "    epoch_accuracies = []\n",
        "\n",
        "    for idx_batch, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        x_batch, y_batch = x_batch.to(torch.float32).to(device), y_batch.to(device)\n",
        "        batch_size = x_batch.shape[0]\n",
        "\n",
        "        # Separate malicious and benign samples\n",
        "        mal_x_batch, ben_x_batch = x_batch[y_batch.squeeze() == 1], x_batch[y_batch.squeeze() == 0]\n",
        "        mal_y_batch, ben_y_batch = y_batch[y_batch.squeeze() == 1], y_batch[y_batch.squeeze() == 0]\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        model_AT_max.eval()\n",
        "        pertb_mal_x = PGD_Max2(mal_x_batch, mal_y_batch, model_AT_max, insertion_array, removal_array, attack_list = ['linf', 'l2', 'l1'],steps_max=5, is_sample = False, varepsilon = 1e-20, is_report_loss_diff = False)\n",
        "        #pertb_mal_x = PGD_Max2(mal_x_batch, mal_y_batch, model_AT_max, **kwargs)\n",
        "        pertb_mal_x = round_x(pertb_mal_x, round_threshold=0.5)\n",
        "        x_batch = torch.cat([x_batch, pertb_mal_x], dim=0)\n",
        "        y_batch = torch.cat([y_batch, mal_y_batch])\n",
        "        model_AT_max.train()\n",
        "\n",
        "        # Forward pass and backward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_AT_max(x_batch)\n",
        "        # loss of normal samples\n",
        "        loss_train = criterion(outputs[:batch_size], y_batch[:batch_size].view(-1).long())\n",
        "        #loss of adversarial examples\n",
        "        loss_train += 0.01 * criterion(outputs[batch_size:], y_batch[batch_size:].view(-1).long())\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate metrics\n",
        "        epoch_losses.append(loss_train.item())\n",
        "        predicted = outputs.argmax(1).unsqueeze(1)\n",
        "        acc_train = (predicted == y_batch).sum().item() / len(y_batch)\n",
        "        epoch_accuracies.append(acc_train)\n",
        "        break\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL6DhhPOMlcl",
        "outputId": "7e2f6230-e897-4b5c-a60a-4a643029614d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.24067504703998566\n",
            "0.25714361667633057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adversarial_training(model, train_loader, val_loader, attack, adv_epochs=50, lr=0.001, weight_decay=0., beta=0.01, device=device, verbose=True, **kwargs):\n",
        "    # beta: Float, penalty factor for adversarial loss\n",
        "    # Assuming positive class (malware) is label 1\n",
        "    #class_weights = torch.tensor([0.11, 0.89]).to(device)  # Adjust the weights based on the class distribution, higher weight for positive class\n",
        "\n",
        "    # Define Loss Function and Optimizer\n",
        "    #criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    total_time = 0.\n",
        "    nbatches = len(train_loader)\n",
        "    best_acc_val = 0.\n",
        "    acc_val_adv_be = 0.\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(adv_epochs):\n",
        "        epoch_losses = []\n",
        "        epoch_accuracies = []\n",
        "\n",
        "        for idx_batch, (x_batch, y_batch) in enumerate(train_loader):\n",
        "            x_batch, y_batch = x_batch.to(torch.float32).to(device), y_batch.to(device)\n",
        "            batch_size = x_batch.shape[0]\n",
        "\n",
        "            # Separate malicious and benign samples\n",
        "            mal_x_batch, ben_x_batch = x_batch[y_batch.squeeze() == 1], x_batch[y_batch.squeeze() == 0]\n",
        "            mal_y_batch, ben_y_batch = y_batch[y_batch.squeeze() == 1], y_batch[y_batch.squeeze() == 0]\n",
        "\n",
        "            # Generate adversarial examples\n",
        "            model.eval()\n",
        "            pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "            pertb_mal_x = round_x(pertb_mal_x, round_threshold=0.5)\n",
        "            x_batch = torch.cat([x_batch, pertb_mal_x], dim=0)\n",
        "            y_batch = torch.cat([y_batch, mal_y_batch])\n",
        "            model.train()\n",
        "\n",
        "            # Forward pass and backward pass\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x_batch)\n",
        "            # loss of normal samples\n",
        "            loss_train = criterion(outputs[:batch_size], y_batch[:batch_size].view(-1).long())\n",
        "            #print(loss_train.item())\n",
        "            #loss of adversarial examples\n",
        "            if len(mal_y_batch) > 0:\n",
        "              loss_train += beta * criterion(outputs[batch_size:], y_batch[batch_size:].view(-1).long())\n",
        "            else:\n",
        "              print('no malware in this batch')\n",
        "            #print(loss_train.item())\n",
        "            loss_train.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate metrics\n",
        "            epoch_losses.append(loss_train.item())\n",
        "            predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            acc_train = (predicted == y_batch).sum().item() / len(y_batch)\n",
        "            epoch_accuracies.append(acc_train)\n",
        "\n",
        "            # Print batch level information\n",
        "            #if verbose:\n",
        "                #print(f'Mini batch: {idx_batch + 1}/{nbatches} | Epoch: {epoch + 1}/{adv_epochs} | Batch Loss: {loss_train.item():.4f} | Batch Accuracy: {acc_train * 100:.2f}%')\n",
        "\n",
        "        # Calculate epoch level metrics\n",
        "        mean_loss = np.mean(epoch_losses)\n",
        "        mean_accuracy = np.mean(epoch_accuracies) * 100\n",
        "\n",
        "        # Print epoch level information\n",
        "        if verbose:\n",
        "            print(f'Epoch: {epoch+1}/{adv_epochs} | Training loss (epoch level): {mean_loss:.4f} | Train accuracy: {mean_accuracy:.2f}%')\n",
        "\n",
        "        # Evaluation on validation set\n",
        "        model.eval()\n",
        "        cor_val = 0\n",
        "        cor_ad_val = 0\n",
        "        n_samples = 0\n",
        "        n_ad_samples = 0\n",
        "        for x_val, y_val in val_loader:\n",
        "            x_val, y_val = x_val.to(torch.float32).to(device), y_val.to(device)\n",
        "            n_samples += len(x_val)\n",
        "            outputs = model(x_val)\n",
        "            predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            cor_val += (predicted == y_val).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for validation set\n",
        "            mal_x_batch, mal_y_batch = x_val[y_val.squeeze() == 1], y_val[y_val.squeeze() == 1]\n",
        "            n_ad_samples += len(mal_x_batch)\n",
        "            pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_val += (y_pred == 1.).sum().item()\n",
        "\n",
        "        # Calculate validation accuracy\n",
        "        assert n_ad_samples > 0\n",
        "        avg_acc_val = (cor_val / n_samples)\n",
        "        avg_acc_ad_val = (cor_ad_val / n_ad_samples)\n",
        "        acc_all = (avg_acc_val + avg_acc_ad_val) / 2.\n",
        "\n",
        "        # Update best validation accuracy\n",
        "        if acc_all >= best_acc_val:\n",
        "            best_acc_val = acc_all\n",
        "            acc_val_adv_be = avg_acc_ad_val\n",
        "            best_epoch = epoch + 1\n",
        "            torch.save(model.state_dict(), 'model_AT_max.pth')\n",
        "\n",
        "        # Print validation results\n",
        "        if verbose:\n",
        "            print(f\"\\tVal accuracy(without attack) {(avg_acc_val) * 100:.4}% and accuracy(with attack) {(avg_acc_ad_val) * 100:.4}% under attack and overall accuracy {acc_all * 100:.4}%.\")\n",
        "            print(f\"\\tModel select at epoch {best_epoch} with validation accuracy {best_acc_val * 100:.4}% and accuracy {acc_val_adv_be * 100:.4}% under attack.\")\n"
      ],
      "metadata": {
        "id": "B0v7V8W7lidM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pgd2\n",
        "#model_AT_max = MalwareDetectionModel().to(device)\n",
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'attack_list':['linf', 'l2', 'l1'],'steps_max': 5, 'is_report_loss_diff' : False}\n",
        "adversarial_training(model_AT_max, train_loader, val_loader, PGD_Max2, adv_epochs=10, lr=0.001, weight_decay=0., beta=0.005, device=device, verbose=True, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZzRzUFHrZjY",
        "outputId": "1c7712e9-58c4-4a77-dc6b-4ec3b3d7c7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10 | Training loss (epoch level): 0.0093 | Train accuracy: 96.82%\n",
            "\tVal accuracy(without attack) 98.89% and accuracy(with attack) 67.77% under attack and overall accuracy 83.33%.\n",
            "\tModel select at epoch 1 with validation accuracy 83.33% and accuracy 67.77% under attack.\n",
            "Epoch: 2/10 | Training loss (epoch level): 0.0092 | Train accuracy: 96.78%\n",
            "\tVal accuracy(without attack) 99.02% and accuracy(with attack) 66.94% under attack and overall accuracy 82.98%.\n",
            "\tModel select at epoch 1 with validation accuracy 83.33% and accuracy 67.77% under attack.\n",
            "Epoch: 3/10 | Training loss (epoch level): 0.0091 | Train accuracy: 96.83%\n",
            "\tVal accuracy(without attack) 98.9% and accuracy(with attack) 67.77% under attack and overall accuracy 83.34%.\n",
            "\tModel select at epoch 3 with validation accuracy 83.34% and accuracy 67.77% under attack.\n",
            "Epoch: 4/10 | Training loss (epoch level): 0.0113 | Train accuracy: 95.94%\n",
            "\tVal accuracy(without attack) 98.93% and accuracy(with attack) 63.34% under attack and overall accuracy 81.14%.\n",
            "\tModel select at epoch 3 with validation accuracy 83.34% and accuracy 67.77% under attack.\n",
            "Epoch: 5/10 | Training loss (epoch level): 0.0080 | Train accuracy: 97.00%\n",
            "\tVal accuracy(without attack) 98.92% and accuracy(with attack) 68.33% under attack and overall accuracy 83.63%.\n",
            "\tModel select at epoch 5 with validation accuracy 83.63% and accuracy 68.33% under attack.\n",
            "Epoch: 6/10 | Training loss (epoch level): 0.0075 | Train accuracy: 97.20%\n",
            "\tVal accuracy(without attack) 98.79% and accuracy(with attack) 68.79% under attack and overall accuracy 83.79%.\n",
            "\tModel select at epoch 6 with validation accuracy 83.79% and accuracy 68.79% under attack.\n",
            "no malware in this batch\n",
            "Epoch: 7/10 | Training loss (epoch level): 0.0072 | Train accuracy: 97.22%\n",
            "\tVal accuracy(without attack) 98.79% and accuracy(with attack) 69.9% under attack and overall accuracy 84.34%.\n",
            "\tModel select at epoch 7 with validation accuracy 84.34% and accuracy 69.9% under attack.\n",
            "Epoch: 8/10 | Training loss (epoch level): 0.0071 | Train accuracy: 97.36%\n",
            "\tVal accuracy(without attack) 98.66% and accuracy(with attack) 70.73% under attack and overall accuracy 84.7%.\n",
            "\tModel select at epoch 8 with validation accuracy 84.7% and accuracy 70.73% under attack.\n",
            "Epoch: 9/10 | Training loss (epoch level): 0.0079 | Train accuracy: 97.05%\n",
            "\tVal accuracy(without attack) 98.77% and accuracy(with attack) 62.88% under attack and overall accuracy 80.82%.\n",
            "\tModel select at epoch 8 with validation accuracy 84.7% and accuracy 70.73% under attack.\n",
            "no malware in this batch\n",
            "Epoch: 10/10 | Training loss (epoch level): 0.0081 | Train accuracy: 97.11%\n",
            "\tVal accuracy(without attack) 98.91% and accuracy(with attack) 66.2% under attack and overall accuracy 82.56%.\n",
            "\tModel select at epoch 8 with validation accuracy 84.7% and accuracy 70.73% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rplgNNTUdmtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of your model\n",
        "model_AT_imax = MalwareDetectionModel().to(device)\n",
        "\n",
        "# Load model parameters\n",
        "model_AT_imax.load_state_dict(torch.load('/content/model_AT_imax.pth', map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91016473-633e-4cf6-a325-8d8e953832b0",
        "id": "CFGlvHbLdxYl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(model_AT_imax, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b56c2a8d-49b8-49b9-d59d-e30a7ac00317",
        "id": "6nLCA9uHdxYl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9873\n",
            "Test balanced Accuracy: 0.9740\n",
            "Precision: 0.9376\n",
            "Recall: 0.9566\n",
            "F1-score: 0.9470\n",
            "True Positives (TP): 1081\n",
            "True Negatives (TN): 8360\n",
            "False Positives (FP): 72\n",
            "False Negatives (FN): 49\n",
            "False Negative Rate (FNR): 4.3363\n",
            "False Positive Rate (FPR): 0.8539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    model.eval()\n",
        "    n_samples = 0\n",
        "    cor_test = 0\n",
        "    cor_ad_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            #outputs = model(x_test)\n",
        "            #predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            #acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            #avg_acc_test.append(acc_test)\n",
        "\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "            n_samples += len(mal_y_batch)\n",
        "\n",
        "            outputs = model(mal_x_batch)\n",
        "            predicted = outputs.argmax(1)\n",
        "            cor_test += (predicted == 1).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            with torch.enable_grad():\n",
        "                pertb_mal_x= attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_test += (y_pred == 1).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Accuracy of just malwares (without attack): {(cor_test / n_samples) * 100:.4}% | Under attack: {(cor_ad_test / n_samples) * 100:.4}%.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "0pX6XVMolG7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pgd2\n",
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'attack_list':['linf', 'l2', 'l1'],'steps_max': 5, 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_imax, PGD_Max2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RML6qkVd-aR",
        "outputId": "8f713217-d533-453f-c5f1-ba8b96dd47de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 95.66% | Under attack: 70.35%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pgd_min2\n",
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'attack_list':['linf', 'l2', 'l1'],'steps_max': 5, 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_imax, PGD_Max2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw8TcGRBekwd",
        "outputId": "facfaf5c-9721-4c35-a643-0612ebbbd855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 95.66% | Under attack: 70.18%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 250, 'step_length': 0.02, 'norm': 'linf', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_imax, pgd_min2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbvcSItGe5ro",
        "outputId": "61351979-8067-4953-b396-115adab414b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 95.66% | Under attack: 71.95%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 250, 'step_length': 0.5, 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_imax, pgd_min2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjJcLMDyfK5S",
        "outputId": "e68109bd-4974-4d72-80db-f09427125c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 95.66% | Under attack: 70.8%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'insertion_array':insertion_array, 'removal_array':removal_array,'k': 250, 'step_length': 1., 'norm': 'l2', 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_imax, pgd_min2, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvVOIoMrfWRD",
        "outputId": "fcde0cf3-18f3-47ce-f4a4-46435a5de0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 95.66% | Under attack: 70.0%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzrKz6Eof_9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_predict(test_loader, model, attack, device, **kwargs):\n",
        "\n",
        "    if (attack ==  gkde) or (attack ==  mimicry):\n",
        "      # Pre-select benign samples\n",
        "      benign_samples = []\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "      ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "      # Select the top 500 high confidence benign samples\n",
        "      top_500_high_confidence_benign_samples = ben_x[:500]\n",
        "\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    n_samples = 0\n",
        "    cor_test = 0\n",
        "    cor_ad_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(torch.float32).to(device), y_test.to(device)\n",
        "            #outputs = model(x_test)\n",
        "            #predicted = outputs.argmax(1).unsqueeze(1)\n",
        "            #acc_test = (predicted == y_test).sum().item() / len(y_test)\n",
        "            #avg_acc_test.append(acc_test)\n",
        "\n",
        "            mal_x_batch, mal_y_batch = x_test[y_test.squeeze() == 1], y_test[y_test.squeeze() == 1]\n",
        "            n_samples += len(mal_y_batch)\n",
        "\n",
        "            outputs = model(mal_x_batch)\n",
        "            predicted = outputs.argmax(1)\n",
        "            cor_test += (predicted == 1).sum().item()\n",
        "\n",
        "            # Generate adversarial examples for test set\n",
        "            if attack == mimicry:\n",
        "                pertb_mal_x = mimicry(top_500_high_confidence_benign_samples, mal_x_batch, model, **kwargs)\n",
        "            elif attack == gkde:\n",
        "                with torch.enable_grad():\n",
        "                  pertb_mal_x = gkde(mal_x_batch, mal_y_batch, model, top_500_high_confidence_benign_samples, **kwargs)\n",
        "            else :\n",
        "                with torch.enable_grad():\n",
        "                    pertb_mal_x = attack(mal_x_batch, mal_y_batch, model, **kwargs)\n",
        "\n",
        "            outputs = model(pertb_mal_x)\n",
        "            y_pred = outputs.argmax(1)\n",
        "            cor_ad_test += (y_pred == 1).sum().item()\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    print(f\"Accuracy of just malwares (without attack): {(cor_test / n_samples) * 100:.4}% | Under attack: {(cor_ad_test / n_samples) * 100:.4}%.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "B2S5U28YIGzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'removal_array':removal_array, \"trials\":10, 'is_report_loss_diff':False}\n",
        "adv_predict(test_loader, model_AT_imax, mimicry, device, **attack_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fKZs5sQgS0X",
        "outputId": "89b3b1c2-7019-4e0c-994e-3281225972e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 95.66% | Under attack: 69.56%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEWenkSugp01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SYFzsccghMUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def KDE(x, data, bandwidth, dissimilarity='euclidean', kernel='gaussian'):\n",
        "    \"\"\"\n",
        "    Compute the kernel density estimate (KDE) for given data points.\n",
        "\n",
        "    Parameters:\n",
        "        x (torch.Tensor): Points at which to evaluate the KDE (shape: [num_samples, num_dimensions]).\n",
        "        data (torch.Tensor): Data points used to estimate the density (shape: [num_data_points, num_dimensions]).\n",
        "        bandwidth (float): Bandwidth parameter for the KDE.\n",
        "        dissimilarity (str): The type of dissimilarity to use ('cosine' or 'euclidean').\n",
        "        kernel (str): The type of kernel to use ('gaussian' is supported).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Density estimate at each point in x (shape: [num_samples,]).\n",
        "    \"\"\"\n",
        "    # Convert bandwidth to tensor\n",
        "    bandwidth_tensor = torch.tensor(bandwidth)\n",
        "\n",
        "    # Calculate dissimilarity for all data points\n",
        "    if dissimilarity == 'cosine':\n",
        "        u = cosine_dissimilarity(x, data)\n",
        "    elif dissimilarity == 'euclidean':\n",
        "        u = torch.abs(x[:, None, :] - data)\n",
        "\n",
        "    # Compute kernel contributions for all data points\n",
        "    if kernel == 'gaussian':\n",
        "        if dissimilarity == 'cosine':\n",
        "            kernel_contributions = torch.exp(-u**2 / bandwidth_tensor**2)\n",
        "        elif dissimilarity == 'euclidean':\n",
        "            kernel_contributions = torch.exp(-torch.sum(u**2, dim=-1) / bandwidth_tensor**2)\n",
        "    else:\n",
        "        if dissimilarity == 'cosine':\n",
        "            kernel_contributions = torch.exp(-u / bandwidth_tensor)\n",
        "        elif dissimilarity == 'euclidean':\n",
        "            kernel_contributions = torch.exp(-torch.sum(u, dim=-1) / bandwidth_tensor)\n",
        "\n",
        "    # Sum contributions across all data points\n",
        "    estimate = torch.mean(kernel_contributions, dim=1)\n",
        "\n",
        "    return estimate"
      ],
      "metadata": {
        "id": "Vwegmc-G-OVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_min2_kde_log(x, y, model,centers, bandwidth, dissimilarity, penalty_factor, kernel, insertion_array, removal_array, k=25, step_length=0.02, norm='linf',\n",
        "                 initial_rounding_threshold=0.5, round_threshold=0.5, decaying_penalty=False, random=False, is_report_loss_diff=True, is_sample=False):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) adversarial attack (loss based on goal's class, which we have to minimize the loss).\n",
        "    :param y: Ground truth labels\n",
        "    :param x: Feature vector\n",
        "    :param model: Neural network model\n",
        "    :param k: Number of steps\n",
        "    :param step_length: Step size for each iteration\n",
        "    :param norm: Norm used for perturbation ('linf' or 'l2')\n",
        "    :param initial_rounding_threshold: Threshold parameter for rounding the initial x_next\n",
        "    :param round_threshold: Threshold parameter for rounding\n",
        "    :param random: Flag to generate random thresholds\n",
        "    :param is_report_loss_diff: Flag to report loss difference\n",
        "    :param is_sample: Flag to sample randomly from the feasible area\n",
        "    :return: The adversarial version of x (tensor)\n",
        "    \"\"\"\n",
        "    eps = 1e-10\n",
        "    model.eval()\n",
        "\n",
        "    # Compute natural loss\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    loss_natural = criterion(model(x), torch.zeros_like(y.view(-1).long())) +  penalty_factor * KDE(x, centers, bandwidth, dissimilarity,kernel)\n",
        "\n",
        "    # Initialize starting point\n",
        "    x_next = x.clone()\n",
        "    x_next = get_x0(x_next, initial_rounding_threshold, is_sample)\n",
        "\n",
        "\n",
        "    # Expand insertion_array and removal_array to match the batch size\n",
        "    expanded_insertion_array = insertion_array.expand(x.shape[0], -1)\n",
        "    expanded_removal_array = removal_array.expand(x.shape[0], -1)\n",
        "\n",
        "    # Update insertion and removal arrays based on input x\n",
        "    insertion_array_updated = torch.bitwise_or(expanded_insertion_array, x.to(torch.uint8))\n",
        "    removal_array_updated = torch.bitwise_or(expanded_removal_array, 1 - x.to(torch.uint8))\n",
        "\n",
        "    loss_steps_d = []\n",
        "    # Multi-step PGD\n",
        "    for t in range(k):\n",
        "        #print('*********** ',t)\n",
        "        # Forward pass\n",
        "        x_var = x_next.clone().detach().requires_grad_(True)\n",
        "        ce = criterion(model(x_var), torch.zeros_like(y.view(-1).long()))\n",
        "        k = KDE(x_var, centers, bandwidth, dissimilarity,kernel)\n",
        "        kde = -torch.log(k + eps)\n",
        "\n",
        "        if decaying_penalty == True:\n",
        "            loss = ce + (1./(1.2)**t) * penalty_factor * kde\n",
        "        else:\n",
        "            loss = ce +  penalty_factor * kde\n",
        "\n",
        "\n",
        "\n",
        "        #loss_steps.append(loss.mean().detach().item())\n",
        "        loss_steps_d.append(criterion(model(x_var), y.view(-1).long()).mean().detach().item())\n",
        "        #print(loss)\n",
        "        #print('loss_mal : ',criterion(y_model, torch.zeros_like(y.view(-1).long())))\n",
        "\n",
        "        # Compute gradient\n",
        "        grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "        gradients = -(grad_vars[0].data)\n",
        "        #print('torch.abs(gradients).sum() : ',torch.abs(gradients).sum(dim=-1))\n",
        "\n",
        "        grad4insertion = (gradients >= 0) *(x_var < 1.)* insertion_array_updated * gradients\n",
        "        grad4removal = (gradients < 0) * (x_var > 0.) * removal_array_updated * gradients\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "        #print(torch.abs(gradients).sum())\n",
        "\n",
        "        # Norm\n",
        "        if norm == 'linf':\n",
        "            perturbation = torch.sign(gradients).float()\n",
        "\n",
        "        elif norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = (gradients / (l2norm + 1e-20)).float()\n",
        "\n",
        "        elif norm == 'l1':\n",
        "            # consider just features of a sample which are not updated yet(because our update is 0to1 or 1to0 not stepwise)\n",
        "            un_mod = torch.abs(x - x_var) <= 1e-6\n",
        "            gradients = gradients * un_mod\n",
        "            max_grad = torch.topk(torch.abs(gradients).view(gradients.size(0), -1), 1, dim=-1)[0]\n",
        "            #print('max_grad ',max_grad)\n",
        "            perturbation = (torch.abs(gradients) >= max_grad).float() * torch.sign(gradients).float()\n",
        "            done = get_done(x_next, y, model)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            perturbation[done] = 0.\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l1' or 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # Update x_next\n",
        "        x_next = torch.clamp(x_next + perturbation * step_length, min=0., max=1.)\n",
        "\n",
        "    # Rounding step\n",
        "    if random:\n",
        "       round_threshold = torch.rand(x_next.size())\n",
        "    x_next = round_x(x_next, round_threshold=round_threshold)\n",
        "\n",
        "    # Compute adversarial loss\n",
        "    loss_adv = criterion(model(x_next), torch.zeros_like(y.view(-1).long())).data\n",
        "\n",
        "    # Replace with natural if adversarial loss is higher\n",
        "    replace_flag = (loss_adv > loss_natural).squeeze()\n",
        "    #x_next[replace_flag] = x[replace_flag]\n",
        "\n",
        "    diff = torch.abs(x_next - x).sum(dim=-1)\n",
        "\n",
        "    if is_report_loss_diff:\n",
        "        done = get_done(x_next, y, model)\n",
        "        print(f\"PGD {norm}: Attack effectiveness {done.sum().item() / x.size()[0] * 100:.3f}%.\")\n",
        "        print('mean of differnce featres',torch.mean(diff))\n",
        "\n",
        "    return x_next\n"
      ],
      "metadata": {
        "id": "MY_DS_RMHW1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-select benign samples\n",
        "benign_samples = []\n",
        "for x_batch, y_batch in test_loader:\n",
        "  benign_samples.append(x_batch[y_batch.squeeze() == 0])\n",
        "\n",
        "ben_x = torch.cat(benign_samples, dim=0).to(device)\n",
        "\n",
        "# Select the top 500 high confidence benign samples\n",
        "centers = ben_x[:500]"
      ],
      "metadata": {
        "id": "YHc2-xehhc9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_params =  {'centers':centers,'bandwidth': 1,'dissimilarity':'euclidean','penalty_factor': 1,'kernel':'laplac','insertion_array':insertion_array, 'removal_array':removal_array,'k': 100, 'step_length': 0.5, 'norm': 'l2', 'decaying_penalty':False, 'is_report_loss_diff' : False}\n",
        "adv_predict(test_loader, model_AT_imax, pgd_min2_kde_log, device, **attack_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sCCvXU9gtPZ",
        "outputId": "a4f53e87-2966-40a3-f9bd-4c9554403267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of just malwares (without attack): 95.66% | Under attack: 81.86%.\n"
          ]
        }
      ]
    }
  ]
}